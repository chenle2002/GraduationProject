本发明公开了一种产品表面异常检测方法及终端，采集待检测产品表面的最终异常图像，去除多模态预训练模型中的图像解码器和文本解码器，并将特征映射模型加入多模态预训练模型，得到改进后的多模态预训练模型，利用最终异常图像对改进后的多模态预训练模型进行训练，得到异常检测模型，利用异常检测模型对待检测产品表面进行检测，在模型中引入了特征映射模块并去除多余部分，使得原始的多模态预训练模型可以用于产品表面的异常检测，仅需要少量异常样本的训练，能提高仿真异常图像训练的效果，且具有零样本迁移能力，在一个场景下训练好的模型可迁移到结构相同、表面纹理、图案或颜色变化的其他场景下使用，提高了产品表面异常检测的适用性。用于检测产品即工业产品的表面异常以及各种材料的部分例如划痕、裂纹、污垢和变形的方法。该方法使得原始的多模态预训练模型能够用于产品表面的异常检测，需要少量的异常样本进行训练，提高了模拟异常图像训练的效果，具有零样本传递能力。 该方法将在一个场景中训练好的模型转移到其他具有相同结构、表面纹理、图案或颜色变化的场景中，提高了产品表面异常检测的适用性。该方法涉及采集待检测产品表面的最终异常图像。 所述最终异常图像包括在正常图像上绘制异常得到的模拟异常图像。 在多模态的预训练模型中去除图像解码器和文本解码器。 将所述特征映射模型添加到所述多模态预训练模型中。 得到改进后的多模态预训练模型。 利用最终异常图像对改进后的多模态预训练模型进行训练，得到异常检测模型。 采用所述异常检测模型对待检测产品的表面进行检测，得到检测结果。包括独立权利要求的产品表面异常检测终端。  11
本发明公开了一种基于Transformer结构的图像描述方法和装置，包括：采用swin Transformer基础编码器对原始图像信息进行编码，并提取图像特征向量；采用基于Transformer结构的特征增强编码器分别捕获图像初始特征VG和图像全局特征Vg模态内的隐含关系实现特征增强，得到图像增强特征和图像增强全局特征采用基于Transformer结构的解码器对文本信息、所述图像增强特征以及所述图像增强全局特征进行特征融合，生成对应的图像描述并输出。本发明实现了图像描述任务从两个阶段任务集成到一个阶段，模型结构统一且参数量更少，缩减了模型训练的时间成本和计算成本。一种基于结构的图像描述方法。本发明能够将图像描述任务从两级任务整合到一级，使得模型结构统一，数量较少，从而降低了模型训练的时间成本和计算成本。该方法包括使用SWIN基本编码器对原始图像信息进行编码。 提取图像特征向量，其中图像特征向量具有图像初始特征和图像全局特征。 在结构上利用特征增强编码器捕获图像全局特征VG模式下的图像初始特征和隐藏关系，实现特征增强。 在图像增强特征和图像增强全局特征之间执行特征融合以生成相应的图像描述。本发明还涉及一种基于结构的图像描述装置。   5
本发明公开了基于AIGC构建AI数智人的方法及系统，主要流程包括1)确定需求和目标、2)制作AI数智人、3)数据采集和预处理、4)特征工程和选择、5)模型选择和训练、6)系统开发和集成、7)部署和测试、8)持续改进和优化。本发明中开发的AI数智人可以收集和分析大量的客户数据、从业者数据和行业数据。通过对数据的深度分析和挖掘，可以提供洞察力和决策支持，帮助行业做出更科学、更准确的决策和改进措施，促进行业的发展和规范，AI数智人的应用可以帮助提升效率、提高服务水平和客户满意度，通过自动化和智能化的工具，可以减少人力资源的浪费和错误，提高整体运营效率，并降低服务成本。基于人工智能环球公司的人工智能数字智能人构建方法。该方法能够收集和分析大量客户数据、专业数据和行业数据，通过深入分析和挖掘数据提供洞察力和决策支持，帮助行业做出更科学、更准确的决策和改进措施，促进行业的发展和规范，应用人工智能的数字智能人能够帮助提高效率。 该方法能够提高服务水平和客户满意度，减少自动化、智能化工具对人力资源的浪费和错误，提高整体运营效率，降低服务成本。该方法涉及从不同角度拍摄人像照片。 AI算法用于重建真人的三维模型。 深度学习模型用于在对大量人物表情和动作进行训练的基础上生成通用表情库和动作库。 通过渲染引擎来渲染三维模型。 收集与所选择的服务行业相关的数据，包括客户数据、服务提供商数据和服务单元数据。 进行数据预处理。 根据系统的需求和目标对数据进行特征工程和特征选择。 提取并选择与驾驶训练任务相关的特征。 根据系统需求和数据特点选择合适的人工智能模型。 基于选择的人工智能模型进行系统开发和集成。本发明还公开了一种数字智能系统。 反馈数据是基于实际操作条件收集的。 对系统优化空间进行分析。 通过训练过程中的自回归模型，利用最大似然估计对模型参数进行优化。 1
本公开提出一种文本分类模型的训练方法及装置、文本分类方法及装置，其中，方法包括：获取训练文本，并采用文本分类模型中的编码网络对训练文本进行编码，以得到第一语义特征；获取噪声特征；将噪声特征和第一语义特征进行融合，以得到融合特征；基于第一语义特征和融合特征，对文本分类模型进行第一训练。由此，基于文本分类模型的编码网络捕捉到的训练文本的语义特征，以及融合了噪声的语义特征，可以实现对文本分类模型的预训练，可以使得文本分类模型在真实训练之前，有效学习到训练文本中显著的语义信息，从而在利用少量的训练文本对文本分类模型进行真实训练时，可以提升模型的表现和性能，有效减少模型对标注数据的依赖。训练文本分类模型的方法。基于文本分类模型的编码网络捕获的训练文本的语义特征和融合了噪声的语义特征可以实现文本分类模型的预训练，使得文本分类模型在进行真实训练之前可以有效地学习到训练文本中的显著语义信息，从而可以在利用少量的训练文本对文本分类模型进行真实训练时提高模型的性能，有效地降低了模型对标签数据的依赖性。该方法包括获得训练文本。 利用文本分类模型中的编码网络对所述训练文本进行编码，得到第一语义特征，所述第一语义特征包括所述训练文本中各词的语义向量。 获取所述噪声特征，所述噪声特征与所述第一语义特征的大小相匹配。 将所述噪声特征和所述第一语义特征进行融合，得到融合特征。 基于所述第一语义特征和所述融合特征对所述文本分类模型进行第一训练。 对所述训练文本进行分词处理，得到所述训练文本的词语。 获取分词对应的词向量。包括独立权利要求用于训练文本分类模型的装置。 3
本发明涉及智能问答技术领域，具体涉及基于大模型的企业内知识问答方法、装置、设备及介质，该方法包括：接收输入问题，判断输入问题是否存在于私域数据库内，其中，私域数据库存储有私域问题和对应的私域答案；若输入问题存在于私域数据库内，则根据输入问题在私域数据库匹配对应的私域答案并输出；若输入问题不存在于私域数据库内，则将输入问题输入到数据大模型，通过数据大模型获取并输出输入问题的答案。本发明将数据大模型和私域数据库结合，解决了公域模型无法知晓企业内部信息导致关于企业内部信息回答不够准确的缺陷，同时降低企业隐私机密泄露的风险。基于大模型的企业内知识问答方法。该方法结合大数据模型和私有域数据库，解决公有域模型无法获知企业内部信息，导致企业内部信息回答不准确的问题，同时降低企业隐私秘密泄露的风险。该方法涉及接收(S101)输入问题并确定输入问题是否存在于私有域数据库中。 私密域数据库用于存储私密域问题和对应的私密域答案。 如果所述输入问题存在于所述私密域数据库中，则根据所述输入问题匹配所述私密域数据库中对应的私密域答案(S102)并输出。 如果所述输入问题不存在于所述私有域数据库中，则将所述输入问题输入(S103)到所述大数据模型中，并通过所述大数据模型获得并输出所述输入问题的答案。独立权利要求包括以下内容：基于大模型的企业内知识问答装置； 计算机装置； 以及计算机可读存储介质，其存储有基于大模型的企业内知识问答程序。  11
本公开公开了一种图像分类元模型的训练方法、图像分类方法、装置和介质，涉及元学习领域。该训练方法包括：基于多个预训练模型，得到一批反演图像数据；从反演图像数据中抽取样本，构建多个第一伪任务，其中，每个第一伪任务包括伪支持集和伪查询集；以及利用伪支持集和伪查询集，对图像分类元模型进行训练。本公开能够解决无数据场景下的图像分类元模型训练问题，并且能够提高模型训练的性能。训练图像分类元模型的方法。该方法解决了非数据场景下图像分类元模型训练的问题，提高了模型训练的性能。该方法涉及基于多个预训练模型获得(110)一批反演图像数据。 从反转图像数据中提取样本(120)。 构建多个第一伪任务。 为每个第一伪任务提供伪支持集和伪查询集。 通过使用所述伪支持集和所述伪查询集来训练(130)所述图像分类元模型。 将噪声数据输入任意一个预训练模型，得到预测值。 根据每个噪声数据对应的预测值和标签值确定第一损失函数。 对每个所述噪声数据进行更新，生成一批以所述第一损失函数为目标的反演图像数据。以下包括独立权利要求：图像分类方法； 图像分类元模型的训练装置； 图像分类装置； 以及存储用于训练图像分类元模型的程序的非瞬态计算机可读存储介质。 14
本发明公开了一种水产动物疾病文本的实体语义关系抽取方法，包括：收集水产动物疾病文本，使用标注工具对文本数据标注，将标注完的数据集输入BERT模型，自动获取词语语义上的特征、并表示和抽取深层次语义，得到第二文本，将标签信息嵌入第二文本的词和标签的联合空间、并与每个字进行联合学习，输出第三文本，将第三文本输入Bilstm模型进行学习，获取长距离词的相关性和上下文信息，得到第四文本，将第四文本送入到Attention层，减少文本序列中关键信息的丢失，获得第五文本，将第五文本输入CRF层，得到水产动物疾病文本实体关系联合抽取的结果。该方法可有效地解决篇章级关系抽取中重叠关系抽取不准确的问题。一种提取水产动物与疾病文本的实体语义关系的方法。本发明能够在水产病害文本数据集上获得最优性能，有效提高水产病害文本关系提取的准确率，查全率和价值。该方法包括收集水产动物疾病文本。 通过使用标记工具来标记文本数据。 标记数据集被输入到来自变压器(BERT)模型的双向编码器表示中。 自动获取词语语义特征。 嵌入第二文本的标签。 标签信息被嵌入到单词和第二文本的标签的联合空间中。 组合学习的第三个文本被输入到用于学习的双向长期-短期记忆(BILSTM)模型中。 获得远程词的相关性和上下文信息。 关注处理有用信息集中在大量信息中。 在文本序列中减少关键信息的丢失以获得第五文本。 第五文本被输入到条件随机场(CRF)层以获得最终预测标记序列。 得到水生动物疾病文本实体语义关系的联合提取结果。本发明涉及一种利用网络爬行水产疾病网站上的数据的方法。自然铜 (RTM)：高级，通用编程语言)语句。  12
本申请公开了一种输电线路隐患检测方法，包括：获取卫星巡视拍摄到的待检测图；将待检测图输入地物分类模型，得到地物分类模型输出的分类结果图；根据分类结果图中各地物与输电线路间的距离，确定各地物中的线路隐患；其中，地物分类模型通过以下步骤得到：S1、预先对原始遥感图像中的不同地物进行标注，得到标注遥感图像；S2、以标注遥感图像以及对应的原始遥感图像建立训练集；S3、以训练集对U‑Net网络进行训练；S4、通过验证集对训练后得到的模型进行准确率检验，若准确率小于预设值，调节当前模型的参数，返回步骤S3；若准确率大于或等于预设值，输出地物分类模型；解决了现有检测方法不同的隐患类型需要设计不同的检测方法的技术问题。传输线故障检测方法。该方法包括通过卫星检查获得待发射检测图案。 在一幅原始遥感图像中预先标记不同的特征，得到一幅遥感图像。 利用所述遥感影像和对应的原始遥感影像建立训练集。 利用所述训练集训练U-Net网络。 通过验证集训练后进行准确性检验过程。 当准确率小于预设值时，调整当前模型的参数。 当准确率大于或等于预设值时，输出特征分类模型。 0
本发明公开了一种异构发电设备状态判断方法、装置、存储介质及设备，获取各个发电厂商提供的关于发电设备的测点信息的点表描述文档，输入到Transformer预训练模型，得到测点信息描述相似文本；对测点信息描述相似文本对应的数据类型和数据单位进行递进式匹配处理，得到各个发电厂商之间的共有测点集合和各个发电厂商的独有测点集合；若判定均为共有测点，则根据是否等价确定最终的逻辑表达式；若判定存在独有测点，则将该测点信息所对应的测点采用的状态判断逻辑表达式作为最终的逻辑表达式；确定异构发电设备状态。优点：保证运维工作的正常进行，保障风力发电机组的平稳运行，为风力发电机场的效益最大化提供技术支持。利用计算机装置判断异构发电装置状态的方法(权利要求书)。该方法保证了正常运维工作和风电机组的平稳运行，为风电场的最大效益提供了技术支撑。该方法涉及获取各发生厂家提供的发生装置测点信息的点表描述文件。 将点表描述文档输入到预训练模型。 得到测点信息是为了描述类似的文本。 得到各发电厂家之间的公共测点集和各发电工厂的唯一测点集。 根据发电厂商提供的状态判断逻辑表达式，判断各发电工厂的状态判断逻辑表达式是否等价。 根据最终逻辑表达式确定异构发电装置的状态。独立权利要求还包括用于：一种利用计算机设备判断异构发电设备状态的设备； 以及计算机可读存储介质，所述计算机可读存储介质包括用于通过使用计算机装置来判断异构发电装置的状态的指令集。 0
本发明公开了一种求职者胜任力的智能评测方法及系统，通过接收待评测求职者对应的第二面试文本数据；接收用户输入的个体评测指令；将所述第二面试文本数据与个体评测指令导入预先构建的神经网络模型；所述第二面试文本数据为待评测求职者回答所述问题库内七个评价维度问题所得到的数据；所述个体评测指令为所述七个评价维度中问题的至少一个，所述神经网络模型运行，输出所述待评测求职者的胜任力评价结果。本申请使用预训练和Transformer的自然语言处理技术，使得文本特征提取更有效，从而使得最终的胜任力评估更准确，以概率分布来表示胜任力模型的4个评价等级，减少了以往人工评价的主观性。求职者胜任力智能评价方法。文本特征提取更加有效，使得最终的胜利力量评估更加准确，概率分布代表了胜利力量模型的4个评估等级，降低了以往人工评估的主观性。该方法包括：接收对应于待评估的求职者的第二面试文本数据。 接收用户输入的个体评估指令。 将所述第二面试文本数据和个体评价指令导入预先构建的神经网络模型。 根据所述四维概率分布数据对下游任务的参数模型进行监督学习训练，得到训练后的神经网络模型。 所述第二面试文本数据被提供为所述待评估求职者回答所述题库中的七个评估维度问题所获得的数据以及所述个体评估指令被提供为所述七个评估维度中的问题。 运行所述神经网络模型，以输出所述待评估求职者的胜任力评估结果。独立权利要求包括：(1)求职者获奖权智能评估系统； (2)计算机装置； (3)一种存储用于求职者能力智能评估的程序的计算机可读存储介质。  11
本发明公开了一种相似句子对判断方法、系统及存储介质，所述方法包括如下步骤：步骤1：根据实际使用场景并按照意图冲突和问句相似度，将数据集整理成多组句子对；步骤2：使用与Robert网络对接的Encoder将步骤1中的多组句子对转换为对应的语义表征空间，获取符合语义的Embedding结果样本；步骤3：将步骤2处理后的Embedding结果样本输入Robert网络中训练，并将Robert网络的Cross Entropy Loss函数替换为Focal Loss函数，来消除不同类别的相似句子对样本不平衡问题；步骤4：重复步骤3进行训练优化，直至满足收敛条件, 从而准确地将Embedding结果样本分类为相似句子对和非相似句子对。本发明能够保证相似句子对判断的准确率。一种相似句对的判断方法。保证了相似句对判断的准确性。该方法包括根据实际使用场景并根据意图冲突和问题相似性将数据集组织成多个句子对。 本发明利用与Roster网络对接的编码器将多组句子对转换为对应的语义表示空间，得到语义嵌入结果样本。 将处理后的嵌入结果样本输入到robert网络中进行训练。 用焦点损失函数代替Roster网络的交叉熵损失函数，以消除不同类别相似句子的不平衡问题。 输入嵌入结果样本进行训练和优化，直到满足收敛条件，从而准确地将嵌入结果样本分类为相似句对和不同句对。本发明还涉及一种类似句对判断系统； 以及计算机可读存储介质，其存储用于判断相似句子对的方法的程序。  11
本发明涉及人工智能领域，公开了一种基于知识库与大模型的文档生成方法、系统、设备及介质，包括：获取携带有个性化需求的配置信息，根据配置信息对知识库、大模型、提示词模板及安全策略进行配置，构建垂直领域知识库；对提问信息对应的文本信息进行特征提取，确定问题特征向量；根据安全策略对问题特征向量进行校验，待校验通过后，将问题特征向量输入垂直领域知识库，若匹配到与问题特征向量关联的文档向量，则输出文档向量；将文档向量与问题特征向量填充到提示词模板，生成提示词；将提示词输入大模型进行推理，生成答案文档，对答案文档进行校验，待校验通过后，予以输出，本发明提升了文档编写效率、规范性、专业性和文档质量。一种基于知识库和大模型的电子设备生成文档的方法。该方法能够提高文档编译效率、规范性、专业性和文档质量。该方法涉及获取具有个性化需求的配置信息。 根据所述配置信息配置知识库、大模型、提示词模板和安全策略。 构建垂直领域知识库。 基于垂直领域知识库建立大模型。 获取一输入问题信息。 提取与所述问题信息对应的文本信息的特征，以确定问题特征向量。 如果所述文档向量和所述问题特征向量达到预设阈值，则输出文档向量。 将提示词填充到所述大模型中进行推理处理，生成提示词。 生成答案文档。 根据安全策略对所述答案文档进行二次验证处理。 验证通过后输出答案文档。本发明还公开了一种基于知识库和大模型的文档生成系统。  11
本发明涉及人工智能领域和自然语言处理领域，尤其涉及一种法律案件争议焦点获取方法、装置以及计算机设备；所述方法包括获取具有争议焦点的法律文本，归纳争议焦点的类别并将其视为标签，制作成法律案件争议焦点数据集；将如何获得争议焦点问题转化为分类问题，类的标签由上一步归纳所得，将原被告陈述内容分别作为输入，使用一种孪生BERT模型，对数据集进行训练得到模型结果；对无争议焦点的文书通过训练好的模型得到最终争议焦点结果。本发明收集、制作法律案件争议焦点数据集；使用一种孪生BERT模型，能够扩大输入长度，突破BERT长度为512的限制；得到更加精准的分类结果。本发明能够得到效果更好的法律案件争议焦点结果。用于使用计算机装置获得法律案件中的争议焦点的方法(要求保护的)。该方法得到更准确的分类结果和更有效的法律案件纠纷焦点结果。该方法涉及获得(S1)具有争议焦点的合法文本。 采用规则匹配方法获取/使用纠纷焦点的类别作为标签，创建法律案件的纠纷焦点数据集。 采用规则匹配方法查找历史纠纷焦点数据的焦点类型概率或距离值。 根据所述焦点类型概率值或距离值对应的均方根误差得到对应的回归值。 当均方根误差值对应的损失值最小时，获得分配系数。 将原告和被告的声明作为输入，并使用双胞胎双向编码器表示(BERT)模型来训练法律案件的争议焦点数据集，以获得训练模型结果。 将未知纠纷焦点的合法文本输入到训练好的模型中，输出焦点类型标签，得到最终的纠纷焦点结果。对于用于获得法律案件纠纷焦点的设备，包括独立权利要求。  11
本申请涉及一种大模型训练方法、装置、计算机设备及存储介质，涉及机器学习技术领域。该方法包括：获取包含至少两个语种的语料样本的预训练样本集；不同语种的语料样本的数量不同；基于预训练样本集对大模型进行预训练，获得第一大模型；基于预训练样本集构建包含平行指令样本集以及翻译指令样本集的指令微调样本集；该平行指令样本集中包含任务指令的不同语种的语料样本，该翻译指令样本集中包含翻译指令与回复文本分别为不同语种的语料样本；基于指令微调样本集对第一大模型进行指令微调训练，获得指令微调训练后的第二大模型。通过上述方法，使得训练获得的大模型能够进行知识和表达能力跨语种迁移的同时，提高对大模型的训练效率。方法训练大模型。训练得到的大模型能够进行知识和表达能力的跨语言迁移，同时，提高了大模型的训练效率。该方法包括获得预训练样本集。 预训练样本集中包含至少两种语言的语料样本。 不同语言的语料样本数量不同。 基于所述预训练样本集对大模型进行预训练，得到预训练后的第一最大模型。 基于所述预训练样本集构建指令微调样本集。 所述指令微调样本集包括并行指令样本集和平移指令样本集。 并行指令样本集中包括不同语言的任务指令的语料样本。 翻译指令样本集包括不同语言的翻译指令和回复文本。 基于所述指令微调样本集对所述第一大模型进行指令微调训练，得到指令微调训练后的第二大模型。独立权利要求书包括用于：(1)大模型训练装置； (2)计算机装置； (3)一种计算机可读存储介质。  11
本发明公开了一种面向易混淆词考察的选择题干扰项自动生成方法及装置，该方法包括：通过预训练的Word2vec生成词向量，并通过计算相似度选取出N个候选词；将考察词和N个候选词分别代入题干中，通过预训练的BERT模型生成上下文相关的词向量，并排除相似度过高的词，得到M个候选词；对M个候选词进行聚类，然后分别选出每个类簇中与考察词相似度最高的词作为代表，得到Q个候选词，最后根据相似度，在Q个候选词中选取合适数量的干扰项。本发明的方案具有效率高、科学性强以及保证了干扰项的多样性等优点。一种自动生成易混淆模糊词检查选择问题干扰项的方法。本发明能够高效，科学性强地实现干扰项的易混淆检字，从而保证干扰项的多样性。该方法包括获取待生成干扰项的问题和考试选择问题。 获得对应于考试词的第一候选词集。 第一候选词集合具有多个干扰词候选词。 计算候选词与第一候选词集合中的检查词之间的相似度。 形成第二候选词集。 根据第四候选词集合中的候选词与检查词之间的相似度，选择第四候选词集合中的预定数量的词作为最终干扰项。本发明还涉及一种用于生成选择问题的装置。  12
本说明书实施例提供了基于大型语言模型的协议文本检测方法及装置。该方法包括：从预设的多个要素中确定目标协议文本(例如与隐私数据有关的协议文本等)中的目标段落对应的目标要素；其中，该多个要素中的任一要素为与协议文本有关的问题、且被预设有与该要素对应的提词模板；基于目标段落和目标要素对应的提词模板生成目标提词；将目标提词输入大型语言模型，使得大型语言模型进行与目标要素有关的推理，并输出推理结果。基于大型语言模型的协议文本检测方法。该方法能够基于目标段落对应的摘要模板和目标元素生成目标摘要并将目标词条输入大型语言模型，以使大型语言模型进行与目标元素相关的推理，因此提高了大型语言模型的推理准确性。该方法包括：从预设的元素中确定目标协议文本中的目标段落对应的目标元素。 所述任意一个元素作为与所述协议文本相关的问题提供，并预置有与所述元素对应的馈送模板。 基于所述目标段落对应的所述词组模板和目标元素生成所述目标词组。 将所述目标词条输入大型语言模型，以使所述大型语言模型进行与所述目标元素相关的推理，并输出推理结果。 所述元件被提供为柔顺元件。 所述单一隐私数据使用场景为隐私数据获取场景、隐私数据发送场景、隐私数据存储场景和隐私数据共享场景中的任意一种。包括独立权利要求，用于：(1)协议文本检测装置，具有确定单元； (2)一种计算机可读存储介质，用于存储在计算机中执行以执行方法的计算机程序； (3)具有处理器的计算设备。  11
本发明公开了一种基于融合提示序列的弱监督文本分类方法、系统和装置，包括如下步骤：步骤1：获取待标注文本和类别标签集合；步骤2：对待标注文本增加提示序列，提示序列中引入占位符，所述占位符表示需后序处理以预测该位置单词；本发明基于更符合现实应用的弱监督文本分类场景，极大地减少了文本分类任务中人工的介入，降低了不可避免的人工误差，极大地节约了标注成本，提高了标注效率；在不获得任何标注信息的情况下，通过对文本数据进行有效的预处理，以及充分利用预训练模型输出特征，在不微调超大预训练模型的情况下，实现自动标注精度的大幅度提升。针对现实生活领域进行基于融合提示序列的弱监督文本分类的方法。该方法大大减少了文本分类任务中的人工干预， 减少了不可避免的人工误差，大大节约了打标成本，提高了打标效率，并且充分利用了预训练模型输出特性，在不对超大预训练模型进行精细调整的情况下，实现了自动打标，精度大大提高。该方法包括获取待标注文本和类标签集合。 在所述待标注文本中添加提示序列。 提示序列中引入占位符。 确定并加载预训练自然语言模型。 根据所述类标签组和预先训练的自然语言模型建立类标签字典。 根据处理后的文本提取所述文本的特征。 计算融合特性和平均加权中心余弦相似距离。 将所述平均加权中心对应的最小距离确定为文本的标记结果。包括以下独立权利要求：一种基于融合提示序列的弱监督文本分类系统； 以及一种基于融合提示序列的弱监督文本分类装置。  11
一种基于自注意力的融合三元组信息的短序列扩充电影推荐方法，包括以下步骤：1)原始数据处理：处理用户观看电影的历史数据，并根据预先设定好的电影关系为每部电影制作知识图谱；2)根据时间戳为每个用户制作观看的历史电影序列，使用单向Transformer模型反向训练模型，得到反向的预训练模型，使用反向的预训练模型生成扩充的增强数据；3)将扩充后的数据送入预训练模型进行正向模型的微调，得到正向的预训练模型；4)使用正向微调后的模型预测用户下一部即将观看的电影。本发明对短序列进行扩充，增强了数据，解决部分冷启动问题，对电影的推荐提供有力的帮助。基于自关注的融合三重信息的短序列扩展电影推荐方法本发明扩展了增强数据的短序列，减少了局部冷启动问题，为影片推荐提供了有力的帮助。该方法涉及通过使用图卷积网络来获得作为项目的外部信息的关系和尾部实体集合信息。 将嵌入项的项-和三元融合嵌入式KG-ADD的项作为q和k嵌入到模块中。 单向模型被发送用于反向训练。 扩展序列被发送到预训练模型，以根据输入扩展长度的序列来执行前向模型的微调。 最后一个项目由前向模型预测。 根据用户输入的信息显示用户期望的结果。 9
本发明涉及自然语言处理技术领域，尤其涉及一种汽车评论文本观点挖掘方法、设备及存储介质。包括：对数据进行预处理；对数据进行增强；采用由BERT预训练模型、双向LSTM网络和卷积神经网络、全连接层构成的神经网络结构对属性词、观点词、评论类别和情感倾向进行抽取；本发明采用了一种双指针网络标注策略，能实现属性词和观点词的一次性抽取，降低了属性词和观点词配对复杂度，提升了属性词和观点词的抽取准确率；并且实现评价类别和情感倾向同步预测，提升情感倾向预测准确率。挖掘汽车评审文本意见的方法。该方法使得能够实现属性词和观点词的一次性提取，降低属性词和观点词配对复杂度，提高属性词和观点词的提取准确率，并且能够实现评价类型和情感倾向性同步预测，提高情感倾向性预测准确率。该方法包括预处理数据。 对字符列表长度进行标准化处理，对所有训练文本的字符列表长度进行处理，得到固定长度的训练输入。 数据得到增强。 采用双向编码器表示自变换器(BERT)预训练模型+双向长短期记忆(LSTM)网络+卷积神经网络+全连接层组成的神经网络结构提取属性词和观点词。 采用由BERT预训练模型加双向LSTM网络加卷积神经网络加全连接层组成的神经网络结构对评论类别和情感倾向性进行判别。对于以下包括独立权利要求：一种具有存储器的计算机设备； 以及计算机可读存储介质，存储有计算机程序，所述计算机程序被处理器执行时实现所述的矿车审核文本意见方法。  12
本发明公开了人工智能生成内容的管理方法、设备及介质，涉及计算机技术领域。其中，应用于第一用户设备的人工智能生成内容的管理方法，包括：接收对人工智能生成内容AIGC的访问请求；响应于访问请求，获取AIGC对应于第一用户设备的目标内容权利信息；其中，目标内容权利信息来自于平台侧设备；根据目标内容权利信息，确定第一用户设备是否具有AIGC的访问权利；在第一用户设备具有AIGC的访问权利的情况下，获取AIGC对应的目标加密AIGC文件，并获取目标私钥对目标加密AIGC文件进行解密，得到目标AIGC文件；其中，目标加密AIGC文件和目标私钥均来自于平台侧设备；根据目标内容权利信息，对目标AIGC文件进行访问控制。本申请能够实现对AIGC的确权和访问控制，有效规范对AIGC的管理。用于管理用户设备中的人工智能生成的内容的方法。实现了AIGC的权限和访问控制，从而有效地规范了人工智能生成内容的管理。该方法包括接收(S101)对人工智能生成内容(AIGC)的访问请求。 获取所述AIGC对应的目标加密AIGC文件()，并获取目标私钥对所述目标加密AIGC文件进行解密，得到目标AIGC文件，当所述第一用户设备被提供对所述AIGC的访问权限。 从平台侧设备获取目标加密AIGC文件和目标私钥。 根据所述目标内容权限信息对所述目标AIGC文件进行访问控制(105)。以下包括独立权利要求：1。 用户设备； 2. 平台侧装置； 3. 人工智能生成内容的管理系统； 4. 一种存储用于管理人工智能生成的内容的程序的计算机可读存储介质。 1
用于流式传输视频内容的系统和方法包括使用按比例缩小模型来按比例缩小视频内容以生成按比例缩小的视频内容并且将作为视频流的按比例缩小的视频内容和对应的按比例放大模型下载到客户端设备。客户端设备使用接收的按比例放大模型来按比例放大视频流，以供由客户端设备实时地显示。训练系统基于标识视频内容的类型的相关联的元数据来训练按比例缩小模型以生成按比例缩小的视频内容。按比例缩小的视频内容和一个或多个相关联的按比例放大模型被存储以供由边缘服务器访问，边缘服务器将多个按比例放大模型下载到客户端设备，客户端设备被配置为选择按比例放大模型以供由客户端设备使用。示例系统可以包括视频流式传输系统和视频会议系统。用于流式传输视频内容的方法。改进的内容传送系统向各种客户机提供高质量的按需内容，同时有效地利用内容提供商和网络资源。该方法涉及使用缩小模型缩小视频内容以生成缩小的视频内容，以及将该缩小的视频内容作为视频流和相应的放大模型下载到客户端设备(150)。 客户端设备被配置为使用下载的用于显示的放大模型来放大视频流。 使用包括视频内容和相关类型信息的训练数据集来训练神经网络模型。 从客户端设备接收对视频内容的请求。 检测网络(140)的带宽，并基于检测到的带宽选择缩小模型。本发明还涉及一种用于流式传输视频内容的系统。 9
本说明书实施例提供了一种交易对象流动性预测方法、装置、设备及存储介质，该方法包括：获取目标交易对象的待处理数据；将所述待处理数据分别输入至流动性预测模型集合的每个流动性预测模型中，获得多个流动性预测子结果；所述流动性预测模型集合通过预训练贝叶斯神经网络模型生成；根据所述每个流动性预测模型的预测权重，对所述多个流动性预测子结果进行加权平均，获得所述目标交易对象的流动性预测结果。本说明书实施例可以提高交易对象流动性预测的准确率。交易对象流动性预测方法。该方法能够提高交易对象流动性预测的准确性。该方法包括获得目标事务对象的待处理数据。 将待处理的数据输入到流动性预测模型组的流动性预测模型中。 获得多个流动性预测子结果。 流动性预测模型集由预训练贝叶斯神经网络模型生成。 根据流动性预测模型的预测权重对流动性预测子结果进行加权平均。 获得目标交易对象的流动性预测结果。 获得目标事务对象的数据集。本发明还涉及一种用于实施该方法的装置。 一种交易对象流动性预测装置 一种计算机设备，包括：处理器和存储器，用于执行交易对象流动性预测； 以及 一种用于存储用于执行交易对象流动性预测的一组指令的计算机存储介质。  11
本发明的一种基于深度学习的大尺寸二维计算全息图实时生成方法，包括利用分解法消除大尺寸图像的不同图像块之间的数据依赖性，之后利用带宽补偿和空间位移补偿来确保不同图像块在全息平面中的正确映射；在消除了图像块之间的数据依赖性后，利用深度学习中U‑net架构通过非迭代生成经过补偿后得到图像块对应的子子全息图，再利用空间移位将同一图像块在不同空间位置生成的子子全息图合成为一幅子全息图；最后将不同图像块对应的子全息图进行复振幅叠加并提取相位得到最终全息图。本发明利用到的分解方法与深度学习训练网络是转而处理子数据，大大提高了全息图的生成速度与生成质量，实现了大尺寸二维计算全息图的实时生成。一种基于深度学习的大尺寸二维计算全息图实时生成方法。本发明利用分解法和深度学习训练网络对子数据进行处理，大大提高了全息图的生成速度和生成质量，从而实现了大尺寸二维计算全息图的实时生成。该方法包括将待处理的大尺寸目标图像沿水平和垂直方向分成若干等份，以及使用分解方法获得若干子目标图像。 使用带宽补偿和空间位移补偿来确保子图像块在全息平面中的正确映射。 在消除图像块之间的数据依赖性之后，处理每个子目标图像块。 在深度学习中使用U-网架构，通过非迭代生成补偿后生成与图像块对应的子全息图。 使用空间移位将由同一图像块在不同空间位置产生的子全息图合成子全息图像。 对不同图像块对应的子全息图进行复振幅叠加和相位提取，得到最终的全息图。本发明还涉及一种存储大尺寸二维计算全息图的实时生成程序的计算机可读存储介质。   6
本发明公开了一种局部‑全局自适应引导增强的车辆重识别方法及系统，该方法包括：对训练图像进行图像预处理并构建训练集；基于训练集对局部‑全局自适应引导增强的车辆重识别协同表示网络进行训练；所述局部‑全局自适应引导增强的车辆重识别协同表示网络包括基于VisionTransformer的骨干网络模块和基于局部注意力引导的自适应优化特征编码模块；获取待查询图像和图库集，对待查询图像在图库集进行检索匹配，得到匹配结果。该系统包括：预处理单元、网络训练单元和检索匹配单元。通过使用本发明，能够提高车辆重识别的精确度。本发明可广泛应用于车辆重识别领域。局部-全局自适应引导增强车辆再识别方法。可以提高车辆再识别的准确性。 局部细粒度特性，针对不同车辆相似度的重点高，可以解决同一车辆差异大的问题。该方法包括预处理训练图像的图像。 构建训练集。 基于所述训练集训练局部‑全局自适应引导增强车辆再识别协同表示网络。 所述局部-全局自适应引导增强的车辆再识别协同表示网络包括基于视觉变换器的骨干网络模块和基于局部注意力引导的自适应优化特征编码模块。 得到查询图像和图像库集合。 查询所述查询图像以对所述图像库组进行搜索匹配，得到匹配结果。本发明还涉及一种用于重新识别局部-全局自适应引导增强车辆的系统。 13
本发明涉及人工智能技术领域，提供一种法律智能问答方法、装置、电子设备及存储介质，所述方法包括：接收用户输入的目标问题，当目标问题为法律问题时，从预设的数据源中确定目标问题的多个第一候选问题；将目标问题输入至预先训练好的BERT模型中得到目标向量，并根据目标向量从预设问题库中匹配出多个第二候选问题；对多个第一候选问题和多个第二候选问题进行预处理得到多个第三候选问题；采用多种相似度算法计算目标问题与每个第三候选问题之间的目标相似度，根据目标相似度确定目标问题的目标答案。本发明通过采用多种相似度算法计算得到的相似度确定目标问题的目标答案，提高了法律智能问答系统反馈答案的准确率。智能法律问答方法。该方法能够利用采用多种相似度算法计算出的相似度确定目标问题的目标答案，以提高合法智能问答系统反馈答案的准确性。该方法包括接收用户输入的目标问题。 进行判断，检查所述目标问题是否被选为合法问题。 在将所述目标问题选为所述合法问题时，通过检索工具从预设数据源中确定与所述目标问题对应的第一候选问题。 将目标问题输入到预训练的双向编码器表示从变换器(BERT)模型中以获得目标向量。 根据所述目标向量从预设题库中确定第二候选问题。 根据目标相似度确定所述目标问题的目标答案。包括以下独立权利要求：一种智能法律问答装置； 一种电子设备，包括处理器和存储器，所述处理器和存储器用于执行用于执行智能法律问答的指令集； 以及计算机可读存储介质，用于存储执行智能法律问答方法的指令集。  12
本发明公开了一种基于深度学习的软件众包任务推荐方法。目前已有很多相关研究提出使用深度学习的方法对众包任务文本信息来进行众包任务推荐，但在现有的方法中，众包任务文本信息的提取方法缺乏通用性，且由于众包数据分布不平衡的特点，在推荐结果的指标上，命中率与多样性无法兼顾。本发明方法包含三部分的内容：基于预训练模型Bert提取众包文本特征、基于CNN+LSTM对众包文本特征进行进一步的特征学习和基于上述两个模型作用下的输出，能够自适应克服众包数据分布不平衡的损失函数。通过本发明可以在简单高效地针对特定软件众包平台实现开发者的推荐，同时也提高了推荐结果的命中率与多样性。一种基于深度学习的多类型软件众包任务推荐方法。本发明能够在特定的软件包平台上以简单高效的方式实现开发者的推荐，从而提高推荐结果的命中率和多样性， 因此，损失函数能够有效地自适应地平衡众包数据组中开发者样本分布不均衡的现象，从而在训练过程中进行多开发者训练，从而有效地提高推荐命中率。所述方法涉及在众包平台处收集和过滤众包任务和相应的完成开发者的文本信息。 收集并过滤的文本信息被分成训练组和测试组。 对群发任务的文本信息进行分段。 从训练组获得最大长度序列。 在训练组中填充分词长度小于长度序列的样本。 在测试组中截取分词长度大于长度序列的样本。 对分词后的训练组样本进行输入并填入BERT预训练模型。 生成下游任务所需的字向量。 生成的词向量被发送到卷积神经网络(CNN)和长期短期记忆(LSTM)深度学习模型以进行特征学习。将每个开发者的置信度得分和对应于每个开发者的任务的真实结果输入到损失函数中以计算损失并反向传播梯度直到模型收敛。  11
本发明涉及语音语义技术，揭露一种对话生成方法，包括：将获取的原始对话划分为提问内容和回复内容；提取回复内容的关键词，根据关键词设置条件标签；利用提问内容以及回复内容构建训练数据，将条件标签向量化后对预构建的生成式预训练模型进行参数设置，并使用训练数据对生成式预训练模型进行模型训练，将利用所述训练数据中回复内容作为监督信号生成的训练结果与所述训练数据相比较，得到训练完成的生成式预训练模型；接收用户的提问，利用训练完成的生成式预训练模型生成所述提问对应的回复。本发明还提出一种对话生成装置、设备及存储介质。本发明还涉及区块链技术，所述训练数据可存储于区块链节点中。本发明可以提高对话生成的准确性。基于语音语义技术的对话生成方法。该方法能够将训练数据存储在对话生成装置中，以提高对话生成的准确性。该方法包括获取原始对话数据。 原始对话数据分为提问内容和回复内容。 提取所述回复内容的关键词。 根据所述关键词设置所述回复内容的条件标签。 利用所述问题内容和所述回复内容构建训练数据。 将条件向量标签向量化，得到条件向量标签。 利用所述条件向量标签建立预先构建的生成预训练模型。 利用所生成的训练完成的预训练模型，生成与问题对应的回复。还公开了一种基于语音语义技术的对话生成装置； 电子设备，包括存储器和处理器，所述处理器执行所述存储器中存储的指令，用于基于语音语义技术生成对话； 以及存储用于基于语音语义技术生成对话的指令集的计算机可读存储介质。 8
本发明公开了一种支持异构集群下的模型并行训练方法及相关设备，所述方法包括：各个集群根据自己的框架编写好代码，然后在各自的框架上训练一部分数据，接着先在集群内部进行模型拼接，把模型并行切分到多张卡的模型参数合并成一个完整的模型，不同集群的拼接后得到的模型是一致的，然后将拼接完的模型参数进行分片传输到参数服务器，参数服务器对模型参数进行融合，接着参数服务器将融合后的模型下发到各个集群，最后各个分集群将收到的模型按照各自的模型并行训练策略进行模型并行切分后训练；本发明实现了用户隐私保护、数据安全、大模型并行训练和大模型传输，能整合不同计算中心资源，满足了异构框架，异构集群共同训练大模型的需求。支持异构集群的方法及相关设备。该方法能够实现用户隐私保护数据安全、大模型并行训练和大模型传输，并集成不同的计算中心资源，满足大模型的异构框架、异构集群训练需求。该方法包括基于参数服务器初始化(S10)麻木模型。 初始化的nump模型被发送到图形处理单元(GPU)群集和NPU群集。 参数服务器从所述GPU集群和所述NPU集群接收统一格式的nump模型。 所述参数服务器根据训练框架和模型并行策略对每个训练集群划分融合后的模型片段。 根据所述训练框架将所述模型片段分发给不同的设备。 进行所述训练。包括以下独立权利要求：(1)支持异构集群的模型并行训练系统； (2)一种存储用于支持异构集群的程序的计算机可读存储介质及相关设备。  11
本申请提供了一种未登录词词向量生成方法及装置，该方法包括：获取预训练字向量模型和未登录词；针对所述未登录词进行分字处理，得到至少两个分字，并通过所述预训练字向量模型，得到各分字的字向量；从构词贡献库中获取各分字的构词贡献值；根据所述各分字的字向量和构词贡献值，通过预设词向量加权算法，计算得到所述未登录词的词向量。本申请实施例所提出的一种未登录词词向量生成方法为针对中文文本的NLP应用中的词嵌入模型提供了未登录词的词向量生成解决方案，进而提高了词嵌入模型的分词效率和精确度。该方法对于通过使用计算机设备(要求保护的)生成未登录词语的未登录词语向量是有用的。该方法在中文文本的自然语言处理(NLP)应用中对词语嵌入模型生成未注册词语的词语向量，以提高词语嵌入模型的词语分割效率和准确度。方法包括获取预训练词向量模型和未达成词。 对未到达的词执行分词处理。 得到两个词。 通过所述预训练词向量模型获取每个词语的词向量。 从成词贡献度库中获取每个子词的词贡献度值。 根据所述每个词语的词向量和所述分词贡献值，通过预设词向量加权算法计算分词贡献值。独立权利要求还包括：一种用于生成未登录词语的未登录词语向量的装置； 以及计算机可读存储介质，包括用于生成未登录词语的未登录词语向量的指令集。 .  12
本发明提供一种语音文本联合预训练方法及系统，包括：将非成对语音数据和非成对文本数据输入至预训练联合模型中，得到初始损失总函数和初始训练联合模型；将非成对语音数据、非成对文本数据和成对语音文本数据输入初始训练联合模型，得到更新损失总函数和更新训练联合模型；将非成对语音数据、非成对文本数据和成对语音文本数据输入更新训练联合模型，得到最终损失总函数和最终训练联合模型。本发明利用非成对语音数据、非成对文本数据、成对语音文本数据对联合模型进行多次迭代训练，采用闭环言语链机理和连续累积发放机制，有效解决了非成对数据利用不充分问题，以及成对数据对齐关系学习不充分的问题。一种通过使用电子设备(要求保护)来预训练组合语音文本的方法。该方法能够利用非配对语音数据， 采用闭环语音链路机制和连续累加发布机制对组合模型进行多次迭代训练的成对文本数据和成对语音文本数据， 从而有效地解决了数据利用不够充分，数据对齐关系学习不够充分的问题。该方法包括获得非配对语音数据，非配对文本数据和配对语音文本数据。 非配对语音数据和配对语音数据被输入到预训练的组合模型中。 通过使用非语音语音数据计算更新的损失总函数。 通过使用非语音数据和非语音数据来计算数据丢失函数，计算最终闭环以形成数据丢失函数。 数据丢失函数和更新的丢失函数相加以训练最终训练组合模型，其中预训练组合模型包括文本编码器，语音编码器和交叉模式编码器。 语音识别解码模块和语音合成解码模块。还包括独立的权利要求： 语音文本组合预训练系统； 以及 一种非临时性计算机可读存储介质，包括一组用于通过使用电子设备来预训练组合语音文本的指令。 3
本申请公开了一种针对虚拟人的语音合成方法、装置、设备、介质及产品，属于人工智能领域。该方法包括：获取第一文本内容，第一文本内容包括与虚拟人进行互动的文本信息；将第一文本内容输入大语言模型，得到第二文本内容，大语言模型用于对第一文本内容进行自然语言回复处理；基于文本转语音模型，将第二文本内容转换为第一语音内容，第一语音内容是与第二文本内容对应的语音信息；基于虚拟人语音模型对第一语音内容进行推理，得到第二语音内容，第二语音内容包括目标人的语音特征。该方法通过获取与虚拟人进行互动的第一文本内容，基于大语言模型、文本转语音模型和虚拟人语音模型，实现最终推理得到具有目标人的语音特征的第二语音内容。用于对虚拟人进行语音合成的方法。该方法通过基于语言大模型、文本转语音模型和虚拟人语音模型获取与虚拟人进行交互的第一文本内容，使得能够实现最终推理得到具有目标人的语音特征的第二语音内容。所述方法包括：获取第一文本内容，所述第一文本内容包括与虚拟人进行交互的文本信息。 将所述第一文本内容输入语言大模型，得到第二文本内容。 对所述第一文本内容进行自然语言回复处理。 基于文本到语音模型将所述第二文本内容转换为第一语音内容。 基于虚拟人物语音模型对所述第一语音内容进行推理，得到第二语音内容，所述第二语音内容包括目标人物的语音特征。 利用虚拟人物语音模型将具有通用语音特征的语音内容实现并推理为具有目标人物的语音特征的语音内容，其中，文本到语音模型在训练过程中所利用的样本词的数量大于虚拟人物语音模型在训练过程中所利用的样本词的数量。包括独立权利要求，用于：(1)对虚拟人进行语音合成的装置； (2)一种计算机设备，包括存储器和处理器，用于对虚拟人进行语音合成； (3)计算机可读存储介质，用于存储对虚拟人进行语音合成的一组指令； (4)一种计算机程序产品，用于执行对虚拟人进行语音合成的一组指令。 8
本发明公开了一种基于bert的命名实体识别方法、系统、电子设备及存储介质，该方法包括：根据识别需求确定命名实体标签；根据命名实体标签对训练集进行标注；分别将训练集中每一个训练文本进行分词，得到所对应的词序列；将词序列输入bert特征表示层中得到词向量；将词向量输入至BiLSTM模型和CRF模型进行训练，得到实体识别模型；获取待识别文本；将待识别文本输入实体识别模型中得到识别结果；获取归一化词典；将识别结果与归一化词典进行匹配，得到归一化的识别结果。通过使用Bert数据训练出来的词向量模型输入，使模型能够充分学习文本特征，大大提高了实体识别的效果；通过构建归一化词典将识别结果进行归一化处理，去除重复和冗余，提高识别结果准确度。来自基于变换器的双向编码器表示的用于识别电子设备中的命名实体的方法(要求保护)。本发明提高了实体识别的效果，通过构建归一化字典对识别结果进行归一化处理，去除重复冗余，提高了识别结果的准确性。该方法包括根据识别要求确定命名实体标签。 命名实体标签用于识别文本的命名实体。 得到训练集。 根据所述命名实体标签对所述训练集进行标注。 获取与所述训练文本对应的词序列。 将词序列输入到Bert特征表示层。 得到归一化字典。 将识别结果与所述归一化字典进行匹配，得到归一化识别结果。 对所述归一化字典进行去重处理，得到去除权重后的归一化字典。独立权利要求包括：用于识别电子设备中的命名实体的基于变压器的双向编码器表示的系统； 以及存储用于识别命名实体的计算机指令的计算机可读存储介质。  12
本发明公开了一种标点符号添加方法、装置、电子设备及存储介质，所述方法包括：构建初始浅层神经网络模型；获取初始文本数据，将所述初始文本数据进行数据预处理，生成待标注文本数据；将所述待标注文本数据进行标注处理，生成带标签的预训练文本数据；将所述预训练文本数据映射至所述初始浅层神经网络模型进行训练，得到目标浅层神经网络模型；获取预处理文本数据，将所述预处理文本数据映射至所述目标浅层神经网络模型中进行标签预测得到标签预测结果；根据所述标签预测结果对所述预处理文本数据进行标点符号的添加，生成目标文本数据。本发明可实现无标点符号文本分析，快速自动进行标点符号添加且结果准确。一种在电子装置中增加标点符号的方法。本发明实现了无标点符号的文本分析，快速自动添加标点符号，结果准确。该方法包括建立(S101)初始浅层神经网络模型。 获取初始文本数据(S102)，对初始文本数据进行数据预处理，并生成待标记的文本数据。 对要标注的文本数据执行标注处理(S103)，以生成标注的预训练文本数据。 将预训练的文本数据映射(S104)到初始浅层神经网络模型以用于训练以获得目标浅层神经网络模型。 获得预处理文本数据(S105)，并将预处理文本数据映射到目标浅层神经网络模型以进行标签预测，从而获得标签预测结果。 根据标签预测结果，标点符号被添加(S106)到预处理的文本数据，以生成目标文本数据。独立的权利要求书被包括在以下内容中： 1. 标点符号添加装置； 以及 2. 一种存储用于添加标点符号的程序的计算机可读存储介质。  11
一种利用深度学习算法实现垃圾分类的方法，1)将轻量级卷积神经网络模型squeezenet用于垃圾分类：将单张经预处理的垃圾图片输入训练完成的squeezenet模型，最终得到4种输出中的一种，即为该图片中垃圾的种类；2)里用卷积核提取垃圾图片特征：在CNN中用卷积核对图像进行卷积操作，能够提取图像特征，经由训练得到最优参数的卷积核，得以准确识别垃圾图片；3)用Adam算法对神经网络进行训练优化。方法利用深度学习算法实现垃圾分类。采用Adam算法对模型训练进行优化，是一种在梯度下降训练过程中不断改变学习率的优化算法，使得迭代收敛速度和收敛程度增加。该方法涉及将单个经过预处理的垃圾图片输入到训练好的squeezenet模型中，最终得到4种输出中的一种，即图片中的垃圾类型。 利用卷积核在卷积神经网络(CNN)中对图像进行卷积，CNN提取图像特征，训练得到最优参数的卷积核，从而准确识别垃圾图像。 采用Adam算法对神经网络进行训练优化。 对垃圾图像进行归一化处理并随机裁剪，SqueezeNet用于分类任务。 利用卷积核提取图像特征再利用CNN识别垃圾图片。   4
本发明公开了一种遥感影像超分辨率模型训练方法，包括以下步骤：获取遥感影像数据集，其中数据集由真实的遥感影像实验数据集对构成，一组遥感影像实验数据集对包括LR低分辨率遥感影像块和HR高清遥感影像块；构建初始超分辨率遥感影像模型和对抗网络模型，初始超分辨率遥感影像模型由生成器网络训练生成；对抗网络模型由生成器网络和U‑net型判别器网络共同训练生成。根据上述技术方案，可以为网络训练真实学习到高‑低分辨率遥感影像的特征映射提供了良好数据保障，解决了超分辨率处理后出现重叠伪影的情况，加强了超分辨率处理后的遥感影像的真实纹理细节，为后续遥感影像场景解译应用提供更好数据基础。遥感图像超分辨率模型训练方法。该方法可以为网络训练学习高、低分辨率遥感影像的特征图提供很好的数据保障，解决超分辨率处理后伪影重叠的问题。 超分辨率处理后的遥感影像真实纹理细节得到了增强，从而为后续的遥感影像场景解译应用提供了更好的数据基础。该训练方法涉及获取遥感影像数据集，该数据集由真实的遥感影像实验数据集对组成。 构建初始超分辨率遥感影像模型和对抗网络模型，所述初始超分辨率遥感影像模型通过生成器网络训练生成。 对抗网络模型由生成器网络和U-net型判别器网络共同训练生成。 将遥感影像数据集送入生成器网络，输出SR超分辨率遥感影像，计算损失约束，形成初始超分辨率生成模型。 将所述SR超分辨率遥感影像与所述HR高清遥感影像块在所述U-net判别器网络中进行对抗训练。包括一个独立权利要求用于一种遥感图像超分辨率模型训练装置。   6
本发明实施例提供一种基于知识蒸馏和联邦学习的电力调度方法及调度系统，属于电力调度技术领域。所述电力调度方法包括获取电网系统中各个区域平台的历史用电数据；根据各个所述区域平台的历史用电数据获取每个所述区域平台的智能调度模型；本发明通过对每个区域平台的历史用电数据，分别构建对应的智能调度模型，利用每个智能调度模型作为大模型，训练聚合模型的小模型，进而可以得到聚合模型的模型参数，将该聚合模型的模型参数下发给每个智能调度模型，进而可在各个智能调度模型互相不交互的情况下，利用每个区域平台的历史用电数据更新迭代各个智能调度模型，最后根据当前区域平台的智能调度模型对当前区域的耗电进行预测。电网系统大区域配电站基于知识蒸馏和联合学习进行电力调度的方法。所述方法使得通过各区域平台的历史用电数据构建对应的智能调度模型，以将各智能调度模型作为一个大模型，对聚合模型的小模型进行训练，以得到聚合模型的模型参数，并将聚合模型的模型参数发送给各智能调度模型， 从而在各智能调度模型互不交互的情况下，利用各区域平台的历史用电数据对各智能调度模型进行更新迭代，从而最终根据当前区域平台的智能调度模型预测当前区域的用电情况。该方法包括获取电网系统中区域平台的历史用电数据。 根据各区域平台的历史用电数据得到区域平台的智能调度模型。 根据所述各区域平台的智能调度模型训练聚合模型。 获取所述聚合模型的模型参数。 将聚合模型的模型参数下发给各区域平台的智能调度模型。 各区域平台的智能调度模型，用于根据聚合模型的模型参数更新迭代的模型。 区域平台之间根据各区域平台的智能调度模型进行电力调度。独立权利要求包括：(1)基于知识蒸馏和联合学习的电力调度系统； (2)一种计算机可读存储介质，其包括用于基于知识蒸馏和联合学习执行电力调度的一组指令。 0
本公开提供了内容推荐方法、装置、电子设备以及存储介质，涉及人工智能技术领域，尤其涉及大模型、LLM(Large Language Model，大语言模型)、智能搜索、信息流、计算机视觉等领域。具体实现方案为：根据针对对象的推荐场景信息、推荐候选集信息以及对象的对象相关信息其中至少一种信息，生成提示信息；将提示信息输入大语言模型，得到与提示信息相对应的输出信息；以及根据输出信息，生成针对对象展示的推荐内容。一种利用电子装置推荐浏览内容的方法(权利要求书)。该方法能够有效地根据输出信息生成用于对象呈现的推荐内容。 该方法允许用户将提示信息输入到大型语言模型中，以获得与提示信息相对应的输出信息，从而用户可以选择要呈现给用户的推荐内容，因此以高效的方式提高了用户体验。该方法涉及根据推荐场景信息、推荐候选集信息和对象相关信息生成提示信息。 将所述提示信息输入大型语言模型，得到提示信息对应的输出信息。 根据输出信息生成推荐内容用于对象呈现。 根据输出规则信息对推荐候选集信息进行处理，得到输出信息。包括独立权利要求，用于：(1)一种利用电子设备推荐浏览内容的装置； (2)一种介质，包括一组指令，用于存储通过使用电子设备推荐浏览内容的计算机指令； (4)一种产品，包括一组指令，用于存储通过使用电子设备推荐浏览内容的计算机指令。  11
本发明公开了一种知识问答方法及系统，涉及信息交互设备技术领域，方法包括步骤1：获取知识图谱，利用语义嵌入模型获得语义向量表示并存储至faiss向量库；步骤2：接收问题语句，利用语义嵌入模型获得语义向量表示，并根据语义向量表示通过语义相似度计算从faiss向量库中召回与问题语句相似的实体、关系和属性；将召回的实体、关系和属性与根据问题语句生成的图谱查询模板拼接成查询语句，根据查询语句在连接的知识图谱数据库中进行查询获得查询结果；步骤3：根据查询是查询结果为用户生成合理回复。本发明通过构建通用的知识图谱问答框架，提高知识问答的适用性，解决直接使用文本生成大模型存在令牌限制的问题，提高问答回复的准确性。知识问答方法，用于信息交互装置的技术领域。通过本发明，能够提高知识问答的适用性和问答的准确性，并能够直接利用文本实现生成的大模型中存在的令牌限制过程。该方法涉及获得知识地图。 获得地图语义向量表示，并利用语义嵌入模型存储到faiss向量库。 接收问题语句。 利用语义嵌入模型得到问题语义向量表达。 根据问题语义向量表达式和映射语义向量表达式，通过语义相似度从faiss向量库中对问题语句计算实体关系和属性。 将查询结果和问题语句输入大模型，生成合理类型的答复。本发明还涉及一种知识问答系统。  12
一种基于生成式人工智能驱动的不良内容的检测方法涉及不良内容检测技术领域，解决了检测不准确、依赖人工的问题，方法包括：自动收集不良内容得到第一不良内容数据集，并通过内容安全检测平台进行检测得到第一检测结果，提取第一不良数据集中数据的样本标签，获得未被检测到的不良特征及其组合规律；人工分析以得到不良内容的高隐藏性不良特征和新型组合方式，生成AIGC模型的提示词；根据AIGC模型生成的且未被所述内容安全检测平台检测到的不良内容构建多元高隐藏性的不良内容数据集；利用上述两不良内容数据集的标签和多模态特征训练内容安全检测模型。本发明检测效率高、检测准确度高，能够检测高隐藏性、多元化的不良内容，且减少了对人工的依赖。基于生成的人工智能驱动检测缺陷内容的方法，在学习软件、短视频、微博等平台中。以较低的成本实现了高隐藏性和多样化缺陷内容的高检测效率和高检测精度，保证了对人工依赖的降低。该方法包括：根据缺陷内容的关键词，自动收集缺陷内容，得到第一缺陷内容数据集。 将所述第一缺陷内容数据集输入至内容安全审计平台进行检测，得到第一检测结果。 得到不良内容的高隐藏不良特征和新的组合方式，根据不良特征和组合规则。 根据图像和视频输入审计平台得到的检测结果，得到由人工智能生成内容(AIGC)模型生成的未被审计平台检测到的缺陷内容。 基于样本标签和缺陷内容数据组的多模态特征以及多变量高隐藏缺陷内容数据组训练内容安全检测模型。 对所述内容安全检测模型进行优化，直至检测模型满足预设要求。  11
本申请涉及人工智能技术领域，提供了一种问答方法、装置、电子设备及可读存储介质。该方法包括：获取待解答的目标问题文本；根据所述目标问题文本，通过文本检索模型，从预先设置的语料库中检索得到至少一个目标问答对，其中所述语料库中包括多个问答对，所述问答对包括问题文本和与所述问题文本对应的答案文本，所述目标问答对与所述目标问题文本之间的相似度大于第一预设阈值；根据所述至少一个目标问答对，通过大语言模型，得到所述目标问题文本对应的目标答案。本申请实施例解决了现有技术中存在常见问答方法对复杂语句识别不准确的问题。一种人工智能领域的问答方法。该方法使得能够获取待回答的目标问题文本，并通过文本检索模型从预设语料中接收目标问答对从而准确识别复杂句子。所述方法包括：获取待回答的目标问题文本，根据所述目标问题文本，通过文本检索模型从预设的语料中接收目标问答对，所述语料包括问答对集合，每个问答对包括问题文本和与所述问题文本对应的答案文本，所述目标问答对与所述目标问题文本的相似度大于第一预设阈值。 根据所述目标问答对，通过大语言模型获取所述目标问题文本对应的目标答案。独立权利要求包括：(1)一种用于执行问答方法的装置； (2)一种电子设备，包括用于执行问答方法的处理器； (3)一种可读存储介质，包括用于执行问答方法的指令。  11
本发明提供一种大语言模型的交互方法和系统，在用户本地或云端通过容器为大语言模型的生成内容或者为大语言模型运行调试生成的代码提供一个隔离、完整的用户环境，且所述用户环境包含IDE集成开发环境、依赖库和数据挂载模块。本发明容器技术既能在将大语言模型连接到编程语言解释器时提供一个隔离、独立的环境，供大语言模型生成的代码进行运行，又能克服因沙盒带来的上述缺陷，从而能让用户实现更多的使用场景。一种通过容器技术促进大型语言模型在用户本地或云端交互的方法。容器技术不仅为大语言模型连接编程语言解释器运行时提供一个隔离独立的环境，供大语言模型生成的代码运行，而且可以克服沙箱带来的缺陷，使用户实现更多的使用场景。该方法包括提供具有集成开发环境、依赖库和数据安装模块的隔离且完整的用户环境。 由大型语言模型生成的代码由用户生成。 在本地或云端对所述大语言模型的生成内容或所述代码生成的代码进行调试。 用户环境被提供有集成IDE的开发环境。 通过交互模块提供给用户选择的大型语言模型。 选取容器镜像，根据选取的容器镜像通过容器管理模块从镜像库中拉取对应的镜像。本发明还公开了一种大型语言模型的交互系统。  11
一种基于智能语音芯片的中文自定义唤醒与物联交互方法，包括：步骤1：唤醒语音，具体包括：步骤1‑1：提取语音特征；从麦克风获取语音信号，把语音信号进行特征提取得到二维的特征序列；步骤1‑2：检测唤醒词；把步骤1‑1中得到的语音特征输入CNN‑CTC声学模型神经；步骤2：识别离线语音；包括：步骤2‑1：运用CNN‑CTC声学模型，将输入的语音转换为拼音；步骤2‑2：把CNN‑CTC声学模型得到的拼音输入Transformer语言模型，输出拼音转化成的文字；步骤3：意图识别和槽填充；把2‑2步骤中得到的文字输入BERT模型，输出是文字所代表的意图；通过识别出的意图，进行天气查询和音乐播放；步骤4：生成对话文本；把2‑2步骤中得到的文字输入GPT模型，输出是对话的文本，提供闲聊的功能。基于智能语音芯片的中文自定义唤醒与物联网交互方法。基于智能语音芯片的中文自定义唤醒及物联网交互方法提供了聊天的功能。该方法包括提取语音特征。 从麦克风获取语音信号。 取绝对值或平方值作为二维声谱。 通过卷积神经网络声学模型检测唤醒词。 将所述CNN声学模型的输入转换成拼音。 基于序列解码模型填充意图标识和时隙填充。 通过编码器的自关注机制对挖掘词的上下文信息进行编码。 在进行对话预处理时，将每组对话数据合并为一个句子文本。 标识符用于分开。 在文本的开头添加标识符。 利用语言模型根据所述前一文本预测所述后一词的特征。 交叉熵用作损失函数以最大化公式的后验概率。 生成多个候选回复。 3
本发明提供了一种基于AIGC的景区多场景内容创作及应用系统，包括服务器、AIGC模块、用户行为采集模块、用户选择模块，用户行为采集模块采集用户提供的至少两个兴趣关键词，AIGC模块根据至少两个兴趣关键词与设定的特征向量进行比较，以获得至少两个兴趣关键词在特征向量的各个元素中的权重，将至少两个兴趣关键词相关联的权重构建权重判别向量，并将权重判别向量进行景区特征向量进行匹配，以生成与兴趣关键词相适配的推荐内容，用户选择模块将生成的推荐内容向用户进行展示；本发明通过AIGC模块和用户选择模块的相互配合，以提升整个系统的智能程度和内容推荐的可靠性和精准性。基于网格计算人工智能(AIGC)的景区多场景内容创建和应用系统。该系统实现了AIGC模块和用户选择模块的配合，提高了智能化程度，实现了内容推荐操作的可靠性和准确性。该系统有一个服务器，服务器与一个人工智能网格计算(AIGC)模块连接。 用户动作采集模块，采集用户提供的兴趣关键词； 所述AIGC模块将所述兴趣关键词与特征向量进行比较，得到所述兴趣关键词的权重。 用户选择模块向用户显示推荐内容。 所述用户动作采集模块设有数据采集单元和存储单元。 数据采集单元采集用户提供的兴趣关键词。 1
本发明涉及图像分割领域中的鼻咽部肿瘤图像分割技术，具体的说是一种基于多尺度特征金字塔的3D CNN鼻咽癌分割方法。针对训练样本，需要由有经验的放射科肿瘤医师对若干鼻咽癌病例进行标注，使用整个三维MRI图像建立数据集，并对数据集进行一定的预处理，然后用网络对训练数据集进行训练，取得高精度的分割模型。对于新的病例，可以用该分割模型分割其MRI图像。相对传统的方法，除了训练阶段需要人工标注外，其余部分均可实现自动处理，大大降低对于有经验医师的需求，且与五种主流网络对比能取得较高的精度。基于多尺度特征金字塔的3D CNN鼻咽癌图像分割方法。该方法能够通过网络训练分割模型以由放射医生检测癌症病例，分割MRI图像，满足需求，提高体验和图像分割精度。该方法包括收集鼻咽癌图像。 获得三维(3D)MRI图像数据的鼻咽部。 对所述MRI图像数据执行标准化处理操作。 将人工边缘病理区域标记为标签数据。 根据金字塔多尺度特性构建三维卷积神经网络。 对MRI图像数据进行预处理和分割，以采集医学图像。 在肿瘤位置收集重采样图像。 将所述重采样图像切割成预定尺寸。  7
本发明提供一种基于对比学习区分对话摘要与对话者的方法，其特征在于，首先基于BART构建增强序列到序列的神经网络模型，该神经网络模型的编码器‑解码器能够对对话进行编码解码；然后基于训练时生成的训练用对话摘要与目标摘要的交叉熵损失以及采用三种对比学习任务辅助神经网络模型对训练用对话进行对话编码时的对比学习损失，对该神经网络模型进行训练直至生成能够根据对话者来区分对话从而生成摘要的对话者区分模型；由于采用了三种对比学习任务来辅助编码器进行对话编码，因此使得本发明的模型能够更好地理解对话数据，令生成摘要取得了更高的准确率，避免了事实一致性错误。自然语言处理生成任务中基于对比学习的对话摘要与对话者区分方法。由于交际者判别模型能够区分交际者以生成摘要。 因此，与以往的基于对比学习的对话判别模型相比，该方法区分了对话摘要和对话者，从而更好地理解对话数据，在生成摘要方面取得了更高的准确性，避免了事实一致性错误。该方法包括构建(S1)基于BART的序列到序列神经网络模型。 将用于训练的对话输入(S2)到神经网络模型中以生成用于训练的对话摘要，并且计算用于训练的对话摘要与目标摘要之间的交叉熵损失。 利用(S3)三个对比学习任务辅助神经网络模型对训练对话进行对话编码，并计算三个对比学习任务的对比学习损失。 对所述神经网络模型进行训练(S4)，直至基于所述整体训练损失生成训练后的神经网络模型，作为区分交际者的模型。 将所述待测试对话输入(S5)所述对话者判别模型，得到所述待测试对话对应的对话摘要。 8
基于深层时序特征表示的语种识别方法，本发明涉及一种基于深层时序特征表示的语种识别方法，属于语种识别技术领域。本发明的目的是为了解决现有方法对语种识别的精度低的问题。过程为：步骤1、获取不同语种的音频数据集；分别对不同语种的音频数据集进行数据增强；将数据增强后的不同语种的音频数据集裁剪成同等长度音频数据，作为训练集；步骤2、构建深度学习模型，将步骤1的训练集输入深度学习模型进行训练，直至达到了设置的最大迭代次数，获得训练好的深度学习模型；所述深度学习模型依次包括预训练模型、时间池和全连接层；步骤3、将待测音频数据输入训练好的深度学习模型，获得待测音频数据的语种类别。基于深度时序特征表示的语言识别方法。该方法能够提高语言识别的准确性。 该方法允许用户选择要测试的音频数据的语言类型。该方法涉及获得不同语言的音频数据集。 增强不同语言的音频数据集的数据。 将增强后的数据裁剪成与训练集长度相同的音频数据。 构建深度学习模型。 将所述训练集输入所述深度训练模型进行训练。 将所述待测音频数据输入训练好的深度学习模型。 获取所述待测音频数据的语言类型。 FCLT依次包括特征表示层、池层和网络层。 特征表示层是全连接层。 所述池层为均方差池层。 网络层为前馈神经网络。 CNNLT依次具有特征表示层、池层和网络层。 3
本发明公开了一种基于深度学习的文本分类方法及系统，属于自然语言处理技术领域，其中，该方法包括：从互联网获取文本数据集，并划分为训练集和测试集；利用ALBERT技术将训练集转换为词向量；利用改进的深度学习算法对词向量进行特征提取，得到最优特征向量；利用Cross Entropy Loss函数改进Softmax算法的分类函数，以建立文本分类模型，利用数据集文本分类模型进行训练，得到文本分类预测模型；通过参数优化算法Adam对文本分类预测模型进行参数优化，得到最佳文本分类预测模型；将测试集输入最佳文本分类预测模型中得到分类预测结果。该方法解决了文本词向量缺少全局特征的问题，也极大改善了文本分类效果。用于在自然语言处理领域中基于深度学习来分类文本的方法。 使用包括但不限于情感分析，主题标记，自动提问和答案字段。本发明能够避免文本词向量缺乏全局特征，有效提高文本分类效果。该方法包括获得文本数据集并对其进行预处理(S1)。 将预处理后的文本数据集按照预定比例划分为训练集和测试集。 将训练集转换(S2)为文本特征词向量。 使用深度学习算法执行(S3)文本特征词向量的特征提取。 获得最优特征向量。 利用交叉熵损失函数(S4)来改进分类函数的Softmax算法。 使用数据集和文本分类模型执行训练处理以获得文本分类预测模型。 通过参数优化算法自适应矩估计(ADAM)对文本分类预测模型进行参数优化处理(S5)，得到最优的文本分类预测模型。 将测试集输入(S6)到最优文本分类预测模型中以获得分类预测结果。本发明还涉及一种基于深度学习的文本分类系统。  12
本发明公开了一种基于城运投诉工单识别的自动派单方法及系统，属于工单分发技术领域，方法包括：接收城运投诉工单；对城运投诉工单进行删除式的脱敏处理；构建具有BERT层、注意力机制层和单维最大池化层的工单语义识别模型，并利用历史城运投诉工单数据对工单语义识别模型进行训练；对脱敏后的城运投诉工单进行包括权重分析的语义识别，判断城运投诉工单的工单类型；根据工单类型确定工单紧急程度，并结合工单投诉时长和工单地理距离计算城运投诉工单的派单优先级；结合派单优先级和工单类型，构建基于随机森林的决策模型；利用决策模型将城运投诉工单派发至相应的接收单位。提升工单自动派发能力和派发速度，避免工单长时间搁置的问题。基于城市交通投诉工单识别的自动派单方法。该系统提高了工作单的自动分发能力和分发速度，避免了工作单长时间铺设的问题。 利用历史城市运输投诉工单数据训练工单语义识别模型。该方法涉及接收(S101)城市交通投诉工单。 对城市交通投诉工单进行删除脱敏处理(S102)，去除投诉信息。 以BERT层、注意力机制层和单维最大池化层构建工单语义识别模型(S103)。 利用训练好的工单语义识别模型(S104)对脱敏后的城市运输投诉工单进行包含权重分析的语义识别。 基于工单类型确定工单的紧急程度(S105)，计算城市交通投诉工单的派单优先级。 将所述派单优先级和所述工单类型相结合(S106)，构建决策模型。 利用所述决策模型(S107)将所述城市交通投诉工单调度至接收单位。包括独立权利要求的基于城市运输投诉工单识别的自动派单系统。  11
本发明公开了知识问答系统构建方法及系统，属于大数据处理技术领域，要解决的技术问题为如何结合大模型与知识图谱来构建知识问答系统。包括如下步骤：收集和整理化学领域相关的知识数据，提取实体、关系和属性之间的关系，构建知识图谱；对用户输入的问题文本进行分析理解，抽取实体、关系和属性；根据问题文本中的关键词和实体，在知识图谱中进行信息检索；对用户输入的问题文本和检索到的实体、关系和属性进行信息整合，得到prompt以prompt为输入、基于通过大模型技术构建的答案预测模型生成对应的答案；基于用户的界面要求，将生成的答案进行格式化呈现，包括以文本和图表的形式展示。化工领域知识问答体系构建方法。该方法使得结合大模型和知识图谱能够以有效的方式构建知识问答体系。该方法包括收集(S100)和整理与化学领域相关的知识数据，并通过自然语言处理技术预处理知识数据。 提取所述实体、所述关系和所述属性之间的关系。 通过自然语言处理技术对用户输入的问题文本进行分析(S200)和理解，提取出实体、关系和属性。 搜索所述知识图谱中的信息(S300)，以获得所述相关实体、关系和属性。 将用户输入的问题文本的信息与搜索到的实体、关系和属性进行整合(S400)以获得提示。 将所述提示作为输入(S500)，基于大模型技术构建的答案预测模型生成对应的答案。 基于用户界面要求对生成的答案进行格式化(S600)，包括以文本和图表的形式呈现。包括独立权利要求的知识问答系统构建系统。  11
本申请公开了一种获取提示文本的方法、电子设备及计算机可读存储介质，涉及大模型、计算机技术技术领域。该方法包括：获取第一种子内容、第一种子模板和目标信息，其中，第一种子内容用于确定预设管控行为、第一种子模板用于描述预设管控行为对应实施方式的仿照示例，目标信息用于描述第一种子内容匹配的目标意图；对第一种子内容、第一种子模板和目标信息进行扩展，得到扩展提示文本；从扩展提示文本中选取目标提示文本。本申请解决了相关技术中向大语言模型输入的提示文本无法使大语言模型输出符合预期的回复或文本的技术问题。一种电子设备获取提示文本的方法(权利要求书)。该方法使得能够对种子内容、种子模板和目标信息进行扩展，以得到扩展提示文本，并从扩展提示文本中确定目标提示文本，从而使得大型语言模型能够高效地提供符合回复和文本的输出。该方法包括获得种子内容、种子模板和目标信息。 所述种子内容用于确定预设管控动作。 所述种子模板用于描述与所述预设管控行为对应的仿真实例。 所述目标信息用于描述所述种子内容匹配的目标意图。 对所述种子内容、所述种子模板和所述目标信息进行扩充，得到扩充提示文本。 从所述扩展提示文本中确定目标提示文本。独立权利要求还包括用于：评价提示文本的方法； 以及一种计算机可读存储介质，用于存储电子设备获取提示文本的指令集。  11
本发明公开了一种基于对比学习融入动态调整机制的文本聚类方法，其特征在于，基于语境增强的方法得到一组增强文本，通过预训练模型得到增强文本的特征表示，通过K‑Means聚类方法得到语义集群的初始簇心；提高文本聚类分布的置信度，进行动态筛选；最后得到模型总损失函数，并通过动态调整函数不断动态调整，使模型训练重量从对比学习平滑过渡到聚类任务。本发明缓和对比学习和聚类目标不一致的问题；实现对比学习到聚类的平滑过渡；通过为簇分配概率的置信度高的数据分配伪标签对负例进行筛选，以此解决同一簇数据互为负例的问题，有效提高了负例质量；对比学习得到的数据表示对聚类更友好；在大部分数据集上优于现有的短文本聚类方法。一种基于对比学习融合动态调整机制的文本聚类方法。本发明解决了文本深度聚类中辅助任务和聚类任务带来的聚类语义置信度不高的问题。 解决了同一集群数据为负实例的问题，有效提高了负实例质量。 通过比较学习得到的数据对聚类更加友好，大多数数据集优于现有的短文本聚类方法。所述方法包括：通过高浓度簇软分布概率分布得到文本分布伪标签。 相同伪标记的数据以正例从负例中移除。 通过动态调整函数得到聚类损失的当前迭代次数和比较学习损失权重比。 根据重量得到模型总损失。 根据损失更新模型参数。 重复该过程直到训练结束。  11
本发明适用于互联网安全技术领域，尤其涉及一种生成式人工智能服务的数据传输系统、方法及相关设备。本发明提出了一种针对生成式人工智能服务的用户隐私数据的传输系统，该系统采用用户身份验证信息与服务数据分离的方案，可以使生成式人工智能服务提供商在不获取用户身份数据的情况下为用户提供服务，使服务提供商无法通过分析自身提供的服务内容挖掘用户隐私信息，提高了用户数据的隐私度；并且，该系统能够在不加密用户数据的基础上利用单向通信传输提供生成式人工智能服务，在提高了用户数据的安全性同时还能够保证服务生成数据的准确性和完整性，进一步优化了生成式人工智能服务的用户体验。用于使用计算机装置的所生成的人工智能服务的数据传输系统(权利要求)。该系统能够在不对用户数据进行加密的基础上，利用单向通信传输提供生成的人工智能服务，提高了用户数据的安全性并保证了服务生成数据的准确性和完整性，进一步优化了生成的人工智能服务的用户体验。 服务提供方无法通过分析自身提供的服务内容挖掘用户隐私信息，可以提高数据的隐私性。该系统具有生成人工智能服务模块，用于为用户使用生成的人工智能服务提供身份认证信息和隐藏通信信息。 生成人工智能维护模块，存储所述生成人工智能服务模块发送的所述身份验证信息和所述隐藏通信信息。 用户终端模块提供用户界面，并根据用户操作通过通信密钥安全连接到生成的智能服务模块。 认证模块，在所述用户端模块连接所述生成人工智能业务模块之前，根据身份识别信息对所述用户的身份进行认证并生成令牌文件。独立权利要求还包括用于：生成的人工智能业务的数据传输方法； 以及计算机可读存储介质，其包括用于传输数据的一组指令。  11
本发明公开了一种命名实体识别模型的训练方法，利用预训练好的成分句法分析器，构建出输入文本的成分分析树；基于生成规则，通过所述成分分析树形成关键句法成分候选集合；通过掩蔽不同的关键句法成分，筛选出所述关键句法成分候选集合中最重要的两个关键句法成分；分别掩蔽实体和最重要的两个关键句法成分，得到两种词嵌入并引入一种门控机制对两种词嵌入进行融合，形成每个词最终的词嵌入表示；将文本中所述每个词最终的词嵌入表示作为输入，输入条件随机场中进行训练，得到命名实体识别模型。本发明加强了最终词嵌入的表达能力；省去标注样本数据所需的人力成本；有效减轻整个句子复杂语义的影响，简化人类阅读和理解的过程，可解释性较强。一种命名实体识别模型的训练方法。该训练方法提高了韵母嵌入的表达能力。 节省了标记样本数据所需的人工成本。 本发明有效降低了整句复杂语义的影响，简化了人的阅读理解过程，可解释性强。该训练方法包括利用预先训练的部件语法分析器来构造输入文本的部件分析树。 通过基于生成规则的部件分析树形成关键语法部件候选集。 通过屏蔽不同的关键语法组件，在关键语法组件候选集中筛选出两个最重要的关键语法组件。 分别屏蔽实体和两个最重要的关键语法部件以获得两个词的嵌入。 以文本中每个词的最后一个词嵌入式表示作为输入，输入条件随机场训练得到命名实体识别模型。  12
本申请涉及基于LSTM的植物生长数据多步预测方法、装置、介质及设备，其中方法包括：获取植物生长的时间序列数据；采用signal函数对所述时间序列数据进行波长转换，得到重构时间序列数据；通过所述重构时间序列数据对基于LSTM的编码器和解码器进行预训练，得到输入特征；以所述输入特征训练融入注意力机制的LSTM，基于训练完成的LSTM对植物生长数据进行多步预测。通过对时间序列数据进行波长转换，能对时间序列数据起到去噪作用。而且对基于LSTM的编码器和解码器的预训练，提取重构时间序列数据中适当的特征作为输入特征，通过输入特征对LSTM模型进行训练，能较好的使得注意力机制融入LSTM模型，缩小LSTM多步预测的误差，提升植物生长数据多步预测的准确性。基于LSTM的植物生长数据多步预测方法。该方法较好地将注意力机制融入LSTM模型中，降低了LSTM多步预测的误差，提高了植物生长数据多步预测的精度。该方法涉及获得(S101)植物生长的时间序列数据并使用(S102)信号函数对时间序列数据执行波长转换以获得重建的时间序列数据。 通过重构的时间序列数据重新训练(S103)基于LSTM的编码器和解码器以获得输入特征。 利用所述输入特征来训练(S104)集成到注意力机制中的LSTM。 基于训练后的LSTM进行所述植物生长数据的多步预测。 利用小波变换对所述时序数据进行表示，得到表示结果。 将表示结果分解为低频近似集合和高频细节集合。以下包括独立权利要求：1。 一种基于LSTM的植物生长数据多步预测的装置； 2. 一种计算机可读存储介质，存储有基于LSTM的植物生长数据多步预测的程序。  11
一种基于多架构NLP预训练模型和区块链的营商环境评价系统，涉及人工智能技术领域，该系统包括：企业大数据中台模块，用于获取认证后的训练样本数据；NLP预训练模型预处理模块，用于基于训练完成的NLP预训练模型以及用户对目标营商环境的调研需求进行数据采集和预处理，生成对目标营商环境的调研设计方案；异构NLP预训练模型校核模块，用于基于训练完成的异构NLP预训练模型对调研设计方案进行校核，得到最终调研设计方案；数据评价信息化管理模块，用于对最终调研设计方案以及调研数据进行可信度量化评价的评价结果。实施本申请提供的技术方案，可以提高对营商环境评价的准确度。多架构NLP预训练模型和基于区块链的商业环境评估系统，用于对城市、地区或企业的商业环境进行科学评估和监测的过程。数据评估信息管理模块，用于对最终的研究设计方案和研究数据进行可靠性量化评估的评估结果。 本申请提供的技术方案，能够提高商业环境评估的准确性。该系统具有企业大数据中间平台模块(10)，用于获取认证后的训练样本数据。 NLP预训练模型预处理模块(20)根据所述训练数据训练NLP预处理模型。 数据评估信息管理模块，获取根据最终研究设计方案收集的研究数据，并获取所述最终研究设计方案的评估结果和所述研究数据的可靠性量化评估。本发明还涉及一种电子设备。  11
本发明公开一种面向三维场景重建的高精度单目深度估计系统及方法，属于图像处理技术领域，在编码器处通过引入Vision Transformers主干网络，ViT主干网络代替卷积网络作为密集预测的主干架构，以恒定的和相对较高的分辨率处理表示，并在每个阶段都有一个全局的接受域，以减少卷积网络中下采样过程中的信息丢失，从而获取图像更多的细节特征和感受野。在解码器处通过利用小波变换来捕获深度图中深度不同的平坦区域之间的深度“跳跃”，这些“跳跃”可以很好地在高频分量中捕获，从而达到强化深度信息图边缘的效果。通过对ViT和小波变换的引入，能够在不使得网络计算更复杂的前提下，又兼顾单目深度估计网络模型对全局特征和局部边缘特征的提取，提高单目深度估计的精度。高精度单目深度估计系统，用于自动驾驶、虚拟现实和增强现实等实时三维场景重建。该系统减少了卷积网络中下采样过程中的信息损失，从而得到图像的细节特征和感受野。 该系统通过改进网络模型对全局特征和局部边缘特征的提取，提高了自监督单目深度估计的精度。该系统具有提供有视觉变换器(ViT)主网络的视觉变换器网络。 小波逆变换解码器网络将瓶颈尺度的特征图片发送到深度估计网络和位姿估计网络。 预测瓶颈尺度的深度信息图连续迭代小波反变换连续迭代采样，输出最终的深度信息图。 一种自监督单目深度估计网络架构，具有深度信息网络和位姿估计网络。包括一种高精度单目深度估计方法的独立权利要求。   5
本发明公开了一种基于知识蒸馏的多层神经网络语言模型训练方法与装置，该方法首先构建BERT语言模型和多层BILSTM模型作为教师模型和学生模型，其中所构建的BERT语言模型中有六层transformer，多层BILSTM模型中有三层BILSTM网络；然后将文本语料集进行预处理后，对BERT语言模型进行训练得到训练好的教师模型；再基于知识蒸馏技术将预处理后的文本语料集输入到多层BILSTM模型训练学生模型，在学习教师模型中的嵌入层、隐藏层以及输出层之时，通过线性变换将不同空间表示进行计算。基于训练好的学生模型，可将文本进行向量转换，进而训练下游网络更好地进行文本分类。本发明可以有效提升文本预训练效率以及文本分类任务的精确度。基于知识蒸馏的多层神经网络语言模型训练方法。该方法能够有效提高文本预训练效率和文本分类任务准确率。该方法涉及构建BERT语言模型和多层BILSTM模型，作为教师模型和学生模型。 对所述BERT语言模型进行预处理文本语料后训练得到训练好的教师模型。 将预处理后的文本语料输入到所述多层BILSTM模型中，以训练所述学生模型，并在学生模型训练时在嵌入层、隐藏层、输出层中学习所述教师模型。 通过线性变换计算不同的空间表示。 利用教师模型的softmax层输出的概率分布熵作为知识蒸馏的目标损失函数，得到训练后的学生模型。包括以下独立权利要求：基于知识蒸馏的文本分类方法； 以及包括用于执行基于知识蒸馏的多层神经网络语言模型训练过程的处理器和存储器的计算设备。  12
本发明公开了一种基于大语言模型提取倒闸操作信息的方法及系统，涉及变电站运维技术领域，解决了传统NLP技术进行倒闸操作信息提取时，无法理解设备、操作同义表达的问题，其技术方案要点是：首先，通过分析设备/操作存在的同义表达，借助现有PLM预训练大语言模型对同义表达进行识别，基于模型识别错误的同义表达生成知识对话集，用于训练大语言模型的专业理解能力；其次，基于工作票和人工标注的倒闸操作信息生成任务对话集，用于训练大语言模型的问答功能；最终获得电力领域LLM模型，可从理解设备、操作的同义表达并以问答的方式提取倒闸操作信息，提高开票效率。用于电力系统变电站运行的基于大语言模型的倒闸操作信息提取方法。最终得到电力现场的LLM模型，通过理解装置的同义表达和问答方式的操作提取倒闸操作信息从而提高计费效率。该方法包括收集(S1)历史工作票数据。 对历史工作票数据进行清洗和拆分。 提取所述有效工作票数据。 对所述有效工作票数据进行词性分析和实体命名任务处理。 将处理后的所述有效工作票数据存储在工作票库中。 对工作票库中的有效工作票数据进行名词实体和动词实体抽取(S2)。 对名词实体和动词实体进行向量化转换。 对相关聚类数据进行分析。 得到多组映射对。 通过知识对话集和任务对话集构建(S3)训练语料和测试语料。 将所述训练语料输入PLM预训练大语言模型进行指令微调。 得到功率场中的LLM模型。 将测试语料输入(S4)到功率场的LLM模型中，以验证准确性。一种基于大语言模型的倒闸操作信息提取系统，其特征在于，所述倒闸操作信息提取系统包括： 0
本发明涉及人工智能技术，揭露了一种基于审单的图文字符识别方法、装置、设备及存储介质。所述方法包括：获取用户输入的待审核单据图像，并根据预设的文字清洗策略对所述待审核单据图像进行基于文字调整及水印消除的处理操作，得到干净图像；根据预设的模型构建策略，获取预训练的字符识别模型，并利用所述字符识别模型中的改进DB网络对所述干净图像进行图像特征提取操作及图像裁剪操作，得到裁剪图像集合；利用所述字符识别模型的改进文字识别网络对所述裁剪图像集合进行文字识别，得到所述待审核单据图像对应的字符识别结果。本发明可以提高基于审单的图文字符识别的准确性。图文字符识别方法。该方法提高了基于文档审核的图文字符识别的准确率。该方法包括获取(S1)用户输入的待审核文档图像并根据预设的文字清洗策略对所述待审核文档图像进行文字调整和水印去除处理，以获得干净的图像。 根据预设的模型构建策略得到(S2)预训练的文字识别模型，并利用文字识别模型中的改进DB网络对干净图像进行图像特征提取和图像裁剪操作，得到裁剪图像集。 利用(S3)所述文字识别模型的改进文字识别网络对所述裁剪后的图像集进行文字识别，得到所述待审核文档图像对应的文字识别结果。以下包括独立权利要求：1。 图文字符识别装置； 2. 电子设备； 3. 存储有用于识别图文字符的程序的计算机可读存储介质。   6
本发明属于软件工程技术领域，具体为一种基于深度学习的交互式API代码片段推荐方法。本发明通过对大量包含目标API的源代码进行解析来构造大量的训练样本；使用深度学习模型中的Encoder‑Decoder模型框架实例化深度学习网络，包括Seq2Seq模型、Transformer模型或Graph2Seq模型，并用训练样本训练深度学习模型，以用于预测推荐；根据深度学习模型的推荐结果，通过后处理方式来优化推荐结果；所述后处理方式包括：启发式束搜索、聚类以及交互式意图选择。本发明为软件开发人员提供基于代码上下文的智能化多行API代码推荐，在开发人员已经编写好的代码的基础上为其推荐多行API代码，从而辅助开发人员完成当前代码的开发。基于深度学习推荐Java开发包(JDK)和Android(RTM：基于Linux的操作系统)等交互式API代码段的方法。可以基于开发者已经编写的代码来推荐多行API代码，从而可以帮助开发者完成当前代码的开发。该方法包括通过分析和抽象代码库中源代码文件中的每种方法来构造训练样本，以获得相应的代码表示。 为代码表示挖掘API代码的一部分，使得剩余的API代码和挖掘的API代码组合以形成训练样本。 训练深度学习模型和编解码器模型。 将所有训练样本输入深度学习模型进行训练，得到训练好的深度学习模型。 训练的深度学习模型用于做出预测以推荐API代码段。 通过输入用户输入来分析深度学习模型所需的代码，通过运行深度学习模型进行预测，通过使用启发式波束搜索来优化推荐结果，通过生成聚类结果的摘要，以及通过将最终结果可视化以供开发者交互选择，来推荐分段。  11
本发明涉及电力违章样本生成技术领域，公开了一种电力作业人员违章样本生成方法、装置、设备及介质，该方法包括：构建电力多模‑图像配准大模型，利用电力多模‑图像配准大模型提取正确作业图像的特征和多模态数据的特征，构建生成器，利用生成器根据正确作业图像的特征、多模态数据的特征以及随机生成的噪声生成违章作业图像，在生成违章作业图像时参考了正确作业图像的特征，可以保留作业人员核心特征，仅对其姿势和作业背景进行编辑，对违章行为图像样本进行生成，大大缩小了作业人员违章样本生成难度并使得生成的违章作业图像更加准确。电力运营商违规样本生成方法。该方法能够大大降低操作人员的违规样本的生成难度，并以准确的方式获取生成的违规图像。该方法包括建立能量多模图像配准大模型。 利用电力多模式图像配准大模型提取对应所述违章图像的正确操作图像的特征和违章多模式数据的特征，所述违章多模式数据为除图像模式数据外的任意模式违章数据。 根据所述正确作业图像的特征、多模态数据的特征和随机产生的噪声利用用于生成违规作业图像的生成器。 将生成的违规操作图像划分为操作背景生成图像和人员生成图像。 所述多模态数据分为场景描述和人员描述。 根据所生成的作业背景的图像与所述场景描述在图像空间中的距离，确定第一代损失。包括独立权利要求，用于：(1)电力运行人员违规样本生成装置； (2)一种计算机设备，包括存储器和处理器，用于执行电力作业人员违规样本生成方法; 以及(3)一种计算机可读存储介质，用于存储执行电力作业人员违规样本生成方法的一组指令。 0
本申请提供一种对话回复方法、装置、通信设备及可读存储介质，其中，所述方法包括：根据预训练的小样本学习模型对回复语料进行识别，获得至少一个第一回复模板；在所述至少一个第一回复模板中将与待回复信息匹配程度最高的第一回复模板确定为目标回复模板；将所述待回复信息填入所述目标回复模板，生成第一回复语句；将所述第一回复语句下发至用户端。利用小样本学习模型构建回复模板的方式，提高回复模板生成阶段的效率，降低回复模板的生成成本，同时使回复模板的生成过程具备可扩展性，以适配人机对话系统在业务增广或业务迁移过程中的需求变化。人机对话系统中恢复对话回复动作的方法。该方法利用小样本学习模型构建回复模板，提高了恢复模板生成阶段的效率，同时降低了回复模板的生成成本，使得回复模板的生成过程具有可扩展性，以适应人机对话系统在业务增强或业务迁移过程中的需求变化。该方法涉及根据预训练的小样本学习模型识别(101)返回语料库。 获取第一回复模板。 确定(102)与待返回信息匹配度最高的所述第一回复模板。 将所述待返回信息填充(103)至所述目标回复模板中，生成第一回复语句。 将回复句子发送(104)到用户终端。包括以下独立权利要求：(1)会话回复装置； (2)通信装置； 以及(3)存储用于恢复人机对话系统中的对话回复动作的程序的可读存储介质。  11
本发明涉及自然语言处理技术领域，尤其涉及一种基于层级编码的联合实体识别及关系抽取方法，包括采用预训练语言模型BERT编码词向量；构建类似LSTM门控机制；构建实体识别任务特征向量及关系抽取任务特征向量；将实体识别任务、关系抽取任务特征向量分别经线性层，进行实体识别及关系抽取的评分计算；将二分类交叉熵损失、二分类交叉熵损失和关系对称损失按照系数相加得到总损失；根据实体类型的预测分数和主语与宾语之间的关系类型为l的预测分数与阈值进行比较，得到最终三元组。本发明改善目前联合抽取的弱交互和单向交互的问题，并且解决无法识别出文本信息中存在的实体嵌套及关系嵌套的情况。基于分层编码的自然语言处理实体识别与关系抽取相结合的方法。该方法：改善了目前联合抽取的弱交互和单向交互的问题，解决了文本信息中的实体嵌套和关系嵌套无法识别的问题。 能够利用实体识别和关系抽取方法从非结构化文本中准确高效地识别结构化三元组。该方法包括使用预先训练的语言模型双向编码器表示从变换器(BERT)来编码词向量，并通过BERT模型输出文本词向量序列。 构建了一种门控机制，它类似于长短期存储器(LSTM)。 构建实体识别任务特征向量和关系提取任务特征向量。 获取的实体识别任务特征向量和关系提取任务特征向量分别经过线性层。 实体识别任务的两个分类交叉熵损失、关系提取任务的两个分类交叉熵损失和关系对称损失根据系数得到总损失。 通过损失训练模型。 将根据实体类型的预测得分和主语言与对象的关系类型1的预测得分与阈值进行比较，得到最终的三元组。  12
本发明提供一种基于T型注意力结构的医学图像分割方法。本发明提出了一种用于医学图像分割的改进的U‑Net模型，在U‑Net网络的解码网络结构中引入带有T注意力模块的门控注意力机制，在编码网络结构和解码网络结构中加入ResNet残差模块；通过带有T注意力模块的门控注意力机制，可以将浅层的输入图像的全局特征信息提取出来，解决了之前因为直接进行跳跃结构引起的图像特征不充分问题。并且T注意力模块之间共享模型参数，降低时间和空间复杂度。对于每一个卷积层，加入了残差模块，解决了训练过程中梯度消失和爆炸问题，网络训练时更容易优化。该方法对于基于T型注意力结构的医学图像分割是有用的。该方法：T个注意力模块之间共享模型参数，因此降低了时间和空间复杂度； 加入残差模块，解决训练过程中梯度消失和爆炸的问题； 并且在网络训练时更容易优化。基于T型注意力结构对医学图像进行分割，包括以下步骤：(1)对医学图像数据进行预处理和划分，得到训练集和测试集，(2)对U-Net网络进行改进，得到预测模型：在U-Net网络的解码网络结构中引入具有T个注意力模块的门控注意力机制，在编码网络结构和解码网络结构中加入ResNet残差模块，(3)将训练集数据输入到预测模型中进行训练，将训练集输入到预测模型中； 采用随机初始化和随机梯度下降优化方法，设定初始学习率、分割层学习率、动量、权重衰减系数，基于设定的训练策略进行训练并得到训练好的网络模型和(4)将测试集数据集输入预测模型，得到分割数据。   6
本发明涉及一种基于自然语言生成的中文隐写方法及系统，涉及信息安全、自然语言处理领域，该系统框架包括：将隐蔽信息嵌入相应的分组校验码；基于中文生成模型和隐蔽信息生成隐文；通过中文生成模型解码隐文为比特流集合；使用校验算法确定隐文提取结果。针对中文隐写的分词问题，本发明提出轻量级校验机制等系列创新，使接收方能够正确提取隐写方所写入文本的有效隐蔽信息，保证系统鲁棒性及计算可行性；本发明结合基于大规模语料库的中文预训练语言模型实现智能化自然语言生成，具有语料丰富多样、行文自然流畅等特征，有效提升隐文的嵌入率和隐蔽性。信息安全、自然语言处理领域中基于自然语言生成的中文隐写方法。该方法使得能够结合基于大规模语料的汉语预训练语言模型，实现具有语言学数据、线条自然流畅等多种特征的智能自然语言生成，有效提高隐藏文本的嵌入率和隐蔽性。 该方法保证了接收方的快速筛选，正确提取有效信息。 保证了系统鲁棒性和计算可行性。该方法包括通过大规模语料库执行汉语生成模型的训练。 将待嵌入的隐藏信息转换为比特流形式。 比特流形式按照特定规则进行分组。 在数据包的末尾添加相应的校验码。 得到具有校验功能的数据包比特流。 根据所述汉语言生成模型和所述比特流形式逐步生成短语。 构建候选池和候选短语概率分布。 根据编码规则在所述候选池中选择所述词组用于生成文本，直至达到所述结束条件。 形成完整的隐藏文字。还包括用于基于自然语言生成的中文隐写的系统的独立权利要求。  11
本申请公开了一种基于图卷积网络的方面情感分析方法及装置，方法包括：采用Bert模型编码处理；基于WC‑DE算法进行词序列增强；基于语法图卷积网络对编码词序列和增强词序列进行相关特征交换分析，得交换语法图表示；将交换语法图表示输入双仿射注意力网络层进行词对关系分析，得到邻接张量；依据邻接张量计算出节点聚合矩阵后，根据节点聚合矩阵、邻接张量和预设语言特性张量计算词节点表示和边表示；采用分类器链进行分类预测，得到标签概率分布；根据标签概率分布对目标文本句子进行三元组解码分析，得到情感三元组。本申请能解决现有技术忽略了文本之间的关联关系，导致结果不准确，无法满足实际情感分析需求的技术问题。用于解决现有技术中生成三元组的分析过程忽略了词与词、词与语言特征之间的关系，导致结果不准确，无法满足实际情感分析需求的技术问题的基于图卷积网络进行方面情感分析的方法。该方法使得能够解决现有技术忽略了文本之间的关联关系，导致结果不准确，无法满足实际情感分析需求的技术问题。该方法涉及利用Bert模型对目标文本语句进行编码，得到编码词序列。 通过WC-DE算法和随机位置张量对编码字序列进行增强。 根据节点聚合矩阵计算词节点表达式和边词表达式。 分类器链，用于根据所述词节点表示和所述边表达式进行分类预测，得到标签概率分布。 根据标签概率对所述目标文本语句进行三元组解码分析，得到情感三元组。 三元组提供有方面、意见和情感。独立权利要求还包括一种基于图卷积网络的方面情感分析装置。  12
本发明涉及一种基于微调BERT模型的电力零售套餐向量表示方法，属于结构化数据处理技术领域。该方法首先将使用结构化数据描述的电力套餐转换为使用非结构化进行描述的文本，使得该文本包含套餐的属性参数信息；然后通过预训练BERT模型微调后的结果对描述文本进行向量化；最终对向量化结果通过基于余弦相似度的计算来进行评估，之后便可以对电力套餐基于其向量表示进行聚类和用户推荐等操作，可大大提升电力零售平台的数据处理效率，易于推广应用。基于修整BERT模型的电力零售集餐向量表示方法。该方法能够在量化结果评价达到预设目的时，重新调整BERT模型，提高电力零售平台的数据处理效率，实现适用范围广。该方法涉及收集电力零售市场中的信息。 对收集到的信息进行过滤，去除标点符号、特殊符号、网页标签和随机码字符。 文本被调整到预训练BERT模型以微调所需的单个词形式。 将文本形式输入到BERT模型中进行训练。 在电力零售市场中收集电力套餐。 特征是在电套餐中提取的。 将结构化数据描述的特征转换为利用非结构化数据描述的文本。 使用非结构化描述对文本执行矢量化。 当量化结果评估达到预设目的时，重新调整所述BERT模型。 0
本发明涉及一种5G通信助理文本分类的方法、装置、电子设备及存储介质。5G通信助理文本分类的方法包括步骤：S1、对语料数据进行ASR转换，再对数据进行ETL数据清洗得到模型所需的原始语料数据集；S2、数据输入，将字向量、词向量和位置向量进行合并，生成训练数据，传递给BERT的嵌入层进行输出；S3、由分类模型分别进行训练；S4、结果融合，将由基于Attention机制改进的BiLSTM模型、Text CNN模型、DPCNN模型、Text RCNN模型输出的语义特征，分别输入至分类器层，得到分类场景下各分类类别的预测概率；S5、采用算数平均进行融合，输出分类结果。依据本发明的5G通信助理多场景语料数据进行文本分类的方法，可以解决分类正确率低的问题，并能够提升服务质量、挖掘数据潜在价值。用于通过电子设备对融合深度学习模型的第五代(5G)通信助理文本进行分类的方法(权利要求书)。所述5G通信助理多场景语料数据的文本分类方法能够解决分类准确率低的问题，并且能够提高服务质量，挖掘数据潜在价值。 融合模型可以利用各个模型的优势，提取多个方面的语义特征，保留更多的语义信息，具有更好的泛化能力，预测精度更高。 平衡网络深度的方法，采用Bert模型作为词嵌入层，能够在海量语言学数据的基础上运行自监督学习方法，为通信语言学数据学习更好的特征表示。该方法包括：对语料数据进行自动语音识别(ASR)转换，并对数据进行ETL数据清洗操作; 将词向量和位置向量进行组合，生成训练数据; 将训练数据通过双向编码器表示从变换器(BERT)的嵌入层输出; 将训练数据通过BERT的嵌入层输入到分类模型中，得到每个分类类别在分类场景中的预测概率，利用算术平均值进行融合，输出分类结果。独立权利要求还被包括用于：一种用于对5G通信助理文本进行分类的设备； 以及计算机存储介质，包括用于对第五代通信助理文本进行分类的指令集。  12
本发明涉及基于DCNN边界引导的遥感图像建筑物提取方法，包括步骤：获取遥感图像，使用编码器对遥感图像进行特征提取，从而得到多张特征图，编码器为主干子网络；使用解码器从多张特征图中检测建筑物边界特征和估计建筑物掩膜特征，所述解码器包括边界子网络、掩膜子网络；使用解码器将建筑物边界特征和建筑物掩膜特征进行融合，最终获取建筑物提取结果，编码器还包括细化子网络。本发明从边界子网络中检测建筑物边界特征，同时从掩膜子网络中估计建筑物掩膜特征；为了利用建筑物边界特征和建筑物掩膜特征之间的语义相关性，进一步通过细化子网络利用它们之间的互补信息，生成在建筑物边界处具有强烈响应的最终建筑物提取结果。基于深度卷积神经网络(DCNN)边界引导的遥感图像提取方法。该方法使得能够使用精细子网络之间的互补信息利用建筑物边界特征和建筑物掩模特征之间的语义相关性，因此生成在建筑物边界处具有强响应的最终建筑物提取结果。 该方法允许深度卷积神经网络(DCNN)同时提取建筑物的掩码和检测建筑物的边界，挖掘不同层次的语义信息，从而设计了并行的空洞卷积和全局平均池模块(PAGM)，用于提取不同空洞率的高级特征。该方法包括获得遥感图像。 利用编码器对所述遥感图像进行特征提取，得到多幅特征图像。 编码器是骨干网络。 通过使用解码器来检测建筑物边界特征并估计建筑物掩模特征。 估计来自多个特征映射的构建掩模特征。 解码器设有边界子网络和掩码子网络。 利用所述解码器对所述建筑物边界特征和所述建筑物掩膜特征进行融合，得到建筑物提取结果，其中，所述编码器还包括细化子网络。   6
本发明公开了一种基于BERT模型的反驳论辩语句检索方法及设备，所述方法包括：构造一个有着形式的数据集，其中是对应着论辩语句的语境语句，yi来标记第二个论辩语句是否是第一个论辩语句的反驳论辩语句；基于预训练模型提出了Bipolar‑encoder模型，用联合训练来衡量语境语句是否存在关联，并且衡量两个论辩语句是否互相反驳，若互为反驳论辩语句，它们应当主题相同但是有着不同的立场。本发明在没有主题先验信息的情况下同时考虑了主题相似性和立场不相似性，检索时渐进时间复杂度低，能够在大数据情况下继续保持良好效果与性能。基于双向编码器从变压器表示(BERT)模型的反向庇护变元句子检索方法。该方法能够在没有话题先验信息的情况下，考虑话题相似性和立场非相似性，使得搜索时渐进的时间复杂度较低，提高了大数据情况下的效果和性能。该方法包括构建训练数据组。 构建上下文相关层，用于获得两个争论语句的上下文相似度。 构建反向分类层。 建立反驳斥争论语句搜索模型。 采用训练好的反驳句搜索模型对争论句二元组进行处理。 反向驳斥分类层，用于获取反向驳斥度概率得分。 反向驳斥候选组的二元组被重新排序以获得所需的结果。 将字符串输入至对应的BERT模型。独立权利要求包括：(1)一种计算机设备，包括处理器和存储器，以执行用于执行基于BERT模型的反向庇护自变量语句检索方法的指令集； (2)一种计算机可读存储介质，用于存储用于执行基于BERT模型的反向庇护变元语句检索方法的指令集。  12
本发明提供一种用于小额贷款智能客服语义匹配的方法；包括S1：进入模型预训练阶段，对预设文档进行遮掩处理，将遮掩后的预设文档与没遮掩的预设文档输入BERT模型进行训练，得到训练后的匹配模型；本发明提供的用于小额贷款智能客服语义匹配的方法增强了BERT模型对小额贷咨询业务领域关键信息的建模能力，提升模型在语义匹配任务中的效果，相对于其他语义匹配技术，BERT模型可以学习到语义层的信息，支持数据并行处理，提高了语义匹配准确率，进一步的优化了模型，也降低了训练时间和成本。该方法对于使用基于双向长短期记忆(Bi-LSTM)的语义匹配系统来匹配小额贷款的智能客户服务的语义是有用的。该方法增强了BERT模型对小信用咨询服务领域关键信息的建模能力，相对于其他语义匹配技术提高了模型在语义匹配任务中的效果，支持数据并行处理。 该方法提高了语义匹配精度，优化了模型，降低了训练时间和成本。该方法包括：进入模型预训练阶段，对预置文件进行屏蔽处理，将屏蔽处理后的预置文件和未屏蔽处理后的预置文件分别输入到来自变压器(BERT)模型的双向编码器表示中进行训练，得到训练后的匹配模型; 进入模型调整阶段，获取互联网上关于微金融咨询业务的问题，对获取的问题进行处理并与标签进行匹配，形成调整后的语料，对训练好的匹配模型进行调整训练； 进入模型应用阶段，接收用户提出的问题，并将用户提出的问题与预设题库中的多个标准问题形成问题对，输入至调整后的匹配模型中计算相似度，得到相似度最高的问题对，根据相似度最高的问题对中的标准问题向用户反馈该问题的答案。还包括所述小额贷款智能客服语义匹配系统的独立声明。  12
本申请涉及一种变电站缺陷异常检测方法、装置和计算机设备。所述方法包括：获取变电站的采集图像；将采集图像输入异常检测模型，以获取针对采集图像的缺陷异常检测结果；其中，异常检测模型基于预训练模型迁移学习获得；预训练模型由自监督学习的网络模型训练获得，预训练模型的训练数据包括数据扩增处理生成的伪样本图像。采用本方法能够提升变电站异常检测效果。用于检测变电站中的缺陷和异常的方法，例如用于将高压电能转换成用于配电的低压电能的变电站。改进了变电站缺陷和异常检测的流程。该方法涉及获得(202)从变电站收集的图像。 将所采集的图像输入(204)异常检测模型，以获得针对所采集的图像的缺陷和异常检测结果。 所述异常检测模型是基于预先训练的模型通过迁移学习得到的。 所述预训练模型通过自监督学习的网络模型进行训练，所述预训练模型的训练数据包括通过数据增强处理生成的伪样本图像。独立权利要求包括以下内容：(1)一种变电站缺陷异常检测装置； (2)用于检测变电站缺陷和异常的计算机装置; (3)存储有用于检测变电站中的缺陷和异常的程序的计算机可读存储介质; 以及(4)用于检测变电站中的缺陷和异常的计算机程序产品。 0
本专利公开了一种基于多种实体上下文的实体对齐方法，主要处理因为实体结构异构性、实体属性异构性以及实体文本描述异构性引起的实体对齐困难问题。对于实体结构异构性问题，本专利使用TransE和RDF2Vec方法分别处理一跳和多跳结构信息，获取实体结构编码。对于实体属性异构性，本专利使用图卷积网络技术和图注意力机制，对每个实体按其属性的重要性提取其属性、属性值的信息，并映射到低维稠密的向量空间中。对于实体文本描述异构性，本专利使用预训练语言模型BERT获取文本语义信息，基于种子对齐实体信息进行模型的训练和学习，将实体的文本信息映射到低维稠密的向量空间。最后，本专利使用拼接技术和多视角技术对多种实体上下文进行联合对齐学习。基于多实体上下文的实体对齐方法。该方法使得能够处理由实体结构异构、实体属性异构和实体文本描述异构引起的实体对齐难题。该方法包括使用来自知识图谱关系三元组的TransE来学习实体的一跳结构信息。 从知识图谱关系三元组中利用TransE学习实体的一跳结构信息。 确定正样本的得分和负样本的得分。 确定负样本的一组误差三元集。 所述负样本是对所述正样本进行负采样得到的。 利用GCN模型学习三元属性组中实体的结构信息和内容信息。 利用预训练模型得到不同语言的文本信息。 得到所述待对齐知识图谱中所有实体的向量表示。 计算矩阵乘积，找出与每个实体最相似的实体。 最终得到最相似的实体对作为对齐实体。  12
本公开是关于一种基于预训练模型的任务规划与控制方法、装置、电子设备及存储介质。该方法包括：采集指挥人员的自然语言，并以自然语言作为输入，基于预设大语言预训练模型分析所述自然语言对应的任务，根据任务的任务类型，对任务进行拆解，生成任务拆解范式输出；以任务拆解范式作为输入，基于预设匹配方法，匹配任务拆解范式中所述任务对应的任务模型工具，生成任务工具确定范式，并将任务工具确定范式输出；以任务工具确定范式作为输入，调用任务工具确定范式对应的任务模型对所述任务进行处理，生成模型执行结果。本公开可减少指挥人员的重复性低效劳动，提高指挥效率，提高了模型的可扩展性与灵活性。基于预训练模型的任务规划控制方法。该方法减少了指挥人员的重复低效劳动，提高了指挥效率，提高了模型的可扩展性和灵活性。该方法涉及采集(S110)指挥人的自然语言，以自然语言为输入，基于预设的大型语言预训练模型分析自然语言对应的任务，根据任务的任务类型对任务进行拆解，生成任务拆解范式输出。 将任务拆卸范式作为输入(S120)。 通过任务工具确定范式输出。 将任务工具确定范式用作输入(S130)。 调用所述任务工具，确定与范式对应的任务模型，以处理所述任务。 生成模型执行结果。独立权利要求包括如下内容：(1)一种基于预训练模型的任务规划与控制装置； (2)电子设备； 以及(3)计算机可读存储介质，其存储用于基于预训练模型来规划和控制任务的程序。  11
本发明属于人脸识别技术领域，涉及一种基于特征扩充的单样本人脸识别方法。本发明基于迁移学习，采用了深度卷积神经网络提取具有鲁棒性的人脸特征，提出了一种特征空间的样本扩充方法：首先，基于迁移习，在多样本公共人脸集上训练一个深度卷积神经网络，并应用于目标人脸数据集，用预训练好的模型提取人脸特征；再利用辅助数据集的类内差异在特征空间扩充数据，然后用扩充后的数据训练分类器，获得更好的识别性能。同时这种基于特征空间的样本扩充方法克服样本不足的问题，比一般的图像域的数据增强更具潜力，提高了模型的识别率。基于特征扩展的单样本人脸识别方法。该方法避免了样本不足，实现了比一般图像域的数据增强更有潜力，从而提高了模型的识别率。该方法包括预处理人脸图像以检测人脸对齐。 使用已知的多样本面部数据集基于转移学习来预训练深度卷积神经网络(DCNN)模型，以学习面部嵌入空间。 将单样本数据集和通用数据集在深度卷积神经网络模型预训练完成后同时输入深度卷积神经网络模型。 对特征空间样本进行扩展。 将所述单个样本集特征扩展所述通用数据集特征的类内方差。 网络的softmax分类器的最后一层用扩展的特征样本来训练，以使用经训练的模型来识别单样本面部。 2
本发明提供一种基于最优运输规划的图自监督分类方法，涉及人工智能技术领域。该方法首先收集原始图数据，并对每个图数据进行图增强，生成两个扰动图，得到扰动图的图表示；再使用图神经网络作为编码器，生成图中各个节点的嵌入，得到扰动图的节点表示；然后对两个扰动图的图表示和节点表示分别生成最优运输概率矩阵；并以两个相同维度的最优运输概率矩阵为基础构建编码器的损失函数，将节点的向量表示空间与图空间对齐进行比较；重复执行该过程，直至损失函数收敛至数值稳定，获得扰动图的节点表示的编码器作为下游任务的预训练模型。该方法不依赖正负样本对的区分，不使用优化意义模糊的损失函数，能够在数据不完整的情况下表现出良好的性能。基于最优运输方案的图自监督分类方法，用于电子商务、交通、化学领域，如引文和社交网络或化学、医学等有知识需求的研究领域。该方法不依赖于正负样本对的差异化，不使用具有模糊优化意义的损失函数，在数据不完整的情况下能够表现出良好的性能。该方法包括收集原始图像数据。 确定所述图像数据的节点集合、相邻矩阵、节点的经验分布和节点属性特征矩阵。 对每个图数据进行图增强操作。 生成两个扰动图。 获得所述扰动图的图表示。 根据扰动图生成对应的节点表示。 对两个扰动图的图表示和节点表示生成最优传输概率矩阵。 基于两个相同维度的最优传输概率矩阵构建编码器的损失函数。   4
本发明提供了一种基于汉字和拼音信息融合的情感分析方法，首先将BERT模型拓展为双通道，分为汉字通道和拼音通道，在拼音通道通过本发明的拼音编码方式替换原始BERT模型的词嵌入编码方式，同时获得汉字通道BERT模型输入词向量，然后将获得的两种词向量输入到双通道BERT模型中进行预训练，最后将BERT模型训练出的词向量输出到双层Bi‑GRU模型中完成情感极性的分类。本发明中的编码方式与传统的编码方式相比占用更少的存储空间，表达的信息与内容更加丰富，同时结合汉字和拼音的双通道BERT模型增强了BERT模型对谐音字的语义识别能力。一种基于汉字与拼音信息融合的情感分析方法结合汉字和拼音的双通道BERT模型增强了对谐调词的语义识别。 本发明的编码方式比现有的编码方式占用更少的存储空间，信息和内容的表达更加丰富。该方法包括将由来自变压器(BERT)的双通道双向编码器表示训练的汉字拼音信息融合词向量输入到双层BIGRU模型中以训练情感极性分类模型。 情感极性由双层Bi-GRU模型输出。 省去了双通道BERT预训练模型和双层BI-GRU模型。 预测时输入的文本数据根据多音字规则生成多个汉语拼音编码序列对。 用相同数量的序列对生成模型。 将序列对分别输入到模型中。 最终预测结果取多个模型中预测概率最高的情感极性。  12
本发明属于语音识别技术领域，具体涉及一种语音识别预训练模型微调的方法及系统。包括以下步骤：步骤1：训练编码器解码器的语音识别模型；步骤2：对训练好的编码器解码器的语音识别模型做QLoRA微调。本发明的有益效果在于：与全量微调技术相比，本发明可以在消费级GPU上微调大型的语音识别模型，且性能没有损失。与adapter微调技术相比，没有增加模型层数，因此未引入额外的推理延迟。与LoRA微调技术相比，训练时GPU内存和存储进一步减小，且由于它在所有全连接层处都插入了适配器，增加了训练参数，因此弥补了精度带来的性能损失。一种用于精细调整在自动语音识别(ASR)领域中使用的经训练的编码器解码器的语音识别模型的预训练模型的方法。本发明在不增加模型层数的情况下，在GPU上对大型语音识别模型进行微调，避免了额外的推理延迟，从而减少了训练时GPU的内存和存储，增加了训练参数，从而补偿了精度带来的性能损失。该方法涉及训练编码器解码器的语音识别模型。 对训练后的编码器解码器的语音识别模型进行QLoRA微调处理。 利用QloRA对训练好的解码器进行语音识别。本发明还公开了一种用于对经训练的编码器解码器的语音识别模型的预训练模型进行微调的系统。 3
本发明公开了一种白细胞分割分类方法，包括获取多个RGB彩色血细胞图像，并将每个图像均转换为HSV彩色血细胞图像，分割每个HSV彩色血细胞图像中的明度、色调、饱和度三个分量，并将每一个分量的灰度图像均分成若干个大小相同的方形图像块；对每个方形图像块进行自适应Retinex校正；根据白细胞特征图像中的各类白细胞的特征，利用U‑net卷积神经网络进行白细胞分类模型训练，实现血细胞中的五类白细胞的分割分类。本发明通过直方图均衡化和Retinex理论融合的自适应Retinex方法，对血细胞图像进行预处理，加强单个白细胞间的不同特征，并消除采集时光照不均的问题，实现了精准的白细胞5分类的分割分类操作。一种医学图像处理领域的用于人体免疫系统的白细胞分割分类方法。本发明能够对血细胞图像进行预处理，增强单个白细胞的不同特性，消除采集时光照不均的问题，从而实现白细胞分类的精确分割分类操作。该方法包括获得多个红，绿，蓝(RGB)彩色血细胞图像，其中每个RGB彩色血细胞图像被转换为色调饱和度值(HSV)彩色血细胞图像。 RGB彩色空间图像是白细胞特征图像。 根据白细胞特征图像中各种类型白细胞的特点，利用U-网卷积神经网络训练白细胞分类模型，实现对血细胞中五种类型白细胞的分割和分类。   6
本发明公开了一种事件抽取方法、系统、存储介质以及设备。本发明通过匹配法对文本中的字符串进行匹配，得到候选事件元素，将候选事件元素输入到训练好的BERT序列标注模型中，得到候选事件元素的触发词以及触发词的特征并将两者输入到训练好的Argument Span模型中，得到事件元素；最后将触发词和事件元素进行组合，从而形成一个完整事件。本发明在进行事件抽取的过程中无需进行人工标注，利用匹配法来获取候选事件元素，利用机器学习来完成触发词和事件元素的抽取，将字符串多模匹配算法和机器学习相互结合完成了事件抽取，大大提高了事件抽取的准确率以及效率。针对预先训练的BERT序列标签模型和预先训练的幅角跨度模型的事件提取方法。该方法使得在事件提取过程中避免了人工标注，利用匹配方法获取候选事件要素，利用机器学习完成触发词和事件要素的提取，将字符串多模式匹配算法和机器学习相结合完成事件提取，大大提高了事件提取的准确率和效率。该方法包括获取文本中的待匹配字符串。 基于匹配方法对所述文本中的待匹配字符串进行匹配，得到候选事件元素。 在所述匹配处理之后，对所述字符串进行预处理。 将所述预处理后的字符串输入训练好的BERT序列标记模型。 获得所述候选事件元素的触发词和所述触发词的特征。 所述触发词与所述事件要素组合形成完整的事件。独立权利要求还包括：用于提取事件以预训练BERT序列标签模型和预训练的幅值跨度模型的装置； 以及存储介质，包括提取事件以预训练BERT序列标签模型和预训练变元跨度模型的指令集。  12
本申请公开了一种数据库管理系统、数据处理方法及设备，系统包括：包含n个模型的优化器、训练数据收集器、模型管理器、模型评估器。优化器，用于根据SQL语句，通过n个模型得到目标物理计划；训练数据收集器，用于根据数据库进程的运行数据构建m个训练集；模型管理器，用于采用目标训练集(属于m个训练集)对第一目标模型(属于n个模型，需满足预设要求，如性能下降)进行微调(finetune)得到第二目标模型；模型评估器，用于评估第二目标模型的性能，并在性能满足预设要求(如性能提升)时将第一目标模型更新为第二目标模型。本申请通过与机器学习结合，以实现自动执行数据库调优、更新及其他传统上由DBA执行的数据库管理任务的功能，无需人工干预。数据库管理系统，用于当前输出计算的计算机设备(要求保护的)中。通过结合机器学习技术，从而实现自动执行数据库优化、保护、更新等传统由DBA执行的常规数据库管理任务功能，无需人工干预。 数据库的正常运行时间，性能和安全受到灾难性的影响。该系统具有提供有n个模型(BB)的优化器，其中n大于或等于1。 所述优化器根据数据库的输入SQL语句，通过所述n个模型得到目标实物规划。 所述目标物理计划是所述物理计划用于执行所述开销满足所述训练数据采集器(1021)的第一预设要求。 根据数据库中进程的运行数据得到训练数据。 模型管理器(1022)，用于满足所述第一目标模型的第二预设要求的条件。 所述目标训练集被配置为与所述第一目标模型对应使用，用于对所述第一目标模型进行微调，得到所述第二目标模型。 所述模型评估器(1023)被配置为用于评估所述第二目标模型的性能。 满足第二目标模型的性能为第三预设要求。 将所述第一目标模型更新为所述第二目标模型。以下包括独立权利要求：一种数据处理方法； 计算机设备； 存储用于处理数据的程序的计算机可读存储介质； 用于处理数据的计算机程序产品； 以及芯片。  11
本发明涉及大语言模型技术领域，具体地说，涉及一种基于人工智能大语言模型平台的数据治理方法及系统。其包括数据处理平台以及优先级评估模块。本发明通过数据处理平台接收到预选取文本数据，结合用户提供的使用场景，规划不同处理方案，并记录各项处理方案对应的处理流程以及预选取文本数据处理结果，统计相同预选取文本数据中不同处理结果的选取率，通过优先级评估模块对相同预选取文本数据中不同处理结果进行优先级评估，后期遇到相同数据特征检索模式以及使用场景时，大语言模型会通过优先级给用户顺序推送处理结果，从而减少大语言模型处理方案流程，提高大语言模型响应速度。基于人工智能大语言模型平台管理数据的系统，用于处理文本分类、问答、对话等多个自然语言任务。大语言模型在后期满足相同的数据特征检索模式和使用场景时，可以通过优先级依次向用户推送处理结果，以减少大语言建模处理求解流程，提高语言模型的响应速度。 数据处理平台可以对同一预选文本数据中的不同处理结果进行优先级评估。该系统具有数据处理平台，其输出端与优先级评估模块(70)输入端连接。 优先级评估模块在选择率的不同处理结果中结合相同的预选文本数据。 对所选取的相同文本数据执行相同处理结果中相同选取率的选取速率。 结合处理结果中相同的选择率，对不同处理结果中的选择数据进行相同的优先级评估。 数据处理平台输出端连接有多个评估模块。 所述优先级评估模块结合所述同一预选文本数据在所述选择率不同的处理结果中，对所述同一预选文本数据不同的处理结果进行优先级评估。本发明还公开了一种基于人工智能大语言模型平台的数据管理系统的使用方法。  11
本公开关于一种关键词识别模型的训练、提取方法、装置、设备及介质，涉及自然语言处理领域，训练方法包括：获取文本样本集；将所述文本样本集中的各文本样本输入预训练后的语言模型进行单个字符类别预测，得到各所述文本样本对应的类别预测结果；确定各所述文本样本中每个字符的参考类别，得到各所述文本样本对应的类别标签结果；所述参考类别指示相应字符是否为多字关键词的边界字符；根据各所述文本样本的对应的类别预测结果和类别标签结果，计算得到损失数据；基于所述损失数据训练所述语言模型，得到文本关键词识别模型。利用本公开实施例提供的技术方案可以提升模型识别多字关键词的效率，以及提高从文本中提取关键词的效率。用于由电子设备训练文本关键词识别模型的方法(要求保护)。 使用包括但不限于智能手机，台式计算机，平板计算机，笔记本计算机，数字助理增强现实(AR)/虚拟现实(VR)设备，智能可穿戴设备和终端设备。本发明使得基于语言模型的文本关键词识别模型的训练过程能够在预训练后实现微调，使用少量经过监督训练的标记文本样本即可获得满足模型任务要求的性能，缩短了开发时间，提高了训练效率。 本发明能够实现文本关键词提取任务，提高关键词的识别和提取效率。该方法包括获得文本样本集。 文本样本集中的每个文本样本被输入到用于单字符类型预测的预训练语言模型中。 获得对应于每个文本样本的类型预测结果。 确定每个文本样本中字符的引用类型。 获得对应于每个文本样本的类别标签结果，其中参考类型指示对应的字符是否是多词关键词的边界字符。 根据对应的类别预测结果和每个文本样本的类别标签结果获得损失数据。 基于丢失数据训练语言模型以获得文本关键词识别模型。还包括独立的权利要求： (a)文本关键词提取方法； (b)文本关键词识别模型训练装置； (c)文本关键词提取装置； (d)计算机可读存储介质，用于存储用于训练文本关键词识别模型的一组指令； (e)用于存储用于提取文本关键词的一组指令的计算机可读存储介质。  11
本发明解决武器装备领域文本数据因其稀缺性，存在噪声大、句子短、质量差、不具备丰富的上下文语义等现象，利用多模态方法可有效提高实体识别的效果，包括以下步骤：由ResNet提取视觉特征，同时对图像进行分类；将分类标签在字典中的解释通过BERT得到向量信息，取到包含全部分类信息的[CLS]；由BERT提取整个文本特征，将含有分类信息的[CLS]替换文本向量的[CLS]部分，然后进行自注意力得到关注实体的特征向量；将两种模态处理好的特征向量进行跨模态注意，通过互注意力模块对两种特征向量进行交互感知；最后通过CRF层提取出实体。在武器装备多模态数据集上进行实验，表明本发明优于单文本模态和主流多模态模型，可实现对武器装备领域实体的有效识别。基于标签关注的武器装备领域多模态命名实体识别方法。多模态命名实体识别方法解决了武器装备领域文本数据的稀缺性，如噪声大、语句短、质量差、缺乏丰富的上下文和语义等问题。 多模态方法有效提高了实体识别的效果。 实验在武器装备多模态数据集上进行，表明该方法优于单文本模态和主流多模态模型，实现了武器装备领域实体的有效识别。该方法包括通过来自变换器(BERT)的双向编码器表示从字典中的分类标签的解释获得向量信息，并获得包含所有分类信息的[CLS]。 通过BERT提取整个文本特征。 将文本向量的[CLS]部分替换为包含分类信息的[CLS]，然后进行自我关注，得到感兴趣实体的特征向量。 对两种模态处理后的特征向量进行跨模态关注。 两个特征向量通过相互关注模块进行交互感知。 通过条件随机场(CRF)层提取实体。 根据训练数据训练网络模型并更新参数，然后提取测试集上的文本特征和视觉特征进行相互关注操作和测试。  12
本发明公开了一种少样本跨领域情感分析方法及装置，其中方法包括：获取句子数据，将句子数据输入训练后的BERT编码器，获得第一特征向量；将句子数据输入训练后的GCN编码器，获得第二特征向量；对第一特征向量和第二特征向量进行特征融合，获得句子的向量表示；将句子的向量表示输入到训练后的少样本原型网络模型，输出句子的情感极性；本发明利用少样本学习技术捕捉领域共享特征以及领域特定特征，从而提高模型从源领域迁移到目标领域的情感预测效果。本发明可广泛应用于自然语言处理技术领域。一种小样本跨领域情感分析方法。本发明通过使用较少的样本学习技术捕获领域共享特征和领域特定特征，提高了模型从源领域迁移到目标领域的情感预测效果。该方法包括获得句子数据。 该句子数据被输入到训练的BERT编码器中。 获得第一特征向量。 将句子输入训练好的GCN编码器以获得第二特征向量。 对第一和第二特征向量执行特征融合处理。 在训练之后，句子的向量表示被输入到小样本原型网络模型，以输出句子的情感极性。 获得预置的积极情绪和负情绪的标记样本。 获得已标记样本的句子向量表示。 对应的句子向量被映射到特征空间。 将由相同极性的句子向量表示的平均向量作为表示相应情感极性的原型表示。本发明还涉及一种小样本跨场情感分析装置。  12
本申请公开了一种专利文本实体的抽取方法、装置、设备及介质，根据权利要求文本中的权利要求主题、权利要求引用关系和权利要求序号生成至少一个三元组，并根据三元组生对应成权利要求主题的引用关系拓扑图；将各个引用关系拓扑图对应的权利要求文本输入至预训练模型bert中，生成第一实体对；按照引用关系将各个引用关系拓扑图对应的权利要求文本划分为至少一个技术方案块，并分别将技术方案块输入至预训练模型bert中，生成对应的技术方案实体对；对技术方案实体对进行拼接生成第二实体对；剪切融合第一实体对和第二实体对生成权利要求实体对。根据权利要求主题的整体文本和技术方案块文本提取实体对，使得生成的权利要求实体对具有更高的准确度。应用于笔记本电脑、台式电脑等终端设备等计算机设备(主张)的专利文本实体提取方法。由于通过将文本拆分成技术方案块的方式，将整个文本和技术方案块文本提取实体对输入到预训练模型bert中，使得每个技术方案的实体不会遗漏，然后将多个技术方案实体对进行拼接，使得得到的第二实体对更加准确。 根据所要求保护的主题的整个文本和技术块文本提取实体对，使得所生成的要求保护实体对具有更高的准确度。该方法涉及根据权利要求主题、相应的权利要求引用关系和权利要求文本中的相应的权利要求序号生成(S101)三元组。 根据三联组生成对应于所要求保护的主题的引用关系拓扑图。 将对应于每个参考关系拓扑图的权利要求文本输入(S102)到预训练模型bert中以生成第一实体对。 根据所述引用关系，将对应于每个所述引用关系拓扑图的所述权利要求文本划分(S103)到所述技术方案块中。 将所述技术方案块输入所述预训练模型bert中，生成对应的技术方案实体对。 将所述技术方案的实体对进行拼接(S104)以生成第二实体对。 对所述第一实体对和所述第二实体对进行切割和融合(S105)以生成权利要求实体对。包括以下独立权利要求：一种专利文本实体的提取装置； 计算机设备； 以及存储用于提取专利文本实体的程序的计算机可读存储介质。  11
本发明属于互联网信息抽取跟挖掘领域，公开了基于BERT跟LSTM的一种智能化网页信息抽取方法，包括以下步骤：S1、爬取网页；S2、网页预处理；S3、网页目标标注；S4、训练神经网络模型；S5、部署神经网络模型；S6、训练完成之后，使用得到的模型来对输入网页进行目标信息的识别。本方案在页面内容更新、网页结构变化后仍能够准确的定位信息，得到准确的抽取结果，从而实现智能化从网页抽取信息，降低网页信息抽取成本，提高网页信息抽取速度，经检测，模型对于训练集中的页面的识别准确率在98％以上, 召回率达到97％以上。一种基于BERT和LSTM的智能网页信息提取方法。本发明通过改变网页结构获得精确的提取结果后，能够对信息进行精确定位，从而智能地从网页中提取信息，降低了网页信息提取的成本，提高了网页信息提取的速度和训练集中页面布局的识别精度。本发明公开了一种基于垂直域的网页爬行方法，该方法通过对待提取的垂直域网页进行爬行，以3000个企业页面信息为训练集，以500个页面信息为测试集。 对网页进行预处理以清除无用的HTML标签。 根据人工规则自动标注网页目标。 通过初步建立词汇表来训练神经网络模型。 从网页中自动提取信息，评估模型的准确性和查全率。 训练操作完成后，利用得到的模型识别输入网页的目标信息。 根据文本节点的内容和上下文判断目标信息的类型。  12
本申请实施例公开了一种语句文本检测方法、系统、电子设备及存储介质。本申请实施例提供的技术方案，通过采用预训练后的语言表征模型来提取文本信息中的词语特征信息，并通过构建的句法分析模型来对文本信息进行句法结构解析得到语句主体结构，根据语句主体结构来加强语句文本中的关键部分词语的联结强度，降低语句中介词以及其他干扰词的影响，进而准确的捕捉句子的整体语义信息以确定是否违规。本申请实施例的方案能够实现更精准的违规语句检测。检测句子文本的方法。本发明通过对文本信息的语法结构进行分析，根据句子主体结构，通过降低句子中介词等干扰词的影响，增强句子文本中关键词的连接强度，从而准确地捕捉到句子的语义信息是否违规，实现了更加准确的违规句子检测。该方法包括获取用户输入的文本信息。 通过预先训练的语言特征模型提取所述文本信息的词特征，得到对应的词特征信息。 根据所述句法分析模型对所述文本信息的句法结构进行分析，以确定所述文本信息的句子主体结构。 通过根据所述句子主体结构在所述文本信息中确定对应的主体位置，根据所述句子主体结构和所述词语特征信息确定文本检测结果。包括以下独立权利要求：句子文本检测系统； 句子文本检测电子设备； 以及存储检测句子文本的指令集的存储介质。  11
本申请提出一种代码生成方法和装置、电子设备、非瞬时性计算机可读存储介质，所述代码生成方法包括构建符合预设的工控国际标准语言的结构化文本代码数据集；利用所述结构化文本代码数据集对预设的模型进行训练；根据用户的输入数据，利用训练后的所述模型生成符合所述工控国际标准语言的结构化文本代码。根据本申请的实施例，首先构建符合工业控制领域国际标准的结构化文本代码数据集，并利用构建的结构化文本代码数据集对基于大模型的情景式代码自动生成模型(也即，开源低参数量大模型)进行训练，以使得基于大模型的情景式代码自动生成模型能够输出符合标准的结构化文本语言代码。用于在电子设备中生成代码的方法(要求保护)。该方法使得利用结构化文本代码数据集对基于大模型的场景类型代码自动生成模型进行训练，使得基于大模型的场景代码能够按照标准自动生成模型输出结构化语言代码。该方法涉及根据预设的工业控制国际标准语言构建结构化文本代码数据集。 利用所述结构化textcode数据集训练预设模型。 所述结构化码是根据用户的输入数据，根据用户的输入数据，按照训练好的模型生成的。 使用所述训练模型的结构化代码，根据工业控制语言生成所述结构化代码。独立权利要求还包括用于：代码生成装置； 以及一种非暂态计算机可读存储介质，其包括用于在电子设备中生成代码的指令集。  11
本申请提供训练向量转换模型、转换语义向量的方法及装置，该方法包括，按照预设概率从文本集合中选择目标文本，得到前缀样本，其中，前缀样本为目标文本或者文本集合中的非目标文本；将前缀样本输入生成式预训练模型，得到衔接样本，其中，衔接样本携带一个衔接样本和目标文本是否存在语义蕴含关系的标签，当前缀样本为目标文本时，衔接样本和目标文本存在语义蕴含关系；通过衔接样本和目标文本对应的目标文本向量对主网络和辅助网络进行训练，得到向量转换模型。通过该方法可以达到准确的将文本转换成文本向量的效果。训练向量转换模型的方法。通过概率选取目标文本，以及选取的用于训练主网络和辅助网络的连接文本对应的前缀样本，通过自学习和辅助网络辅助的方式使得主网络学习根据文本和文本的内容分析文本的含义，从而通过得到的向量转换模型得到文本向量表示，能够准确地将文本转换为文本向量效果。 主网络在后续对文本转移向量进行更准确的预训练。该方法包括按照预设概率从文本集合中选择(101)目标文本，以获得前缀样本，前缀样本为文本集合中的目标文本或非目标文本。 将前缀样本输入(102)到生成的预训练模型中以获得连接样本。 在所述前缀样本为所述目标文本时，所述连接样本携带有所述连接样本与所述目标文本之间是否存在语义暗示关系的标签，所述连接样本与所述目标文本之间存在语义暗示关系。 通过所述连接样本和所述目标文字对应的目标文字向量训练(103)主网络和辅助网络，得到向量转换模型。以下包括独立权利要求：用于转换语义向量的方法； 用于训练向量转换模型的装置； 语义向量转换装置； 以及电子设备。  12
本发明公开了一种基于频域信息与生成对抗网络的伪造图像检测方法及系统，涉及图像处理及深度学习技术领域，该方法包括：获取目标图像；所述目标图像为人脸图像或者自然场景图像；将所述目标图像从图像空间转换到频域空间，以得到目标频谱图；将所述目标频谱图输入到伪造图像检测模型中，以确定所述目标图像的判别结果；所述判别结果包括真实图像和伪造图像；其中，所述伪造图像检测模型的网络结构为生成对抗网络；所述生成对抗网络包括生成器和鉴别器；所述鉴别器采用U‑Net结构。本发明不仅能够对伪造人脸图像进行检测，而且还可以对自然场景伪造图像进行检测。基于频域信息和生成电阻网络的假冒图像检测方法。所述方法能够获取所述目标图像，所述目标图像为所述人脸图像或所述自然场景图像，以增强所述鉴别器的鉴别能力，检测出伪造的人脸图像和自然场景伪造图像。该方法包括获取目标图像，该目标图像为人脸图像或自然场景图像。 将所述目标图像从图像空间转换到频域空间，得到目标频谱图。 将所述目标光谱图像输入假冒图像检测模型，确定所述目标图像的判断结果。 所述判断结果为真实图像和伪造图像。 利用所述假冒图像检测模型的网络结构生成反制网络。 生成防伪网络包括生成器和鉴别器。一种基于频域信息和生成电阻网络的假冒图像检测系统包括一种基于频域信息和生成电阻网络的假冒图像检测系统。   6
本发明涉及自然语言处理，提供一种文档检索方法、设备及介质。本发明通过获取被检索文档的多层级跨句语义信息，能够挖掘到被检索文档在单词级、句子级再到文档级层面的内在语义的联系，并提取跨句语义信息，为后续在预训练语言模型中进行匹配提供了更为全面的文档特征；通过对模型采用不同比例掩盖处理方式进行预训练，使得模型能够对文档中的单词采用不同的掩盖处理方式，有利于捕捉更重要的内在联系；通过为模型输入被检索文件的多层级跨句语义信息，并结合模型的不同比例掩盖处理方式进一步挖掘语义内在联系，使得模型所得到的特征相似度更为精确，匹配结果也更加准确。此外，本发明还涉及区块链技术，上述被检索文档可存储于区块链中。方法进行文献检索。模型特征相似度更准确，匹配结果更准确。该方法包括获得(S10)在整合检索到的文档之后获得的检索到的文档矩阵并且基于检索到的文档矩阵提取检索到的文档的多级跨句子语义信息，以获得包含多级跨句子语义信息的第一输入向量。 获取预设的检索文档库中的若干检索文档的包含多级跨句语义信息的第二输入向量集(S20)。 将所述第一输入向量和所述第二输入向量集作为采用不同比率掩蔽处理方法训练的预训练语言模型的输入。 获取所述第一输入向量和所述第二输入向量集的特征相似度，以基于所述特征相似度确定与所述检索文档匹配的目标检索文档。包括以下独立权利要求：一种用于文档检索的装置； 以及存储用于文档检索的程序的计算机可读存储介质。  11
本申请公开了一种电池包强度的确认方法，属于电池包强度计算技术领域，本申请提供的电池包强度的确认方法包括在电池包的装配模型中获取超级子模型，通过电池包的参数信息和工况信息将装配模型与超级子模型进行匹配，将匹配结果与超级子模型进行结合，以确定目标电池包的强度；本申请通过整体装配模型中的局部超级子模型进行求解，以超级子模型为计算基础，结合电池包各处的受力情况，通过超级子模型计算电池包各处的受力情况，即可得出电池包各处的强度信息，相较于对电池包的整个大模型进行强度计算，采用超级子模型可有效减少计算区域和部位，减少计算时间。电池包强度确认方法，用于确认目标电池包的强度。结合电池组的受力情况，通过超子模型计算电池组的受力情况，得到电池组的强度信息。该方法涉及基于目标电池包的装配模型获取(1)目标电池包的超级子模型。 基于所述参数信息和所述目标电池组的工况信息将所述装配模型与所述超级子模型进行匹配(2)，得到匹配结果。 基于匹配结果和超级子模型确定(3)目标电池组的强度。 获取所述关注区域的目标边界。 基于所述目标边界进行区域分割，得到区域子模型。 对区域子模型进行模型细化，得到超子模型。  11
本发明公开了一种基于XLNet和Longformer的集体实体消歧方法，包括生成候选实体步骤：对于给定的一个提及，从知识库中生成包含若干个候选实体的候选实体集，以此来控制候选实体的数量。获取消歧序列步骤：将所有待消歧提及按照消歧难易程度进行排序，形成消歧序列；执行序列消歧步骤：将消歧序列中的提及依次解析得到对应的目标实体。本发明基于XLNet和Longformer构建了一个集体实体消歧模型，将实体消歧视为序列决策任务，同时结合局部特征和全局一致性，并利用已消歧实体所包含的丰富知识实现集体实体消歧，实现了更高的性能和更快的推理速度。基于XLNet和Longforor的集体实体消歧方法，用于舆情分析、事件检测、新闻推荐。该方法构建了基于XLNet和Longformer的集体实体消歧模型，从而实现了更高的性能和更快的推理速度。 该方法结合局部特征和全局一致性，利用消歧实体所蕴含的丰富知识实现集体实体的消歧，因此提高了方法的性能和推理速度。所述集体实体消歧方法是根据消歧难易程度对所有待消歧的参考文献进行排序，形成消歧序列。 依次对消歧序列中的所有引用进行分析，得到对应的目标实体。 候选实体集合是在命名字典模式的基础上生成的。 利用维基百科中包括实体页面、重定向页面和消歧页面的信息构建名称字典。 重定向页面包括实体别名和页面，页面与对应的实体页面链接。  12
本公开提供一种预训练语言模型的训练方法、语言模型的训练方法及装置，包括：获取样本文本，根据样本文本执行预训练任务中的至少两种，得到预训练语言模型，其中，预训练任务包括：前向因果语言建模任务、反向因果语言建模任务以及掩码语言建模任务，前向因果语言建模任务为由样本文本中在前的词预测样本文本中在后的词的建模任务，反向因果语言建模任务为由样本文本中在后的词预测样本文本中在前的词的建模任务，掩码语言建模任务为由样本文本中非掩码位置的词预测样本文本中掩码位置的词的建模任务，可以实现从多个维度进行预训练，从而实现训练的多样性和灵活性，且可以使得从多个维度训练得到的预训练语言模型具有较高的准确性和可靠性。一种自然语言处理任务的预训练语言模型的训练方法。 使用包括但不限于对话系统，机器翻译，文本摘要，信息检索和标题生成。通过多维度训练得到的预训练语言模型具有较高的准确性和可靠性。 反向因果语言模型任务和掩码语言模型任务在至少两次预训练任务训练中得到预训练语言模型的技术特征， 可实现从一组维度进行训练，实现训练的多样性和灵活性，提高训练的可靠性和准确性。该方法包括获得样本文本。 根据样本文本执行预训练任务以获得预训练语言模型。 预训练任务具有正向因果语言建模任务，反向因果语言建模任务和掩码语言建模任务。 反向因果语言建模任务由文本中的非掩码位置的词来预测。本发明涉及一种用于语言模型预训练的训练装置。 (4)一种电子设备，包括存储器和用于预训练语言模型的训练的处理器； (5)计算机可读存储介质，用于预训练语言模型的训练； (6)用于预训练语言模型的训练的计算机程序产品。  11
本发明公开了一种基于特征增强与重建的小目标快速检测网络方法，该方法采用(UNET)作为基础架构，以逐像素的方式检测小物体。为了提高对小目标的识别精度，提出了一种亚像素卷积来丰富特征图信息并使用空洞卷积块和SE注意力机制解决小物体的尺度变化。本发明可以提高目标检测器的检测小目标性能。民用和军事领域的无人机，航空，卫星对地观测任务基于U网目标探测器的小目标探测方法。该方法通过提供亚像素卷积来丰富特征地图信息，并利用空腔卷积块和SE注意机制来解决小目标的尺度变化，从而提高小目标的识别精度， 从而提高了目标探测器的探测小目标性能。 本发明使得U-NET跨层连接增强了抓取上下文信息的能力，使得对象大小变化大。所述方法包括获得训练图像数据和预处理所述训练图像数据。 U-NET网络框架由编码器，网络底层块和解码器三部分组成。 训练图像数据被输入到建立的U-Net网络中，用于训练以增强数据特征。 编码器具有编码块。 通过在编码块的池层之后使用子像素卷积来恢复小对象特征细节。 解码器具有解码块。 输入测试图像以基于训练的网络进行检测以获得最终的小目标检测结。   6
基于BERT‑TextCNN的复杂装备制造BOM智能分解方法，包括以下步骤：首先，通过类别标注、语义扩充、去除停用词等3个步骤对制造BOM进行文本预处理；其次，通过嵌入标记法、MLM和NSP机制对预处理后的BOM文本语句进行向量化描述；最后，利用BERT‑TextCNN对向量化的BOM文本语句进行特征提取和分类，按照必须自制件、必须外协件、非必须自制件、非必须外协件的四种类型实现对复杂装备制造BOM智能分解；具有成本低，效率高的特点。基于语义计算的复杂设备制造BOM的智能分解方法制造BOM智能分解，成本低，效率高。该方法包括通过类别标记，语义扩展和停止字的去除来执行制造BOM的文本预处理。 BERT-TextCNN被提供来提取和分类矢量化的制造BOM文本语句。 文本特征提取层分为卷积和合并两部分。 提供核心函数以提取向量并制造由BOM中的工件所描述的向量特征。 提供卷积运算以描述来自输入的固定长度工件的向量序列。 提取伪影描述向量的主要特征。 提供合并操作以将主要特征组合成高级特征。  12
本申请公开了一种跨模态图文匹配训练方法及装置、存储介质、电子设备，该方法包括将待训练图像输入至图像编码器，由图像编码器对待训练图像进行编码，得到待训练图像的图像向量特征；将待训练图像的图像内容的描述作为文本输入文本编码器，文本编码器对文本进行分词，将文本转换成token向量，将token向量进行基于transformer的文本编码处理，得到编码为与图像向量特征的维度相同的文本向量特征；训练达到所选取的样本数后，图像编码器和文本编码器分别对图像向量特征和文本向量特征进行模态交互，利用反向梯度更新图像编码器和文本编码器模型参数。本申请支持更精确和个性化方式进行图文匹配联合检索。一种用于电子设备的跨模式深度学习技术的跨模式图文匹配训练方法(要求保护)。 用途包括但不限于字幕生成、视觉问题、视觉对话、文本检索和基于文本的图像生成领域。该方法能够实现多模式的图文匹配训练表达，方便图像搜索领域。 该方法支持更准确、个性化的方法进行图文匹配联合搜索。该方法包括将待训练图像输入到图像编码器。 基于对文本的文本编码处理，将文本转换为令牌向量。 得到与图像向量特征的维度相同的文字向量特征。 所述图像向量特征和所述文字向量特征在训练达到选定的样本数量后，相互模态交互。 计算向量的余弦相似度和交叉熵损失。 通过使用反向梯度来更新模型参数。独立权利要求还包括：一种跨模式图文匹配训练装置； 以及一种可读取的非临时存储介质，包括一组用于跨模式图文匹配训练方法的指令。 14
基于机器阅读理解和因子图注意力机制的事件检测方法，其步骤为：步骤1首先在模型的输入序列中引入预先设计好的触发词问题模板等和触发词相关的先验信息；步骤2利用预训练语言模型BERT对输入序列进行向量表示；步骤3利用因子图注意力网络对输入序列中的不同组成单元进行语义交互；步骤4将触发词识别及分类转化为传统的序列标注任务，利用多类型分类器识别并分类待检测文本中的单词。本发明通过上述结构，提供了一种利用相应的先验知识辅助事件检测，同时增加图注意力机制来优化触发词识别能力的方法，提升了事件检测的准确性。基于机器阅读理解和因子图注意力机制的事件检测方法，用于识别文本中的事件触发词和划分事件类型，在信息检索和自动摘要等领域具有广泛的应用。该方法通过使用相应的先验知识辅助事件检测，优化了触发词的识别能力，并增加了图注意力机制Cato，提高了事件检测器的准确性。该方法涉及使用多类型分类器对待检测文本中的词进行识别和分类。 将预定义的事件类型映射为触发词分类标签。 将触发词识别分类转化为传统的序列标记任务。 设置分类标签。 对所述待检测文本中的词语进行识别分类。 采用预先训练的语言模型对输入序列进行向量表示。 通过简单的编码器得到输入序列的动态向量表示。 利用因子图注意力网络对所述输入序列进行语义交互。  12
本发明提供了一种基于AIGC技术的拜访陈列指引建议生成方法及系统，所述方法包括：获取移动终端上传的门店的商品陈列的图像数据，并使用预设的商品陈列识别模型对所述图像数据进行识别，获得所述门店商品陈列的总结文本。然后以预设的提示词格式将所述总结文本与所述门店的陈列协议、所述门店的历史商品销量报告组合成提示词，并将其输入预设的LLM模型，使LLM模型生成相应的商品陈列建议。最后将所述商品陈列建议传回所述移动终端进行展示。相比于现有技术，本发明简化了在快消领域中从陈列拜访核查到给出陈列指引建议流程的一系列流程，使得业务员仅需拍摄上传商品陈列图像即可获得相应的商品陈列建议，提高了业务员的业务拜访效率。一种基于人工智能生产内容(AIGC)技术的快速消费行业和商店的参观展示指南建议生成方法。简化了快拆领域从展示访问检查到展示引导建议流程的一系列流程，使得业务员仅通过拍摄上传的商品展示图像即可获取对应的商品展示建议，提高了业务员的服务访问效率。该方法涉及获取(S1)移动终端上传的商店的商品展示的图像数据。 根据预设的商品展示识别模型对所述图像数据进行识别(S2)，得到商品展示的摘要文本。 将带有门店展示协议的摘要文本和门店历史商品销售报告组合(S3)成预设提示词格式的提示词。 将所述提示词输入(S4)所述预设LLM模型，获取与所述店铺商品展示相对应的商品展示建议，并将所述商品展示建议传回所述移动终端。 LLM模型是基于产品展示相关的语料数据对初始LLM模型进行训练得到的。包括独立权利要求的一种基于AIGC技术的来访显示指南建议生成系统。 1
本发明公开了一种基于大语言模型的多层级可视化评估报告生成方法、装置、计算机设备及存储介质，其方法实现，包括：采集基础数据，并按照预设切分规则对所述基础数据进行任务切分，得到切分后的数据，作为训练样本数据；通过所述训练样本数据对待训练模型进行迭代训练，直到当前迭代符合预设迭代终止条件时，得到目标模型；基于所述训练样本数据，构建目标领域知识向量数据库；基于所述目标领域知识向量数据库，获取提示词向量，将待分析数据以及所述提示词向量输入至所述目标模型中，得到目标评估报告。无需人工编撰，且可提高评估报告生成效率以及准确性。基于大型语言模型的多级可视化评价报告生成方法。该方法无需人工编写，提高了评估报告的生成效率和准确性。该方法包括收集基本数据。 根据预设的切分规则对所述基础数据进行任务切分，得到切分后的数据作为训练样本数据。 通过所述训练模型数据对待训练模型进行迭代训练，直至当前迭代满足预设的迭代结束条件。 基于训练样本数据构建目标领域知识向量库。 基于所述目标领域知识向量库获取提示词向量。 将所述待分析数据，以及对所述目标训练模型的提示词向量输入，得到目标评价报告。独立权利要求书包括用于：(1)基于大型语言模型的多层次可视化评估报告生成系统； (2)计算机装置； (3)一种可读存储介质，用于存储计算机可读指令。  11
本发明公开了一种基于自适应多特征融合的双重图像退化修复方法，包括：搭建修复网络，选择带有椒盐噪声或高斯噪声的图像作为所述修复网络的输入图片；输入图片首先经过自引导模块去除杂点噪声，同时提取输入图片的多维特征；自适应多特征融合模块通过模拟人脑视觉皮层的神经元的工作机制，将来自于自引导模块的多维特征自适应调整并传送到修复网络后端；中间图像联合自适应多特征融合模块提取的特征使用基于U‑net的编码解码器结构恢复图像颜色，其中编码解码器的最底端使用带有空洞卷积的残差模块提取深层特征，解码器部分使用双线性上采样操作还原图像分辨率，以避免传统转置卷积出现的棋盘伪影现象；本发明能够自动实现图像的精准着色和修复。基于自适应多特征融合的双图退化复原方法。该方法能够自动实现图像的精确着色和修复。该方法涉及构建修复网络，选择带有椒盐噪声或高斯噪声的图像作为修复网络的输入图片。 首先通过用于同时提取输入图片的多维特征的自引导模块去除输入图片的杂点噪声。 通过自适应多特征融合模块模拟人脑视皮层神经元的工作机制，自适应调整多维特征并将其从自引导模块传输到修复网络的后端。 利用中间图像联合自适应多特征融合模块提取的特征，采用基于U-net的编解码结构恢复图像颜色。   6
本发明公开了一种结合视觉大模型的智能交互式遥感信息提取方法及系统，涉及人工智能技术及遥感技术领域，方法包括：利用训练好的MAE模型和训练好的SAM模型，对通用非监督语义分割网络进行参数初始化，对预处理后的待提取遥感影像标记多个第一提示信息；对预处理后的待提取遥感影像构建提示信息采样网格，得到每个第二提示信息对应的掩膜，以每个掩膜为边界，对预处理后的待提取遥感影像进行裁剪，得到多个切片并分组，进行特征映射以及阈值判断后，确定最终结果，本发明能够提升遥感解译智能化水平。结合大视觉模型的智能交互遥感信息提取方法。该方法提高了遥感解译的智能化水平。该方法涉及构建(S1)通用的无监督语义分割网络。 对预处理后的待提取遥感影像构建提示信息采样网格。 获取所述第二提示信息对应的蒙版。 所述提示信息采样网格中每个交点的绘制坐标分别为一个第二提示信息。 将预处理后的待提取遥感影像以每个掩膜为边界进行裁剪(S2)得到多个切片。 将具有第一提示信息的切片划分(S3)为目标分组。 将没有第一提示信息的切片划分为背景组。 基于所述剪辑模型对所述目标组和所述背景组进行所述特征映射(S4)。 计算所述目标组与所述背景组中每个掩膜的相似度。 提取相似度大于设定阈值的mask作为最终结果。独立权利要求书包括以下内容：一种结合大型可视化模型的智能交互式遥感信息提取系统； 计算机装置； 以及存储有结合视觉大模型的智能交互遥感信息提取程序的计算机可读存储介质。   6
本发明涉及一种基于Voronoi多边形与Hilbert曲线编码的隐私保护查询方法，包括以下步骤：服务器端对目标对象所在平面进行Voronoi多边形划分，并利用Hilbert曲线进行划分编码，构建映射Hilbert单元格编码和Voronoi多边形的B+树索引；用户通过客户端向服务器提交自身位置p的Hilbert曲线编码值H(p)进行k近邻查询；服务器端在索引树上查找H(p)对应的Voronoi多边形C，生成C的最小外接矩形R；服务器端查找R的k‑1近邻Voronoi多边形，并将这些Voronoi多边形对应的Hilbert曲线编码值组成候选查询结果集合CaS，返回客户端；用户对CaS中的Hilbert曲线编码值进行解码，筛选出最近邻目标对象。实现保护位置隐私的k近邻查询。基于Voronoi多边形和Hilbert曲线的代码隐私保护查询方法。该方法能够以有效的方式提高隐私保护查询效率。该方法涉及在服务器上存储平面的二维(2D)位置坐标以执行Voronoi多边形划分过程。 Voronoi图设置在POI点处。 对象构造过程的希尔伯特曲线参数在曲线起始点处执行。 以一个希尔伯特值点为单位间隔，获得一个坐标点的希尔伯特编码值。 在客户端和服务器端之间编码有希尔伯特曲线函数。 根据目标搜索结果计算邻居位置坐标与位置之间的最小欧式距离。  12
本申请提供了一种基于大语言模型的导购方法和系统，该方法应用于人工智能技术领域。该方法包括：获取用户端输入的导购需求和所述导购需求携带的内容增强配置；对所述导购需求进行自然语言理解，得到需求理解结果；基于所述需求理解结果和所述内容增强配置，生成描述所述导购需求的提示词；采用预设大语言模型对所述提示词进行语言处理，生成并输出所述导购需求对应的目标导购信息至所述用户端。该方法既能够节省用户决策时间，还能够为用户端提供更加贴合用户端自然语言的目标导购需求。基于大语言模型的导购方法。该方法节省了用户的决策时间，为用户提供了更贴合用户自然语言的目标导购需求。该方法包括获取(S201)用户侧输入的导购需求以及导购需求携带的内容增强配置。 对所述导购需求进行自然语言理解(S202)，得到需求理解结果。 基于所述需求理解结果和所述内容增强配置，生成描述所述导购需求的提示词(S203)。 采用预设的大语言模型对所述提示词进行语言处理，生成并输出与对用户侧的导购需求相对应的目标导购信息。 采用所述预设的大语言模型对所述提示词进行语义分析，以确定响应所述导购需求所需的应用程序接口。本发明还公开了一种基于大型语言模型的导购系统。  11
本发明公开了一种语音唤醒与检测模型的生成方法、装置、设备及介质，方法包括：获取第一语音数据集和第二语音数据集，第一语音数据集为无标注语音数据集，第二语音数据集为基于语音合成技术生成的语音数据集；将第一语音数据集输入至预构建的语音模型中，采用自监督预训练的方式对语音模型进行训练，生成语音预训练模型；将第二语音数据集输入至语音预训练模型中，对语音预训练模型进行多任务学习训练，生成语音唤醒与检测模型，多任务学习训练包括语音检测训练和语音唤醒训练。本发明通过上述方式，即可通过无标注的方式实现唤醒，降低唤醒对人工标注的依赖性，从而使得唤醒成本变低。用于由计算机设备生成语音唤醒和检测模型的方法(要求保护的)。该方法能够通过非标注方式实现唤醒，降低唤醒对人工标注的依赖，从而降低唤醒成本。所述方法包括：获取第一语音数据集合和第二语音数据集合，其中，所述第一语音数据集合为未标记语音数据集合，所述第二语音数据集合为基于语音合成生成的语音数据集合。 将所述第一语音数据集合输入预先构建的语音模型。 对自监听中的语音模型进行训练，生成语音预训练模型。 将所述第二语音数据集合输入所述语音预训练模型。 对所述语音预训练模型进行多任务学习训练，所述多任务学习训练包括语音检测训练和语音唤醒训练。 生成语音唤醒及检测模型。独立权利要求还包括用于：一种用于由计算机设备生成语音唤醒和检测模型的装置； 以及计算机可读存储介质，用于存储用于由计算机设备生成语音唤醒和检测模型的指令集。 3
本申请公开了一种文本分析模型的训练方法、装置、设备及存储介质，涉及人工智能技术领域。该方法包括：获取多个不同的文本分析任务各自的训练数据，将上述多个不同的文本分析任务各自的训练数据进行混合，得到多任务训练数据，采用该多任务训练数据对预训练的大语言模型进行调整，将调整后的大语言模型作为文本分析模型。该方法实现了通过使用多任务训练数据对同一个预训练的大语言模型进行训练，得到一个能执行不同文本分析任务的文本分析模型，使对文本分析模型训练的过程更佳精简，减少了模型训练消耗的时间。针对不同的文本分析任务训练文本分析模型的方法。该方法实现了利用多任务训练数据对同一个预先训练的语言大模型进行训练，从而得到能够执行不同文本分析任务的文本分析模型。 简化了训练文本分析模型的过程，以减少训练分析模型的时间。该方法涉及获取(210)多个不同文本分析任务的各自的训练数据。 每个文本分析任务的训练数据包括与该文本分析任务相关的提示信息和标注回复结果。 所述提示信息用于指示与所述文本分析任务相关的文本内容，针对所述文本内容执行所述文本分析任务。 将各个所述不同文本分析任务的训练数据进行混合(220)，得到多任务训练数据。 采用所述多任务训练数据对所述预先训练的语言大模型进行调整(230)。 将调整后的大型语言模型作为文本分析模型。 所述文本分析模型用于执行所述不同的文本分析任务。独立权利要求包括用于：(1)文本分析模型的训练装置； (2)计算机装置； 以及(3)计算机可读存储介质，其存储有用于训练文本分析模型的程序。  11
本发明中提出的一种基于卷积神经网络的图像像素分类方法，其主要内容包括：数据输入、预处理、核心抽样、像素预测、输出结果，其过程为，输入图像首先被叠加在一起并调整为统一大小后被输入到预训练模型，获取对应每个图像的每一像素生成的中间映射，同一像素对应的多个中间映射形成皮层柱；接下来，从皮层柱的集合中随机抽取样本，并将得到的核心样本反馈到第二阶段的深度置信网络；然后网络对核心样本进行像素预测；最后，根据当前任务的不同输出不同的结果。本发明在图像分割方面，与现有的技术相比，它有助于产生细粒度分割；使用预训练的VGG 16模型，提高了整体性能，加快训练速度，另一个优点是避免使用巨大的数据集。基于卷积神经网络的图像像素分类方法。该方法使得能够使用视觉几何组-16(VGG-16)模型训练来生成精细划分，以便提高性能、加速训练速度并且避免使用大数据集。该方法包括获得测试数据。 对获取的测试数据进行预处理操作。 预测核心样本中的图像的像素。 得到输出结果。 从获得的测试数据组合特征和响应。 将得到的测试数据处理到单独的深度信念网络。 鉴定动物数据集。 从输入图像提取映射响应。 查看金字塔图像的不同级别。 确定空间损失和局部信息。 映射每一层的响应。   4
本发明公开了一种可用于小样本场景下的可信图像识别分类方法，包括：基于预训练的证据获取模块，使用预训练得到的卷积神经网络对输入图像进行特征提取，特征经过预训练证据神经网络得到预训练证据；基于元训练的证据获取模块，使用元训练得到的元变换参数对预训练模型进行任务自适应，得到特定于某一任务的元训练卷积神经网络，对图像进行特征提取，特征经过元训练证据神经网络得到元训练证据；基于证据融合机制的可信预测模块，将预训练证据和元训练证据进行加权融合，通过融合证据机制得到融合证据向量，并根据主观逻辑理论和证据理论进一步得到图像的识别分类结果和预测不确定性。本发明具有图像识别正确率高、泛化性好的特点，同时能对识别结果做出合理的不确定性估计，使模型预测结果更可信。用于农业生产的管防、智能监控系统和医疗诊断领域的可信小样本图像识别分类方法。该方法具有图像识别精度高、泛化性好的特点，对识别结果做出合理的不确定性估计，使模型预测结果更加可信。该方法涉及输出预训练证据向量epre和元训练证据向量emeta。 通过证据融合机制进一步得到待识别图像的融合证据向量e，提供该融合证据向量以确定其预测的狄利克雷分布Dir(p α)。 根据Dirichlet分布构造证据损失优化函数和aim，使该函数最小化。 提供梯度下降算法来更新模型参数。 针对待识别分类的新图像提取不同的特征。 得到图像对应的狄利克雷分布Dir(p α)。 进行可靠的图像识别和分类，并将图像识别和分类结果以及结果的不确定性系数作为输出返回给用户。   4
本发明提供一种基于自监督学习的前视场景深度估计方法，包括以下步骤：计算自监督学习重投影公式；构建深度估计和位姿估计联合训练网络，设计损失函数，对KITTI可见光数据进行预训练得到可见光预训练模型；将可见光预训练模型迁移至FLIR红外数据进行训练，实现红外图像的稠密深度估计，解决了现有的基于视觉方法的前视场景三维深度估计方法只适用于可见光条件，而无法在夜间或可见度较低条件下使用的问题，能够在没有真实深度数据监督的情况下实现夜间或可见度较低情况下的红外单目图像的三维深度估计，进而弥补视觉辅助驾驶系统对夜间红外图像深度估计的不足。该方法可用于基于自监督学习的前视场景深度估计。本发明能够在夜间或能见度低的情况下，实现红外单目图像在无真实深度数据监测的情况下的三维深度估计，弥补了夜间红外图像深度估计的视觉辅助驾驶系统的缺陷。一种基于自监督学习的前视场景深度估计方法，包括计算自监督学习重投影公式。 构建深度估计和姿态估计相结合的训练网络。 设计了损耗函数。 对Kitti可见光数据进行预训练以获得可见光预训练模型。 可见光预训练模型被传送到FLDR红外数据集进行训练。 实现了红外图像的密集深度估计。 计算红外图像的深度估计值。 获得红外图像的深度估计值。 14
本发明属于恶意账号检测技术领域，提出一种基于主动学习的恶意账号检测方法及装置，该方法包括：首先构建图神经网络和账号的拓扑连接图，然后使用训练集样本对图神经网络进行预训练，使用预训练的图神经网络得到账号节点的伪标签，利用账号在拓扑连接图的邻域标签一致性的值，筛选出更有价值的样本进行标注和更可靠的伪标签，然后，将标注样本和可靠的伪标签共同用于模型的训练，最后基于最终训练好的图神经网络深度学习检测模型进行恶意账号检测。在相同的标注量下，本发明提升了模型的恶意账号检测正确率。基于主动学习的恶意账号检测方法。该方法能够提高模型恶意账号检测准确率，增强训练当前账号后的模型训练性能并提供可靠的假标签账号。该方法涉及构建社交网络拓扑图。 基于构建的社会网络拓扑图进行图神经网络深度学习检测模型预训练过程。 根据邻域标签的一致性排序，选取待标注账号和当前账号作为伪标签样本。 对所述待标注账号进行标注选取。 将所述待标注账号和所述伪标注样本输入预先训练的地图-神经网络深度学习检测模型。 进行模型再训练过程。 训练过程结束。 基于最终训练好的地图-神经网络深度学习检测模型进行恶意账号检测过程。本发明还公开了一种基于主动学习的恶意账号检测装置。   4
本发明公开了一种基于手势和面部表情的行为异常人群检测方法，其步骤包括：利用摄像机进行现场人群的实时检测，获取含有手势和面部表情的图像；进行手势动作识别，提取手势的情绪特征；进行面部表情识别，判断表情开始‑结束时间，提取面部的情绪特征；融合手势和面部的情绪特征，进行情绪识别，判断行为是否异常。对于表情识别过程，将面部表情图像数据输入到卷积神经网络，进行相邻帧图像特征的学习训练，将特征数据输入到BiLSTM网络进行特征融合；然后输入到卷积网络进行卷积运算，再通过聚变网络进行聚类运算，得到面部表情的情绪特征。该方法对人员目标识别具有较高的精准性，应用于复杂人群、空旷单人和其他目标场景具有较高的自适应性。一种基于手势和面部表情的异常行为检测方法。本发明对人体目标识别精度高，适用于复杂人群，闲置单人等目标场景，适应性强。该方法包括使用相机实时检测现场人群，并获得包含姿势和面部表情的图像。 进行手势动作识别，提取手势的情感特征。 执行面部表情识别，并确定表情开始-结束时间。 提取脸部的情感特征。 融合手势的情感特征和人脸情感，进行情感识别以确定行为是否异常。 2
本发明涉及医学图像人工智能技术领域，旨在提供一种在动态超声实例分割中应用时空视觉Transformer的方法。包括：构造时空视觉Transformer模型的网络结构：收集超声检查的动态视频数据，构建为数据集集；为空间维Transformer模块临时构建一个用于解码的Transformer结构，然后进行预训练；用动态超声数据集训练、调优和测试时空视觉Transformer模型；在动态超声检查时，提取实时视频的当前帧输入模型，然后执行实时的应用处理，最终输出图像的实例分割结果。本发明能够解决超声实时扫查过程中的实例分割任务，从而简化实例分割流程并实现端到端训练优化；基于Transformer长距离全局注意力机制提取的时空特征，能够提高实例分割准确性；使用掩模自动编码方法进行预训练更容易调优，并且收敛得更快。在医学图像人工智能领域的动态超声实例分割中应用时空视觉系统的方法。该方法能够在超声实时扫描过程中求解实例划分任务，以简化实例划分流程，实现基于长距离全局注意力机制提取的时空特征的端到端训练优化，从而提高实例分割精度。 该方法允许通过掩码自动编码过程的预训练更容易被优化和更快地收敛。该方法包括构建时空视觉系统模型的网络结构。 所述网络结构包括依次连接的空间维度、时间维度和混合维度。 所述混合电源模块后并联有像素级解码模块和像素级解码模块。 所述像素级解码模块和所述像素级解码模块输出至所述掩码预测模块。 所述催化剂解码模块进一步同步输出至类别预测模块。 输入时空视觉滤波器模型，然后根据前向传播流程执行实时应用处理，最后输出图像的实例划分结果。   5
实施例包括设备、方法和系统，该设备、方法和系统包括用于控制由一个或多个处理器操作不同应用的不同功耗的功率控制单元。功率控制单元可以接收针对要在一个或多个处理器上操作的每个应用的功率信息，该功率信息包括优先级信息，确定基于针对不同应用的功率信息来控制由一个或多个处理器操作不同应用的不同功耗。也描述和要求保护其他实施例。用于诸如车载汽车系统、可穿戴设备、智能电话、计算机平板电脑、膝上型计算机、游戏控制器、机顶盒、信息娱乐控制台、物联网设备(均要求保护)等设备中的电源管理的计算机设备。该计算机设备具有耦合到处理器(502)的功率控制单元(505)，以接收包括操作处理器上的第一应用程序的第一优先级信息的第一功率信息和包括操作处理器上的第二应用程序的第二优先级信息的第二功率信息。 确定基于相应的第一和第二功率信息来控制第一和第二功率消耗，并且操作相应处理器上的相应的第一和第二应用。独立权利要求包括：一种用于通过具有一个或多个处理器的计算机设备的功率控制单元来控制功耗的方法； 存储用于计算机设备处理错误的程序的计算机可读介质； 以及一种用于通过具有一个或多个处理器的计算机设备的功率控制单元来控制功耗的装置。  11
本申请公开了图像处理方法、预训练模型的训练方法、装置和电子设备，涉及深度学习、计算机视觉技术领域。具体实现方案为：获取训练后的预训练模型，其中，预训练模型采用多帧训练图像进行训练，使得训练后的预训练模型所输出的图像特征满足第一图像特征距离与第二图像特征距离之差最小，进而，根据通用的预训练模型和目标图像处理任务，生成对应的图像处理模型，提高了目标处理任务对应的图像处理模型的生成效率，采用生成的图像处理模型对目标图像执行目标图像处理任务，由于图像处理模型是和目标图像处理任务对应的，因此，提高了图像处理的效果和效率。用于针对目标的预训练模型处理基于深度学习的图像的方法。该方法能够提高目标处理任务对应的图像处理效率和图像处理模型生成效率。该方法包括：获取训练后的预训练模型，所述预训练模型采用多帧训练图像进行训练，使得所述训练后的预训练模型输出的图像特征满足两个图像特征距离之间的最小差值。 根据所述预训练模型生成用于执行目标图像处理任务的图像处理模型，所述目标图像处理任务包括图像分类任务、目标检测任务或物体识别任务。还包括以下独立权利要求：一种用于训练预训练模型的方法； 图像处理装置； 预训练模型训练装置； 电子装置，所述电子装置包含存储器和处理器，所述处理器用以执行存储于所述存储器中的指令以用于处理基于深度学习的图像； 以及存储计算机指令以执行用于处理基于深度学习的图像的方法的非暂时性计算机可读存储介质。 14
本发明公开了一种基于注意力机制的双模态情感分析方法，使用了预训练的BERT模型和ResNet152模型进行文本和图片的信息编码，在得到文本编码和图片编码后先分别提取了文本模态和图片模态的局部信息和全局信息，充分考虑了模态内的高维特征对最终分类的积极作用。在模态间融合部分，本发明使用了双向注意力机制和门控多模态单元相结合的方式，考虑了图文模态之间双向的交互作用，从而提取到更多互补的信息。在模态间融合之后采取细粒度的特征提取，进一步对所拼接的特征进行过滤，剔除可能冗余的特征，得到更紧凑对情感极性更有益的细粒度特征表示，再对文本模态和图片模态进行加权拼接，从而提高了分类的准确度。基于注意力机制的双模式情感分析方法。该方法能够消除可能存在的冗余特征，获得情感极性的紧凑细粒度特征表示，并对文本模式和图片模式进行加权拼接，从而提高分类的准确性。该方法包括获得文本数据和图片数据(S1)。 对所述文字数据和所述图片数据进行预处理。 文本被编码(S2)为作为文本模式的输入的词向量。 在文本模式和图片模式中的一种模式下提取高维特征(S3)。 利用双向注意力机制模式和选通多模式单元对文字模式和图片模式的数据进行深层次的交互抽取工作(S4)。 对文本侧模态之间的互补特征表示和图片侧模态之间的互补特征表示执行细粒度特征提取处理(S5)。 表达文本模式细粒度特征和图片模式细粒度特征表示(S6)，以进行加权拼接处理。 对针对双模情感分类任务的准确率最高的模型进行多次迭代训练过程(S7)。  12
本公开提出了一种图文对话方法、模型训练方法、装置和电子设备，涉及人工智能技术领域，尤其涉及计算机视觉、深度学习、大模型技术领域，可应用于人工智能的内容生成等场景。方法包括：获取待对话的目标图像；对目标图像进行目标检测，得到目标图像的目标检测结果；基于目标检测结果，得到提示文本；将提示文本输入至大模型，由大模型输出针对目标图像的对话文本。一种利用电子设备实现图文会话的方法(权利要求书)。该方法能够对目标图像进行目标检测，得到图像的目标检测结果，并基于目标检测的结果得到提示文本，将提示文本输入到大模型中，输出模型针对图像的对话文本，从而能够以高效的方式训练模型。该方法包括：获取待对话的目标图像。 对所述目标图像进行目标检测，得到所述目标图像的目标检测结果。 基于所述目标检测结果得到提示文字。 提示文本被输入到大模型中。 通过所述大模型在所述目标图像处输出对话文本。 提取所述目标图像的特征，得到所述目标图像的视觉特性。 基于所述目标检测结果和所述视觉特性得到所述提示文字。 将图像粒度的视觉特性输入到目标检测模型中的编码器。 目标检测模型中的编码器输出目标粒度的视觉特性。独立权利要求包括用于：模型训练方法； 图文对话装置； 模型训练装置； 电子装置； 一种非暂态计算机可读存储介质，具有用于实现图文会话的指令集; 以及计算机程序产品。 14
本申请提供一种人工智能评分训练方法和装置，包括：获取用于训练人工智能的原始数据，原始数据包括对比数据和迭代数据；根据预设数据清洗规则，清洗原始数据，生成样本数据；根据样本数据的属性，提取对应样本数据属性的分类‑回归模型样本；根据分类‑回归模型样本，构建相似度分类‑回归模型；获取用户数据，并根据相似度分类‑回归模型分析用户数据的相似度。用以结合数据收集、数据清洗与增广、模型架构设计、模型训练，模型上线等流程机制，基于注意力机制、孪生网络、预训练模型等多项自然语言处理技术生成学员与培训标准之间的语义相似度得分，使机器人具备理解学员培训水平，识别学员后续意图的智能，达成智能化人机对练。该方法可用于人工智能分级训练。该方法包括：通过训练前模型和自然语言处理技术生成学生与训练标准的语义相似度得分； 通过机器人了解学生的训练水平； 识别学生后续意图，实现智能人机训练。一种人工智能分级训练方法，包括：获取训练人工智能的原始数据； 其中原始数据包括对比数据和迭代数据， 按照预设的数据清洗规则对原始数据进行清洗， 根据样本数据的属性生成样本数据； 提取样本数据属性对应的分类回归模型样本，根据分类回归模型样本构造相似度分类回归模型，获取用户数据，根据相似度分类回归模型分析用户数据的相似度。本发明还涉及一种人工智能分级训练装置。  11
本发明涉及一种基于BERT的网络不良短文本检测方法、装置及计算机可读存储介质，一种基于BERT的网络不良短文本检测方法，包括以下步骤：采集短文本并进行标注，将标注后的短文本分为测试数据集和训练数据集，根据测试数据集和训练数据集训练BERT模型，得到基于不良短文本检测的BERT模型；将待检测短文本及其对应的额外信息输入至基于不良短文本检测的BERT模型中，获取对应的隐藏状态的语义表示，根据隐藏状态的语义表示，获取不良短文本标签；将不良短文本标签、待检测短文本及其对应的额外信息输入至基于不良短文本检测的BERT模型中，获取对应的隐藏状态的语义表示，根据隐藏状态的语义表示，判别出不良短文本的类型。该方法提高了不良短文本检测的性能。基于双向编码器表示的来自变换器(BERT)的网络不良短文本检测方法，使用网络不良短文本检测装置(权利要求书)。该方法提高了不良短文本检测的性能。该方法包括收集(S1)短文本。 短文字标注。 将标注好的短文本分为测试数据集和训练数据集。 得到基于不良短文本检测的BERT模型。 将待检测的短文本和相应的附加信息输入(S2)至基于不良短文本检测的BERT模型。 输入不良短文本标签(S3)。 将所述待检测短文本和对应的附加信息输入至基于不良短文本检测的BERT模型。 根据所述隐藏状态的语义表示，得到对应的隐藏状态的语义表示。 进行判断，以判断不良短文本的类型。本发明还提供了一种用于网络不良短文本检测的计算机可读存储介质，该计算机可读存储介质存储用于网络不良短文本检测的指令。  12
本发明提供了一种面向数字城市的去中心化人工智能生成内容的方法及系统，区块链上的任务发布节点通过预先部署的智能合约发布AIGC任务；每个AIGC任务接受节点执行相应AIGC任务以训练相同的初始扩散模型，并通过训练后得到的第一扩散模型对相应第一信息进行推理，以及将第一扩散模型和相应第一信息的第一推理结果存储至任务发布节点；数字城市的多个边缘设备通过以最大化数字城市运营效用为目标的预设资源调度模型调用各AIGC任务接受节点的第一扩散模型对用户输入的相应第二信息进行推理以提供数字城市服务。采用本发明可以避免现有AIGC技术中采用中心化架构可能会导致的单点故障、数据垄断、数据泄露、资源调度效率低等问题。面向数字城市的去中心化人工智能生成内容(AIGC)方法，用于通过数字技术和数据分析获取和加载城市信息，创建智能交通导航系统，根据实时交通状况自动生成交通路线和建议，或者为公众提供个性化的社交媒体推荐内容，应用于区块链和人工智能技术领域。通过增强学习模式求解资源调度模型可以得到包括计算总时长和通信总时长的最优解的最优资源调度策略，以提高数据城市的资源利用率。 该方法通过引入预设资源调度模型调用各AIGC任务接收节点提供数字城市服务，能够避免现有AIGC技术中中心结构导致的单点故障、数据垄断、数据泄露以及资源调度效率低的问题。 可以以最大化数字城市运营商的效用为目的构建以下资源调度模型。该方法涉及由区块链上的任务发布节点通过预先安排的智能合约发布(S102)一个AIGC任务。 执行对应的AIGC任务(S104)，以由每个AIGC任务对应的AIGC任务接收节点训练初始扩散模型。 将训练后得到的第一扩散模型存储至任务发布节点对应的存储位置。 由用户通过各自的第一扩散模型对输入的相应第一信息进行推理(S106)，并将得到的相应第一信息的第一推理结果存储至任务发布节点的相应存储位置。 各AIGC任务接收节点的第一扩散模型，用于通过预设的资源调度模型以最大数字城市运行效果为目标推理出用户输入的对应的第二信息以提供数字城市服务(S108)。本发明还公开了一种面向数字城市的分散式AIGC系统。 1
本申请实施例公开了用于训练换脸模型的方法和设备。该方法的一具体实施方式包括：接收用户发送的换脸模型训练请求，其中，换脸模型训练请求中包括用户提供的换脸前人脸样本集和指定的模板人脸标识；从模板人脸标识对应的预训练模型集中确定与换脸前人脸样本集匹配的预训练模型，其中，预训练模型集包括基于目标人脸样本集组和模板人脸标识对应的模板人脸样本集组预先训练过的模型；从模板人脸样本集组中确定与换脸前人脸样本集匹配的模板人脸样本集；利用机器学习方法，基于换脸前人脸样本集和所确定的模板人脸样本集对所确定的预训练模型进行训练，得到换脸模型。该实施方式节省了换脸模型的训练耗时，提高了换脸模型的训练效率。训练人脸变化模型的方法。该方法能够节省训练变脸模型的时间，提高变脸模型的训练效率。该方法包括接收用户传输的变脸模型训练请求，所述变脸模型训练请求包括人脸样本集合。 从与模板人脸标识对应的预训练模型集合中确定与所述换脸前的人脸样本集合匹配的预训练模型， 其中，所述预训练模型集合包括所述基于目标人脸样本集合组和模板人脸样本集合组的预训练模型。 从所述换脸前的模板人脸样本集组中确定与所述人脸样本集匹配的模板人脸样本集。 基于所述变脸前人脸样本集和所述模板人脸样本集对所述预训练模型进行训练，得到变脸模型。独立权利要求还包括用于以下的：计算机设备用于存储用于执行用于训练人脸变化模型的方法的指令集的计算机可读存储介质。 2
本申请涉及一种意图识别模型训练的方法、系统、装置和介质，其中，该方法包括：通过原始数据对预训练模型进行微调，通过微调后的预训练模型对原始训练集数据进行打分排序，其中，原始训练集数据包括原始数据和合成数据；对排序后的原始训练集数据进行筛选，并将筛选后的数据划分为不同的训练子集；最后通过不同的训练子集对意图识别模型进行训练，得到最终训练好的意图识别模型。通过本申请，解决了训练意图识别模型时，存在的训练数据质量不高，以及训练得到的模型性能不好的问题，提高了模型性能和识别准确度。一种意图识别模型的训练方法。本发明解决了训练意图识别模型时训练数据质量低，训练后模型性能差的问题，从而提高了模型性能和识别精度。该方法包括通过原始数据微调(S201)预训练模型。 通过微调的预训练模型对原始训练集数据进行评分和排序。 原始训练集数据包括原始数据和合成数据。 对排序后的原始训练集数据进行滤波(S202)。 滤波后的数据被分成不同的训练子集。 通过不同的训练子集训练(S203)意图识别模型以获得最终训练的意图识别模型。独立的权利要求书被包括在以下内容中： 用于训练意图识别模型的系统； 用于训练意图识别模型的电子设备； 以及 一种存储用于训练意图识别模型的程序的存储介质。  11
本发明属于图像识别技术领域，具体涉及一种基于3DU‑Net的黄斑裂孔方法，包括如下步骤：S1、数据采集：采集黄斑裂孔图像数据，对获取的图像进行数据标注，完成模型训练所需数据集的构建；S2、数据预处理：预处理包括去噪、归一化、数据切割，统一数据尺度大小，保证模型训练效果；S3、分割模型：采用深度学习相关技术搭建分割模型，输入训练数据，完成参数模型的搭建；S4、模型保存：当模型的损失函数不再降低之后，保存模型；S5、性能评估：利用相关的评价指标评估模型的训练效果。本发明通过整个3D图像，在不到一秒的时间内产生更加精确的分割，具有极高的分割性能。一种基于3D U网的黄斑分割方法。 也可用于医学影像。该方法能够在少于一秒的时间内产生精确的分割，并且通过3D图像提高分割性能。该方法包括收集黄斑分裂孔图像数据。 标记所获得的图像数据。 完成模型训练所需数据集的构建。 预处理后的数据具有去噪，归一化，数据裁剪，数据尺度大小统一等特点，保证了模型训练的效果。 通过对相关技术的深入学习，建立分割模型。 输入训练数据，完成参数模型的建立。 在模型的损耗函数不再减小之后存储分段模型。 使用相对评价指标评价训练效果。   6
本发明公开了一种老年综合征预警方法、终端设备及存储介质，首先建立XGBoost、DBN、SVM等3个不同类型的预测器，而后建立MLP表征预训练模型，并以微调的方式建立MLP预训练模型到3个基础预测器的映射模型，在此基础上设置GS真实类别概率向量为输出层输出，训练得到最终的GS分类预测模型。通过集成多个现有预测效果表现良好的基础模型，可以进一步挖掘与GS相关的特征信息，提高模型对GS严重程度的预测精度和鲁棒性。方法对住院老年患者进行老年综合征预警方法。该方法通过整合已有的多个预测效果好的基本模型，挖掘与GS相关的特征信息，提高模型对GS严重程度的预测精度和鲁棒性。该方法涉及收集患者数据向量。 方便室内从和加热显示至少2.技术新的技能区内来自核酸估计利核酸记录。 从患者数据向量中筛选变量作为特征。 患者数据集分为训练集和测试集。 利用所述训练集训练多个机器学习模型。 采用测试组对训练后的模型进行测试，以选择性能最优的模型。 对所述训练组选择的模型的预测结果进行动态权重调整，得到最终预测模型。独立权利要求包括以下内容：终端设备； 以及计算机可读存储介质，所述计算机可读存储介质存储有用于早期预警sensile综合征的程序。  11
本发明提供一种基于预训练模型和微调技术的医疗文本命名实体识别方法，本发明首先利用大规模非结构化的电子病历等医疗文本对BERT预训练模型进行预训练，以训练出包含文本中语义表示信息的预训练模型。利用堆叠扩张卷积神经网络对所产生的预训练模型进行微调，以获得能够进行医疗领域命名实体自动识别的深度神经网络模型。本发明提供的预训练模型能够更为准确的捕获文本中的语义信息，能够更有效的迁移到特定的任务中，提高模型进行命名实体识别的准确性；本发明将堆叠扩张卷积神经网络与预训练模型结合以对模型进行微调，最终进行医疗文本命名实体的识别，不仅能够很好的捕获文本中的语义信息，而且能够进行并行计算，以提高模型训练速度。基于预训练模型和调整技术的医疗文本命名实体识别方法。该方法使得能够将堆叠扩展卷积神经网络与预训练模型相结合，对模型进行微调，进行医学文本命名实体的最终识别，很好地获取文本中的语义信息，进行并行计算，从而提高了模型训练的速度。该方法包括通过使用文本数据挖掘的相关技术对医疗文本进行预处理。 对大规模非结构化的无标签医学文本采用BERT预训练模型进行预训练。 预先训练医疗领域中包含语义表征信息的模型。 对所述预训练模型进行微调。 利用堆叠扩展卷积神经网络IDCNN识别医学文本中包含的相关医学命名实体的深度神经网络模型。 利用训练好的深度神经网络模型进行医疗文本的命名实体识别任务，识别出有价值的命名实体。  12
本公开提供了一种文本推送方法，涉及人工智能技术领域，尤其涉及自然语言处理、深度学习、预训练模型技术，可应用在智慧城市、智慧政务场景下。具体实现方案为：获取与目标类别相关联的目标文本集合，其中，目标类别包括关键词组，目标文本具有与目标类别相关联的置信度；根据置信度从目标文本集合中确定多个候选文本；针对每个候选文本，确定候选文本和关键词组之间的相似度；根据相似度和置信度，从多个候选文本中确定至少一个候选文本作为与目标类别相关联的推荐文本；以及推送推荐文本。本公开还提供了一种文本推送装置、电子设备和存储介质。文本推送方法，用于智慧城市和智慧政府场景中。 可应用于人工智能、自然语言处理、深度学习、预训练模型技术等技术领域。结合相似度和置信度确定候选文本的综合评价值，综合评价值从语义层面反映候选文本与类别的相关性。 该方法基于语义相关的综合评价值对多个候选文本进行精确排序，提高了排序精度。方法(200)涉及获得(S210)与目标类别相关联的目标文本集合。 所述目标类别包括关键词组。 目标文本具有与目标类别相关联的置信度。 基于置信度从目标文本集合中选择候选文本(S220)。 针对每个候选文本确定候选文本与关键词短语之间的相似度(S230)。 根据所述相似度和所述置信度，从候选文本中选择候选文本作为与所述目标类别相关联的推荐文本(S240)。 推送所述推荐文本(S250)。包括以下独立权利要求：1。 文本推送装置； 2. 电子装置； 3. 存储有文本推送程序的非瞬时计算机可读存储介质； 以及4。 一种用于文本推送的计算机程序产品。  11
本说明书实施例提供基于可信执行环境的联邦学习方法以及系统，其中所述方法应用于客户端，所述客户端包括部署在可信执行环境内的本地隐私计算节点，以及部署在所述可信执行环境外的本地公开计算节点，包括通过所述本地公开计算节点利用本地样本数据对本地预训练模型进行训练，获得本地训练数据；通过所述本地隐私计算节点对所述本地训练数据进行加密，获得本地加密数据；将所述本地加密数据发送至服务端，并接收所述服务端针对所述本地加密数据返回的目标加密数据；通过所述本地隐私计算节点利用所述目标加密数据对所述本地预训练模型进行更新，获得目标模型。通过在可信执行环境处理客户端与服务端之间的通信数据，提高数据的隐私性和安全性。应用于计算设备执行的客户端的基于可信执行环境的联合学习方法(声明)。通过在可信执行环境中处理客户端与服务器之间的通信数据，提高了数据的隐私性和安全性。该方法涉及通过本地公共计算节点使用本地样本数据来训练(202)本地预训练模型，以获得本地训练数据。 通过所述本地隐私计算节点对所述本地训练数据进行加密(204)，得到本地加密数据。 将所述本地加密数据发送(206)到服务器。 接收所述服务器针对所述本地加密数据返回的目标加密数据。 通过所述本地隐私计算节点利用所述目标加密数据更新(208)所述本地预训练模型，以获得目标模型。包括独立权利要求：(1)一种基于可信执行环境的联合学习系统； (2)计算设备； 以及(3)用于存储基于可信执行环境的联合学习程序的计算机可读存储介质。  11
本发明公开了一种融合引导注意力的中文长文本摘要生成方法，融合引导注意力的中文长文本摘要生成方法包括：S1：获取原始BART词表和摘要生成源文本；S2：对原始BART词表进行词汇扩展和预训练，得到长文本词表和长文本词表嵌入矩阵；S3：根据长文本词表和长文本词表嵌入矩阵，得到文本嵌入模块；S4：根据摘要生成源文本中的长文本序列和引导序列，利用文本嵌入模块，得到长文本词嵌入向量和引导信息词嵌入向量；S5：根据长文本词嵌入向量和引导信息词嵌入向量，得到长文本上下文编码隐向量和引导信息上下文编码隐向量；S6：根据长文本上下文编码隐向量、引导信息上下文编码隐向量和t‑1时刻生成摘要，得到t时刻生成摘要。融合引导关注的中文长文本摘要生成方法。该方法增加常用词和常用标点符号得到构建的基于分词的词表，缩短了词到短语的文本长度，有效减少了提取更丰富粒度特征的输入文本长度，并且允许文本嵌入模块引入分级位置分解编码技术，使得BART位置编码嵌入长度有效扩展。该方法包括：(i)获取原始湾区快速转运词汇和摘要，生成源文本; (ii)利用长文本词汇扩展模块对原始湾区快速转运词汇进行词汇扩展和预训练，得到长词表和长词表嵌入矩阵; (iii)根据长词表得到文本嵌入模块; (iv)根据摘要生成源文本中的长词序列和引导序列; (v)利用文本嵌入模块获得长词嵌入向量和引导信息词嵌入向量; (vi)利用具有引导注意力的稀疏编码模块获得长文本上下文编码隐藏向量和引导信息上下文编码隐藏向量; (vii)利用具有双重交叉注意力的稀疏解码模块根据短文本上下文编码隐藏向量和t-1时间生成摘要。  12
一个基于Gabor卷积和Transformer的学生表情识别模型，属于计算机视觉领域。针对复杂环境变化无法精准识别学生表情问题，发明了一个基于Gabor卷积和Transformer的学生表情识别模型。将Gabor卷积和Transformer的思想相结合，设计了一个特征提取块GVT‑block(Gabor‑Vision‑Transformer‑block)。通过Gabor卷积提取富含丰富纹理和边缘信息的面部局部特征，再利用Transformer提取特征之间的全局依赖关系，使得模型可以更好的学习面部关键特征，显著提高模型的分类效果。本发明得到的学生表情识别模型在RAF‑DB和FER2013Plus数据集上的准确率分别为88.56％和87.38％，并与多个模型进行对比实验和分析，验证了本发明效果的优越性。基于Gabor卷积和变换器的学生表情识别模型。通过Gabor卷积提取富含丰富纹理和边缘信息的人脸局部特征，提取特征之间的全局依赖关系，使得模型能够更好地学习到人脸关键特征，明显提高了模型的分类效果。学生表情识别模型具有用于处理输入图像的全局上下文(GC)块模块。 特征提取模块包括换能器模块和GC-basic-block模块，引入残差连接并通过主干对特征图进行更细粒度的特征提取和增强。 一个骨干重复四次，构建更深的网络。 访问全局平均池化层和全连接层，实现对图像的分类。   5
本公开提供了基于多任务AI大模型的目标检测方法、模型训练方法，本公开涉及计算机技术领域，尤其涉及人工智能、神经网络模型、智慧城市技术领域。目标检测方法的具体实现方案为：识别待检测图像中的目标对象，得到第一识别结果；根据第一识别结果的置信度和对应第一精确率的第一阈值，从第一识别结果中确定第一告警对象，以作为检测结果；在满足触发条件的情况下，对第一识别结果对应的待补检图像进行目标检测，得到第二识别结果；根据第二识别结果的置信度和对应第二精确率的第二阈值，从第二识别结果中确定第二告警对象；以及根据第二告警对象，更新检测结果。本公开可以保证目标检测的高精确率，同时降低漏召率。电子设备基于多任务人工智能大模式实现智能城市目标检测的方法(权利要求书)。该方法能够确保目标检测的高精确率，降低漏检率。该方法包括对待检测图像中的目标物体进行识别，得到第一识别结果。 通过第一精准率根据置信度和第一阈值确定第一报警对象作为检测结果。 根据所述第二识别结果的置信度和所述第二阈值以第二准确率从所述第二识别结果中确定第二报警对象，所述第一准确率高于第二准确率。 根据报警对象更新所述检测结果。 在所述待检测图像中对所述目标物体进行识别，得到第一识别结果。独立权利要求还包括：一种用于训练多任务人工智能(AI)大模型的方法; 一种基于多任务AI大模型的目标检测装置； 一种多任务AI大模型训练装置； 一种非瞬时计算机可读存储介质，用于存储电子设备实现基于多任务人工智能大模式的智能城市目标检测的一组指令； 以及计算机程序产品，所述计算机程序产品用于包括用于通过电子设备实现基于多任务人工智能大模式的智能城市中的目标检测的指令集。 14
本发明公开了一种物体识别的训练方法、装置及存储介质，所述方法包括获取输入图片；使用自训练的物体识别模型，对所述图片进行识别，预测物体的位置和类别，获取物体的位置信息和第一类别信息；将所述图片中每个物体对应区域的内容提取出来，送入自训练的图片分类模型进行分类，进一步预测对应区域物体的类别，获取第二类别信息；将所述物体的位置信息和所述第二类别信息作为最终结果输出；本发明通过使用公开的预训练模型，组合自训练的物体识别与图片分类模型，将标注数据的工作量降到最小，方便模型的快速验证和灵活调整。用于识别对象的训练方法。最大限度地减少了标注数据的工作量，便于模型的快速验证和灵活调整。训练方法包括获取输入图片。 利用所述自训练对象识别模型对所述图片进行识别。 预测对象的位置和类型。 获取所述对象的位置信息和所述第一类信息。 提取图片中对象对应区域的内容。 将所述自训练的图片分类模型发送进行分类。 预测相应区域对象的类型。 获取所述第二类信息。 输出对象的位置信息和第二类信息作为最终结果。包括用于以下的独立权利要求：(1)用于对象识别的训练装置； (2)用于物体识别的训练装置； (3)一种计算机可读存储介质，其存储有用于实现所述用于识别对象的训练方法的指令。 14
本发明提供了一种数字警务警情地址分词方法及数字警务警情系统，通过Ernie做语句编码的预处理以捕获中文语义特征，通过双向LSTM和Attention机制捕获字与字之间的关联，通过警务地址语料库POI令双向LSTM对应的神经网络进行数据增强学习，通过CRF得到分词结果，通过字典修正分词结果。本发明采用一种基于Ernie、深度学习神经网络、Attention和字典树修正技术解决数字警务警情地址分词准确度的技术难题。一种用于精确细分和提取地址的数字警务地址分词方法。本发明使得警用地址语料库能够对应循环和数据增强学习的数据神经网络进行双向LSTM，从而通过CRF得到词结果，并通过字典对词段结果进行修正。该方法包括利用ERNIE作为句子编码的预处理以捕获汉语语义特征。 两个字之间的相关性由双向长短时存储器(LSTM)和机制捕获。独立的权利要求书包括： (1)数字警务地址分词系统； (2)计算机可读存储介质，用于存储用于执行数字警务地址分词处理的一组指令； (3)数字警务管理系统。  12
本发明提出基于语义理解的从文本序列到指令序列的在线翻译，尤其涉及研究利用语言预训练模型和深度学习来进行文本序列到指令序列的翻译，属于自然语言处理领域；为解决现有技术中无法将人工文本和json语言进行直接转换以及文本转换过程中复杂语句无法翻译的问题；本发明引入模板生成层，可以根据训练数据中的SQL语句，抽取出SQL模板，让模型可以根据输入问句不同，选择不同的模板，依据模板进而可以划分出不同的SQL子任务，在此基础上生成结构复杂的SQL语句；拓展了填充SQL子语句的方法，可以生成复杂的SQL语句；并且不需要额外的编码器和解码器，除此之外，也不需要引入额外的中间表示层，这些特点降低了模型复杂度，并且能提高模型泛化能力。基于语义理解的文本序列到指令序列的在线翻译系统。该系统降低了模型复杂度，并且提高了模型泛化能力，并且保证填充SQL子句以生成复杂的SQL语句并且避免了额外的编码器和解码器以及引入额外的中间表示层。该系统具有模板提取模块，用于引导翻译系统生成指令序列。 在线翻译子系统包括训练和预测模块，用于完成从文本序列到指令序列的在线翻译过程。 SQL后处理子系统执行引导模块连接SQL语句剪枝模块和指令约简模块，用于去除SQL语句冗余部分，进行SQL语句综合处理。本发明还公开了一种基于语义理解的文本序列在线翻译成指令序列的方法。  11
本发明提供一种基于大语言模型的钓鱼邮件检测方法，属于人工智能技术领域，大语言模型不需要进行复杂的特征工程，将写有待测邮件的提示模板输入大语言模型，大语言模型就可以直接处理邮件内容，最后由大语言模型判断待测邮件是否为钓鱼邮件；而且，大语言模型具有出色的语义理解能力，可以深入识别和理解邮件的上下文内容，从而更准确地识别钓鱼邮件中应用的社会工程学技术和心理操纵技巧；此外，大语言模型具有强大的多语言处理能力，可以解决语言障碍问题，为其他语言的钓鱼邮件检测提供新的研究思路；最后，本发明同时使用没有开源的和开源的大语言模型进行钓鱼邮件检测，能够更好地研究开源大语言模型检测钓鱼邮件的性能和探索社会工程学领域的垂直大模型构建。一种人工智能领域的基于大型语言模型的钓鱼邮件检测方法，适用于银行等权威部门，或者是受客户和家人信任的朋友。该方法能够实现大语言模型具有优秀的语义理解能力，能够深入识别和理解邮件的上下文内容从而准确识别应用在钓鱼邮件中的社会工程技术和心理操作技能。该方法包括对待测邮件进行预处理。 将预处理后的邮件写入设定的提示模板中。 所述提示模板设置有问题单元和邮件单元。 问题单元，用于编写预处理后的待测邮件。 分析邮件的疑问因素。 分析邮件的URL。 识别邮件意图。 给出了该邮件是否为钓鱼邮件的结论和理由。 以JSON(开放标准文件格式和数据交换格式)格式输出判断结果，其中大语言模型为GPT-4(多模态大语言模型)、GPT-3.5(自回归语言模型)或开源大语言模型Llama2(最先进的大语言模型)、BAICCHUAN2(开源模型)、ChatGLM2(来源中英文双语对话模型)。  11
本申请涉及人工智能领域，提供了一种数据标注方法、装置、计算机设备和存储介质，获取待标注图片；通过OCR识别技术处理所述待标注图片，得到具有若干第一候选区域框的第一图片及对应的第一输出数据，并对所述第一候选区域框进行编号；通过预设规则在第一候选区域框中生成第二候选区域框，并根据第二候选区域框和第一输出数据生成第二输出数据；将所述第二输出数据输入至预训练完成的标注模型，得到标注数据；根据所述标注数据对待标注图片中的字符进行标注。本申请提供的数据标注方法、装置、计算机设备和存储介质，能够对待标注图片中具体字符进行标注，无需标注整行文字。数据标记方法。该方法能够在不标记字符线的情况下对待标记图片中的特定字符进行标记。该方法包括获取待标注图片。 利用光学字符识别(OCR)识别技术对所述待标记图片进行处理。 以多个第一候选区域框和对应的第一输出数据得到第一图片。 通过预设规则在所述第一候选区域框中生成第二候选区域框。 根据所述第二候选区域框和所述第一输出数据生成第二输出数据。 将所述第二输出数据输入至预先训练的打标模型，得到打标数据。 根据所述标注数据对所述待标注图片中的字符进行标注。独立权利要求包括：一种数据标记装置； 一种计算机设备，包括用于标记数据的存储器和处理器； 以及用于存储标记数据的指令的计算机可读存储介质。  11
本公开提供了训练文本审核模型的方法和装置，涉及人工智能领域，尤其涉及自然语言处理领域。具体实现方案为：获取预训练语言模型、预训练语言微小模型、标注数据、无标注数据；将所述标注数据输入预训练语言模型进行有监督训练，得到教师模型；将所述标注数据输入预训练语言微小模型进行有监督训练，得到学生模型；将所述无标注数据分别输入所述教师模型和所述学生模型，使用教师模型对学生模型进行蒸馏，得到文本审核模型。该实施方式能够在小规模人工标注数据和大规模无标注数据上进行训练，得到效果好、速度快的文本审核模型。一种使用智能手机，平板电脑，电子书阅读器，运动图像工作组音频层III等电子设备在文本审计设备中训练文本评论模型的方法。MP3播放器 2)动态图像专家压缩标准音频层3，笔记本便携式计算机和台式计算机。本发明对小规模人工标注数据和大规模非标注数据进行训练，得到效果好，速度快的文本审计模型。 提高了预测速度。 本发明加快了模型的收敛速度，提高了文本验证的准确性。该方法(200)包括获得(201)预训练语言模型，预训练语言微模型，标记数据和未标记数据。 将标记的数据输入(202)到预训练的语言模型中，用于监督训练，以获得教师模型。 将标记的数据输入(203)到预训练的语言微模型中，用于监督训练，以获得学生模型。 未标注的数据被分别输入(204)到教师模型和学生模型中，并且教师模型用于提取学生模型以获得文本评论模型。独立的权利要求书被包括在以下内容中： (1)用于审计文本的方法； (2)文本验证模式训练装置； (3)文本审核装置； (4)电子设备； 以及 (5)用于训练文本评论模型的计算机程序产品。  11
本发明涉及人工智能技术领域，具体地说，是一种电网客服对话情绪感知分析模型，该模型基于用户建模和层级Transformer，包括句子级编码器、对话级编码器、融合方法和情感分类器，其中，句子级编码器利用BERT对目标话语的语义表示进行编码，对话级编码器利用Transformer捕获上下文信息，本发明将会话中用户的依赖关系简化为发言者内部和发言者之间的依赖关系，内部依赖性关注同一发言者的影响，而发言者间不是在每两个说话者之间，而是将其他说话者作为一个整体。该简化模型容易扩展到，并能在不引入新关系的情况下处理用户数量动态变化的场景。电网客服对话情感感知分析模型，用于在文本情感分析任务中使用。简化后的模型易于扩展，无需引入新的关系即可处理用户数动态变化的场景。该模型具有句子级编码器、对话级编码器。 目标语音的语义表示由句子级编码器通过使用来自变换器(BERT)的双向编码器表示来编码。 通过对话级编码器利用目标语音的语义表示捕获上下文信息。 会话中的句子级别上下文由BERT模型编码。 对单个对话中的单词进行编码。 BERT输入，得到上下文词的向量表达式。 用于表示用户的内部依赖性的传统上下文建模模块和在用户之间使用的模块。 8
本发明公开了一种检测机器生成中文文本的方法，包括：将待检测中文文本按照设定步长进行切分得到N个文本段落的列表；遍历N个文本段落的列表，对每个文本段落以设定的采样率进行采样，采样M次进行掩码得到M个有掩码文本段落，将M个有掩码文本段落依次输入T5模型中解码，得到无掩码文本段落列表；根据每个文本段落的负对数似然函数值分数和每个元素的负对数似然函数值分数计算出每个文本段落的置信度分数；将置信度分数与设定的阈值进行比较，判定该文本段落为人工撰写或机器生成，将平均置信度分数与设定的阈值进行比较，判定待测中文文本为机器生成或人工撰写。该方法实施简单，能快速、准确地检测出中文文本是否由机器生成。用于智能终端的中文文本的检测机器生成方法(请求保护)。方法实现简单，能够快速准确地检测中文文本是否是机器生成的。该方法包括按照设定步长对待检测中文文本进行切分，得到文本段落列表。 遍历所述文本段落的列表。 以设定的采样率对每个文本段落进行采样。 对样本M次进行掩码处理，得到M个掩码文本段落。 将所述屏蔽文本段落解码成T5模型，得到所述非屏蔽文本段落列表。 计算每个文本段落的负对数似然函数值分数。 将置信水平分数与设置的阈值进行比较。 确定检查中文文本是否是手工书写的。独立权利要求包括：(1)一种用于检测机器生成中文文本的系统； (2)检测机器生成中文文本的智能终端; (3)用于检测中文文本的机器生成的计算机可读存储介质；  11
本发明涉及一种基于深度学习的图片自动调整对齐的方法及设备，包括以下步骤：模型的建立包括以下步骤：采用卷积神经网络对图像进行学习，在训练阶段，首先转换现有的所需调整对齐的图片和模板图片成灰度图并标注标签信息，形成的训练数据集中的标签集；然后将训练数据集输入U‑net网络中，采用随机梯度下降法更新网络的参数，迭代多次，得到U‑net网络模型；将变换后的灰度图均输入模型，计算初图片背景S1和模板背景S2的质心点z1和z2；比较质心点z1和z2在图片中的相对位置，得到偏移量，然后根据该偏移量用计算机调整得到自适应调整后的准确图片，通过运用深度学习技术，经过图像训练后能快速、精准地识别图像的背景，所得结果快速、客观、准确、稳定。一种基于深度学习的科研船上用摄像仪获取图像自动调整对位的方法。本发明能够快速，准确地识别图像的背景，结果快速，客观，准确，稳定。该方法包括采用卷积神经网络对图像进行学习。 采用随机梯度下降法更新网络参数。 对船上拍摄的初始图像和模板图像进行变换，得到变换后的灰度图像。 初始图像的灰度图像输出被划分为初始图像背景和非背景部分的二值图像。 将模板图像的灰度图像输出分为模板背景和非背景部分的二值图像。 计算主图像背景和模板背景的质心点。 比较图像中质心点的相对位置以获得偏移。 用计算机调整偏移量，得到自适应调整后的精确图像。本发明还涉及一种用于自动调整和对准图像的装置。   4
本申请公开了临床医学检验知识库构建与应用方法、装置、设备及介质，涉及计算机技术领域，包括：基于预设大语言模型将采集到的临床医学数据转换为相应的密集向量，以得到目标临床医学检验知识库；针对目标临床医学检验知识库执行对话式检索模式的配置操作，并在配置完成后，基于预设大语言模型对接收到的待答复自然语言语句进行向量转换，以得到相应的问题向量；通过对问题向量与目标临床医学检验知识库中每个密集向量之间的余弦相似度分别进行计算，确定与问题向量最相关的目标向量；基于预设大语言模型以及目标向量生成相应的目标自然语言答复语句，以对待答复自然语言语句进行答复。这样一来，能够有效提高检索效率，并进而提高检索的便利性。临床医学检验知识库的构建和应用方法。能够有效提高查找效率，提高查找便利性。该方法涉及基于预设的大语言模型将采集到的临床医学数据转换为对应的密集向量，得到目标临床医学检验知识库。 针对所述目标临床医学检验知识库执行对话型检索模式的配置操作。 基于所述预设的大型语言模型对接收到的配置完成后的待回复自然语言语句进行向量转换，得到对应的问题向量。 通过分别计算所述问题向量与所述目标临床医学检验知识库中各密集向量的余弦相似度，确定与所述问题向量最相关的目标向量。 基于所述预设大语言模型和所述目标向量生成对应的目标自然语言回复语句，以回复所述待回复自然语言语句。包括独立权利要求：(1)用于构建和应用所述临床医学检验知识库的装置； (2)一种电子设备，包括存储器和处理器，用于构建和应用所述临床医学检验知识库； (3)计算机可读存储介质，用于存储所述构建和应用所述临床医学检验知识库的计算机程序。  10
本发明提出了一种面向异构环境的大模型混合并行训练方法及系统，基于异构环境中不同数据中心的算力情况，以及不同数据中心之间的网络延迟情况，以待训练模型的每个训练阶段中数据中心的算力均衡性和每个训练阶段中数据中心所包含节点的计算任务传输的对等性为目标，利用遗传算法进行迭代优化，得到每个训练阶段所对应的数据中心，以及每个训练阶段内不同节点的计算任务，对待训练模型进行训练，从而将资源平衡和跨域带来的计算成本降低，提升大模型训练效率。国际AI前沿研究与应用中使用的超大规模预训练模型的管道并行、数据并行训练等异构环境的大模型混合并行训练方法。将每个训练阶段不同节点的计算任务用于训练待训练模型，以降低资源均衡和跨域带来的计算代价，提高大模型训练效率。该方法涉及在异构环境中获得不同数据中心的计算能力，以及对不同数据中心之间的网络延迟进行排序。 将网络延时最高的两个数据中心分配到所述待训练模型的生产线并行训练的头尾训练阶段。 以所述数据中心在每个训练阶段之间的一个计算力均衡以及每个训练阶段所述数据中心包含的节点的计算任务传输的对等性能为目标。 采用遗传算法进行迭代优化。 对应每个训练阶段获取数据中心，并在每个训练阶段计算不同节点的任务。 根据每个训练阶段对应的数据中心以及每个训练阶段中不同节点的计算任务，对待训练模型进行训练。独立权利要求包括如下内容：面向异构环境的大模型混合并行训练系统； 计算机装置； 以及存储用于异构环境的大模型混合并行训练的程序的计算机可读存储介质。  11
本发明涉及人工智能技术领域，具体为基于LLM和ANN的数字人生成方法及其在云视频的应用，包括以下步骤：基于捕获的视频数据，采用渐进式关键帧优化技术，通过卷积神经网络的边缘检测算法分析视频帧的特征，自动识别出关键帧，并筛除非关键帧，进行视频数据处理和关键帧的优化处理，生成关键帧数据集。本发明中，通过渐进式关键帧优化技术和基于子空间学习的特征分离算法能够更加高效和准确地从大规模或多源异构数据中提取关键信息，通过自动化特征提取与优化算法的应用，本发明在处理复杂环境下的人体姿态估计方面显著提高了准确性和运算效率，此外，还包括针对数据预处理的优化措施，更有效地处理各种噪声和异常值，提高生成数字人的质量。基于大型语言模型(LLM)和人工神经网络(ANN)的数字人生成方法及其在云视频中的应用，应用于娱乐、教育和客户服务领域。通过自动化特征提取和优化算法的应用，可以更高效、更准确地从大规模或多源异构数据中提取关键信息。 提高了在处理复杂环境下的人体姿态估计方面的准确性和运算效率。 对数据进行预处理的优化措施有效地处理了各种噪声和异常值，提高了生成的数字人的质量。该方法包括采用(S1)基于捕获的视频数据的渐进关键帧优化技术。 采用基于子空间学习的特征分离算法(S2)。 所述统计独立性分析通过独立成分分析进行。 采用自动特征提取和优化算法(S3)。 通过遗传算法和模拟退火技术在多维参数空间中找到匹配解。 采用特征映射优化技术(S4)。 采用异构数据集成和优化框架(S5)。 采用数据驱动的实时优化策略(S6)。 采用深度学习和自然语言处理技术(S7)。 结合LLM模型优化数字人在语言交互和情感表达方面的自然性和准确性，从而生成成型的数字人。 9
本发明公开了一种社交网络中基于情感偏移感知的交互式微博文本情感挖掘方法，其步骤为：首先基于单条微博语义及其交互历史的文本内容，对微博文本进行情感极性标注；其次采用自然语言处理领域中的预训练语言模型BERT，提取语句级的微博情感语义特征；接着利用长短期记忆网络LSTM，在交互式的社交网络语境下，提取语境级的情感语义特征；然后引入多任务学习的学习范式，建立情感偏移感知辅助任务，利用该情感偏移特征设计情感关联关系增强的Attention机制，从交互历史中提取出与当前微博相关的情感影响因素，再与情感语义特征融合并进行情感极性分类，构建微博文本情感识别模型。该方法大幅提高了交互式微博文本情感挖掘的准确率与模型的泛化能力。社交网络中基于情感转移感知的交互式微博文本情感挖掘方法。大大提高了交互式twitter文本情感挖掘的准确性和模型的泛化能力。 基于增强情感关联的注意力机制提取关键上下文影响因素，有效地进行情感溯源，提高了微博文本情感识别的准确率。 采用隐层参数硬共享的方法，达到主任务和辅助任务知识共享并促进彼此学习的目的，从而指导模型识别情感动态变化的模式，提高模型的泛化性。该方法涉及对微博文本进行情感极性标注，训练集、验证集和测试集根据单个微博文本在社交网络中的上下文语义信息及其交互历史进行划分。 利用自然语言处理领域中预先训练好的语言模型BERT提取句子级别的微博情感语义特征。 将多任务学习范式作为微博文本情感识别的主要任务，使得两个共享的隐含层参数共同学习，通过采用极大似然估计和梯度下降法训练学习得到模型参数，完成微博文本情感识别模型的构建。 将待推断文本情感的新样本输入到模型中并最终输出情感极性类别的概率值。 概率值最大的类别即为推断出的微博文本情感。  12
本发明公开了一种基于XLNet‑BiGRU‑CRF的智能问答方法，包括步骤：训练XLNet中文模型；获取语料数据；构建XLNet‑BiGRU‑CRF神经网络模型并训练；对待识别的用户问题的文本内容进行实体识别；根据实体识别结果提取数据库中具有对应实体的若干相关问题，将用户问题分别与若干相关问题作Embedding句向量余弦相似度比较，将相似度得分最大的相关问题的答案作为目标结果，同时将相似度分数排名第二和第三的相关问题提供给用户作为相似问题供用户参考。本发明利用训练完成的模型对用户问题的文本语料进行处理，并结合知识图谱检索方法能够更加快速、精准地得到问题答案。基于XLNet-BiGRU-CRF的智能问答方法。该方法使得能够利用训练模型对用户问题的文本语言学数据进行处理，并结合知识图谱检索方法，快速准确的获取问题答案。该方法涉及利用训练XLNet-BiGRU-CRF模型对用户待识别问题的文本内容进行实体识别，得到实体识别结果。 根据所述实体识别结果在一个Neo4j数据库中用对应的实体提取若干相关三元组数据。 利用所述XLNet中文模型提取所述用户问题的嵌入句向量。 对应于所述相关三元组获取所述提取的嵌入语句向量的余弦相似度。 将相似度得分最高的问题对应的答案作为目标结果。 将答案作为类似问题提供给用户以供用户参考。 将所述相似度分值中排名第二和第三的相关三元组对应的问题和答案作为相似问题提供给用户，以供用户参考。  12
本发明提出一种基于BERT模型的在线对话日志违规检测方法及系统，所述方法包括如下步骤：确定违规关键词，构造违规词库；利用所述违规关键词，抽取对话日志中涉及所述违规关键词的语句，构造违规句库；确定待对比在线对话日志，基于BERT模型结合预设的相似度算法检测在线对话日志的违规语句；所述系统包括：违规词库生成模块，违规句库生成模块和违规语句检测模块。本发明通过自动构造违规词库、违规句库，同时利用BERT模型与相似度算法相结合的方法，能够精确的针对目前市场上的在线客服平台无法及时通过客服日志分析找出平台中存在的疑似违规客户的问题，进行及时、针对性处理，保障网络安全，助力网络健康发展。在线会话日志违规检测方法。能够准确解决目前市场上的线上客服平台无法通过客服日志分析及时发现平台中的疑似非法客户的问题，进行及时有针对性的处理，保障网络安全，保障助力网络的健康发展。该方法包括确定(S01)非法关键词和构建非法词典。 使用违规关键词(S02)。 提取与会话日志中的违规关键字相关的语句。 构建违规语句库。 确定(S03)待比较的在线会话日志。 基于来自变换器的双向编码器表示(BERT)模型结合预设的相似性算法来检测在线会话日志的违规声明。 从会话日志中提取与关键字相关的用户标识(ID)。 采用IDF关键词提取方法提取疑似违规用户的疑似违规关键词。  12
本发明提供了一种中文口音识别方法、装置、设备及介质，涉及口音识别技术领域，能够识别非母语人群的口音。首先，语音信号输入Wave2vec2.0预训练模型抽取编码器的深层隐藏层进行拼接，得到层次化聚合向量。然后，将层次化聚合向量输入到注意力统计池化网络，根据注意力权重计算统计特征均值和统计特征方差，两者拼接得到紧凑的聚合口音特征。最后，聚合口音特征输入到LSTM网络中学习语音序列的长期依赖关系，获得口音依赖特征，将口音依赖特征输入全连接分类器实现口音分类。利用语音预训练模型提取更高层次的语义信息，并利用注意力统计池化捕捉语音特征在时间上的变化和分布，有效地提取口音特征并增强口音特征的判别性。非母语人的汉语口音识别方法。该方法能够保证使用语音预训练模型提取更高级别的语义信息，并利用注意力统计语音特征在时间内的变化和分布，有效地提取语音特征，增强语音特征的可判别性。 该方法使得能够确保语音信号输入到wave2vec2.0预训练模型中以提取编码器的深层隐含层进行拼接以获得层次聚合向量，并将层次聚合向量输入到注意力统计池网络中，并因此能够有效地识别非母语人的口语声音。该方法包括获取待识别的语音信号。 将所述语音信号输入Wave2vec2.0预训练模型。 在wave-wave-wave训练模型中提取编码器模块的深度隐含层对语音信号进行拼接。 生成分层聚合向量。 将分层聚合向量输入到注意力统计池网络中。 根据注意力权重生成统计特征平均值和统计特征方差。 基于所述重音分类结果生成重音分类结果。 调用长期依赖(LSTM)网络来执行语音序列的学习过程。独立权利要求书包括用于：(1)汉语口音识别装置； (2)一种存储有用于执行非母语人的汉语口音识别方法的计算机程序的可读存储介质。 3
本申请提供了一种语音识别模型训练方法、装置、设备及存储介质，涉及人工智能技术领域，该方法包括：获取训练数据和分布式并行训练待使用的设备数量N，N为正整数，使用深度学习训练优化库启动器对语音识别模型训练任务进行封装，对分布式训练启动器进行初始化，加载用于进行分布式并行训练的多进程信息，多进程信息包括分布式并行训练的进程数，分布式并行训练的进程数为N，根据训练数据和多进程信息，使用深度学习训练优化库进行N个进程的语音识别模型的分布式并行训练，将任意一个进程的语音识别模型确定为训练得到的语音识别模型。从而，可简化语音识别模型的训练流程，提高训练速度。使用基于并行数据的分布式训练方法训练语音识别模型的方法，用于人工智能领域。简化了语音识别模型的训练过程，提高了训练速度。 将整个模型的状态信息进行划分，分配给各个设备进行并行训练，从而减少内存的消耗。 通过调整训练速度的样本数(批次大小)进行初级训练。该方法包括获得(S101)训练数据和在分布式并行训练中使用的设备的数量。 N为正整数。 使用深度学习训练优化基本启动器(S102)来封装语音识别模型训练任务。 初始化分布式训练启动器(S103)。 加载多进程信息用于分布式并行训练。 所述多进程信息包括分布式并行训练的进程数。 根据训练数据和多进程信息，使用深度学习训练优化库执行N进程语音识别模型的分布式并行训练(S104)。 确定(S105)任何一个过程的语音识别模型作为通过训练获得的语音识别模型。本发明还涉及一种语音识别模型训练装置； 电子设备； 以及存储用于语音识别模型训练的程序的计算机可读存储介质。 3
本发明公开了一种融合字与词语特征的中文命名实体识别方法，该方法包括：获取数据集并对BERT模型进行特征提取训练，得到含有语义特征的序列向量；根据含有语义特征的序列向量训练BILSTM模型，得到含有上下文特征的序列向量；根据含有上下文特征的序列向量训练FLAT模型，得到预测的标签序列；整合BERT模型、BILSTM模型和FLAT模型，得到中文命名实体识别模型；将待测数据输入中文命名实体识别模型进行识别，得到识别结果。通过使用本发明，能够加强模型对命名实体识别的效果。本发明作为一种融合字与词语特征的中文命名实体识别方法，可广泛应用于中文命名实体识别技术领域。字符和词特征相结合的中文命名实体识别方法。该方法能够增强模型识别命名实体的效果，提高语言特征能力和特征提取能力。该方法涉及获得数据集。 对BERT模型进行特征提取训练过程，得到包含语义特征的序列向量。 根据所述序列向量训练BILSTM模型。 获得包含上下文特征的序列向量。 得到预测标签序列。 将所述BERT模型、所述BILSTM模型和平面模型进行整合，得到中文命名实体识别模型。 将待测数据输入所述中文命名实体识别模型进行识别，得到识别结果。  12
本发明公开一种基于交通大模型的多模态数据融合方法以及系统，涉及人工智能技术领域。方法包括：获取初始多模态交通数据；对初始多模态交通数据进行数据匹配对齐，形成多模态交通数据；对多模态交通数据进行时空多维度、多目标、多类型、多任务的数据标注，形成多模态标注数据；对多模态标注数据进行场景整合与数据加密处理，形成多模态融合数据。将多个不同模态下的数据依次进行匹配对齐、时空多维度标注、多目标标注、多类型标注、多任务标注、场景整合以及加密处理后，获得多模态融合数据，能够应对各种复杂繁多的交通场景，避免了依靠单一数据源导致的准确率低的技术问题。基于交通大模型的多模态数据融合方法用于判断和预警交通拥堵、检测和预警区域内车辆迭代更新状况和交通异常状况。得到多模态融合数据，用于各种复杂的交通场景，避免了单一数据源导致的精度不高的技术问题，场景融合加密后。 增强了不同行政区域内和区域间的交通建设和沟通程度，在此提高了居民交通出行的便利性。 同时采用红外感知图像进行视觉感知从而提高感知精度。该方法包括获得(S10)初始多模式交通数据。 对初始多模交通数据的数据进行匹配和对齐(S20)，以形成多模交通数据。 对多模式交通数据进行时空多维度、多目标、多类型和多任务的数据标注(S30)，形成多模式标注数据。 对所述多模态标签数据进行场景整合和数据加密处理，形成多模态融合数据(S40)。 以初始多模态交通数据中的任一模态交通数据为参考坐标系对应拍摄传感器观测图片。独立的权利要求包括一种基于交通大模型的多模态数据融合系统。 13
一种道路识别方法，包括：获取待识别的遥感图像；计算所述遥感图像在YUV颜色空间的图像金字塔；对于所述图像金字塔的每层图像，计算每个颜色通道上各个像素点的梯度特征，得到所述图像金字塔的每层图像的梯度特征；将所述图像金字塔的每层图像的梯度特征作为改进U‑Net模型每层网络的输入，得到所述遥感图像的第一概率分布图，其中所述改进U‑Net模型的每层网络包含一个1x1的卷积作为预测模块；根据所述第一概率分布图中各个像素点的道路概率得到所述遥感图像中的所有道路。本发明还提供一种道路识别装置、计算机装置及计算机可读存储介质。本发明可以有效提高道路识别的准确性。道路识别方法。该方法能够有效提高道路识别精度。该方法包括收集识别的遥感图像。 检测色彩空间中的遥感图像的金字塔点，用于形成金字塔图像的层。 在颜色通道上检测图像中像素点的梯度特征。 得到图像中像素点的梯度特征。 利用所述图像中像素点的梯度特性绘制概率分布图并输入增强的U-Net模型，得到遥感图像，所述U-Net模型包括预测模块。 在所述遥感影像中获取道路中的概率分布图。独立权利要求还包括用于以下的：一种道路识别设备一种计算机设备，其包括存储器和处理器以执行道路识别方法一种计算机可读存储介质，其用于存储执行道路识别方法的一组指令。   6
本公开提供了一种字符图像生成方法、深度学习模型的训练方法、装置和设备，涉及人工智能技术领域，具体涉及深度学习和计算机视觉等技术领域，可应用于AIGC等场景。字符图像生成方法包括：获取初始图像，初始图像包括噪声；将初始图像作为待推理图像执行推理操作，推理操作包括：将待推理图像与包括具有预设字体的目标字符的预设图像进行融合，以得到融合图像；将融合图像输入深度学习模型，以得到中间噪声图像，中间噪声图像表征对待推理图像中的噪声的推理结果；以及基于中间噪声图像对待推理图像进行噪声去除，得到推理后的图像；以及基于推理后的图像，得到包括具有目标字体的目标字符的目标图像。产生人物图像的方法。可以直接以预设图像为基准进行目标字体的目标图像生成，以提高生成的字体图像的质量和稳定性。该方法涉及获得初始图像，其中初始图像包括噪声。 将所述初始图像作为待推理图像进行推理运算。 所述推理操作设置有将所述待推理图像与具有预设字体的目标字符的预设图像进行融合，得到融合图像。 将所述融合图像输入深度学习模型。 中噪声图像由图像中噪声的推理结果表示。 对所述待推断图像进行噪声去除处理。 得到目标图像。 所述目标图像中包括具有目标字体的所述目标字符。包括独立权利要求：(1)用于训练人物图像生成模型的方法； (2)用于生成人物图像的装置； (3)用于训练人物图像生成模型的装置; (4)具有处理器的电子设备； (5)—种非暂时性计算机可读存储介质，其存储有用于实现用于生成人物图像的方法的指令； (6)一种用于产生人物图像的计算机程序产品。 14
本发明涉及一种基于深度神经网络和锯齿点匹配的低应变波形图异常检测方法，利用OCR预训练模型、直线检测以及DB‑scan聚类算法得到预处理图像以及像素坐标系和真实长度坐标系的映射；通过锯齿点匹配、加速度滤波和一维线性插值得到波形序列数据；后将波形数据送入深度学习模型产生异常预测；后经过数据后处理进行数据的结果修正和格式转换。本发明的优点是：可以最大程度的利用先验知识有助于提高该方法的准确性；通过图像预处理确定波形图范围以及刻度轴数字信息，再压缩图像信息时，最大程度的保留了图像中的有效先验；使用基于锯齿点匹配的方法进行序列化，可以基本消除坐标轴、未擦除干净的文本、竖直虚线的影响，因此具有较强的鲁棒性。基于神经网络和锯齿匹配的低应变波形异常检测方法，用于预测源于低应变机器的图像中的异常。该方法最大限度地利用有助于提高方法精度的先验知识，通过图像预处理确定波形范围和尺度轴数字信息。 最大程度地保留了图像中的有效先验，在重新压缩图像信息时，采用基于锯齿点匹配的方法进行序列化基本消除了坐标轴、未擦除文本、垂直虚线的影响，因此具有很强的鲁棒性。该方法包括通过线性插值获得序列化的数据。 根据上下边界对序列的y轴坐标进行归一化处理。 附对应位置的真实物理坐标系对应的x轴坐标。 将序列化后的图像序列附加到完成最终训练的低应变波形异常检测模型中。 由所述低应变波形异常检测模型生成基于所述序列的整个序列上的置信度序列。 选取概率值最大的类型作为序列中该点的预测分类。 对预测分类进行预处理。 标准轴以下的误差被移除并且被分类为无异常。 错误序列以大于5个像素的连续长度合并。 将中点作为误差位置对应的真实物理坐标位置进行输出。   6
本发明公开一种基于解耦表达学习生成对抗网络的人脸图像转正方法，其方法是通过训练包括U‑net网络结构的自编码器与三个判别器的模型，然后通过自编码器学习人脸图像的身份信息表征，结合姿态隐码可以显式的控制生成人脸图像的姿态，三个判别器分别预测人脸图像的真假、姿态和身份信息，从而生成具有丰富纹理细节的人脸图像。本发明能显著的提高生成的人脸图像的视觉质量。基于解耦表情学习修正人脸图像生成对抗网络的方法。该方法显著提高了生成的人脸图像的视觉质量。 将损失函数进行组合，使得模型收敛更快，效果更好，泛化能力更强。 该方法生成纹理细节丰富的人脸图像。该方法涉及对人脸图像数据集中的图像进行预处理，得到训练数据集和测试数据集。 利用训练数据集训练基于解耦表情学习的模型生成对抗网络，得到将侧脸图像校正为正脸图像的人脸图像校正模型。 将输入的人脸图像和生成的人脸图像输入到三个判别器中并分别预测输入图像的真伪、姿态信息和身份信息。 经过多次迭代，模型稳定后，完成一次模型训练。 采用训练好的人脸图像校正模型在测试集上测试校正性能。 输入人脸图像并给出前脸的姿势隐藏码，并显式控制解码器以生成前脸的人脸图像。 2
本发明涉及自然语言处理技术领域，具体涉及一种模型创建方法、装置、电子设备和可读存储介质。所述模型创建方法包括：分别获取第一预训练模型和第二预训练模型；其中所述第二预训练模型是包含目标领域数据的预训练模型；引入目标领域结构化数据至预存训练数据集生成目标训练数据集；利用所述目标训练数据集获取所述第一和第二预训练模型各自的特征集；根据预设规则和所述第一和第二预训练模型各自特征集获取目标预测模型；输入目标问题至所述目标预测模型并获取目标答案。本发明能够提升目标领域内预测模型机器阅读的准确性。使用电子设备的用于学术和工业领域的模型创建方法(要求保护)。该方法能够提高目标领域中预测模型的机器读取的准确度。该方法包括获取第一预训练模型和第二预训练模型，其中，第二预训练模型为包含目标领域数据的预训练模型。 将目标领域的结构化数据引入预先存储的训练数据集，生成目标训练数据集。 利用所述目标训练数据集获取所述第一预训练模型和第二预训练模型的特征集。 根据预设规则以及所述第一预训练模型和所述第二预训练模型的特征集，获取目标预测模型。 将目标问题输入所述目标预测模型，得到目标答案。独立权利要求包括：模型创建装置； 以及计算机可读存储介质，其存储用于执行模型创建方法的指令集。  11
本发明提供一种奖励模型的训练方法、答案评价方法、装置和设备，该训练方法包括：获取多个样本对，各样本对包括第一样本和第二样本，第一样本包括样本问题和第一样本答案，第二样本包括样本问题和第二样本答案，第一样本答案的目标分数高于第二样本答案的目标分数，目标分数和知识正确性相关，知识正确性为基于知识图谱中与样本问题匹配的目标答案确定的；针对各样本对，将样本对中的第一样本和第二样本输入初始奖励模型中，得到初始奖励模型输出的第一样本的第一评分和第二样本的第二评分；基于第一评分和第二评分，调整初始奖励模型的模型参数得到奖励模型。本发明可以提高对大语言模型输出文本的事实正确性的识别准确度。一种利用电子装置训练用户奖励模型的方法(权利要求书)。该方法能够提高大型语言模型的输出文本的事实正确性的识别精度。所述方法包括：获取多个样本对，所述样本对包括第一样本和第二样本，所述第一样本包括样本问题和第一样本答案，所述第二样本包括所述样本问题和第二样本答案，所述第一样本答案的目标评分高于所述第二样本答案的目标评分。 基于知识图谱中与所述样本问题匹配的目标答案，确定知识正确性。 将所述样本对中的第一样本和第二样本输入初始奖励模型。 获取所述初始奖励模型输出的所述第一样本的第一分值和所述第二样本的第二分值。 基于所述第一分值和所述第二分值调整所述初始奖励模型的模型参数，得到目标奖励模型，所述目标奖励模型用于对大型语言模型输出的当前答案进行评价。独立权利要求还包括用于：答案评价方法； 一种利用电子设备训练用户的奖励模型的装置； 答案评价装置； 以及一种非暂态计算机可读存储介质，用于存储利用电子设备训练用户奖励模型的指令集。  11
本公开公开了一种旋律生成方法及装置。该方法中获取歌词文本中的至少一个分句；对各分句进行情感分析，得到相应分句的情感信息；将各分句与相应分句的情感信息进行拼接后，输入已训练的基于自注意力机制的模型，得到各分句对应的旋律向量；其中，基于自注意力机制的模型用于依照上一输入数据获得的旋律向量，对当前输入数据进行处理，得到当前输入数据对应的旋律向量；基于各分句的旋律向量，生成歌词文本的旋律。该方法在存在歌词文本的条件下，通过对歌词文本进行文字情感分析，得到该歌词文本对应的情感信息使生成的旋律在情感上与歌词保持一致，提高了生成旋律的自然程度，以及生成旋律的质量。根据歌词生成旋律的方法。该方法通过获取歌词文本的旋律信息，使得生成的旋律与歌词一致，提高了生成旋律的自然程度，提高了旋律的生成质量。该方法涉及获取(S110)歌词文本中的至少一个分句。 对每个所述分句进行所述情感分析(S120)，得到对应分句的情感信息。 基于自注意力机制输入(S140)训练好的模型，以在拼接(S130)每个分句的情感信息和对应的分句之后，获得每个分句对应的旋律向量。 采用基于自注意力机制的模型，根据之前的输入数据得到旋律向量。 对所述当前输入数据进行处理，得到所述当前输入数据对应的旋律向量。 基于所述每个分句的旋律向量生成所述歌词文本的旋律(S150)。独立权利要求包括：一种旋律生成装置； 电子设备； 以及存储用于执行旋律生成方法的程序的存储介质。  12
本发明提供了一种语言任务模型训练方法、装置、电子设备及存储介质；方法包括：基于预训练样本集合中对应语言任务的语料样本，在所述语言模型中进行分层预训练；将训练样本集合中对应语言任务的语料样本，在所述语言任务模型中进行正向传播；固定所述语言模型的参数，在所述语言任务模型中进行反向传播，以更新所述任务模型的参数；将所述训练样本集合中对应所述语言任务的语料样本，在所述语言任务模型中进行正向传播和反向传播，以更新所述语言模型和所述任务模型的参数。通过本发明，能够防止语言模型的灾难性遗忘现象，同时保证语言模型和任务模型均能达到符合对应学习率的训练效果。用于训练在电子设备中使用的基于人工智能的语言任务模型的方法(权利要求书)。针对所述任务模型和所述语言模型设置所述不同的学习率，以保证所述任务模型和所述语言模型中的层按照对应的合适的学习率进行。 训练到位，在语言模型上对语言任务对应的语料样本进行分层预训练，使公知常识有效地转移到语言任务中。该方法涉及基于与预训练样本集中的语言任务相对应的语料样本在语言模型中执行(101)分层预训练。 将所述语料样本在所述语言任务模型中对应于所述训练样本集中的语言任务进行转发(102)。 语言模型的参数被固定(103)，并且在语言任务模型中执行反向传播以更新任务模型的参数。 将所述训练样本集中与所述语言任务对应的语料样本在所述语言任务模型中进行前向传播和反向传播(104)，以更新所述语言模型和所述任务模型的参数。独立权利要求包括如下：一种基于人工智能的语言任务模型训练装置； 以及存储用于训练基于人工智能的语言任务模型的程序的计算机可读存储介质。  11
本发明公开了一种基于大数据算法的工单智能派发方法，该方法包括步骤1，获取n个承办单位的所有处理完成的历史工单数据，构建n个承办单位的初始关键词库，步骤2，根据初始关键词库，生成关键短语，构建关键短语库；步骤3，根据历史工单，训练BERT分类模型：步骤4，热线接收市民诉求内容，根据派发规则将诉求内容派发给承办单位。该方法基于大数据的工单智能派发过程，可以快速提高工单的派发速度和派单的准确性，而且通过给出关键词和关键短语，有利于承办单位和热线工作人员快速了解市民的诉求内容，提高工单处理速度。一种基于大数据算法的智能工单调度方法。本发明通过给出关键词和关键词短语，可以快速提高工单调度的速度和准确率，使热线工作人员快速了解市民的求助内容，从而提高工单处理的速度， 从而减少了人力消耗，提高了工单发放速度和发放精度。所述方法包括：获取经处理的承接单位的历史工单数据。 使用局部注意卷积(LAC)分词工具对承接单元的历史工单数据进行分词和词性标注。 选择具有重要语音部分的词。 通过使用词语频率反向文档频率(TF-IDF)算法来提取关键词。 构建承接单元的初始关键字库。 根据初始关键词库生成关键词短语。 构建关键短语库。 构建关键词词组时采用两个关键词组合的二元词组结构和三个关键词组合的三元词组结构。 根据关键字库构造二元短语结构和三元短语结构。 计算两个或三个字的点互信息(PMI)。根据历史工单数据训练来自变压器的双向编码器表示(BERT)分类模型。 将剩余历史工单数据的申请内容作为测试组。 进行模型测试过程。 所述申请内容由热线接收。 根据分发规则将所述申请内容分发到所述承接单元。 通过语音识别过程将语音数据转换为文本SATA，得到工单内容。 通过LAC分词工具进行分词。 选择具有重要语音部分的词。 删除停止字。 通过TF-IDF提取关键字。 根据多个承接单元的关键词词库，判断所构造的二元词组结构或三元词组结构是否属于关键词词库。  11
一种半监督目标检测方法，用于检测待测样本图像的缺陷检测框与缺陷类别，包括：获取样本图像，包括：缺陷样本图像与待检测样本图像；根据带标签的缺陷样本图像，完成对Teacher模型和目标检测模型的预训练；根据目标检测模型与Student模型，获取每一个缺陷样本图像对应的Teacher模型的检测框和分类结果与Student模型的检测框和分类结果，并计算分类结果之间的距离Ldiff；判断距离Ldiff与损失Ls之和L是否收敛，若收敛，则表明Teacher模型和Student模型训练完成；否则继续迭代执行；将待测样本图像输入到Teacher模型和Student模型中，输出待测样本图像的缺陷检测框与缺陷类别。该发明联合训练有标签以及无标签样本数据，提升目标检测模型精确率。半监督目标检测方法，用于检测待检测样本图像的缺陷检测框和缺陷类型。降低了人力标记成本，提高了模型的检测率和准确率。 通过有标签和无标签样本数据联合训练，提高目标检测模型精确率。 将现场拍摄的缺陷样本制作成模型训练，以减少人力标注成本。 提高了半监督目标检测方法的准确度和精度。该方法包括获得样本图像。 模型的预训练和目标检测模型结束，根据带有标签的缺陷样本图像。 获取所述学生模型的检测框和分类结果与所述分类结果对应的各缺陷样本图像的检测框和分类结果。 计算距离。 判断距离和损失是否收敛，当收敛时，则表示训练模型和学生模型训练完成。包括一种用于半监督目标检测系统的独立权利要求。 14
本发明公开了一种基于AIGC的文章编辑自动插图方法、装置、设备及存储介质，涉及信息处理技术领域。所述方法是在获取待插图文章、绘画风格关键词和绘画类型关键词后，先确定需要绘图的目标自然段以及从该自然段中提取出绘画提示词组，然后将关键词和绘画提示词组导入AI绘图工具，输出得到多张绘制图，再然后根据各张绘制图的图像特征和目标自然段的文本特征，确定各张绘制图与目标自然段的图文一致性程度，最后将具有最高图文一致性程度的且该最高图文一致性程度超过预设程度阈值的某个绘制图作为目标插图，插入到待插图文章中，如此可无需文章作者人工绘图，实现在解放作者的同时还能快速得到图文并茂的以及确保图文一致性的新文章的目的。一种基于人工智能(AIGC)的图像的新奇、叙述、描述和应用等文章编辑的自动说明方法。在发布作者的同时，快速获取图文并存的新文章并保证图文的一致性。该方法包括获得(S1)待插值文章、绘图样式关键字和绘图类型关键字。 物品具有多个自然部分。 从所述自然片段中确定要绘制的目标自然片段(S2)。 首先利用预先训练的BERT网络模型对每个目标自然片段提取对应的自然片段的文本特征，利用预先训练的VGG19卷积神经网络模型基于每个图纸的图像特征和对应的自然片段的文本特征提取对应的多个图纸中每个图纸的图像特征。 确定每个所述附图与对应的所述自然段之间的一致程度，并将所述一致程度插入到要图示的文章中的对应的所述自然段与前一个自然段之间或对应的所述自然段与后一个自然段之间。包括独立权利要求，用于：(1)基于人工智能的自动说明图像的文章编辑的装置； (2)计算机装置； 以及(3)计算机可读存储介质，其存储用于基于人工智能自动地示出图像的文章编辑的程序。 1
本发明公开一种基于掩码的人脸图像生成模型隐私保护方法、系统及装置，方法包括：获取原始人脸数据集并进行预处理得到裁剪对齐图片；基于所述裁剪对齐图片，得到通用的人脸特征重要性热力图；进行归一化处理，得到归一化特征重要性数值；基于归一化特征重要性数值将原始人脸图像分割为图像块，得到人脸关键部分并基于人脸关键部分代替原始人脸数据集中相同部位，得到训练数据集；对训练数据集中每张图片加入随机噪声，进而得到训练损失结果；根据训练损失结果进行参数优化及更新，得到深度伪造人脸生成预训练模型；对深度伪造人脸生成预训练模型进行训练微调，得到深度伪造人脸生成模型。本发明能有效的保护人脸数据集隐私，减少人脸数据泄露。针对现有技术存在的缺陷，提供一种基于掩码的人脸图像生成模型隐私保护方法。该方法能够有效保护人脸数据集隐私，减少人脸数据泄露。该方法包括获取原始人脸数据集并进行预处理得到切割对齐图片。 获取人脸不同位置的关注度。 对人脸特征重要性热谱图进行归一化处理，得到归一化后的特征重要性数值。 基于所述无隐私保护目标信息的人脸数据组对深度假冒人脸生成预训练模型进行训练和微调整。独立权利要求还包括用于：一种基于mask的人脸图像生成模型隐私保护系统； 一种计算机可读存储介质，包括用于基于掩码代码保护人脸图像生成模型的隐私的指令集； 以及基于mask的人脸图像生成模型隐私保护装置。 2
本发明公开了一种基于自监督学习的全视野医学图片区域分割方法，属于图片分割技术领域。本发明包括：首先进行数据预处理，过程包括组织区域分割，采样图像块，通过随机裁剪、高斯模糊、颜色变换等方式进行数据增强。然后，对图像块进行自监督预训练，保存预训练模型。最后，构建语义分割网络，完成区域的分割。本发明使用自监督学习技术，在医学图像数据集上训练预训练模型，代替常用的ImageNet预训练模型，能够对数字病理切片提取更好的特征表示，提高区域分割的准确度。与此同时，充分利用了不完全标注的数据，有利于提高模型的泛化性能。用于图像分割技术领域的基于自监督学习的全视角医学图像区域分割方法。该方法使得能够在医学影像数据集上训练预训练模型，替代常见的ImageNet预训练模型，提取数字病理切片更好的特征表示，提高了区域划分的准确性，并且充分利用了不完整的标记数据，有利于提高模型的泛化性能。 该方法提高了医学图像区域划分的效率和准确性。该方法涉及获得医学图像数据集。 对数据进行预处理。 执行自监督预训练过程。 构建语义分割模型。 该模型设有骨干网络、腔体空间金字塔池模块和解码器。 基于获得的模型分割医学图像区域。 将所述图片数据集image存储在所述多分辨率金字塔结构中。 图像文件包括原始图像的多个下采样版本，其中金字塔中的每个图像被存储为一系列图像块。 在特性模式上对编码器的输出特性进行采样。 将收敛效果最好的模型存储在验证集上。   6
本发明提供了一种建筑信息的建模方法、装置及电子设备，基于用户输入的建筑信息，向预先训练好的大语言模型发送所述建筑信息的处理请求；其中，处理请求包括建筑信息、BIM角色指令、响应规则和预设目标操作集合，BIM角色指令表征大语言模型的响应内容范围；通过大语言模型基于预先配置的总操作集合，对处理请求进行响应；其中，总操作集合包含预设BIM软件的全部或部分BIM操作；基于响应对应的操作内容，通过预设BIM软件生成所述建筑信息的建模结果。采用本发明可以缓解现有建筑信息建模技术在软件操作方面存在的专业知识门槛较高、人工操作效率较低等问题。建筑信息建模的方法。该方法解决了现有BIM技术软件操作中专业知识门槛高、人工操作效率低的问题。该方法包括基于用户输入的建筑信息向预先训练的大型语言模型发送(S102)建筑信息的处理请求，该处理请求中设置有建筑信息、BIM角色指令、响应规则和预设目标操作集合。 所述预设目标操作集合中设置有完成所述预设操作目标所需的至少一个BIM操作。 大语言模型的响应内容范围由BIM角色指令表示。 基于由所述大语言模型设置的预配置总操作来响应(S104)所述处理请求。 基于与所述响应对应的所述操作内容，通过预设的BIM软件生成(S106)所述建筑物信息的建模结果。包括如下独立权利要求：一种建筑信息的建模装置； 以及电子设备。  11
本发明公开了一种端到端的基于关键点与卷积神经网络的动作识别方法，包括：(1)从时序视频中采样，获取多帧时序图片序列；(2)选取边缘设备端的神经网络作为关键点检测模型，从多帧时序图片序列中预测出多帧关键点数据；(3)使用关键点预测大模型对关键点检测模型进行蒸馏，或者使用真实标签训练关键点检测模型；(4)根据预测出的关键点生成高斯分布热力图；(5)在多帧高斯分布热力图上提取时空特征；(6)根据时空特征预测动作类型；(7)设置目标函数训练模型，将训练好的关键点检测模型和动作识别模型分别部署在边缘设备端、云端，进行实时目标动作检测。利用本发明，可以提高基于关键点的动作识别的准确性与真实性。基于关键点和卷积神经网络的端到端动作识别方法，用于公安、学校的战斗识别和市场上楼梯的坠落识别。该方法能够提高基于关键点的动作识别的准确性和真实性。该方法包括从时序视频中采样以获得多帧时序图片序列。 选取边缘设备端的深度卷积神经网络作为关键点检测模型。 从所述多帧时序图片中预测出多帧人体关键点数据。 根据预测出的关键点生成高斯分布热谱图。 对多帧高斯分布式热谱图进行三维卷积，提取时空特征。 将提取的时空特征输入动作识别模型，预测动作类型。 设置目标函数，训练关键点检测模型和动作识别模型。 将训练好的关键点和动作识别模型分别设置在边缘设备端、云端、实时目标动作检测。   4
本发明公开了一种智能外呼多轮交互中时间文本提取与推算方法，包括以下步骤：S1、使用ASR算法将智能交互过程中用户说话的实时音频转化为多轮交互的文本信息；S2、构建停用词库去除无关词汇内容，通过预处理筛选有效文本信息，并将文本信息进行文本特征工程处理与特征表示；S3、通过Bert‑Attention意图识别模型获取交互中时间特征文本表述信息，将智能交互中文本特征划分出时间特征意图。本发明通过Bert‑Attention意图识别模型实现对是否具有时间特征的文本意图进行划分，缩小了文本时间节点提取范围；通过HanLP框架与Bert‑BiLSTM‑CRF命名实体抽取融合策略提取时间节点文本信息，提升时间提取准确率；实现智能外呼系统根据用户提及时间定时外呼的能力。一种金融借阅领域智能外呼的智能外呼多轮交互时间文本提取与计算方法。本发明能够有效提高时间信息的提取能力，减小时间节点文本匹配范围。 本发明能够准确提取用户表情的实时日期方法，实现根据用户的时间日期定时呼出提醒能力。该方法包括使用ASR算法将用户在智能交互过程中的实时音频转换为多轮交互文本信息。 构建Bert-Bilstm-CRF命名实体提取模型。 输入文本特征信息。 在时间实体中输出当前文本。 在文本中设置被命名为实体集的时间。 文本由HANLP帧分割。 标记词属性。 文本中的词被匹配。 获得单轮交互时间节点文本集。 制定有效时间校核规则。 确定是否检查转换后的时间日期与有效时间一致。 8
本发明公开了一种融合RoBERTa和外部知识库的企业行业分类方法，包括：步骤1、基于预训练语言模型的语义表征编码；步骤2、基于GRU的候选集生成网络；步骤3、额外知识嵌入；步骤4、行业类别预测。该企业行业分类方法不仅能够使用预训练语言模型提取企业经营范围特征，而且还可以通过外部知识库和类别语义信息增强行业分类的准确性。该方法对于结合RoBERTa和外部知识库的企业行业分类是有用的。该方法使得能够利用预训练语言模型提取企业操作范围特征，并通过外部知识库和类别语义信息增强行业分类的准确性。该方法涉及基于预训练语言模型执行语义表示编码过程，基于GRU的候选集合生成网络，执行附加知识嵌入过程，执行行业类型预测过程，以及生成GRU的候选集合。  12
本申请公开了一种文图生成方法、装置、设备及存储介质，本申请借助大语言模型的语言能力，令大语言模型执行对原始文本描述内容进行加工处理的任务，该任务为使得大语言模型所得到的编辑后文本描述内容相对于原始文本描述内容的丰富度更高的任务，获取大语言模型输出层所提取的文本表征，该文本表征可以作为大语言模型输出的编辑后文本描述内容对应的特征表示，由于编辑后文本描述内容相对于原始文本描述内容的信息丰富度更高，因此获取的输出层所提取的文本表征相对于传统对原始文本描述内容的编码特征，其特征表达能力更强，将该文本表征送入预配置的文图生成模型，得到模型生成图像，该生成图像与文本内容更加匹配，也即图像效果更佳。生成文本图像的方法。由于编辑后的文字描述内容比原始文字描述内容的信息更丰富，因此，得到的输出层提取的文字表示比原始文字描述内容的现有编码特征具有更强的特征表达能力。 将所述文本表示送入预先配置的文本和图像生成模型，得到模型生成图像。 生成的图像与文字内容更加一致，即图像效果更好。该方法涉及获取(S100)待生成图像的原始文字描述内容。 在执行设定文本处理任务的过程中，获取(S110)由预配置的大语言模型的输出层提取的文本表示。 设定文字处理任务是对原始文字描述内容进行处理，生成编辑后的文字描述内容的任务。 编辑后的文字描述内容比原始文字描述内容更加丰富。 将文本表示馈送(S120)到预先配置的文本和图形生成模型中，以获得由文本和图形生成模型生成的图像。包括以下独立权利要求：(1)一种文本图像生成装置； (2)文本图生成装置； 以及(3)存储用于生成文本图像的程序的计算机可读存储介质。  11
本发明涉及人工智能技术领域，具体涉及一种基于大型语言模型的导诊预约系统，包括：用户交互模块，接收用户输入的交互信息；模型转发模块，向大型语言模型转发交互信息，并获取反馈信息；信息处理模块，对反馈信息进行修正后形成修正信息后反馈给用户；判别模块，采集修正信息，并生成导诊建议并经由用户交互模块反馈至用户。有益效果在于：引入大型语言模型，通过大型语言模型与用户进行交互来实现较好的信息采集效果，并通过信息处理模块结合医学知识对反馈信息进行修正，从而给出较为准确的响应。通过重复多次的交互流程来使得判别模块最终判断出用户需要前往的科室，并生成导诊建议，同时推送给院内预约系统进行预约，实现了较好的导诊效果。基于大型语言模型的引导诊断预约系统，用于引导患者到医院相关科室。判断模块采集修正信息并生成导诊建议，通过用户交互模块反馈给用户，与用户交互实现更好的信息采集效果，信息处理模块结合医学知识对反馈信息进行修正，做出更准确的反应。该系统具有用户交互模块，以接收用户输入的交互信息。 模型转发模块，分别与所述用户交互模块和外部的大型语言模型连接，将所述交互信息转发至所述大型语言模型，并获取所述大型语言模型反馈的反馈信息。 信息处理模块，与所述模型转发模块连接，用于对所述反馈信息进行修正，形成修正信息。 用户交互模块还与信息处理模块连接，用户交互模块将修正信息反馈给用户。 判断模块，与所述信息处理模块连接，获取所述修正信息并判断是否能够输出所述诊断指导建议。  11
本发明公开了一种基于生成对抗网络的图像融合方法、系统及存储介质。该方法包括：利用样本集预训练模糊区域识别模型，输出样本集中每张图像样本标记出模糊区域的掩码图像，其中，样本集中包括图像样本以及融合图像标签Ir；将图像样本与对应的掩码图像堆叠而成的多通道图像输入融合模型进行训练，融合模型包括生成器和判别器，将生成器输出的融合图像If，和融合图像标签Ir输入到判别器进行对抗训练；将待融合的图像输入到训练好的模糊区域识别模型和融合模型，生成融合图像。本发明只需要采集少量几张多焦点图像就可以实现图像融合，可以有效降低图像融合的时间成本与硬件成本，特别适合超大尺寸的病理切片图像的融合。该方法对于基于生成对抗网络的图像融合是有用的。该方法：只需采集少数多聚焦图像即可保证图像融合； 能够高效降低图像融合的时间成本和硬件成本； 并特别适用于超大尺寸病理切片图像的融合。方法包括利用样本集预训练模糊区域识别模型，所述模糊区域识别模型的输出为所述样本集中的每个图像样本标注模糊区域的掩模图像，通过叠加形成所述多通道图像的图像样本和对应的掩模图像输入到基于生成对抗网络的融合模型中进行训练，将融合图像标签Ir和融合图像If输入到判别器中进行对抗训练， 将融合图像If和融合图像标签Ir输入对抗训练的判别器，输出概率值图像，对概率值图像中的每个像素点计算交叉熵，然后将所有像素点的交叉熵的最大值作为判别器的损失，将待融合图像输入训练好的模糊区域识别模型和融合模型，生成融合图像。独立权利要求还包括：一种基于生成对抗网络的融合图像的系统； 以及计算机可读存储介质，包括用于基于生成对抗网络来融合图像的指令集。   6
本发明实施公开了一种基于物理‑数据协同驱动的超表面光谱响应预测方法，根据超表面结构的电场传播物理机制和电场边界条件，建立电场与超表面结构相互作用的偏微分方程；以偏微分方程残差作为U‑Net网络的损失函数，通过最小化偏微分方程残差使U‑Net网络编码器输出的电场逐渐满足偏微分方程，同时反向传播更新U‑Net网络编码器、解码器神经元权重参数，实现物理驱动的无监督学习；通过物理驱动训练好的U‑Net网络能够学习超表面结构特征，在物理驱动U‑Net网络的基础上，能够采用互信息法筛选部分超表面结构特征作为极限学习机的输入，训练极限学习机隐藏层权重参数，实现小样本光谱响应快速预测。本发明专利具有预测速度快、精度高、有效降低数据训练成本的特点。基于物理-数据协同驱动的超地表光谱响应预测方法。该方法能够实现小样本光谱响应的快速预测，预测速度快，精度高，有效降低数据训练成本。该方法涉及将横向截取的不同超级表面的二维像素图片输入到U-net网络中。 将偏微分方程的残差作为反向传播限制U-Net网络的损失函数。 更新编码器的参数和网络的解码器神经元权重，直到电场收敛。 确定超表面结构与通过网络的电场之间的映射关系。 超表面结构特征信息在无监督训练完成时由编码器从多个维度上学习。 在对极限学习机的小样本进行训练后，基于小样本训练设计了一个精细化似然模型(ELM)特征化模型。 输入超表面二维图像。 通过ELM描述模型输出预测频谱响应。   6
本申请实施例属于人工智能领域，涉及一种敏感词句识别模型处理方法，包括获取初始数据源；将初始数据源输入完成预训练的初始敏感词句识别模型以及预先构建的规则库，得到初始敏感词句集合；获取用于对初始敏感词句识别模型进行增量训练的生语料数据源；基于语义相似度，在生语料数据源中对初始敏感词句集合进行迭代扩充，得到增量数据源；通过增量数据源对初始敏感词句识别模型进行训练，得到敏感词句识别模型。本申请还提供一种敏感词句识别模型处理装置、计算机设备及存储介质。此外，本申请还涉及区块链技术，初始数据源和生语料数据源可存储于区块链中。本申请提高了敏感词句识别的兼容性。敏感词句识别模型处理方法。本发明能够提高敏感词句识别模型的兼容性。该方法包括获得初始数据源。 初始数据源输入初始敏感词句子识别模型和预先构建的规则数据库，得到初始敏感词句子集。 获取原始语言数据源，用于对初始敏感词句识别模型进行增量训练。 对原始语言数据源中的初始敏感词句子集执行迭代扩展以获得增量数据源。 通过增量数据源训练初始敏感词句子识别模型，得到敏感词句子识别模型。本发明还涉及一种敏感词句识别模型处理装置。 以及计算机设备，包括存储器和处理器，用于处理敏感词和句子识别模型； 以及计算机可读存储介质，用于存储用于处理敏感词和句子识别模型的一组指令。  11
一种基于预训练模型的特种设备中文命名实体识别方法，包括以下步骤：1)按照中文命名实体标注策略BIEOS对中文命名实体数据集进行标注，将实体类别分为四种类别；2)基于BERT预训练模型将中文句子转换为字向量表示；3)将字向量表示输入到biLSTM模型中，学习字向量序列双向编码，提取句子特征；4)采用CRF条件随机场学习上下文的标签概率，得到了每个汉字的所有可能的标签序列；5)最后输出汉字序列对应的实体类别。本发明通过无监督的方式对无标签语料中进行训练，能够有效解决小数据集、样本特征信息不足情况下中文命名实体提取的问题，用于构建特种设备领域的知识图谱。基于预训练模型的特种设备中文命名实体识别方法。该方法以无监督的方式在无标注语料中进行训练，有效解决了在数据集较小、样本特征信息不足的情况下提取中文命名实体并构建特种设备领域的知识图谱的问题。该方法涉及提取与特种设备领域相关的文本数据，并对数据进行清洗去重处理，将数据集划分为训练集和测试集，作为中文实体识别的数据集。 损失函数用于在训练过程中最大化正确标签的似然性。 基于维特比算法对最终的标签序列进行解码。 每个汉字可能的标签序列是在中文命名实体识别模型训练完成后得到的。 采用Viterbi算法对标签序列进行解码，并计算标签序列中的最优序列。 动态编程用于减少不必要的重新计算。 对一组未知标签序列采用Viterbi算法得到所有标签序列中预测总分最高的标签序列。 输出所述汉字序列对应的最终实体标签序列。  12
本发明提出了一种基于BERT和依存句法联合实体及关系抽取方法，所述方法包括以下步骤：构建句子的依存句法图；基于BioBERT进行模型嵌入，得到词嵌入、词性嵌入、依存关系嵌入和实体标签嵌入；利用BiLSTM作为序列编码器，结合CRF完成实体识别；利用依存句法树和Bi‑TreeLSTM模型获取两个实体之间的关系。本发明旨在解决误差传递和实体冗余的问题，更加准确、更加高效地识别特定领域实体，以及实体之间的关系，生成医疗领域三元组以供构建医疗领域知识图谱，从而构建医疗领域的知识图谱。一种基于双向编码器表示从变换器(BERT)和依存句法提取组合实体和关系的方法。该方法解决了错误传输和实体冗余的问题，更准确、更高效地识别具体域实体，以及实体之间的关系。该方法涉及构建句子的依存句法图。 使用依赖语法树和来自变换器的双向树双向编码器表示(双树LSTM)模型来获得两个实体之间的关系。 字嵌入层作为双向长短时记忆网络Bi长短时记忆网络的输入输出。 在双向长时长时短时短时短时存储网络之后加入条件随机场(CRF)层，计算相邻标签之间的依赖信息，提高标签预测精度。 利用依存句法树和双树长短期记忆模型得到两个实体之间的关系。  12
本发明提供一种低数据场景下的对话模型训练方法及计算机设备，本发明提供的低数据场景下的对话模型训练方法，包括如下步骤：步骤一、在语言模型2上附加小型transformer自注意力层，训练附加小型transformer自注意层，此步骤训练中，语言模型的参数被固定不变。步骤二、将训练好的附加transformer自注意层与复制下来的嵌入层组成新的transformer模型，继续训练新的transformer模型。本发明提供的低数据场景下的对话模型训练方法能够在缺乏对话数据的情况下，通过本发明的训练方法可以训练得到可用的检索式端到端对话模型，参数量小，不容易过拟合，推理运算速度快。计算机设备中的低数据场景下的对话模型训练方法(colow data scenarios in computer device，Cheart)。该对话模型训练方法可以训练得到可用的搜索型端到端对话模型，参数量小，不易拟合，推理运算速度快。该方法涉及向具有变换器和嵌入层的语言模型添加(S1)3层变换器。 形成对话历史，根据所述对话历史获取所述模型的输入序列。 输入序列经过嵌入层映射后得到768维稠密向量(S2)。 该768维稠密向量通过变换器进行变换(S3)，得到768维输出向量。 在[CLS]占位符的输出向量上建立(S4)线性层，将768维输出向量映射为2维。 语言模型的变换器的参数和语言模型的嵌入层的参数是固定的，在训练过程中不会发生变化。 利用训练好的3层变压器和复制的嵌入层组成新的变压器模型，重新执行新的变压器模型，继续训练。包括用于计算机设备的独立权利要求。 8
本申请涉及人工智能领域的一种模型迁移方法，包括：获取目标任务的样本数据，样本数据中包括多个图像样本；基于样本数据分别对N个预训练模型进行评估，得到N个评估值，该评估值用于表征预训练模型与目标任务间的适配度，N≥2；基于N个评估值，从N个预训练模型中确定出K个预训练模型，K个预训练模型为在对N个评估值由大到小排序后的前K个评估值对应的模型, 1≤K≤N；基于K个预训练模型对样本数据进行处理，得到用于处理目标任务的目标模型，目标模型中包括K个预训练模型。由此可以从大量的预训练模型构成的模型库中，快速找到适用于当前任务的预训练模型，并能融合多个最优的预训练模型的能力共同解决当前任务，有效提升了预训练模型的分布外泛化能力。用于人工智能领域的模型迁移方法。可以从由大量预训练模型组成的模型库中快速找到适合于当前任务的预训练模型。 本发明能够综合多个最优预训练模型的能力，共同求解当前任务，有效提高预训练模型的离线泛化能力。所述模型迁移方法涉及获得目标任务的样本数据，其中所述样本数据包括一组图像样本。 分别对N个预训练模型进行评估，以基于样本数据获得评估值，评估值用于表示预训练模型与目标任务之间的适应程度。 K个预训练模型是将N个评价值从大到小排序后的前K个评价值对应的模型。 处理样本数据以基于K个预训练模型获得目标模型，其中目标模型包括K个预训练模型，并且目标模型用于处理目标任务。本发明还涉及一种模型迁移装置； (2)电子设备，包括用于存储程序的存储器和处理器； (3)存储有计算机程序的计算机可读存储介质； (4)计算机程序产品。  11
本发明公开了一种语音提取方法、神经网络模型训练方法、装置及存储介质，该方法包括：采集待提取的多说话人混叠的语音数据和目标说话人的声纹注册语音数据；将待提取的多说话人混叠的语音数据输入语音编码网络，获取混叠语音的时间序列表征；将目标说话人的声纹注册语音数据输入说话人编码网络，获取目标说话人的声纹特征；将混叠语音的时间序列表征和目标说话人的声纹特征同时输入说话人提取网络，对多说话人混叠的语音数据中属于目标说话人的语音时间序列表征进行提取；将提取出的目标说话人语音时间序列表征输入的语音解码网络，还原目标说话人的时域语音信号。本发明能够精确有效地从多说话人的混叠语音中提取出目标说话人的语音。提取语音的方法。该语音提取方法能够准确有效地从多说话人的混叠语音中提取目标说话人的语音。该方法包括采集待提取的多说话人混叠语音数据和目标说话人的声纹注册语音数据，将待提取的多说话人混叠语音数据输入训练好的预设神经网络模型中的语音编码网络，得到混叠语音的时间序列表示。 将所述目标说话人的声纹注册语音数据输入训练后的预设神经网络模型中的说话人编码网络，得到所述目标说话人的声纹特征。 将所述混叠语音的时间序列表示和所述目标说话人的声纹特征同时输入训练好的预设神经网络模型中的说话人提取网络。 将提取的目标说话人的语音时间序列表示输入训练好的预设神经网络模型中的语音解码网络，恢复出目标说话人的时域语音信号。独立权利要求包括：(1)一种用于训练神经网络的方法； (2)语音提取装置; (3)用于训练模型的神经网络； (4)一种计算机可读存储介质。 3
一种用于识别眼底自发荧光图像中地理萎缩(GA)表型模式的自动分割和识别系统/方法。混合过程将监督式像素分类器与主动轮廓算法相结合。经训练的机器学习模型(例如SVM或U‑Net)提供初始GA分割/分类，并且其后是Chan‑Vese主动轮廓算法。然后分析GA分割区域的交界区的几何规律性和光强度规律性。至少部分地从这些参数确定GA表型。眼睛GA的分类方法。该方法减少了Chan-Vese主动轮廓分割的执行时间，提高了性能。 由于集群扫描中的扫描是相同的区域，所以静态结构在集群扫描内从扫描到扫描保持相对不变，而满足预定义标准的扫描之间的运动对比度可以被识别为血流。 由于每个卷积神经网络(CNN)层倾向于降低输入图像的分辨率，因此需要另一个阶段来将图像上采样回到其原始分辨率。该方法涉及使用(M1)眼科诊断装置来获取眼睛眼底的图像。 将所获取的图像提交(M3)至基于使用计算机处理器的机器学习模型的表型分类器，使得表型分类器识别GA区域，并且将所识别的GA区域分类为条带表型或扩散表型。 表型分类器的结果显示在电子显示器上或存储用于处理的结果。本发明还涉及一种用于对眼睛中的GA进行分类的系统。   6
一种基于生成式大模型的恶意短信变体字还原方法，方法包括：构建用于表征不同汉字间对抗关系的对抗图；构建并训练大规模预训练语言模型，将变体字文本以及变体字文本中每个字的对抗图信息组合成模板prompt，然后将模板prompt作为大规模预训练语言模型的输入，输出是将变体字还原后的短信文本、以及从输入变体字文本中提取的变体词与正常词的映射关系；获取待还原的变体字文本，生成对应的模板prompt，然后将生成的模板prompt输入训练后的大规模预训练语言模型，输出获得还原后的短信文本、以及从待还原的变体字文本中提取的变体词与正常词的映射关系。本发明涉及自然语言处理领域，能有效提高恶意短信变体字还原的准确性和效率。手机中基于生成的大模型还原恶意短信变体词的方法。该方法有效提高了恶意短信变体词约简的准确性和效率。该方法涉及构建对抗图来表示不同汉字之间的对抗关系。 对输入的变体文本中提取的变体词与正常词的关系进行映射。 得到待复原变体文本。 生成对应的模板提示。 将生成的模板提示输入到训练好的大规模预训练语言模型中，以输出还原后的短信文本。 将从所述待还原变体词文本中提取的变体词与正常词之间的关系进行映射。  11
本发明公开了一种基于U‑net的InSAR干涉图像相位解缠方法，包括S1，创建InSAR模拟数据集；S2，创建准实测数据集；S3，将S1和S2创建好的两种数据放入改进的U‑net模型中进行训练；S4，将待解缠相位图像放入已训练好的U‑net模型中得出解缠出的真实相位图像。本发明将U‑net架构、ASPP网络以及瓶颈残差网络结合起来，将不同扩张率的扩张卷积特征结合捕获丰富的上下文信息，能够在不牺牲特征空间分辨率的同时扩大特征接收野，有利于精确获取缠绕干涉图特征信息，提高相位解缠算法的稳健性；瓶颈残差单元可使网络模型在减小参数计算量的同时防止网络退化，提高网络训练精度与效率。与现有技术相比，本发明解缠精度相对较高、抗噪性能相对较强。基于U-net的InSAR干涉图像相位解扭方法。该方法能够将不同扩展率的扩展卷积特征与丰富的上下文数据相结合，在不牺牲特征空间分辨率的情况下扩展特征接收场，准确获取缠绕干扰模式特征数据，提高相位解缠算法的鲁棒性，减少参数计算量，防止网络退化，提高网络训练精度和效率，保证缠绕精度高，抗噪性能强。该方法涉及创建干涉合成孔径雷达(InSAR)模拟数据集。 建立准实测数据集。 将InSAR模拟数据集创建的两个数据输入到改进的U-net模型中进行训练。 将待扭曲相位图像输入所述训练好的U-net模型，得到解缠后的真实相位图像。   6
本发明涉及数据处理技术领域，特别涉及一种电力领域文本分类的方法和存储设备。所述一种电力领域文本分类的方法，包括步骤：构建电力预训练模型；获取待训练数据，对待训练数据进行预处理；对预处理后的待训练数据进行随机取样生成K组训练数据；设置M个超参组合，生成L*K*M个业务分类子模型；对L*K*M个业务分类子模型进行验证，得每个业务分类子模型的模型评估数据；根据模型评估数据调整模型参数，直至确定最佳超参使得获得的业务分类子模型符合预设条件，共生成L*K个符合预设条件的业务分类子模型；输入待预测文本至符合预设条件的业务分类子模型，得文本分类结果。通过上述步骤，大大提高电力领域文本分类准确率。电力领域文本分类的方法。该方法大大提高了电力领域文本分类的准确性。该方法涉及构建电量预训练模型。 得到所述待训练数据。 对所述待训练数据进行预处理。 选择L深度学习帧。 对所述待训练数据进行随机采样处理，生成K组训练数据。 所述训练数据包括模型训练数据和模型验证数据。 生成业务分类子模型。 获取所述业务分类子模型的模型评估数据。 向所述业务分类子模型输入待预测文本，得到文本分类结果。本发明还公开了一种用于电力领域文本分类的存储装置。 0
本公开的实施例公开了基于预训练模型的分布式文本模型训练方法、装置、终端设备。该方法的一具体实施方式包括：获取训练数据集；生成输入适配参数集和输入适配数据集；将输入适配数据集发送至第一终端；接收第一终端发回的输出适配数据集；基于输出适配数据集和训练数据集，生成输出适配参数集；将输入适配参数集和输出适配参数集的集合确定为初始目标模型；基于训练数据集和初始目标模型，生成目标模型，其中，目标模型包括目标输入适配参数集和目标输出适配参数集。该实施方式训练输入适配数据集和输出适配数据集以得到目标模型，训练结构简单、参数少，节省训练资源，提高了训练速度，提升了应用目标模型的后续任务的完成效率。用于基于预训练模型训练分布式文本模型的方法。训练结构简单，参数少，节省了训练资源，提高了训练速度，提高了应用目标模型后续任务的完成效率。所述方法涉及获得(201)训练数据集，其中所述训练数据包括训练源文本和与所述训练源文本相对应的训练目标文本。 基于训练信息集生成(202)输入适配参数集和输入适配数据集，并且将输入适配数据集发送到第一终端。 由第一终端接收(203)输出适配数据组，并且使用预定的预训练模型(204)基于输入适配数据组来生成输出适配参数组。 确定(205)一组输入适配器和输出适配器参数组作为初始目标模型。 根据训练数据集和初始训练模型生成目标模型。 目标模型包括目标输入适配器适配器组和目标输出适配器组。本发明还涉及一种基于预训练模型的分布式训练装置。 (2)终端设备。  11
本发明公开了一种多标签文本分类方法及装置，该方法包括：获取已知标签类别的多个文本，构建训练集和测试集；将训练集中的每个文本和多个标签类别，输入BERT模型，输出第一嵌入式序列；将建立的关系矩阵转换为第二嵌入式序列；将第一嵌入式序列、第二嵌入式序列输入相对注意力网络RAT，输出语义关联信息和多种内在关联信息，经过双向LSTM网络，转化为对应的一维向量；将一维向量经过线性网络映射至训练集中的多个标签类别，得到每个文本的标签类别预测结果；计算网络模型的损失值，根据损失值更新网络模型参数得到训练好的网络模型；利用通过测试的网络模型对待分类文本进行分类，可以在低资源条件下，提升多标签文本分类的准确率。对商品标签和主题标签中的多标签文本进行分类的方法。采用测试后的网络模型对待分类文本进行分类，使得在低资源条件下，提高了对多标签文本进行分类的准确性。该方法包括获得(101)已知标签分类的多个文本，构造训练集和测试集。 将训练集中的每个文本和多个标签类型输入(102)到BERT模型中并输出第一嵌入序列。 根据各文本的标签类型预测结果和已知的各文本的标签类型，基于损失函数计算(105)网络模型的损失值，根据损失值更新网络模型参数，当损失值不小于预设阈值时，利用更新后的网络模型继续获取各文本的标签类型预测结果，直至网络模型的损失值小于预设阈值，得到训练后的网络模型。 根据测试集对训练后的网络模型进行测试(106)，利用测试后的网络模型对待分类文本进行分类。包括独立权利要求，用于：(1)多标签文本分类的装置； (2)计算机装置； (3)一种计算机可读存储介质，其存储有用于对多标签文本进行分类的程序； 以及(4)用于对多标签文本进行分类的计算机程序产品。  12
本发明公开了一种基于改进卷积神经网络结构的机器视觉室内定位方法，该方法主要是提出了一种改进的卷积神经网络结构及针对该结构的神经网络模型训练方法，最终通过训练后的卷积神经网络对输入的视频图像进行分类，得到装备RGB摄像头的移动机器人室内位置，其中，卷积神经网络功能包括：提取语义分割图像及RGB图像的位置特征，利用这两类位置特征来确定移动机器人的实时室内位置。改进的卷积神经网络结构是U‑Net、两个VGG16Net的前13层及一个VGG16Net的后3层相结合的产物，其卷积神经网络由U1、VGG2、VGG3、VGG4及ArcFace分类器五部分构成。本发明可精准实现移动机器人室内位置的实时定位。基于卷积神经网络结构的机器视觉室内定位方法。该方法能够准确实现移动机器人室内位置的实时定位。该方法涉及提供一种卷积神经网络结构以及针对该结构的神经网络模型训练方法，对输入的视频图像进行分类，得到装有RGB摄像头的移动机器人的室内位置。 提取所述语义分割图像和所述RGB图像的位置特征，确定移动机器人的实时室内位置，其中，所述神经网络结构为U-Net、13层VGG16Net和一个VGG16Net的最后3层的乘积。 得到所述输入图像的语义分割图。 提取语义分割地图位置特征和原始图像的位置特征，并为每个位置特征分配权重参数。   4
本发明公开了一种基于规则生成数据增强的手语词目序列翻译方法及系统，包括以下步骤：基于语义相似度建立中文词到手语词目的映射关系；基于映射关系通过替换方式将中文文本序列翻译成伪手语词目序列，基于噪声规则将伪手语词目序列增强以生成伪平行语料对；利用伪平行语料对预训练机器翻译模型得到预训练模型；利用真实双语语料对预训练模型进行微调得到最终翻译模型；利用最终翻译模型进行手语词目序列的翻译。系统包括：映射关系建立模块、数据增强模块、预训练模块、微调模块以及翻译模块。上述方法及系统针对中文文本生成手语词目序列的任务，旨在尽可能提高手语词目翻译水平，为听障人士提供便利。基于规则生成数据增强的手语词序列翻译方法。该方法能够生成针对中文文本的手语单词序列，因此尽可能地提高了单词的翻译水平，为听力障碍者提供了便利。该方法涉及基于语义相似度建立(S110)从中文词到手语词的映射关系。 基于所述映射关系通过替换方式将中文文本序列翻译(S120)为伪手语词序列。 对所述伪手语词序列进行增强，生成基于噪声规则的伪并行语料对。 利用所述伪并行语料对预训练机器翻译模型得到预训练模型(S130)。 利用真实双语语料对所述预训练模型进行微调(S140)，得到最终的翻译模型。 通过使用最终翻译模型来翻译手语输入序列(S150)。独立权利要求包括以下内容：一种基于规则生成数据增强的手语词序列翻译系统； 计算设备； 以及存储用于手语词序列翻译方法的程序的计算机可读存储介质。  12
本公开公开了样本生成方法、模型训练方法、文本处理方法、装置、电子设备以及存储介质，涉及人工智能技术领域，尤其涉及自然语言处理、深度学习、预训练模型技术领域。具体实现方案为：分别对多个实体各自的实体文本进行切分，得到多个实体各自的多个第一实体元素；基于多个实体各自的多个第一实体元素，生成多个第一字符树，第一字符树包括对多个实体加以表征的至少一个路径，至少一个路径包括与多个第一实体元素相对应的多个节点；分别对多个第一字符树进行剪枝处理，得到多个第二字符树；对于每个第二字符树，基于多个实体中与第二字符树关联的第一目标实体，生成至少一个实体对样本，其中，实体对样本包括两个第一目标实体。AI领域样本生成方法，特别涉及自然语言处理、深度学习、预训练模型技术领域，可应用于智慧城市、智慧政务场景中。样本生成方法涉及对多个实体的每个实体文本进行划分，并且基于多个第一实体元素来获取实体的多个实体元素，并且因此确保了简单且高效地生成用于生成实体对的样本。该方法涉及划分(S210)多个实体的每个实体文本。 获取所述多个实体中的多个第一实体元素。 基于每个所述实体的所述多个第一实体元素生成(S220)多个第一字符树。 所述第一人物树由多个实体提供至少一条路径，所述路径中提供有与所述第一实体元素对应的多个节点。 对多个第一字符树进行剪枝处理(S230)，得到多个第二字符树。 基于所述多个实体中与所述第二人物树相关联的第一目标实体，为每个第二人物树生成实体对样本(S240)，所述实体对样本中设置有两个第一目标实体。包括以下独立权利要求：模型训练方法； 实体匹配方法； 样本生成装置； 模型训练装置； 实体匹配装置； 电子设备； 存储用于生成样本的程序的非暂时性计算机可读存储介质； 以及用于产生样本的计算机程序产品。  11
本发明涉及基于热点词的司法领域热点事件发现方法，属自然语言处理领域。本发明先对爬取的司法舆情新闻进行处理，通过HanLP工具分词并抽取舆情新闻中的舆情要素，然后通过对舆情要素进行词频统计得到热点词集合并建立热点词与舆情新闻的对应关系，接下来通过相似度计算系统对舆情新闻进行两两评估以决定归并与否，相似度计算系统包括三个子系统：基于舆情新闻正文要素统计的文本相似度计算系统、基于BERT的舆情标题相似度计算系统以及基于tf‑idf的舆情标题相似度计算系统。在得到以上子系统的结果后，通过分别设置阈值的方式决定两条舆情文本是否属于同一热点事件。最后根据子系统的最终结果决定两条舆情是否为同一热点事件。基于热词司法领域的热点事件发现方法。该方法包括利用爬虫爬取司法舆情新闻和预处理数据。 利用开源工具对中国舆情新闻中的元素进行抽取得到元素集合。 通过相似度计算系统计算所述每个热词对应的舆情新闻之间的相似度。 如果词频大于或等于阈值的元素，则将所述元素定义为热点词。 根据计算结果确定舆情新闻是否属于原始热点事件。  12
本公开实施例中提供了一种基于Xlnet模型的类案检索方法、系统及设备，属于数据处理技术领域，具体包括：将目标案件文本与案件检索数据库内的文本进行预处理；根据预设算法计算预处理后的目标案件文本与案件检索数据库内文本的案件文本相似度特征，以及，利用Xlnet模型提取语义特征；将案件文本相似度特征与语义特征融合后输入全连接神经网络，输出检索结果。通过本公开的方案，对案件文本数据预处理时进行数据清洗，使原始数据包含的信息更加规范精确，然后计算案件文本相似度特征，以及，利用Xlnet模型将文本转为词向量，得到语义特征并进行融合，输入全连接神经网络得到检索结果，提高了类案检索的效率、精准度和适应性。基于Xlnet模型的类案例搜索方法。将案例文本数据预处理数据清洗，对原始数据包含的信息标准更加准确，然后计算案例文本相似度特征，并利用Xlnet模型将文本转化为词向量，得到语义特征并融合，输入全连接神经网络得到搜索结果，提高了类搜索的效率、精度和适应性。该方法包括对目标案例中的文本和案例搜索数据库中的文本进行预处理。 根据预设算法在案例检索数据库中计算所述预处理后的目标案例文本与文本的案例文本相似度特征。 采用Xlnet模型对所述文本进行提取。 在搜索数据库中提取文本的语义特征。 结合所述文本相似度特征和所述语义特征得到全连接神经网络输出检索结果。对于基于Xlnet模型的类搜索系统，包括独立权利要求。  11
本发明涉及人工智能技术领域，尤其涉及一种图像分类的增强处理方法、装置、设备及介质。上述方法应用于医疗领域，获取上一任务对应的预训练模型、预训练生成器以及当前任务对应的真实数据、对应真实数据的真实标签值，将基于预训练生成器生成的伪数据与真实数据作为训练数据，使用训练数据对当前任务中的模型进行训练，得到当前任务中的初始预训练模型，对初始预训练模型进行增强训练，确定训练好的模型为目标预训练模型。本发明中，利用历史伪数据进行训练保证了模型的特征分布的稳定性，利用知识蒸馏来最小化这些伪数据在上相邻任务模型之间的差异，降低伪数据带来的特征偏移，从而提高训练得到的当前任务中的目标预训练模型的输出精度。用于医疗领域的图像分类的增强处理方法。利用历史伪数据进行训练，保证了模型特征分布的稳定性，利用知识蒸馏使得上层相邻任务模型之间伪数据的差异最小化，因此减小了伪数据带来的特征偏移，从而提高了训练得到的当前任务中目标预训练模型的输出精度。该方法涉及获取前一图像分类任务对应的预训练模型、当前图像分类任务对应的预训练生成器和真实图像，以及真实图像对应的真实标签值。 将基于所述预训练生成器生成的伪数据和所述真实图像作为训练数据。 训练数据用于训练当前图像分类任务中的模型。 获取当前图像分类任务中的初始预训练模型。 根据所述第一损失和所述第二损失对所述初始预训练模型进行增强训练。 将所述训练好的模型确定为所述目标预训练模型。 所述目标预训练模型用于对待处理图像进行分类。 得到图像分类结果。独立权利要求包括：1)一种用于图像分类的增强处理设备; 2)一种计算机设备; 以及3)一种计算机可读存储介质。 14
本公开的实施例提供了一种基于大型语言模型的数据处理方法、装置、设备和计算机可读存储介质。本公开的实施例所提供的方法通过利用从双语语料库中获取的平行双语数据对大型语言模型进行微调，以基于经微调的大型语言模型和所设计的翻译信息提取指令从双语语料库中的平行双语数据和非平行双语数据自动且高效地提取翻译信息。通过本公开的实施例的方法能够利用大型语言模型的强大翻译能力，实现从双语语料库的自动化高效翻译信息提取。此外，通过外置显式地保存所提取的双语翻译信息，能够将翻译信息融入大型语言模型的翻译过程，从而进一步优化机器翻译性能。用于基于大型语言模型处理智能手机中的数据的方法(来自附图)，所述大型语言模型即预先训练的用于双语语料库中的两种语言下的双语翻译任务的大型语言模型，用于商业和社交领域中的机器翻译。该方法能够利用从双语语料中获取的并行双语数据对大型语言模型进行微调，并基于微调后的大型语言模型和设计的翻译信息提取指令，自动高效地从双语语料中的并行双语数据和非并行双语数据中提取翻译信息。 该方法使得利用大型语言模型的强大翻译能力实现对双语语料的自动高效翻译信息抽取，使得抽取的双语翻译信息能够对外显式存储，并将翻译信息纳入大型语言模型的翻译过程中，从而优化机器翻译性能。该方法涉及从双语语料库获得并行双语数据和非并行双语数据。 基于所获得的并行双语数据对大型语言模型进行微调。 基于所述微调整后的大型语言模型和翻译信息提取指令，从获取的所述并行双语数据和非并行双语数据中提取双语翻译信息，所述双语翻译信息包括用于指示所述双语语料中的词对齐关系的词对齐信息。 将两种语言的句子进行匹配，得到所述并行双语数据。独立权利要求包括用于：(1)一种基于大型语言模型的智能手机中数据处理的装置； (2)一种计算机程序产品，包括用于基于大型语言模型在智能电话中处理数据的一组指令； (3)一种计算机可读存储介质，用于存储用于在智能手机中基于大型语言模型处理数据的一组指令。  11
本发明公开了一种基于GAN网络结构自动学习失真的图像隐写方法和系统，其将增强载体图像输入预设的改进U‑Net网络，依次生成初始像素改变概率图和初始含密图像，将初始含密图像输入判别网络，得到判别结果，根据判别结果计算判别网络的损失，根据判别结果和当前的隐写容量计算生成网络的总损失函数，以最小化损失函数为目标优化生成式对抗网络，当损失下降并保持稳定时认为训练结束，在训练结束后从生成式对抗网络中提取生成网络，将待传输的原始图像输入生成网络，得到像素改变概率，计算像素改变概率对应的嵌入失真，依据嵌入失真采用伴随式矩阵编码技术对秘密信息与待传输的原始图像进行编码，得到与原始图像对应的隐写图像。基于GAN结构的自动学习畸变的图像隐写实现方法。该方法使得能够获得与原始图像相对应的隐写图像。该方法涉及生成初始像素变化概率图。 进行初始像素变化概率模拟最优嵌入过程。 生成初始加密图像。 进行判断以检查初始加密图像是识别为载体图像还是识别为加密图像。 根据判断结果和当前隐藏容量计算生成网络的总损失函数。 根据嵌入失真对秘密信息和原始图像进行编码得到隐写图像。本发明还公开了一种基于生成对抗网络(GAN)结构的自动学习失真的图像隐写实现系统。   6
本发明是一种服务资源的语义分析及实体关系联合抽取方法，包括以下步骤：获取待处理服务资源数据；对待处理服务资源数据预处理；构建语义分析训练集；进行语义分析；将待处理服务资源数据进行多标签标注；将经过多标签标注的数据输入到训练后的实体关系联合抽取模型中；识别数据中所包含的实体以及实体之间的关系，构建三元组；对抽取出来的三元组进行校正。本发明利用预训练的BERT语言模型，半监督迁移式训练方法，提升了抽取效果，提高了实体关系三元组抽取的准确率。一种基于预先训练的双向编码表示(BERT)语言模型对服务资源进行联合语义分析和实体关系提取的方法。采用预先训练的BERT语言模型和半监督迁移型训练方法，提高了抽取效果，提高了实体关系三元组的抽取精度。该方法包括获取待处理的业务资源数据。 对所述待处理业务资源数据进行预处理，并基于预设词库获取所述待处理业务资源数据的特征向量。 对所述一组特征向量进行向量编码，得到上下文编码向量。 对预处理后的所述待处理业务资源数据进行多标签标注。 利用待处理的业务资源数据对预先构建的实体关系联合抽取模型进行训练，得到所述训练后的模型。 将多标签标注数据输入训练后的实体关系联合抽取模型，输出对应的实体关系抽取结果。 利用训练好的实体关系联合抽取模型识别数据中包含的实体以及实体之间的关系，构建三元组。 对提取的三元组进行校正。  11
本发明实施例公开了一种预训练语言模型的生成、检测方法及装置，包括：获取多个训练用的动态API指令序列；分别对所获取的每个API指令序列按照预定的编码规则进行编码，得到多个API指令编码序列；根据所述多个API指令编码序列对预设的语言模型进行训练，得到预训练语言模型。一种生成预训练语言模型的方法。本发明能够有效地获取预训练语言模型。该方法包括获得(100)用于多个训练的动态应用编程接口(API)指令序列。 根据预定的编码规则对API指令序列进行编码(101)，以获得多个API指令编码序列。 根据API指令编码序列训练预定语言模型以获得(102)预训练语言模型。本发明还涉及一种预训练语言模型的生成装置。 以及计算机可读存储介质，其存储用于生成预训练语言模型的计算机可执行指令。  11
本申请公开了一种语言模型的预训练方法、装置、设备和存储介质，涉及计算机技术领域，尤其涉及深度学习及自然语言处理领域。具体实现方案为：根据搜索词、搜索结果和历史行为日志，构建语义图，并对语义图进行采样，生成第一文本序列；对第一文本序列中的第一文本进行掩码处理，得到第二文本序列，并通过初始模型之中编码器对第二文本序列中第二文本进行编码，生成第二文本的第一语义表征；将第一语义表征输入至初始模型之中图聚合模块，获得第二文本的第二语义表征；对第二语义表征进行掩码预测，获得第二文本中掩盖词的预测值，并根据掩盖词的预测值和真实值，确定损失函数；根据损失函数，对初始模型进行预训练，得到语言模型。一种用于在电子设备中预训练语言模型的方法(权利要求)。通过对语义图进行采样，获得包含语义和语义边缘关系的第一文本序列，并由编码器训练初始模型，从而在预训练语言模型的同时对编码器和图形聚合模块进行预训练。 本发明使语言模型中的图像聚合模块热启动，提高语言模型语义理解能力，从而提高下游任务的性能。该方法包括(i)根据搜索词，搜索结果和历史行为日志构建语义地图，对语义地图进行采样，生成第一文本序列； (ii)获得第二文本序列，并由初始模型中的编码器对第二文本序列中的第二文本进行编码，并生成第二文本的第一语义表示； (ii)在图像聚合模块中将第一语义表示输入到初始模型中，并获得第二文本的第二语义表示； (iv)对第二语义表示执行掩蔽预测，获得第二文本中掩蔽词的预测值，并确定损失函数； 以及(v)对初始模型进行预训练以获得语言模型。还包括独立的权利要求： 1. 一种神经网络建模方法； 2. 一种用于在电子设备中预训练语言模型的装置； 以及 3. 一种计算机可读存储介质，包括一组用于在电子设备中预训练语言模型的指令。  11
本发明是关于特定词语音的处理方法及装置。该方法包括：获取带噪声的待训练语音；提取所述待训练语音的第一特征；将所述第一特征输入至待训练的U‑NET模型中，以得到目标U‑NET模型；获取待测试语音，并提取所述待测试语音的第二特征；将所述第二特征输入至所述目标U‑NET模型，以判断所述待测试语音中是否存在特定词语音，并得到所述待测试语音的降噪语音。通过本发明的技术方案，可充分有效地提高降噪质量以及带噪语音中关键词的检测效率。一种特殊词语语音的处理方法。处理方法充分有效地提高了带噪语音中关键词的降噪质量和检测效率。该处理方法包括获取带噪的待训练语音，提取待训练语音的第一特征，将第一特征输入待训练U网模型，得到目标U网模型，获取待测试语音，提取待测试语音的第二特征。 将所述第二特征输入至所述目标U-NET模型，以判断所述待测语音中是否存在特殊词语音。 获取所述待测语音的降噪语音。本发明还涉及一种处理装置。 3
本发明提供了一种视频处理方法及系统，该方法为：对待处理视频进行预处理，得到多个待处理视频片段；针对每一待处理视频片段，将待处理视频片段输入预设的类别预测模型进行动作类别预测，得到待处理视频片段对应的动作类别预测信息。本方案中，利用经过空间变换规则和时间变换规则处理得到的第二样本数据训练第二神经网络模型得到预训练模型，将预训练模型的参数作为第一神经网络模型的初始化参数，并根据第一样本数据训练第一神经网络模型得到类别预测模型，通过类别预测模型确定待处理视频片段的动作类别预测信息，不需要人工标注训练数据，提高神经网络模型的训练效率、降低训练成本和提高类别预测模型的预测准确率。视频处理方法。该方法增强了类型预测模型的预测精度。该视频处理方法包括对待处理视频进行预处理，得到多个待处理视频段。 将所述待处理视频段输入所述预设类型预测模型进行动作类型预测。 获取与所述待处理视频段对应的动作类型预测信息。 所述类别预测模型是基于所述第一样本数据对第一神经网络模型进行训练得到的。 所述预训练模型是基于所述第二样本数据对所述第二神经网络模型进行训练得到的。本发明还涉及一种视频处理系统。 9
本发明公开了一种结合序列标注的事件联合抽取模型与方法，涉及文本数据挖掘领域技术领域，通过构建事件描述文件模板，对文本内容进行分词预处理；利用BERT预训练模型转换成对应的词向量，得到事件词向量，并输入至一维卷积神经网络对词向量进行局部特征提取，得到融合上下文特征的词向量；将词向量和通过序列标注编码的事件元素特征输入到条件随机场中，通过随机梯度下降优化方法进行训练；最后利用训练完成的条件随机场序列标注解码模型进行事件联合抽取；本发明利用单个汉字级的字符特征，避免词表分词错误的问题，通过局部卷积神经网络，融合局部上下文特征，提升捕捉语义能力，强化事件元素实体边界，提高抽取精度。绑定序列标记的事件组合抽取模型，用于文本数据挖掘领域。事件组合提取模型利用单个汉字级别的字符特征，避免词分词错误，通过局部卷积神经网络结合局部上下文特征，提高捕获语义能力，强化事件要素实体边界，提高提取精度。该模型具有卷积特征融合层，用于实现局部窗口卷积和上下文语义信息，以改进获得融合上下文词层次特征。 卷积特征融合层通过电动方式将融合框架词级别的特征传递给条件随机场序列解码层。 条件随机场解码层通过BI标签由文本序列识别事件触发词。 一个事件要素标识被视为一个序列标签分类任务。 输出层输出正确的标签组合。 输入层，用于对输入的文本序列进行BERT的中文字典编码。本发明还公开了一种结合序列标签的事件联合提取方法。  12
提出了一种遵循自然语言指令的机器人行为导航的可扩展解决方案。该解决方案的示例包括：通过预训练的序列预测模型接收任务环境的导航图、自然语言指令以及机器人在导航图中的初始位置，其中，导航图包括指示任务环境中的位置的节点、节点的坐标以及指示位置之间的连通性的边；通过预训练的序列预测模型，依次预测机器人可执行的一系列单步行为，以将机器人从初始位置导航到目的地。基于自然语言命令在任务环境中导航机器人的方法。该解决方案提供了用于导航遵循自然语言命令的机器人行为的可扩展解决方案。该方法包括通过预训练的序列预测模型接收任务环境的导航图、自然语言命令以及机器人在导航图中的初始位置。 导航图被提供有指示任务环境中的位置的节点。 指示所述节点的坐标与所述位置之间的连通性的边被指示。 通过预训练的序列预测模型依次预测机器人执行的一系列单步行为，将机器人从初始位置导航到目的地，其中基于当前节点的坐标预测有效节点转移的行为。针对以下内容包括独立权利要求：一种非暂时性计算机可读存储介质； 以及电子设备，特别是电子设备，诸如个人数字处理器、蜂窝电话、智能电话、可穿戴设备和其他类似的计算设备。  11
本发明涉及命名实体识别数据增强的方法、装置、电子设备和介质，该方法包括：获取第一数据集，将第一数据集进行扩充得到扩充数据集，将扩充数据集分为第一份扩充数据集和第二份扩充数据集；将第一份扩充数据集输入到BERT模型中得到句向量数据集；对句向量数据集聚类得到聚类结果；对聚类结果对抗训练确定簇数据集；使用GPT模型微调簇数据集得到第二数据集；使用第二数据集训练GPT模型得到预测模型；将第二份扩充数据集输入到预测模型中得到预测结果数据集；将预测结果数据集中的命名实体标签通配符替换为实体词典中的文字，确定第三数据集；将第三数据集与第一数据集合并得到最终的数据集。本申请实施例采用数据增强的方式可以减小所需要的数据量。用于识别由命名实体进行的数据增强的方法。该方法使得能够使用数据增强模式来减少从变压器(BERT)模型输入到双向编码器表示的所需数据量，从而减少训练BERT模型所需的时间并提高BERT模型的精确度。 本发明通过训练模块对聚类结果进行对抗训练，确定聚类数据集，从而利用聚类数据集训练生成的GPT预训练模型，提高GPT预训练模型的性能。所述方法涉及获得第一数据集，其中所述第一数据集包括与实体标签相对应的字符样本和词样本。 将词向量聚类为聚类结果。 对聚类结果执行聚类训练，以通过执行对抗训练来确定聚类数据集。 使用预训练模型来微调群集数据集以获得第二数据集。 使用第二数据集训练预测模型以获得预测模型。 将扩展数据集输入预测模型以获得预测结果数据集。 命名实体标签通配符在预测结果数据集中被替换为实体字典中的字符。 生成实体标签。独立的权利要求书包括： (a)用于识别由命名实体进行的数据增强的设备； (b)电子设备，包括存储器，用于调用由处理器执行的程序或指令，以实现由命名实体识别数据增强的方法； (c)计算机可读存储介质，其存储由计算机执行的程序或指令，以执行用于识别命名实体的数据增强的方法。  12
本发明通过网络安全领域的方法，实现了一种基于安全多方计算技术的隐私保护实体识别工具。包含嵌入矩阵共享、高敏感模块优化以及隐私保护预分块三个模块；嵌入矩阵共享模块获得高维词矩阵；高敏感模块优化模块对现有的四种高敏感模块进行优化；所述隐私保护预分块模块对两个计算参与方得到各自对应的一半结果A和结果B，并通过秘密共享协议的解密算法得到完整的明文结果“0”或“1”，即实体“匹配”或“不匹配”。本发明提供的方法提出了一个兼具稳定性和鲁棒性的隐私保护实体识别框架PRIBER，能够在Bert模型上采用安全多方计算技术执行实体识别二分类任务，并且不牺牲实体识别本身的准确性。信息安全领域的基于安全多方计算技术的隐私保护实体识别工具。该工具提供了一种稳定和鲁棒性的标识隐私保护PRIBER，能够利用安全多方计算技术对Bert模型执行实体识别两个分类任务，并且不牺牲实体识别本身的准确性。该工具具有嵌入式矩阵共享模块、高度敏感的模块优化和隐私保护预阻塞。 所述嵌入式矩阵共享模块使用嵌入式共享算法处理模型。 索引通过使用电子商务所有者提供的共享嵌入式矩阵来进行。 得到高维词矩阵。 高敏感模块优化模块对四个高敏感模块进行优化，并使用秘密共享协议对数据和模型进行加密。 参与者获得数据和模型的一半密文。 每个参与者独立计算自己的密文，并独立对密文进行计算操作。 隐私保护预阻塞模块对两个计算参与方分别得到一半的对应结果A和B。  11
本发明公开了一种基于预训练模型与提示学习的可解释电力设备查询方法，具体步骤如下：查询文本预处理；通过预处理后的查询文本数据训练实体抽取模型；通过预处理后的查询文本数据和实体抽取模型训练实体预测模型；电力设备查询，将预处理后的查询文本依次输入到实体抽取模型和实体预测模型中，得到电力知识图谱。采用上述一种基于预训练模型与提示学习的可解释电力设备查询方法，采用实体预训练模型结合提示学习的方法，对查询文本进行抽取，并匹配与之相关的电力设备，利用提示学习的优势将相关设备实体特征嵌入引入到查询中，提高查询准确率，同时通过相关设备实体特征对查询匹配做解释，帮助查询人员更全面的了解电力设备。一种用于电力设备和知识图谱技术领域的自然语言处理中的基于预训练模型和提示学习的可解释电力设备查询方法。该方法能够提示学习相关设备实体特征嵌入查询，从而提高查询的准确性，并解释与设备实体特征相关的匹配查询，从而帮助查询高效地了解综合电力设备。该方法涉及预处理文本查询，其中模型由预查询文本数据训练实体提取。 通过所述预查询文本数据和实体提取模型同步训练所述实体预测模型。 将所述预处理查询的电力设备查询依次输入至所述实体抽取模型和所述实体预测模型，得到电力知识图谱。 通过查询字符对文本进行截断，将文本查询中的字符转换为对应的编码，得到文本编码向量。 0
本发明公开基于深度学习的端对端语音识别系统，包括：声学模型，依次包括VGG‑Net层、第一全连接层、双向RNN层、第二全连接层、Softmax层及CTC层，用于提取音频的二维FBank特征经网络处理获得每个时间步的概率分布，根据时间步概率分布的熵值结果输出候选拼音序列；语言模型，与声学模型连接，包括Transformer编码器以及n‑gram模型；Transformer编码器用于根据输入的候选拼音序列，输出等长的汉字序列，n‑gram模型，用于对输出的汉字序列处理，选出目标汉字文本输出。本发明能得到最符合当前语境和人类表达习惯的最终识别结果。基于深度学习的端到端语音识别系统。端到端的语音识别系统得到最符合当前上下文和人类表达习惯的最终识别结果。该端对端语音识别系统包括声学模型，该声学模型依次包括VGG-Net层、第一全连接层、双向递归神经网络(RNN)层、第二全连接层、softmax层和连接时间分类(CTC)层。 根据所述时间步的归一化概率分布的熵值输出所述候选拼音序列。 与声学模型连接的语言模型包括依次连接的变压器编码器和n-gram模型。 变压器编码器，用于根据输入的候选拼音序列，输出与汉语拼音序列等长的汉字序列。 采用n-gram模型对变压器编码器输出的汉字序列进行处理并选择目标汉字文本输出。 3
本发明提供了一种发音偏误检测方法、装置及存储介质，所述方法包括构建语音预训练模型，并基于无标注语音语料库对所述语音预训练模型进行预训练；在所述语音预训练模型上添加一层随机初始化的全连接层，得到微调预训练模型，并使用带标注的发音偏误数据对所述微调预训练模型进行训练，得到发音偏误检测模型；利用所述发音偏误检测模型对学习者的语音进行检测，以获得发音偏误信息。本发明所述发音偏误检测方法、装置及存储介质，通过构建语音预训练模型、微调预训练模型，利用发音偏误检测模型对学习者的语音进行检测以获得发音偏误信息的方式，使得在缺少发音训练数据情况下，依然可以有效提升发音偏误检测系统的性能。本发明可用于基于语音预训练模型的语音偏差检测。本发明提高了语音训练数据缺失情况下的语音偏差检测系统的性能。该方法包括构建语音预训练模型。 所述语音预训练模型基于非标记语音语料库进行预训练。 在语音预训练模型上增加一层随机初始化的全连接层。 得到微调预训练模型。 微调预训练模型利用带标签的语音偏差数据训练得到语音偏差检测模型。 利用发音偏差检测模型对学习者的语音进行检测，得到发音偏差信息。本发明还涉及一种基于语音预训练模型的语音偏差检测装置。 以及计算机可读存储介质，包括一组用于基于语音预训练模型执行发音偏差检测方法的指令。 3
本发明公开了一种基于令牌混合的遥感语义变化检测技术，针对多任务学习耦合二值变化检测和语义分割子任务提高效率和精度。通过采用预训练大模型编码器构建孪生网络，提取双时多尺度特征，并利用交叉注意模块实现两个图像之间的信息通信。将二值变化检测和语义分割子任务在同一框架下进行端到端训练，高度耦合得到语义变化检测结果。与现有技术相比，本发明具有精度高和快速检测的优势，为遥感图像变化检测领域提供了新的解决方案。基于令牌混合的多任务遥感语义变化检测方法，用于利用同一区域的多时相遥感影像识别定位变化目标。该方法能够对同一帧下的二值变化检测和语义划分子任务进行端到端训练，高度耦合得到语义变化检测结果，从而提供高精度和快速检测，为遥感影像变化检测领域提供新的解决方案。该方法涉及堆叠(S1)32层电源块。 采用16个多尺度注意力力头。 通过16个多尺度注意力头添加(S2)可学习位置编码F2的特征F1。 隐藏层是1028维。 通过卷积将维数减少到分类数，MLP大小是3层功率解码器的5120。 通过卷积来减少(S3)通道的数量。 获得原始图像尺寸(S4)。 通过softmax激活函数得到每个像素的语义分割结果。 伪二值变化检测结果与语义分割图像相乘(S5)，得到最终的语义变化检测图像。   6
本发明提供了一种大语言模型人脸特征分析方法、系统及电子设备，所述方法包括对人脸图像进行图像预处理，以得到处理图像数据集；将测试样本集输入训练后的卷积神经网络CNN中进行关键点检测，以得到若干基本关键点；对第一边缘关键点进行数据标注与过滤，以得到人脸稠密关键点；对人脸稠密关键点进行人脸特征分析与描述，以得到特征识别结果；建立结果阈值集与语料匹配规则，根据结果阈值集与语料匹配规则对大语言模型进行训练，本发明对人脸进行稠密关键点特征分析和描述，从而提高人脸识别的准确性，避免误识别和漏识别的情况，同时本发明能够识别人脸的表情和情感，有助于更加全面地理解人脸的信息。用于通过使用在大型语言模型领域中使用的电子设备(权利要求书)来分析大型语言模型中的人脸特征的方法。该方法能够对人脸进行密集关键点特征分析和描述，从而提高人脸识别的准确性，避免误识别和漏识别的情况，能够有效地识别人脸的表情和情感。该方法包括获取人脸图像数据集。 对所述人脸人脸数据集合中的人脸人脸图像进行图像预处理处理，得到处理后的人脸数据组。 将处理后的人脸图片数据组按照预设比例分为训练样本集和测试样本集。 将训练样本组输入卷积神经网络(CNN)进行训练。 将测试样本组输入到训练好的CNN中进行关键点检测，得到多个基本关键点。 基于特征识别结果建立结果阈值集和语言学数据匹配规则。 根据所述结果阈值组和所述语言学数据匹配规则训练大型语言模型。还包括用于大型语言模型人脸特征分析系统的独立权利要求。 2
本发明公开了一种基于RoBERTa模型的情感分析方法及装置，属于自然语言处理技术领域，包括获取文本情感分析数据集并进行预处理，得到训练集、验证集和测试集；提取训练集和验证集的评论文本，转换成无标签数据作为RoBERTa模型预训练任务的语料；构建RoBERTa‑WWM‑ext模型和双向独立循环神经网络并训练，将已完成预训练的RoBERTa‑WWM‑ext模型的最后一层隐藏层外接双向独立循环神经网络，得到情感分析模型，其中，双向独立循环神经网络需要对双向独立循环神经网络输出的特征向量进行权重分配；通过情感分析模型，对测试集进行情感极性预测输出情感类别标签；该方法可以有效提升文本情感分析的精度表现。一种基于Roberta模型的情感分析方法，用于收集观点作为反馈信息，具有促进服务社会的实际意义。本发明有效提高了文本情感分析的准确性能。 采用交叉熵函数对情感分析模型进行训练，得到优化的情感分析模型。该方法包括通过对掩码标志执行字预测来训练roberta-wwm-ext模型，以获得训练的roberta-wwm-ext模型。 构建并训练双向独立递归神经网络。 完成掩蔽预测训练任务的Roberta-WWMEXT模型的最后一个隐藏层被连接到双向独立递归神经网络以获得最终的情感分析模型。 需要双向独立递归神经网络对其输出的特征向量进行权值分配。 通过最终情感分析模型进行情感极性预测。 将测试集中的评论文本输入情感分析模型。 输出情感类别标签。本发明还涉及一种基于罗伯塔模型的情感分析装置。  12
本发明公开了一种轨交智能运维大模型MOT及其构建方法，该模型轨交多专业知识图谱、大语言模型、LangChain代理框架，所述LangChain代理框架第一端与用户通信连接；所述LangChain代理框架第二端与大语言模型通信连接；所述LangChain代理框架第三端与轨交多专业知识图谱连接。该构建方法包括基于轨交运维知识数据构建轨交多专业知识图谱；基于LangChain代理框架依次对轨交多专业知识图谱、用户和大语言模型构建通信连接，得到轨交智能运维大模型。通过使用本发明，能够将大语言模型和轨道交通运维场景有效结合。本发明可广泛应用于轨交智能运维技术领域。轨道穿越智能化运维大模式。该模型能够有效地将大型语言模型与轨道交通运维场景相结合。该模型具有LangChain代理框架，其第一端与用户相连，用于问题获取和答案响应。 所述Langchain代理框架的第二端与用于搜索问题、反馈关键词、整合数据和反馈答案的大型语言模型通信连接。 朗链代理框架的第三端与铁路道口多专业知识地图连接，用于搜索问题关键词并反馈答案关键词。 所述铁路道口多专业知识地图上设置有车辆、电源、信号、通讯、机电、多专业运维知识地图。独立权利要求还包括用于：(1)一种轨道跨越智能运维大模型构建方法； (2)存储介质，用于存储构建所述轨道穿越智能运维大模型的指令集。 13
一种基于LoRA技术的领域自适应合成方法，包括：获取应用于大语言模型的m个领域的训练数据集Z1，Z2...Zm；在预训练大语言模型上设置m个Lora适配器组，其中，m个Lora适配器对应m个领域，m为大于2的自然数；按预设规则训练S200中设置的m个Lora适配器组，使用所述预训练大语言模型及所述m个Lora适配器组对相对应领域进行推理。本发明公开的一种基于LoRA技术的领域自适应合成方法，与传统的微调方法相比，可以有效地减少信息遗忘现象，提高模型的泛化性能和学习效率。同时，该方法也具有较好的可扩展性和通用性，在多个领域具有广泛的应用前景，可广泛应用于自然语言处理、语音识别、计算机视觉等多个领域。用于自然语言处理、语音识别和计算机视觉等多个领域的基于Lora技术的领域自适应合成方法。场自适应合成方法与传统的细调方法相比，能够有效减少信息遗忘现象，提高模型的泛化性能和学习效率。 该方法具有良好的可扩展性和通用性，在多个领域具有广泛的应用前景，可广泛应用于自然语言处理、语音识别和计算机视觉等多个领域。该方法涉及获得(S100)m个字段中的训练数据集Z1、Z2和Zm。 在预先训练好的大型语言模型上设置(S200)M个Lora适配器组，M个Lora适配器组对应M个字段，M为大于2的自然数。 根据预设规则对所述m个Lora组进行训练(S300)。 利用所述预训练大语言模型和所述m个Lora组推理出对应的字段(S400)。 将可训练的秩分解矩阵对添加到预先训练的大型语言模型换能器单元中的自注意力模块中的查询矩阵和值矩阵中。本发明还公开了一种基于LoRA技术的场自适应合成系统。  11
本发明的实施例提供了一种语音合成模型训练方法、装置、电子设备和计算机可读存储介质，涉及数据处理技术领域，方法包括：获得待输出文本信息和家居场景对应的训练风格嵌入信息，根据待输出文本信息和训练风格嵌入信息得到与家居场景对应的待合成声音预测特征，对待合成声音预测特征进行合成，获得待输出语音数据，从而合成与家居场景适配、具备较好清晰度的语音。一种使用电子设备训练语音合成模型的方法(要求保护)。本发明能够提高合成语音与家居场景的匹配度。 本发明能够保证智能设备播放语音的清晰度。 用户可以准确地接收广播的语音。 保证了在噪音大的家居环境中与用户语音交互的流畅性。所述方法包括：获取待输出信息；获取与家庭场景对应的训练风格嵌入信息。 训练风格嵌入信息用于表征对应于家庭场景的场景声学风格。 根据文本信息获得待合成声音预测特征。 合成声音预测特征以合成声音预测结果。 输出语音数据。本发明还涉及一种语音合成模型训练装置。 (2)计算机可读存储介质。 3
本申请公开了一种基于深度学习的三维测量分割方法，使用深度模型自动分割识别工件点云，在深度学习网络模型上，为了将全局特征和局部特征融合学习，深度学习网络模型基于特征融合的思想，使用U‑Net网络结构，在采样层使用基于点云相似度的差异度下采样，旨在解决选取编码层每层特征最为突出的感受域来学习点云特征的问题；深度学习网络模型通过自注意力机制提取优化感受域局部特征，借鉴多层感知机混合器里的空间混合多层感知机建立感受域之间的全局联系提取感受域全局特征，在此基础上通过卷积网络进行局部特征和全局特征的特征融合学习，以提高工件点云自动识别分割的准确性。基于深度学习实现工件点云三维测量与分割的方法。本发明利用深度模型对工件点云进行自动分割和识别，从而在深度学习网络模型上对全局特征和局部特征进行融合和学习，在采样层基于特征融合和点云相似度的思想，通过U-Net(Net)结构，实现了深度学习网络模型对差异度的采样，并通过选择编码层的层特征的突出接收域，减少了点云特征学习的问题。 通过自注意力机制提取优化后的感受域深度学习网络模型的局部特征，以参考多层感知器混合器中空间混合多层感知器建立的感受域之间的全局关系，提取感受域的全局特征，并通过卷积网络对局部特征和全局特征进行特征融合学习，从而提高工件点云自动识别分割的准确性。该方法涉及使用深度模型自动分割和识别工件点云。 利用采样层和分组层提取当前输入点云的感受域，得到一层编码层特征。 选择上层编码层特性作为输入。 重复编码操作两次，得到点云的编码特征。 通过邻域自注意力层对所述点云的编码特性进行优化，得到一层解码层特性。 选择上层解码层特性作为输入。 重复两次解码操作，直到解码层特征拼接到初始原始点云上进行解码。 获得点云的点的解码层特性。 使用用于实现分割任务的全连接网络获得所述点云中的点的预测分类。   6
本发明的实施例提供了一种基于语音的交互方法、装置、智能设备和计算机可读存储介质，涉及智能交互技术领域，方法包括：接收所处家居空间的声音数据，获得与声音数据对应的家居场景类型，当获得交互指示时，通过与家居场景类型对应的语音预测策略生成预测声学特征，对预测声学特征进行合成，获得与交互指示对应的输出响应语音数据，从而提高了输出响应语音数据的适配度。用于识别智能设备(要求保护)的基于语音的交互式内容的方法。本发明能够合成出相应场景声学风格的语音数据进行播放，保证了语音的识别度，自然度和可懂度，保证了用户语音交互在噪音大的家居环境中的流畅度。该方法包括接收家庭空间的声音数据。 获得与声音数据相对应的家庭场景类型。 当获得交互指示时，通过对应于家庭情景类型的语音预测策略来生成预测的声学特征。 合成预测的声学特征。 获取与交互指示对应的响应语音数据。 声音数据被发送到语音到语音模块。独立的权利要求书包括： (1)用于识别智能设备的基于语音的交互式内容的设备； (2)包括用于识别智能设备的基于语音的交互式内容的计算机程序的计算机可读存储介质。 3
本发明提供一种基于跨语言的自动问答、模型训练方法及设备，其中的方法包括：获取问题和文本，文本的语言不同于问题的语言；将问题和文本输入至自动问答模型，得到自动问答模型输出的文本中问题的答案的位置信息；其中，自动问答模型是基于问题样本及包含问题样本的答案的文本样本，对包含知识增强的预训练模型的预设模型进行训练得到的，知识增强的预训练模型是基于利用知识图谱构建的多个多元组，对初始的预训练模型进行预训练得到的，能够学习到跨语言的知识以建立不同语言之间的对应关系，从而使得知识增强的预训练模型的推理能力和对不同语言的理解能力得到了增强，进而实现了自动问答模型对跨语言的问答的性能的提升。一种基于跨语言的自动问答方法，用于人工智能技术领域，也可用于自然语言处理任务中。 用途包括但不限于以下问题：中文表达式1：今天原油上升了多少，文本1：基于英文表达式的纽约Mercantile le上的ahead of light，以及纽约商品证券交易所一桶轻质低硫原油的问题，今天上涨1.55美元，收于63.38美元，并提取答案“1.55美元”(声称)。所述知识增强预训练模型的推理能力和对不同语言的理解能力增强，从而实现自动问答模型提高跨语言问答的性能。该方法包括获得问题和文本。 将所述问题和所述文本输入自动问答模型，得到所述问题的答案在所述自动问答模型输出的文本中的位置信息。 基于文本样本和包含问题样本的答案训练包含知识增强的预训练模型的预设模型。 基于利用知识图谱构建的多个多元组构建预训练模型。对于基于跨语言的自动问答模型训练方法，还包括独立的权利要求。  11
本发明公开了一种创建方法、探测方法、装置、电子设备和可读介质，该创建方法包括以下步骤：获取多个网页对应的网页内容，对每个网页内容进行以下处理：基于所述网页内容中的全部第一单词生成所述网页对应的二进制编码C1，获取所述网页中的所有下级路径对应的二进制编码C2，之后，基于全链接神经网络和sigmoid函数将所述二进制编码C1映射到所述网页内容中的每个第一单词出现的概率；创建BERT神经网络，对每个网页进行以下处理：将所述网页的二进制编码C1和二进制编码C2输入到所述BERT神经网络，对所述BERT神经网络进行训练。从而能够产生Web路径。该方法可用于通过使用电子设备(要求保护)来创建神经网络。该方法包括：建立BERT神经网络； 并以简单有效的方式检测网页内容中的网页路径。该方法包括：获取与网页相对应的多个网页内容； 对每个网页内容进行以下处理， 基于网页内容中的所有第一字生成与网页相对应的二进制代码C1； 获取网页中所有下一级路径对应的二进制代码C2， 获取网页中与下一路径对应的二进制代码C2， 基于全链接神经网络和Sigmoid函数，将二进制代码C1映射到网页内容中每个第一个词出现的概率， 创建BERT神经网络，对每个网页执行以下处理，并将网页的二进制代码C1和C2输入BERT神经网络以训练BERT神经网络。还包括独立的权利要求： 用于创建神经网络的设备； 一种计算机可读存储介质，包括一组用于创建神经网络的指令； 一种网络路径检测方法； 以及 一种卷筒纸路径检测装置。  11
本发明提供了一种基于大模型的政策确定方法、系统、终端及存储介质，该方法包括：获取政策文档，并对所述政策文档进行数据清洗；对数据清洗后的所述政策文档进行特征工程，并根据特征工程结果对所述政策文档进行特征标记；根据任务需求确定大模型，并根据特征标记后的所述政策文档对所述大模型进行训练，直至所述大模型收敛；将企业信息输入收敛后的所述大模型进行政策匹配，得到目标政策信息。本发明实施例，基于收敛后的大模型，能自动进行政策匹配，得到目标政策信息，无需采用人工的方式查看政策和解读政策，降低了人力成本和时间成本，提高了政策确定效率。基于大模型确定策略的方法。该方法能够基于收敛后的大模型自动匹配策略，得到目标策略信息，无需人工查看策略和读取策略，降低了人力成本和时间成本，提高了策略确定效率。该方法包括获取策略文档和清理策略文档的数据。 对数据清洗完成后的策略文档进行特征工程。 根据所述特征工程结果对所述策略文档进行标记。 根据任务需求确定大模型。 对特征标记后的大模型进行训练，直至大模型收敛。 对所述企业信息输入进行收敛处理后得到所述目标政策信息。独立权利要求还包括用于：基于大模型的策略确定系统； 以及计算机可读存储介质，其包括用于基于大型模型来确定策略的指令集。  11
本发明提供了一种基于Prompt多模板融合的零样本关系抽取方法。该方法包括：将需要抽取关系的文本数据与预先定义的Prompt模板进行组合后，输入到预训练语言模型中，输出完形填空任务的结果，将这个结果的词嵌入输出转换成关系表示；将需要抽取关系的文本数据按照重复操作输入到不同类型的预训练语言模型中，得到多种关系表示，根据关系描述文本中的词性与不同Prompt模板之间的关系权重，对多种关系表示进行融合；将融合后的多种关系表示与关系描述文本生成的词嵌入进行欧式距离的比较，将距离转化为对应关系的概率，输出最大概率的所述需要抽取关系的文本数据的零样本关系类别。本发明方法优化了模型生成表示的能力，提高了零样本关系抽取任务的F1值。基于快速多模板融合进行零样本关系提取处理的方法。该方法能够优化模型生成表示的能力，提高零样本关系提取任务的F1值。该方法涉及构建形状填充任务模式的预训练语言模型。 将待提取文本数据与预先定义的提示模板进行组合。 将所述待提取文本数据输入所述预训练语言模型。 由所述预训练语言模型输出完整填充任务的结果。 将结果的词嵌入输出嵌入到关系式中。 根据重复操作将所述待提取文本数据输入到不同类型的所述预训练语言模型中。 得到多个关系表示。 根据所述关系描述文本中的词属性与不同的提示模板之间的关系权重对所述多个关系表示进行融合。该方法包括嵌入生成词，用于通过融合的多个关系表达式和关系描述文本进行欧几里得距离比较。 将所述距离转换为所述对应关系的概率。 输出所述关系类型的文本数据的最大概率。  11
本发明公开了一种基于集成学习的细粒度情感分析方法，涉及文本挖掘领域，用于解决单模型的不能对多个类别情感进行分析的问题，该方法包括以下步骤：获取文本数据，基于单层一维卷积神经网络，通过嵌入层、max‑pooling层、transformer层、门单元层、softmax层的处理完成模型训练；通过集成学习获得TEACHER模型；经模型蒸馏得到STUDENT模型；加载TEACHER模型和STUDENT对文本数据进行分析，得到情感分析结果。本发明还公开了一种基于集成学习情感分析装置、电子设备和计算机存储介质。本发明通过文本数据进行分析，得到多类别的情感分析结果。基于集成学习的精细敏感性分析方法。该方法使得能够对文本数据进行分析，得到多类情感分析结果。该方法包括获得文本。 对所述文本进行分词处理，得到切分结果。 将所述分割结果输入嵌入层。 设置最大字数。 对字数进行调整，形成三维矩阵。 将所述三维矩阵输入具有不同核的单维卷积神经网络单层，得到待合并输出结果。 将所述三维矩阵与二维矩阵组合，得到输出矩阵。 输出矩阵被输入到门单元层中。 向量的Score输入到softmax层，得到单维情感向量。 存储最高模型分数。 建立单个模型。 加载单个模型。 对所述单维情感向量进行加权平均处理。 将文本输入教师模型，得到不同类别对应的多个情绪对应的输出结果。本发明还公开了一种基于集成学习的精细敏感性分析装置，包括处理器和存储器，用于执行基于集成学习的精细敏感性分析方法，以及计算机可读存储介质，用于存储用于执行基于集成学习的精细敏感性分析方法的一组指令。  12
本发明涉及一种示例库的构建、使用方法以及生成的代码的评估方法，该构建方法包括如下步骤：构建种子示例库；生成增强示例，基于所构建的种子示例库，使用LLM生成增强示例任务和增强示例代码；对生成的增强示例任务和增强示例代码进行人工校验；将校验后的增强示例任务和增强示例代码对应关联成增强示例，并加入到创建的增强示例库中；判断所述增强示例库中的增强示例的数量是否满足设定要求，若否则重复生成新的增强示例的步骤，直至所述增强示例库中的增强示例的数量满足设定要求为止。本发明基于人工构建的少量的种子示例库，利用LLM自动生成增强示例，大大降低了开发者的工作量和难度，也使得代码生成更为高效和准确。用于构建实例文库的方法。该方法能够利用LLM基于少量人工构建的种子实例库自动生成增强实例，从而有效降低开发人员的工作量和难度，实现高效准确的代码生成性能。该方法包括构建种子实例库，其中种子实例库中的种子实例包括种子实例任务和种子实例代码。 生成增强示例。 基于所构建的种子实例库，使用大型语言模型(LLM)来生成增强型实例任务和增强型实例代码。 手动验证所生成的增强示例任务和所述增强示例代码。 将验证的增强示例任务与增强示例代码相关联以形成增强示例。 增强示例被添加到创建的增强示例库中。 进行确定以检查增强示例库中的多个增强示例是否满足设置的要求。 如果所述增强实例库中的增强实例的数量满足完成实例库的构建的要求，则将所述种子实例库和所述增强实例库组合在一起作为实例库。包括独立权利要求：(1)一种利用实例库的方法； 以及(2)用于评估生成的示例代码的方法。  11
本发明公开了一种基于投影梯度下降和标签平滑的文本意图识别方法及系统，涉及自然语言处理问答系统领域。包括(1)通过嵌入层获取初始向量编码；(2)在嵌入层使用投影梯度下降算法添加满足L2约束的扰动，形成对抗样本；(3)使用Transformer网络编码上下文语义信息；(4)使用标签平滑将真实意图类别进行缩放；(5)将编码器输出特征输入分类器，计算与平滑后的标签之间的交叉熵；(6)优化目标函数；(7)模型训练完毕，预测意图类别并输出。本发明模型在分类任务中，能够对输入的意图进行充分的语义向量编码；同时在文本嵌入层添加扰动形成对抗样本、对最终分类目标进行标签滑动，能显著提升模型的鲁棒性和泛化能力。该方法包括建立预训练语言模型，其中预训练语言模型包括嵌入层、十二层网络和分类层。 根据字符分割执行唯一的热编码。 通过所述嵌入层将所述唯一热度编码转换为固定长度的文本嵌入向量。 采用投影梯度下降算法在嵌入层上添加扰动满足约束。 获取对抗样本的文本嵌入向量。 得到反样本语义向量。 通过标签平滑算法对样本句的意图标签进行缩放，得到平滑的意图标签。 利用所述训练好的语言模型读取待识别文本语句的唯一热编码输出意图识别结果。   5
本公开提供了一种文本分类模型的训练及文本分类方法、装置、设备和介质，涉及深度学习和自然语言处理等领域。具体实现方案为：对获取的多个样本文本进行聚类，得到至少一个目标聚簇；根据各样本文本所属的目标聚簇，生成各样本文本对应的簇标签；采用文本分类模型对各样本文本进行第一类别预测，得到各样本文本的预测标签；根据各样本文本对应的预测标签和簇标签对文本分类模型进行第一训练。由于聚类可捕捉到样本文本中显著的语义特征，通过对多个样本文本进行聚类的方式，来生成各样本文本对应的簇标签，并基于簇标签对文本分类模型进行预训练，可以使得文本分类模型在真实训练之前，有效学习到样本文本中显著的语义信息，提升模型表现和性能。训练文本分类模型的方法。该方法有效地学习了样本文本中明显的语义信息，因此提高了模型性能和性能。 该方法使得文本分类模型能够基于聚类标签进行预训练，从而使得分类模型能够在真正的训练之前进行，从而能够有效地学习文本中明显的语义特征。该方法包括获取(201)若干样本文本。 对若干样本文本进行聚类，得到目标聚类。 根据每个所述样本文本所属的目标聚类生成(202)每个所述样本文本对应的聚类标签。 聚类标签用于指示样本文本所属的聚类类别。 利用文本分类模型(203)对每个所述样本文本进行第一类别预测。 获取每个所述样本文本对应的预测标签。 根据每个所述样本文本对应的所述预测标签和所述聚类标签对所述文本分类模型进行第一训练(204)。独立权利要求包括：(1)文本分类方法； (2)文本分类模型的训练装置； (3)文本分类装置； (4)电子设备； (5)一种存储用于训练文本分类模型的程序的非暂态计算机可读存储介质； 以及(6)计算机程序产品。  11
本申请实施例提供一种构建测试模型的方法、装置、测试方法及存储介质，该方法包括：获取具有缺陷内容的历史数据集；构建初始BERT模型；对所述历史数据集进行预处理得到词表，所述预处理包括分词和编码；通过所述词表对初始BERT模型进行深度学习训练得到测试模型。该方法实现了快速准确的判断缺陷数据。构建试验模型的方法。该方法能够快速、准确地判断缺陷数据。该方法涉及获取具有缺陷内容的历史数据集，构建初始BERT模型。 对所述历史数据集进行深度学习预处理，得到词表。 所述深度学习预处理包括分词和编码，通过所述词表对所述初始BERT模型进行深度学习训练，得到测试模型。 历史数据集包括文本缺陷描述和分类标签。 通过编码器将历史数据集中的每个数据转换成能够被初始BERT模型识别的序列，并根据该序列生成标记。包括独立权利要求，用于：(1)构建试验模型的装置； (2)机器可读存储介质，所述机器可读存储介质存储有用于实现所述测试模型的构建方法的指令； (3)处理器，用于构建测试模型； (4)一种用于构建测试模型的计算机程序产品。  12
本发明涉及一种基于生成式对抗网络的行人检测数据扩充方法，包括：S1、搭建三层级联生成式对抗神经网络模型，并设定模型训练的目标函数；每层生成式对抗神经网络均采用BicycleGAN的结构，生成器采用残差U‑net结构，后一层的网络的输入为行人实例掩码图片和前一层网络的输出；S2、训练数据预处理；S3、采用预处理后的数据训练三层级联生成式对抗神经网络模型；S4、通过三层级联生成式对抗神经网络模型完成行人检测数据的扩充。采用本发明的方案生成的行人与背景融合更加自然，通过生成器的U‑net结构进行改进，使生成的行人细节更加精细；基于级联结构生成多尺度的行人图片，提高了大尺寸、高分辨率行人图片的质量；能够生成多样化的行人，提高了数据扩充的效率。基于生成对抗网络的行人检测数据扩展方法。行人检测数据扩展方法的方案生成的行人和背景更加自然，并且改进生成器的U网结构，使生成的行人细节更加细化。 基于级联结构生成多尺度行人图片，提高了大尺寸、高分辨率行人图片的质量。 生成了多样化的行人，提高了数据扩充的效率。该方法涉及构建三层级联的生成对抗神经网络模型，并设定模型训练的目标函数。 每层生成对抗神经网络采用单车生成对抗网络(GAN)结构，生成器采用残U-net结构。 后一层网络的输入是行人实例的掩模图片。 对所述数据预处理进行训练。 预处理后的数据用于训练三层级联生成对抗神经网络模型。 通过三层级联的生成对抗神经网络模型完成行人检测数据的扩展。   4
本发明提供了一种基于MSDNet和空间划分的场景文本检测方法，包括选取MSDNet网络模型，确定初始预训练模型；搭建空间划分网络；搭建回归网络；构造分类loss；空间划分集成；使用concat‑nms算法第一步后处理；使用box‑fix算法第二步后处理；使用tensorflow深度学习框架对已有的数据进行训练；使用已训练好的模型进行场景文本检测。本发明提供的方法可以自由地根据硬件条件和速度要求来选择不同的模型输出端口，通过提出的concat‑nms和box‑fix算法，来生成任意长的和更精确的文本框，在场景文本检测方面取得了令人满意的实验结果。因此，相较于现有技术，本方法灵活性好、分类精度较高、模型训练简单且实用性高。基于MSDNet和空间划分的场景文本检测方法。增加了进行场景文本检测的灵活性和分类精度。 保证了进行场景文本检测的模型训练简单、实用性高。该方法涉及构建特征金字塔，确定初始预训练多尺度密集网络(multi-scale dense network，MSDNet)的网络模型。 线性分类器被构造成检测图像中的文本区域。 构建帧回归网络，输出帧回归结果。 结合空分网络和文本区域划分结果的学习任务，对文本区域划分结果进行空分整合。 基于边界框回归结果和空分积分结果进行第一后处理，得到第一后处理结果。 利用box-fix算法，根据所述第一后处理结果进行第二后处理，得到第二后处理结果。 利用tensorflow深度学习框架，构建MSDNet和空间划分相结合的检测模型，对已有数据进行训练，得到训练好的检测模型。   6
本发明涉及自然语言处理技术领域，具体涉及一种基于不平衡数据的情感分类方法，包括：对文本集合中的所有文本进行预处理，形成无噪音的若干正、负类文本集合，设定文本数量多于一设定数量值的正类文本集合或者负类文本集合为多类文本集合，设定文本数量少于该设定数量值的正类文本集合或者负类文本集合为少类文本集合；对若干多类文本集合进行聚类，使得若干多类文本集合聚合后生成若干个子类文本集合，从每个子类文本集合中选取一定数量的文本集合，然后与全部少类文本集合融合，生成另一子类文本集合；采用Tensorflow2.0和Bert模型，所有子类文本集合作为训练样本进行训练，得到最优的文本分类模型。该方法可以解决数据样本分布的不平衡的问题。一种基于不平衡数据的情感分类方法，用于自然语言处理研究领域。本发明提供的基于不平衡数据的文本情感分类方法，用于构建平衡数据集，完成数据集平衡处理，然后将数据集划分为训练集，交叉验证集，测试集，进行模型训练。该方法包括预处理文本集中的所有文本以形成多个无噪声的正文本集和负文本集。 文本号被设置为大于被设置为多类型文本集的正文本集或负文本集的设置数值。 文本被设置为小于所设置的数量。 生成子文本集。 本发明通过对文本分类模型的改进，获得了最优的文本分类模型。张紧流 和BertModel。独立的权利要求书包括： (a)具有用于存储计算机程序的存储器的电子设备； (b)用于与计算机程序一起存储的可读存储介质；  12
本公开涉及自然语言处理技术领域，提供了一种基于全媒体内容可信共治的标签生成方法及装置。该方法包括：扩充行业关键词表；计算每个行业对应的关键词的向量加权平均值，将该向量加权平均值作为对应行业的行业分类向量，得到行业分类向量集合；计算该文本信息的向量加权平均值，将该向量加权平均值作为该目标稿件的稿件向量；分别计算该行业分类向量集合中的每个行业分类向量和该稿件向量的余弦夹角，得到余弦夹角集合；选取目标数量个行业标签，将选取到的目标数量个行业标签作为该目标稿件的标签。利用已有的轻量级标注数据和词向量模型，根据相似词查找扩展标注语料，最后根据预训练模型计算余弦夹角继而对语料完成自动化打标。基于全媒体内容可信度协同处理的标签生成方法，用于自然语言处理领域。本发明解决了现有技术中语言数据需要人工标注，成本高，耗时长的问题。该方法包括扩展(S101)行业关键字表以获得行业关键字集。 基于预训练模型和行业关键词集计算(S102)对应于每个行业的关键词的向量加权平均值。 基于预训练模型和与目标原稿相对应的文本信息来计算文本信息的向量加权平均值(S103)，并且将文本信息的向量加权平均值作为目标原稿的原稿向量。 分别计算行业分类向量组中的每个行业分类向量和原稿向量的余弦夹角(S104)，以获得余弦夹角组。 基于余弦夹角组中的余弦夹角选择(S105)目标数目的行业标签，并且将所选择的目标数目的行业标签作为目标原稿的标签。独立的权利要求书被包括在以下内容中： (1)一种基于全媒体内容可信度协同处理的标签生成装置； (2)基于全媒体内容可信度协同处理生成标签的计算机装置； 以及 (3)计算机可读存储介质，存储用于基于全媒体内容可信度共同处理来生成标签的程序。  12
本发明公开了一种基于BERT神经网络和多任务学习的主观题自动评阅方法，涉及人工智能与智慧教育的交叉领域。首先，使用经过大规模语料预训练的BERT神经网络进行编码，有效解决主观题自动评阅任务中语料过小的问题，并联合训练一个具有学生答案代词消代与主观题自动评阅的多任务神经网络模型。其次，使用所训练的多任务神经网络模型，从题干中提取代词成分来替换学生答案中的代词，确保学生答案语义的完整性。然后，将消代后的学生答案与标准答案形成句子对，送入BERT神经网络进行分类，得到学生答案的评分等级。通过消除学生答案中的代词，以更有效的方法解决主观题自动评阅问题。该方法对于人工智能和智能教育的交叉是有用的。该方法：解决主观题自动测评中任务过小的问题，联合训练学生回答代词剔除与主观题自动测评的多任务神经网络模型； 并剔除学生答题中的单词，以高效的方式解决主观题自动评分的问题。该方法涉及使用来自变换器(BERT)神经网络的共享双向编码器表示作为知识源。 将生成后的一个标准答案和学生答案形成为自动测评学习任务的输入序列。 采用所述共享BERT神经网络进行编码分类，得到学生答题评分等级。 通过联合计算损失函数，联合训练出具有学生回答词生成和主观题自动测评的多任务神经网络模型。 多任务神经网络模型用于消除和复习任何学生答案。  12
本发明公开了一种心理学上想法认知偏差的识别方法、装置及电子设备，其中方法包括：接收用户输入的问题文本信息，并将所述问题文本信息进行数据清洗；将数据清洗后的问题文本信息与用户画像信息进行拼接，得到拼接文本信息；基于预先建立的词典，将所述拼接文本信息转换为数值向量，并将所述数值向量输入至预训练模型XLNET，编码用户问题向量特征；利用分类器对所述用户问题向量特征进行分类，预测每个类别对应的概率值，将最大概率值对应的类别作为想法认知偏差的识别结果。本发明将深度学习算法与心理学想法认知偏差交叉学科间创新应用，通过程序自动化识别认知偏差，提升了心理问诊的普适性和便捷性。心理学观念认知偏倚识别方法。该方法创新性地将深度学习算法和心理思想认知偏差应用于交叉学科，通过程序自动识别认知偏差，提高了心理咨询的普遍性和便捷性。所述方法包括接收(S101)用户输入的问题文本信息，所述数据清洗是对所述问题文本信息进行的。 将数据清洗后的问题文本信息与一用户画像信息进行拼接(S102)，得到拼接文本信息。 基于预先构建的词典，将拼接后的文本信息转换(S103)为数值向量。 将数值向量输入预训练模型XLNET中，对用户问句向量特征进行编码。 分类器被配置(S104)以对所述用户问题向量特征进行分类。 预测每个类别对应的概率值。 一个最大概率值对应的类别配置为思想认知偏差的识别结果以下包括独立权利要求：1。 心理学观念认知偏倚识别装置； 2. 电子设备； 3. 一种计算机可读存储介质，其存储用于识别心理学观念认知偏倚的方法的程序。  11
本发明提供了语音合成、语音合成模型训练方法、装置及存储介质，其中，语音合成方法包括：通过获取输入文本，将输入文本输入语音合成模型，利用语音合成模型中的分词子模型对输入文本进行分词得到词向量，并利用语音合成模型中的至少两个语音特征识别子模型分别对词向量进行语音特征识别，对应得到至少两组语音特征，根据至少两组语音特征将输入文本转化成音频输出。本发明所提供技术方案中的语音合成任务包括多个语音特征识别子任务，通过将语音合成任务中的多个语音特征识别任务进行合并，能够提升语音合成效率。用于执行语音合成的方法。本发明将语音特征识别与语音合成任务相结合，提高了语音合成的效率。 本发明克服了现有技术的困难，提高了语音合成的效率。该方法包括获得输入文本。 将输入文本输入到语音合成模型中。 在语音合成模型中使用分词子模型对输入文本进行分词以获得词向量。 在语音合成模型中使用两个语音特征识别子模型，分别对一个词向量进行语音特征识别。 对应获得两组语音特征。 根据两组语音特征将输入文本转换为音频输出。 对原始文本进行正则化处理，得到输入文本。独立的权利要求书包括： (1)语音合成模型训练方法； (2)语音合成装置； (3)语音合成模型训练装置； (4)一种电子设备，包括用于执行语音合成的处理器和存储器； (5)一种用于可读存储介质的计算机，用于存储一组指令以执行用于执行语音合成的方法。 3
本发明提供一种基于搭配修辞语法纠错的作文批改方法及系统，本发明构造了条件随机场层；条件随机场层以马尔科夫决策链为基础，可以重新串联语句词与词之间的关系，将BERT编码单元的输出输入到条件随机场层之后运行改进过后的维特比算法解码出最后的语法修改标签；输出构建单元则基于语法修改标签构造出输出的正确句子。基于搭配修辞语法纠错的构图纠错方法。该方法基于匹配和纠正语法纠错来有效地纠正文本，这减轻了教师和家长的负担。 该方法在一定程度上缓解了数据稀缺的问题，并且有效地扩大了训练集的规模，即解决了训练语料不足的问题，又提高了模型的纠错效果。该方法包括对中文句子进行任务形式化定义，其中句子构造不正确匹配的错误样本，构造BERT编码单元将中文句子编码成词向量，构造条件随机场层单元对中文句子进行解码，构造输出，其中构造单元处理得到最终结果。包括用于基于匹配和校正语法来校正文本的方法系统的独立权利要求。  12
本发明属于智能自然语言处理技术领域，公开了一种智能对话意图识别方法、系统、存储介质及应用，对业务实际场景下收集文本数据进行清洗，形成语料库，对意图类别标注；基于进行数据清洗后的语料进行预训练模型的pre‑train；构造finetune模型，进行权重分配，与每一层transformer的输出构造加权求和的输出向量；将得到的加权输出向量，接入softmax分类层，使用focalloss函数作为网络损失函数；基于finetune模型在标注数据集上训练，利用意图识别模型实现对未知标签样本意图的智能识别。本发明为智能对话意图识别方法提供了一个有效、便利解决方案，具有很强的工程实用价值与应用前景。用于识别信息数据处理终端中的智能对话意图的方法和智能自然语言处理终端(均要求保护)。本发明为智能对话意图识别过程提供了有效，便捷的解决方案，具有很强的工程实用价值和应用前景。该方法包括清理在服务实际场景中收集的文本数据。 去除表达式，图片和停止字。 标记意图类别。 构建微调模型。 提取训练的预训练模型中的每一层的输出。 访问SoftMax函数以执行权重标准化。 加权求和的输出向量与输出的每一层的输出一起输出。 利用意图识别模型对未知标签样本意图进行智能识别。本发明涉及一种用于识别信息数据处理终端和智能自然语言处理终端中的智能对话意图的系统。 8
一种基于基带‑射频联合优化的数字预失真方法及系统，通过采集真实射频功率放大器的收发信号数据集用于对功率放大模型进行训练获取模型系数矢量，采集基带激励信号数据集输入数字预失真模型后经上变频处理后再输入功率放大模型，得到相应的射频输出信号及其功率频谱图；再将射频输出信号进行下变频与线性滤波得到基带恢复信号后通过后失真器模型得到反馈信号，用于计算激励与反馈之间的误差以及MSE，根据数字预失真模型、功率放大模型的模型系数矢量以及上下变频相关参数计算出非线性互调失真的决定因子数学表达式；最后根据基于基带‑射频特性的联合优化目标函数推导递归最小二乘(RLS)改进算法并根据算法迭代更新数字预失真模型系数矢量，使联合优化目标函数收敛从而实现射频功率放大器的线性优化，令数字指标MSE与射频指标IMDs共同降低。基带信号处理和射频功放装置中基于基带-射频联合优化进行数字预失真的方法。该方法针对不同泛化场景，对功率放大模型进行训练得到模型系数向量从而避免带外泄漏，提高线性化性能。该方法包括收集真实射频功率放大器的信号数据集。 对功率放大模型进行训练，得到数字预失真模型系数向量。 基于所述数字预失真模型系数向量采集基带激励信号数据组。 对所述基带激励信号数据组执行上变频处理任务后输入数字预失真模型。 获得射频输出信号和功率谱图。 对所述数字预失真模型系数向量进行迭代更新，使联合优化目标函数收敛，实现射频指标低、射频指标少的射频功率放大器的线性优化。本发明还公开了一种基于基带-射频联合优化的数字预失真装置。 3
本发明提供了一种假音检测方法、假音检测模型获取方法及相关设备，假音检测方法包括：获取目标语音；基于预先获得的目标假音检测模型，检测目标语音是否为假音，目标假音检测模型采用标注有语音类别的训练语音对构建的假音检测模型训练得到，构建的假音检测模型包括语音编码器、根据语音编码器的输出获取说话人表征的说话人表征模块、根据语音编码器的输出获取假音表征的假音表征模块，以及根据说话人表征模块的输出和假音表征模块的输出进行语音分类的语音分类模块，说话人表征模块通过结合说话人分类任务，辅以语音编码器训练得到，语音编码器为通过预训练获得的语音预训练模型。本发明提供的假音检测方法可准确地检测出语音是否为假音。在基于说话人语音到说话人身份验证技术的自动说话人验证(ASV)系统中检测语音克隆的方法。该方法能够对语音进行语音克隆检测，以提高说话人身份验证的安全性和可靠性，从而准确检测语音是否为语音克隆。 该方法让语音编码器训练得到的说话人表征模块在伪声音表征的基础上得到区分性强的说话人表征来进行语音分类，可以得到更准确的语音分类结果。该方法涉及获得(S301)目标语音。 根据预先训练的目标语音克隆检测模型，判断所述目标语音是否为语音克隆(S302)。 通过标注有语音类型的训练语音对构建的语音克隆检测模型进行训练得到目标语音克隆检测模型。 语音类型为真音和语音克隆中的一种。 语音分类模块用于根据说话人表征模块的输出和语音克隆表征模块的输出对语音进行分类。 通过将说话者分类任务与语音编码器训练相结合来获得说话者表征模块。 所述语音编码器作为语音预训练模型。包括以下独立权利要求：(1)一种语音克隆检测模型获取方法； (2)语音克隆检测装置； (3)语音克隆检测模型获取装置; 以及(4)存储用于检测语音克隆的程序的计算机可读存储介质。 3
本公开实施例是关于一种模型训练方法、物品识别方法及装置、电子设备、计算机可读存储介质，涉及计算机技术领域，该方法包括：获取样本物品的样本文本信息以及样本图像信息；基于所述样本文本信息以及样本图像信息对识别模型中的自监督模型进行预训练，获取先验结果；通过所述识别模型中的嵌入模型，结合所述先验结果以及样本文本信息获取参考多模态表征向量；基于所述参考多模态表征向量确定目标损失函数，并基于所述目标损失函数对所述识别模型的模型参数进行调整，以训练识别模型。本公开能够提高模型训练的准确性。模型训练方法。本发明提高了模型训练的准确性。所述模型训练方法包括：获取样本项的样本文本信息和样本图像信息；基于所述样本文本信息和样本图像信息对识别模型中的自监督模型进行预训练，以获得先验结果。 参考多模态特征向量是通过识别模型中的嵌入式模型将先验结果与样本文本信息相结合得到的。 基于参考多模态表示向量确定目标损失函数，并基于目标损失函数调整识别模型的模型参数以训练识别模型。本发明还涉及一种物品识别方法。 (2)模型训练装置； (3)物品识别装置； (4)电子设备； (5)计算机可读存储介质。  11
本发明公开了一种基于混合格自注意力网络的命名实体识别方法，包括：S1，将字词对表示的句子特征向量编码为一个维度固定的矩阵，得到混合格结构的字词向量表示；构造自注意力网络以捕获该向量中词向量对字向量的影响，增强每个字向量的特征表示；在BERT的Embedding层融合词特征，通过微调学习过程，学习得到更好的字向量表示；依据BiLSTM‑CRF网络实现实体识别中的实体序列标注任务和解码过程，通过该网络完成对融合后字特征的建模，构建完成基于混合格自注意力网络的实体识别模型。本发明能够捕获全局的词汇信息，生成语义丰富的字向量表示，在多个数据集上提升了中文命名实体识别的精度。一种基于混合网格自注意力网络的中文人名实体识别方法。该方法能够捕获全局词汇信息，生成词向量表示的语义含义，提高中文名称实体识别一组数据集的精度。 该方法允许模型对词汇信息进行融合，以增强每个词向量的特征表示，使得生成的词向量包含更多的实体边界信息，从而提高了NER任务的准确性。该方法包括在词典中搜索由输入句子中的连续单词组成的单词。 通过位置交替映射将词组合成单个多维向量。 通过混合词格编码将一个词对表示的句子特征向量编码为一个维度固定矩阵。 获得对应的混合点阵结构的词向量表示。 在数据集上基于所述混合网格自注意力网络训练实体识别模型。包括独立权利要求一种基于混合网格自关注网络的命名实体识别装置。  12
本发明通过深度学习的方法，构建训练数据与数据预处理；基于BERT模型预训练语言模型进行文档与查询内容编码；基于BERT模型的查询内容进行词编码；建立基于句子级别的层级结构(Hierarchical结构)模型，实现查询内容与文档关系语义建模；模型训练后封装，通过接口输出抽取式摘要五个步骤，使BERT模型学习词级别的特征向量表示，抽取代表文档的句子和查询的句子，并将上述特征导入Transformer模型进行句子级别的语义关系特征学习，结合查询模型的思想，学习查询内容与文档的关系，通过分类函数判定最终得到文本的摘要。基于查询机制自动抽取可抽取文档摘要的方法。该方法实现了查询内容与文档之间关系的语义建模，结合查询模型的思想，学习查询内容与文档之间的关系，并通过分类功能确定文本的最终摘要。该方法涉及构建训练数据和数据预处理。 基于来自变换器(BERT)模型的双向编码器表示预训练语言模型来编码语义。 基于BERT对模型的查询内容进行语义编码。 基于句子级别建立层次结构模型，实现查询内容与文档关系的语义建模，模型训练后封装，通过接口输出可抽取摘要。 获取所述输入源文本。 对预处理后的输入源文本数据进行处理，首先对源文本进行切分，并在每次源文本切分后的词序列前后添加指示起止的标签。独立权利要求包括如下：一种基于查询机制自动生成可抽取文档摘要的装置； 以及基于查询机制的可抽取文档摘要自动生成系统。  12
本申请提供了一种领域模型生成方法、装置、设备以及存储介质，涉及自然语言处理、大模型和领域模型技术领域。该方法包括：响应于生成领域模型的操作，获取通过自然语言在文本编辑框中输入的文本信息；显示基于文本信息确定的类图的模型文本；显示基于模型文本生成的领域模型。本申请的实施能够基于获取的自然语言文本信息确定出符合PlantUML规范的模型文本，具体地，可以利用大语言模型或正则表达式解析文本信息，基于解析结果确定模型文本，继而通过该模型文本生成对象模型；相应地，能够基于PlantUML技术直接编辑类图的模型文本，并实时显示类图，其操作逻辑简单、效率高、可有效提高业务功能的可维护性。用于在服务支持系统(BSS)、客户关系管理系统(CRM)和物联网(IoT)中生成服务应用的现场模型即对象模型的方法。该方法有效地提高了业务功能的可维护性。该方法涉及响应于生成域模型而通过自然语言获取在文本编辑框中输入的文本信息。 基于所述文本信息确定类图的模型文本。 显示基于模型文本生成的域模型。 根据所述模型文本确定所述类别图的模型文本。 通过自然语言将文本信息输入到文本编辑框中。独立权利要求包括用于：(1)用于产生场模式的装置； (2)用于生成场模型的电子设备； 以及(3)用于生成场模型的计算机可读存储介质。  11
本发明涉及人工智能技术领域，提供一种地址参数处理方法及相关设备，所述地址参数处理方法包括：接收输入的地址信息；将所述地址信息输入至基于Transformer的双向编码器表征BERT的地址解析模型中，获得输出概率；若所述输出概率大于预设阈值，获取所述地址解析模型输出的非规范地址参数；根据所述非规范地址参数，对所述地址信息进行清理，获得清理后的地址信息；根据地址知识模板库，对所述清理后的地址信息进行切分，获得规范地址参数；将所述非规范地址参数和所述规范地址参数进行合并，获得所述地址信息的地址解析结果。本发明还涉及区块链技术，可以将地址解析结果上传至区块链上。本发明能够对地址型参数进行有效解析。电子设备地址参数的处理方法。该方法能够以高效的方式实现地址类型参数分析过程。该方法包括接收输入地址信息。 将输入的地址信息输入到基于BERT的双向编码器的地址分析模型中。 得到输出概率。 若所述输出概率大于预设阈值，则通过所述地址分析模型得到非标准地址参数输出。 根据所述非标准地址参数对所述地址信息进行清洗。 合并所述非标准地址参数和所述标准地址参数。 获取所述地址信息的地址分析结果。 对所述地址信息进行语义识别。独立权利要求如下：一种地址参数处理装置，具有接收模块； 一种电子设备，具有处理器和存储器以及用于存储任何人指令的计算机可读存储介质。  12
本发明公开了生成式大模型训练方法、基于模型的人机协同交互方法，包括获取智能对话中的问答语句；语速分类器对智能对话中的用户的问答语句通过语速分类器进行速度标记，形成第一训练集；利用第一训练集对预先训练好的第一生成式大模型进行监督微调训练，得到第二生成式大模型；语速分类器对不同的语速标签的问答语句进行编码，并将编码存储至编码存储数据库里，利用预训练好的第三生成式大模型调取编码存储数据库编码数据进行有监督训练；提取用户对话语句中问题中的关键词及对应的回答中的关键词、回答的语速，以及提取对应的上下文信息，根据提取的关键词和上下文信息，生成预测模型。本发明能实时预测用户的语速，进行变语速交流。人工智能领域的基于模型的生成大模型训练和人机协同交互方法，即聊天生成预训练变压器(ChatGPT)。该方法能够实时预测用户的语速并进行变语速通信。该方法涉及在智能对话中获取问题答案语句。 通过语言速度分类器基于预先训练的语言速度分类器在所述智能对话中标注所述用户的问题-答案句的速度。 根据提取的关键词和上下文信息生成预测模型，该模型包括第一生成单元和第二生成单元。 第一生成单元，在接收到会话生成请求时，向所述会话控制模型中的编码单元输入请求生成会话的问题语句，得到上下文语义代码。 第二生成单元，在所述对话控制模型中将用于请求生成对话的语言速度分类标签和所述代码输入至所述解码单元，得到与所述语言速度分类标签匹配的答案句表达式。 形成所述答案句表示后输出对应的答案句。 8
本申请提供一种语音应答方法、装置、电子设备及可读存储介质，所述方法包括：获取待应答语音数据；使用预先训练的变压器Transformer模型，提取所述待应答语音数据的第一表征向量；基于所述第一表征向量和表征向量集合获取目标表征向量，所述目标表征向量为所述表征向量集合中与所述第一表征向量的相似度最高的表征向量，其中，所述表征向量集合中每个表征向量对应一个动作；获取应答动作的应答语音，所述应答动作为所述目标表征向量对应的目标动作；输出所述应答语音。本申请可以提高对话体验。用于由电子设备在对话期间提供语音响应的方法(要求保护)。该方法通过相似度确定与表征向量集合匹配的目标表征向量，以输出目标向量对应的目标动作的应答语音，实现了对待接听语音数据的语音应答，从而在不中断通话的同时提高了待接听语音的应答匹配度，提高了通话体验。该方法包括获得(101)待回答的语音数据。 使用(102)预训练的变换器模型提取所述待回答的语音数据的第一表示向量。 基于所述第一表示向量和表示向量集合获得(103)目标表示向量，所述目标表示向量为所述表示向量集合中与所述第一表示向量相似度最高的表示向量，所述表示向量集合中的每个表示向量对应一个动作。 获取响应动作的响应语音(104)，所述响应动作作为所述目标表征向量对应的目标动作。 输出所述应答语音(105)。还包括独立权利要求：1一种用于在由电子设备进行的会话期间提供语音响应的设备：以及2一种包括用于在由电子设备进行的会话期间提供语音响应的指令集的可读存储介质。 3
本公开提供了信息处理方法、装置、电子设备及存储介质，涉及大语言模型、自然语言处理以及深度学习等人工智能领域。其中的方法可包括：获取M条待处理信息，M为正整数；分别对各待处理信息进行有效内容提取，得到对应的内容提取结果；针对各内容提取结果，分别进行以下处理：响应于确定该内容提取结果具有转换清洗需求，按照对应的转换清洗方式，对该内容提取结果进行转换清洗，并将转换清洗结果作为所需的目标处理结果，响应于确定该内容提取结果不具有转换清洗需求，将该内容提取结果作为目标处理结果。应用本公开所述方案，可提升信息质量等。用于通过使用电子设备处理大型语言模型、自然语言处理和深度学习的人工智能领域中的信息的方法(权利要求书)。该方法能够提高信息质量。该方法包括获得待处理的信息片段(101)。 分别提取(102)每个待处理信息的有效内容，得到对应的内容提取结果。 对每个内容提取结果执行信息处理(103)。 响应于确定所述内容提取结果为转换清洗需求，按照对应的转换清洗方式对所述内容提取结果进行转换清洗。 将转换清洗结果作为需要的目标处理结果。 响应于确定所述内容提取结果不为转换清洗需求，将所述内容提取结果作为目标处理结果。独立权利要求书包括用于：利用电子设备对大型语言模型、自然语言处理和深度学习的人工智能领域的信息进行处理的装置； 电子装置； 一种非瞬时计算机可读存储介质，用于存储用于利用电子设备对大型语言模型、自然语言处理和深度学习的人工智能领域的信息进行处理的指令集； 以及计算机程序产品，其包括用于通过使用电子设备来处理大型语言模型、自然语言处理和深度学习的人工智能领域中的信息的指令集。  11
本发明公开了一种基于MacBERT与跨度的碳中和实体关系抽取的方法，利用碳中和文本的关键信息易于碳中和精确搜索同时有助于碳中和的实现。基于DOE模型，结合MacBERT编码的数据，有效的缓解数据标注中出现实体漏标与错误标注导致后期预测结果漏识别的问题，以实体词汇首尾的预测为辅助任务训练改善实体边界错误，在关系预测中加入实体类别，使所得结果更加合理可靠。本发明除用于提取碳中和三元组外，还可以用于搜索引擎搜索更加准确的碳中和信息，具有广泛的应用价值。基于MacBERT和span的碳中和实体关系提取方法。该方法能够以合理可靠的方式提取碳三元基团，并以准确的方式使适用范围广的搜索引擎搜索到碳中性信息。该方法包括将碳中性相关句子划分为单个单词。 将得到的单个词按照最大实体长度和一个句子序列组合为有理实体片段。 将得到的片段的MacBERT编码向量与数据标记片段的MacBERT编码向量进行相似度计算。 将相似度大于阈值的片段添加到真实实体中。 由所述实体片段通过模型得到所述实体的类。 将实体特征和实体类型送入关系抽取模块，计算句子中所有实体的关系。  12
本发明公开了一种基于预训练模型变种的新闻文本分类方法及系统，属于文本分类领域。本发明采用BERT和RNN复合模型对数据集中的特征进行有效提取，对于已经经过预训练的BERT模型，其广泛适用于下游任务的各个集合，不需要利用重复数据进行训练，同时基于self‑attention机制可以有效的可以不仅可以得到源端与目标端词与词之间的依赖关系，同时还可以有效获取源端或目标端自身词与词之间的依赖关系。在此基础上，引入了RNN模型，用于捕捉长距离文本依赖上信息丢失的问题，对结果进行特征融合，在新闻文本分类上取得了较为理想的效果。在自然语言处理，数据挖掘和机器学习领域中基于预训练模型变体的新闻文本分类方法。该方法使得BERT和RNN复合模型能够有效地提取BERT模型的数据集的特征， 广泛适用于每组下游任务，避免了基于自注意机制的重复数据训练的需要，从而有效地获得源端和目标端的词之间的依赖关系。 本发明通过引入RNN模型来捕获依赖于信息丢失的远程文本，从而对结果进行特征融合，在新闻文本分类上取得了理想的效果。该方法包括获得(S1)用类别标签标记的新闻文本语料库以形成分类语料库。 分类语料库用于训练新闻文本分类模型，该模型基于来自变压器(BERT)和递归神经网络(RNN)的预训练模型双向编码器表示来形成模型框架。 将新闻文本处理成相同长度的句子向量， 输入预训练模型BERT进行转换，得到词向量矩阵，然后将词向量矩阵送入RNN，通过卷积层和汇聚层进行二次特征提取，得到语义特征向量。 通过语义特征向量经由全连接层和SoftMax层输出(S2)新闻文本的分类结果。 将待分类的新闻文本输入到训练好的新闻文本分类模型中，并输出新闻文本的分类结果(S3)。本发明还涉及一种新闻文本分类系统。  12
本发明适用于自然语言处理、实体识别领域，提供一种行政审批实体识别方法，首先获取行政审批文档这样为初始样本集，文本识别后建立行政审批语料库和行政审批实体语料库；然后基于所述行政审批语料库训练预训练模型，以及基于行政审批实体语料库，将预训练模型添加实体识别下游任务，得到行政审批实体识别模型；最后基于行政审批语料库进行预测，输出对应的实体识别结果及实体类型。本发明可以解决自动识别行政审批文档中实体及实体类型的问题，为机器辅助审批行政提供帮助。本发明方法对比现有实体识别方法在识别行政审批文档中实体的精度更高。对行政审批实体进行认定的方法。该方法能够解决自动识别行政审批文件中的实体和实体类型的问题，为机器辅助审批管理提供帮助。 该方法对行政批件中的实体进行识别的精度更高。该方法包括：步骤S1，以行政审批文件为初始样本，进行光学字符识别(OCR)识别，形成行政审批文本数据; 步骤S1，根据文本数据构建行政审批语料库，并对实体进行标记; 步骤S1，根据实体标记文本构建行政审批实体语料库。 进行训练(S2)以形成由行政审批实体标识的预训练模型，根据行政审批语料并通过对预训练模型的权重调整，基于引入长程(LoRA)层的Roberta模型。 将下游任务设置(S3)为实体识别，根据预训练模型和行政审批实体语料，训练实体识别模型。 利用实体识别模型(S4)对行政考试语料样本数据进行预测，输出实体识别结果。  11
本发明涉及一种基于句法对比学习的稠密检索方法，包括如下步骤：选用公开文档检索数据集，数据集包括查询Query和正段落Passage+，将一一对应的一组Query和Passage+作为一个训练样本；从数据集中选取部分样本作为训练集C；构建稠密检索模型SynC，SynC包括一个双编码器模型和两个预训练模型，两个预训练模型分别为EncoderQ和EncoderP；所述双编码器模型包括编码器DualEncoderQ和编码器DualEncoderP；遍历所有样本，计算得到训练集C中每个训练样本对应的Eq、cq和cp；最后计算SynC的总损失，对SynC进行训练，利用总损失函数反向更新SynC参数，当训练达到最大迭代次数时停止训练，得到训练好的SynC。使用本发明SynC模型对未知查询进行稠密检索，可以提高稠密检索结果的准确性与训练效率。基于语法对比学习的密集搜索方法。提高了粗搜索结果的准确率和训练效率。 采用句法对比学习方法提高了训练效率。该方法涉及选择公共文档检索数据集。 数据集被提供有查询和积极段落。 所述查询与所述正段落一一对应。 从数据集中随机选取部分样本作为训练集。 构建密集搜索模型sync。 对所述查询进行语法掩码策略，得到查询掩码。 通过使用双编码器模型将通道映射到d维的表示空间。 得到负段落表示矩阵。 计算同步的总丢失。 设置训练最大迭代次数和训练同步。 通过梯度下降法反向更新总损失函数sync参数。 当训练达到最大迭代次数时，停止训练，得到训练好的sync。 将待问答查询作为所述同步的数据输入输出。 执行查询的粗搜索。  11
本发明公开了一种政务问题生成方法及装置，可用于人工智能技术领域，方法包括：获得政务数据，开源问答数据和自建政务问答文本数据；将所述政务数据输入预先建立的UNILM网络模型进行训练，得到预训练模型，其中所述UNILM网络模型根据Bert中文模型参数预先建立；将所述开源问答数据和自建政务问答文本数据输入预训练模型进行微调，得到问题生成模型；利用问题生成模型，进行政务问题生成。本发明可以提高中文数据问题生成效果。人工智能技术中政府议题的生成方法。该方法能够提高中文数据问句生成的效果。该方法涉及获取(101)政务数据、开源问答数据和自建政务问答文本数据。 将政务数据输入(102)到预先建立的统一预训练语言模型(UNILM)网络模型中进行训练，以获得预训练模型。 UNILM网络模型根据双向编码器表示从变压器(Bert)中文模型参数预先建立。 将开源问答数据和自建政务问答文本数据输入(103)预训练模型进行微调，得到问题生成模型。 使用问题生成模型(104)来生成政府事务问题。包括以下独立权利要求：用于生成政府问题的设备； 用于生成政府议题的计算机设备； 以及存储用于生成政府议题的程序的计算机可读存储介质。  11
一种数据处理方法，涉及人工智能领域，包括：获取待处理文本以及预训练语言模型，预训练语言模型包括特征提取网络和预测网络；通过预训练语言模型的特征提取网络，对待处理文本进行特征提取，以得到待处理数据的特征表征，特征表征为复数；通过预训练语言模型的预测网络，对长度单位化处理后的特征表示进行正交变换，以得到正交变换后的结果，并根据正交变换后的结果确定文本预测结果。本申请可以在量子电路上进行预训练语言模型的运算，且通过复值表示的预训练语言模型的构建，提高了模型的表示能力，提高了网络的性能。用于处理数据的方法。本发明通过构建复杂值表示的预训练语言模型，提高了模型的表示能力，提高了网络的性能。该方法包括获得(601)要处理的文本和预先训练的语言模型。 预训练语言模型包括特征提取网络和预测网络。 对所述待处理文本执行(602)所述特征提取，以通过所述特征提取网络获得所述待处理数据的特征表示。 特征表示是复数。 对长度单位化处理后的特征表示执行(603)正交变换，以通过预测网络获得正交变换后的结果，并根据正交变换后的结果确定文本预测结果。本发明还涉及一种用于该方法的装置。 用于处理数据的装置； 和2。 一种用于处理数据的计算机程序产品。  11
本发明属于自然语言处理技术领域，具体涉及一种基于知识图和BART语义的多文档摘要方法。该方法包括以下步骤：构建多文档摘要训练数据集；构建面向多文档摘要的知识图；构建融合知识和图注意力的多文档摘要模型；训练多文档摘要模型并生成摘要。本发明融合外部知识的语义知识图加强远距离实体的联系，采用知识图和BART语义信息融合的方法，使模型能够更好地结合知识图和文本序列的注意力，弥补深度学习模型的缺点，降低模型对大规模标注样本的依赖，生成质量更高的摘要内容。基于知识图谱和BART语义的多文档摘要方法。该方法将外部知识融合到语义知识图谱中，加强远程实体之间的联系，使得模型能够更好地结合知识图谱和文本序列的注意力，弥补深度学习模型的不足，降低模型对大规模标注样本的依赖，生成更高质量的摘要内容。该方法涉及构建(S1)多文档摘要训练数据集。 构建用于多文档摘要的知识图(S2)。 构建集知识和图谱注意力于一体的多文档摘要模型(S3)。 训练多文档摘要模型(S4)，并生成摘要。 下载开源多文档摘要数据。 对开源的多文档摘要数据进行预处理和清洗，得到文档。  12
本发明涉及一种基于卷积神经网络多维度融合的CT图像器官分割方法。该方法包括：S1：利用注意力损失函数、通过标签计算得到的权重、训练数据和标签数据来训练Unet++模型；S2：利用训练数据、标签和二元交叉熵损失函数训练Unet++模型；S3：利用所得到的两个训练后的Unet++模型和待分割数据分别得到两个不同的分割结果；以及S4：将所述两个不同的分割结果进行融合。本发明解决了在眼底图像血管分割问题中，一些细小的血管无法被很好分割的问题，使得提高了分割的准确性。该方法对基于卷积神经网络多维度融合的眼底血管分割有用。该方法解决了眼底图像中血管的分割问题中，一些细小的血管不能很好的分割出来的问题，使得分割的准确性得到提高。基于卷积神经网络多维融合的眼底血管分割方法，包括：(a)利用注意力损失函数，计算标签、训练数据和标签数据得到的权值，训练Unet模型; (b)利用训练数据和标签，通过二元交叉熵损失函数，训练Unet模型; (c)利用得到的两个训练后的Unet模型，对数据进行分割，得到两个不同的分割结果; (d)将两个不同的分割结果进行融合。   4
本发明涉及一种青饲收获机跟随料车车斗识别方法及系统。方法包括：S1、获得料车车斗图像集；S2、获得料车车斗标签集；S3、以多层卷积神经网络作为基础架构搭建具有编码‑解码结构的语义分割神经网络；S4、将料车车斗训练集和料车车斗标签集按照一一对应关系作为训练样本按批次输入U‑Net网络进行训练；S5、通过双目深度相机实时采集待检测料车车斗图像，输入到U‑Net网络中，输出料车车斗预测结果，通过对车斗预测结果进行边缘提取得到车斗轮廓；S6、采用直线拟合算法对车斗轮廓结果进行车斗边沿拟合，剔除超出阈值的交点，完成车斗的识别。本发明能够大大加快车斗识别速度和识别准确度、可显著提高青饲收获机收获效率并节省劳动力。一种用于农业机械自动识别的青饲料收获机随料机构的识别方法。该青饲收获机跟随料车料斗识别实现成本低，自动化程度高，通用化程度高，大大加快了识车速度和识别精度，节省了劳动力。该方法包括获得(S1)材料卡车结构的图像集。 双目深度相机采集各种类型的物料车和结构的一定数量的图像，并将其传送给图像语义分割控制器。 获得物料车结构的标签组(S2)。 使用多层卷积神经网络(S3)作为基础设施来构建具有编解码结构的语义分割神经网络。 使用直线拟合算法(S6)对得到的结构轮廓结果进行结构的边缘拟合。 消除超过阈值的交点，然后通过限制拟合结构边缘直线长度的长度阈值，确定结构的四个角点，完成结构的识别。 13
本发明公开了一种基于多路径激励的视频人体行为识别方法及系统，通过将待识别视频分段后根据各段提取图像帧，然后采用预训练模型对提取的图像帧进行多路径特征提取识别匹配，匹配度最高的行为动作即为该图像帧的动作，将提取的图像帧识别动作连接后即可得到待识别视频中人体行为，本发明使用稀疏采样的策略从原始视频数据中抽取图像帧，考虑了动作在全局时间中的变化，从整个视频中抽样进行识别，利用训练获取的行为识别模型可以直接用于视频中的人体行为识别任务，提高识别的精度，覆盖了整个视频的空间外观与隐性的时间信息。针对稀疏采样策略忽视局部运动信息的问题，利用采样帧前后两帧的帧差生成局部运动信息补充到输入中。一种基于多径激励的视频人体行为识别方法。 可应用于行为识别技术领域，具体公开了一种视频人体行为识别方法及系统。通过覆盖整个视频的空间外观和隐性时间信息，提高了识别的精度。 提高了对人体行为识别的准确性。该方法包括在分割待识别的视频之后根据每个部分提取图像帧。 使用预训练模型来提取所提取的图像帧，用于多径特征提取识别匹配。 最高匹配度的动作是图像帧的动作。 连接所提取的图像帧识别动作以获得待识别视频中的人的行为。本发明还涉及一种基于多径激励的视频人体行为识别系统。 9
本发明涉及智能交通技术领域，具体涉及一种匝道路段通行能效检测方法和系统。该方法包括：获取匝道路段图像数据，并构建匝道路段虚拟道路模型；采集匝道路段通行车辆的图像数据及车辆位置探测数据，输入预训练模型，匹配通行车辆对应的三维模型；根据车辆位置探测数据将匹配的三维模型映射到匝道路段虚拟道路模型中三维可视化展示车辆通行状况。本发明将车辆虚拟的三维模型映射到创建的虚拟道路模型中，对通行车辆进行三维可视化实时展示，根据通行车辆的移动轨迹与虚拟道路模型中的交通标线特征的交叉判断通行车辆的变道压线情况并预警，以便实现对匝道路段的三维可视化管控，替代传统的抓拍实时掌握匝道路段通行状况。一种转弯路段通行能效的检测方法。本发明实现了坡道路段的三维可视化管理和控制，取代了传统的抓拍实时掌握转弯路段交通状况。所述方法包括：获取坡道路段图像数据；构建坡道路段虚拟道路模型。 收集转弯路段通行车辆的图像数据和车辆位置检测数据。 根据车辆位置检测数据，输入预训练模型以匹配与过往车辆相对应的三维模型。 将匹配的三维模型映射到坡道路段虚拟道路模型中的三维可视化显示车辆通行情况。本发明还涉及一种转弯路段通行能效检测系统， 13
本发明公开了一种基于AIGC的网络安全伺服系统，包括信息中转站、信息验证端以及网络控制器，信息中转站与信息验证端通信连接，网络控制器分别与信息中转站以及信息验证端电连接，信息中转站用于中转网络安全伺服系统所针对的对象网络中的交互信息。本发明公开的基于AIGC的网络安全伺服系统对信息传输端之间传输的交互信息的验证因子信息量化值以确定信息传输端之间的通信连接为安全的通信连接或者异常的通信连接，有利于满足应用场景中对于时效性的需求。网络安全伺服系统。网络安全伺服系统通过传输端之间传输的交互信息的验证因子信息量化值确定信息传输端之间的通信连接为安全通信连接或异常通信连接，有利于满足应用场景中及时性的需求。该系统具有与信息验证端连接的信息中转站。 网络控制器，用于控制所述信息验证终端对所述第二目标交互信息执行计算第二验证因子信息量化值的操作。 所述网络控制器用于判断所述第一验证信息量化值与所述第二验证信息量化值是否匹配。 控制所述信息中转站，以暂停要在所述信息传送站点之间传送的交互信息在所述数据传送终端之间的传送。 1
本申请提供一种语料挖掘方法、装置、服务器及存储介质，基于预训练的语料预测模型对语料在目标领域的评分确定语料是否为目标领域中的模糊语料(即，第一候选语料，该语料可能属于目标领域也可能不属于目标领域)；若语料是目标领域的第一候选语料则通过生活化语料集对第一候选语料进行扩展，得到与第一候选语料相似度最高的生活化的第二候选语料；以通过二分类模型确定候选语料(候选语料包括第二候选语料)是否真的属于目标领域的扩展语料。本申请不需要逐一匹配关键字、标准语料或标准模板，因此，相对于现有技术可以降低耗时提高扩展语料挖掘效率，并且基于对第一候选语料相似度最高的生活化的第二语料的扩充，实现了对扩展语料的深入挖掘。扩展语料挖掘方法。该方法能够提高开发语料挖掘效率，实现对扩展语言素材的深挖处理。该方法包括根据预训练过程的领域预测模型对目标领域的语料进行打分。 确定语料库是否对应于目标领域的第一候选语言材料。 从语料集合中确定第二候选语料，其中，当语料对应于所述目标领域的第一候选语料时，第二候选语料等于第一候选语料。 通过预先训练的所述目标领域的两分类模型判断是否选择候选语料作为所述目标领域的扩展语料。 利用负样本训练分类算法判断语料是否与所述目标领域不对应，其中，所述候选语料包括第二候选语料。还包括用于扩展语料库挖掘设备的独立权利要求。  11
本发明公开了一种基于预训练的恶意代码分类方法及装置，其中的方法首先提取恶意代码中的浅层特征和subroutine中的操作码，构建特征集；然后构建改进的预训练模型并进行预训练任务，通过训练得到最终模型；最后将待测代码输入到最终模型中，得到类别概率分布，选择具有最高概率的类别作为最终的预测结果。本发明首先提取恶意代码中subroutine的操作码序列，然后提取了TF‑IDF和Asm2Vec的浅层特征。将subroutine用于预训练模型的输入样本进行预训练，可以提升模型的泛化能力，提高模型的训练速度和效果。使用浅层特征作为prefix，既能减少模型训练过程中需要训练的参数规模，又能提升预训练模型的通用性，实现与预训练‑微调范式相当的性能。基于预训练的恶意代码分类方法。该方法利用子路径对预训练模型的输入样本进行预训练，提高了模型的泛化能力，提高了模型的训练速度和效果，从而减小了模型训练过程中需要训练的参数规模，提高了训练模型的通用性，实现了与预训练-细调模式相当的性能。该方法包括从预设数据集中包含(S2)的恶意代码中提取(S1)浅层特征和子程序中的操作代码。 标签编码层由多个层叠的编码器组成。 每个编码器设置有多头注意力层和前馈网络层。 将待检测的代码输入(S3)最终模型以获得类型概率分布。 根据分布的类型概率选择概率最大的一个类型作为最终预测结果。 前缀优化结构用于将输出向量划分为多段输入系统编码层。独立权利要求包括以下内容：基于预训练的恶意代码分类装置； 计算机可读存储介质，所述计算机可读存储介质存储有基于预先训练对恶意代码进行分类的程序； 以及计算机设备。  11
本发明实施例公开了一种基于大语言模型知识蒸馏的知识图谱构建方法及装置，方法包括：获取元数据；元数据包括知识图谱的关系描述信息以及与关系描述信息对应的多个实体对；将元数据的关系描述信息与实体对进行拼装，得到拼装语句，对拼装语句进行同义改写，提取改写后的拼装语句，得到关系描述集合；关系描述集合包含改写后的拼装语句中的多个关系描述信息；根据关系描述集合以及实体对构建提示词，根据提示词，利用知识蒸馏模块得到候选实体对集合；根据候选实体对集合以及元数据的关系描述信息生成知识图谱。基于元数据快速地从大语言模型中提取、整理和构建候选实体对，实现对知识图谱的更新和扩充，从而高效、可靠、低成本构建知识图谱。基于大语言模型知识蒸馏的知识图谱生成方法。该方法能够快速地从大型语言模型中提取候选实体对，从而对知识图谱进行更新和扩展，高效、可靠、低成本地建立知识图谱。所述方法包括：获取元数据，所述元数据包括知识图谱的关系描述信息和与所述关系描述信息对应的多个实体对。 将所述元数据的关系描述信息和所述实体对进行组装，得到组装语句。 对组装后的句子进行改写。 提取改写组装句，得到关系描述集合，所述关系描述集合包括所述改写组装句中的多个关系描述信息。 根据所述关系描述集合和所述实体对构建提示词。 通过知识蒸馏模块根据所述提示词得到候选实体对集。 根据所述候选实体对集的关系描述信息和所述元数据生成所述知识图谱。独立权利要求包括用于：(1)一种基于大型语言模型知识蒸馏的知识图谱生成装置； (2)计算设备，包括处理器和存储器，用于基于大语言模型知识蒸馏生成知识图谱； (3)计算机存储介质，用于存储基于大语言模型知识蒸馏生成知识图谱的指令集。  11
本发明涉及自然语言处理领域，特别涉及一种降低语义识别计算量的方法、系统及存储介质。本发明的降低语义识别计算量的方法包括如下步骤：获取预训练模型；对预训练模型增加训练优化训练目标成为最终训练模型；将待识别文本输入最终训练模型；输出待识别文本语义。通过增加训练优化训练目标的设计，使得无需改变模型的结构就能提升训练的精确性和模型的鲁棒性，同时还降低了模型的复杂程度，降低了模型的计算量，解决了现有技术模型的计算量过大的问题。一种降低语义识别计算量的方法。本发明降低了模型的复杂程度，减少了模型的计算量，解决了现有技术模型计算量过大的问题。该方法包括获得预训练模型。 增加了训练优化训练目标。 使用预先训练的模型作为最终训练模型。 将待识别的文本输入到最终训练好的模型中。 输出待识别文本的语义。还包括独立的权利要求： 用于减少语义识别的计算量的系统； 以及 一种存储介质，包括一组指令用于减少语义识别的计算量的方法。  11
本发明提供一种语句边界识别方法、语句边界识别装置及电子设备，该方法包括：基于训练完成的BERT模型，对输入的目标文本进行向量转换，得到所述目标文本对应的目标词向量，所述目标词向量基于所述目标文本中无法确定语句边界的目标分句符号确定；对所述目标词向量进行分类标注，确定所述目标文本中每个分词的标注状态，所述标注状态包括用于指示语句边界的状态类型。本发明提供的语句边界识别方法、语句边界识别装置及电子设备，可以快速识别出目标文本中可能存在的语句边界，实现对语句边界的准确预测。基于自然语言处理技术的句子边界识别方法。该方法能够快速识别出目标文本中可能存在的句子边界，实现句子边界的准确预测。该方法包括基于训练的双向编码器表示从变换器(BERT)模型对输入目标文本执行向量转换以获得对应于目标文本的目标词向量。 对所述目标词向量进行分类标注。 确定所述目标文本中各分词的标注状态。 标记状态包括状态类型以指示句子边界。 对所述目标文本进行向量转换，得到每个分词对应的初始词向量。包括独立权利要求：(1)一种基于自然语言处理技术的句子边界识别装置； (2)一种电子设备，包括处理器和存储器，用于实现基于自然语言处理技术的语句边界识别； (3)一种非暂态计算机可读存储介质，包括用于实现基于自然语言处理技术的句子边界识别的指令集； 以及(4)一种计算机程序产品，包括计算机程序，当所述计算机程序被处理器执行时，所述计算机程序用于实现基于自然语言处理技术的句子边界识别。  12
一种信息提取方法、信息提取系统的训练方法和信息提取系统。信息提取系统在接收到输入图像后，将输入图像提取的视觉特征转换大语言模型可识别的特征。信息提取系统在大语言模型接收到任务指令时，可以直接对视觉特征进行目标信息提取，以得到目标文本，实现大语言模型对不同类型的图像进行信息抽取任务，提高大语言模型的实用场景。信息提取方法。通过大语言模型提取不同类型图像的信息，改善大语言模型的实用场景的信息提取方法。信息提取方法包括获得输入图像。 提取所述输入图像的特征，得到所述视觉特征。 所述视觉特征被提供有能够由所述大型预测模型识别的特征。 指示LLM响应任务指令。 提取所述视觉特性的目标信息，得到所述目标文本。 所述任务指令中设置有所述提取所述输入图像中的关键信息并转换为所述约定输出格式的指令。 所述目标文本以文本的形式提供有所述目标信息。本发明还涉及一种用于信息提取系统的训练方法; (b)具有接收和发送单元的信息提取系统; (c)具有存储器和处理器的计算设备; (d)用于存储计算机程序的计算机可读存储介质; (e)一种用于由计算机执行指令的计算机程序产品。  11
本公开的实施例提供了一种大型语言模型的微调方法、装置、设备、计算机程序产品和计算机可读存储介质、以及基于大型语言模型的智能助手。该方法针对来自各种知识库的文本数据，利用待微调的大型语言模型对其进行数据清洗，使得经数据清洗的数据可由大型语言模型直接使用，并且利用该大型语言模型基于经数据清洗的数据生成以问答对形式表示的微调指令，极大地提升了对于知识库的整理和处理效率，并且使得大型语言模型能够通过基于具有更强逻辑性的微调指令的指令微调过程学习并提高对于输入知识的理解和表现能力。通过该方法能够构建基于大型语言模型的智能助手，该智能助手能够更好地理解用户的需求和意图，以提供更加精准和个性化的服务。智能助手(索赔)使用的大型语言模型的微调方法，实现与用户的交互大大提高了知识库的整理处理效率。 大型语言模型基于逻辑更强的微调指令，通过指令微调过程，可以学习和提高对输入知识的理解和展示能力。 智能助理可以更好的了解用户的需求和意图，从而提供更精准、更个性化的服务。该方法包括获取文本数据集，文本数据集中的文本数据来自多个知识库。 对所述待精调整语言大模型设置的文本数据的数据进行清洗(401)。 利用所述待精调语言大模型，基于所述数据清洗后的文本数据集，生成(402)所述精调指令集。 所述细调指令集中的所述每个细调指令以问答对的形式表示。 基于所述微调指令集对所述待微调大型语言模型进行微调，以生成所述微调大型语言模型。独立权利要求包括以下内容：基于大型语言模型的智能助理； 大型语言模型的细调装置； 一种用于大型语言模型和智能助理微调的计算机程序产品。 一种计算机可读存储介质，其存储有用于大型语言模型和智能助理微调的程序。  11
本发明涉及一种军事领域标注数据修正与事件检测方法，属于信息抽取技术领域。本发明使用原始数据集训练模型，并对原始标注数据进行预测，对于预测得分大于一定阈值的样本，将原始数据集的标注结果修改为模型预测结果，从而修正数据集中的错误标注数据和污染数据，提高训练集的质量。本发明在模型训练时引入了分层学习率策略，为靠近下游任务的模型层参数设置更大的学习率，提高预训练模型对于下游任务的适配能力；在模型推理时采用基于投票修正的模型融合方法，通过模型集成的方式提升少样本类别事件的召回率和准确率，融合多个模型的投票结果确定最终预测结果，从而提升模型的鲁棒性。在军事领域中修改标记数据和检测事件的方法。在模型推理中采用基于投票修正的模型融合方法，通过模型集成模式提高了较少样本类型事件的召回率和准确率。 将多个模型的投票结果进行融合，确定最终的预测结果，提高模型的鲁棒性。该方法涉及使用模型超参数搜索方法——网格搜索(Grid‑Search)。 任务摘要将事件检测任务转换为NER任务，将事件类型作为NER任务中的实体类型，将触发词作为NER任务中的待提取实体。 通过开源预训练模型利用编码或解码策略对事件文本进行编码。 模型训练采用分层学习率策略进行模型训练，当样本用于对下游任务进行微调时。 选择性能最好的模型作为主模型，模型的输出作为候选结果之一，称为主模型输出。 然后使用剩余模型校正主模型输出。  11
本申请实施例公开了一种检索方法、装置、设备及可读存储介质，该方法包括：获取用于检索的目标文本；基于目标文本、知识文本和预训练语言模型确定检索结果，知识文本是基于目标文本确定的且用于协助目标文本进行检索，预训练语言模型包括第一部分网络和第二部分网络，由于第二部分网络的输入是基于第一部分网络的输出和知识文本确定的，所以非输入层的第二部分网络可以直接利用知识文本中包含的知识，从而提高预训练语言模型的知识性的增强效果。在计算机视觉、自然语言处理、搜索推荐等人工智能领域搜索预训练语言模型的方法。第二部分网络的非输入层可以直接使用知识文本中包含的知识，以提高增强效果的预训练语言模型的知识。该方法涉及获得(201)用于搜索的目标文本。 基于所述目标文本、知识文本和预先训练的语言模型，确定搜索结果。 根据所述搜索结果确定(202)所述知识文本。 所述预训练语言模型设置有第一网络和第二网络。 确定第二网络的输入(203)。 选择第一网络的输出作为第一部分网络。包括以下独立权利要求：(1)搜索装置； (2)计算机装置； 以及(3)存储用于搜索目标文本的程序的计算机可读介质。  11
本申请提供一种音频数据的预训练、模型训练方法、装置、设备及介质，涉及音频处理技术领域。该方法包括：预训练模型包括：掩码层、第一编码层以及第一前馈层，所述方法包括：采用所述掩码层，对样本音频数据进行掩码处理，得到掩码声学特征；采用所述第一编码层对所述掩码声学特征进行所述第一编码层对应音频任务的编码处理；采用所述第一前馈层对所述编码处理后的声学特征进行掩码重构处理，得到重构预测结果；根据所述重构预测结果，对所述掩码层的掩码参数进行更新，得到目标预训练模型。相对于现有技术，避免了由于样本音频数据质量不高等问题，导致学习到的音频表示的鲁棒性不足的问题。预训练模型训练方法。该方法使得能够避免低样本音频数据质量和学习到的音频表示的鲁棒性不足的问题。该方法涉及使用掩模层处理样本音频数据以获得掩模声学特征。 对所述蒙板声学特征采用与所述第一编码层对应的第一编码层进行音频任务的编码处理。 利用第一前馈层对编码处理后的声学特征进行掩膜重建处理，得到重建的预测结果。 根据重构预测结果更新所述掩膜层的掩膜参数，得到目标预训练模型。 按照预设帧数对样本音频数据进行切片，得到所述样本音频数据的片段。包括以下独立权利要求：一种音频数据预训练方法； 一种音频任务模型训练方法； 预训练模型训练装置； 音频数据预训练装置； 音频任务模型训练装置； 一种计算机设备，包括用于存储用于执行预训练模型训练方法的指令集的存储器和处理器； 以及计算机可读存储介质，用于存储用于执行预训练模型训练方法的指令集。 3
一种基于AIGC的在SolidWorks中智能三维建模的方法，包括建立AIGC输入端口，通过自然语言处理算法将用户的需求转化为建模软件可以理解的结构化格式，定义需要建立3D模型的工件参数和约束；经过精调的AI模型能够生成满足指定条件的二次开发代码，进行优化和分析后使用应用程序接口将优化过的代码发送给SolidWorks，直接在软件内生成对应的参数化3D模型；通过使用自动化脚本语言以及用户友好的网页界面，用户能够轻松地在SolidWorks界面中查看生成的模型。这种基于人工智能的自动生成式3D建模方法能够极大的提高工程零部件设计和绘制效率，对于提升机械制造相关企业和人员的生产力和竞争力方面具有重要意义。一种智能三维(3D)建模方法，用于训练计算机辅助设计(CAD)软件中由solidWorks 3D模型智能生成的人工智能(AI)模型。通过使用自动化的脚本语言和人性化的网页界面，用户可以很方便地在SolidWorks界面中查看生成的模型。 基于人工智能的自动生成型3D建模方法能够大大提高工程零件的设计和绘图效率，对于提高机械制造的相关企业和人员的生产力和竞争力具有重要意义。该方法涉及定义要建模的工程部件的参数和约束。 建立自然语言处理微调模型。 通过使用自然语言处理算法将自然语言输入转换成人工智能(AI)模型可以理解的结构化格式。 自然语言过程中的结构化数据用SolidWorks软件集成。 建立能够与SolidWorks通信的人工编程接口(API)插件，使得AI模型将参数发送到SolidWorks。 SolidWorks被配置为使用这些参数来生成模型。 1
本发明公开了一种基于ERNIE模型与知药物数据挖掘方法和系统，属于数据挖掘领域。本发明方法包括通过中文医疗文本数据构成的语料集对ERNIE模型进行训练；预处理中文医疗文本数据，得到医疗领域实体组块关系语料集；融合医疗领域实体组块关系语料集与医疗领域知识图谱；使用训练完毕的ERNIE模型对语料集进行编码，将编码后的语料集在BiGRU模型中训练，最终得到药物的潜在作用。本发明提出基于训练模型ERNIE与知识图谱的药物发现模型，使用预训练模型降低了训练的时间成本与提高了准确度，融入知识图谱加强了模型在医疗领域的处理能力，实体组块使得数据集的构建更加便捷，从而进一步提高发现药物的潜在作用的准确率。基于ERNIE模型和知识图谱的医学数据挖掘方法。利用预训练模型降低训练的时间成本，提高准确率，知识图谱融入增强模型在医学领域的处理能力，实体块使得数据集的构建更加方便，提高医学潜在效应的准确率。该方法涉及获得并预处理训练ERNIE模型的中医数据。 构建ERNEE模型的预训练语料集。 将ERNNIE模型的语料库输入到ERNE模型中。 获取中文数据并进行预处理。 在医学领域中构建物理组块关系语料集合。 将医疗领域实体组块关系语料与知识图谱进行融合。 融合所述医学领域实体组块连接语料和所述知识图谱，构建医学数据挖掘模型，用于挖掘医学潜在效应。独立权利要求包括如下内容：(1)基于ERNIE模型和知识图谱的医学数据挖掘系统； 以及(2)基于ERNIE模型和知识图谱挖掘医学数据的电子设备。  10
本发明涉及基于视觉大模型的相似背景图像归类方法，包括以下步骤：1)图像编码：对于一张输入图像I∈Rh×w×3，首先进行归一化预处理，然后使用上述预训练好的大模型，仅使用其视觉模块，将预处理的图像编码为一个向量V∈Rd，将其规范化，使|V|＝1。该基于视觉大模型的相似背景图像归类方法，计算效率高，在海量数据集上使用预训练好的模型提取特征，构造相似度矩阵，直接对矩阵进行操作，在内存有限条件下，可将相似度矩阵进行切片，并行计算，图像特征表达能力强，预训练大模型已经在上亿级图像数据上进行了训练，采用(图像，文本)多模态，能够更好的泛化，提出的方法不用事先设定类别数量，可在千万级甚至上亿级别的图像数据库中挑选相同背景的图像。相似背景图像分类方法，用于基于大视觉模型对相似背景图像进行分类，用于判断商户是否上传了同一商铺的多张图片。基于视觉大模型的相似背景图像分类方法计算效率高，在海量数据集上使用预先训练好的模型提取特征，构建相似度矩阵，直接对矩阵进行运算，在内存有限的条件下，可以对相似矩阵进行切片，并行计算，图像特征表达能力强。 所述预训练大模型是在所述数亿图像数据上训练得到的。 该方法不需要预先设置类型号。 背景相同的图像可以从数千万甚至上亿的图像数据库中选取。该方法包括对输入图像执行归一化预处理。 将预处理后的图像编码为向量。 当图像库中的图像编号为N时提取图像特征，构建属于RN的特征矩阵D。 确定D和DT的矩阵乘积。 执行对角线归零。 设定阈值。 选择一行。 计算相似度矩阵Smax的最大值。 取三角矩阵。 对所述三角矩阵和所述图像进行分类。 将相似度矩阵M变为上三角矩阵Mtriu。 当该值大于阈值t时，计算列索引。 14
本发明提供了一种多光谱无人机遥感影像作物分割方法，包括：步骤一，多光谱遥感影像数据处理。步骤二，植被指数提取。步骤三，构建数据集。步骤四，构建深度语义分割模型：在DeeplabV3+模型中添加卷积注意力模块，获得深度语义分割模型。步骤五，模型训练与保存。步骤六，作物分割。本发明在光谱信息方面，通过改进DeepLabv3+模型的输入层结构，添加NDVI归一化植被指数和OSAVI优化型土壤调节植被指数通道，增大不同作物间的光谱差异。本发明在空间信息方面，在空洞空间金字塔池化模块添加包括通道注意力和空间注意力的双通道注意力模块，扩大模型感受野的同时增加像素信息的相关性，优化分类结果的边界，从而提升模型精度。针对作物智能分类技术的多光谱无人机遥感影像作物分割方法，特别是针对多光谱无人机遥感作物切割方法。该方法在腔体空间金字塔池模块中增加了包括通道注意力和空间注意力的双通道注意力模块，扩大了模型感受野，增加了像素信息的相关性，优化了分类结果的边界，从而提高了模型精度。该方法涉及对多光谱遥感影像数据进行处理。 提取植被指数。 构建数据集。 构建深度语义分割模型。 在DeeplabV3模型中加入卷积注意力模块，得到深度语义分割模型。 对所述深度语义分割模型进行训练并存储。 将特征通道图和空间注意力图进行融合，得到包含通道权重和位置权重的输出特征图。 整体过程由元素一个元素一个元素的乘法来表示。   6
本申请公开了一种基于多模态表示的视频分类方法、装置和设备及存储介质，涉及人工智能技术领域，用于降低模型学习的难度，提升模型训练效率。该方法包括：将目标视频的各个模态的数据信息输入至已训练的目标多模态视频表示模型；获得目标多模态视频表示模型输出的目标视频在目标业务场景的视频业务类别；其中，目标多模态视频表示模型是基于各个模态各自对应的基础视频数据样本集合进行视频域的适应性预训练，并基于目标业务场景中各个模态各自对应的视频业务数据样本集合进行再训练获得的，每一基础视频数据样本集合包括各个视频对应于同一模态的基础视频数据样本，每一视频业务数据样本集合包括各个视频对应于同一模态的视频业务数据样本。用于视频平台的视频推荐分类、视频操作分类和视频标题识别服务场景中包括视频内容中的视频文字、视频图片和音频的计算机和人工智能领域的利用计算机设备(声称)基于多模式表示进行视频分类的方法。该方法：能够降低模型学习的难度； 能够提高模型的训练效率； 通过预先训练模型的视频域具有一定的初始表达能力，使得下游视频相关任务的模型训练难度更低，模型更容易收敛； 可相应减少模型训练消耗； 具有较高的训练效率，通过子阶段的训练过程使得多模态表征模型的学习更加具有阶段性。该方法包括获取各模态对应的目标视频的数据信息，将各模态的数据信息输入至训练好的目标多模态视频表达模型，获取目标多模态视频表达模型输出的目标业务场景中的目标视频的视频业务类型。 所述目标多模式视频表示模型是基于所述各个模态对应的各自的基础视频数据样本集，在视频域中进行自适应预训练得到的，其中，基于所述目标业务场景中各个模态对应的视频业务数据样本集进行重新训练得到的。 每个基础视频数据样本集合包括对应同一模式的各视频的基础视频数据样本。 每个视频业务数据样本集合包括对应同一模式的各视频的视频业务数据样本。独立权利要求还包括：一种基于多模式表示的视频分类装置； 以及计算机存储介质，包括用于基于多模式表示对视频进行分类的指令集。 9
本发明属于视觉SLAM技术领域，公开了一种语义特征和词袋模型相结合的视觉SLAM回环检测方法方法：采集工厂的运动视频数据，从运动视频数据中获取每帧图片，判断任意两帧图片之间的相似值，基于相似值删除冗余图片得到训练数据，基于训练数据对U‑net网络进行训练，得到训练U‑net网络；采集工厂的图片，获取该图片的RGB图，并将该RGB图用训练U‑net网络进行语义分割，得到语义标签；对语义标签进行聚类；对聚类后的语义标签进行相似性比较，获取候选关键帧；在检测到有关键帧插入后，进入回环检测。本发明解决了传统的SLAM词袋模型对像光照之类的变化不敏感，在工厂环境有变化的情况下容易造成较大的波动，提取特征存在准确精度低的问题。利用语义特征和词袋模型结合无人飞行器(UAV)的运动视频数据检测视觉定位和映射(SLAM)环的方法。本发明利用高质量数据训练.NET(RTM：Computer software framework)网络，提高图像识别的准确性，利用训练好的U.NET(RTM：Computer software framework)网络对每一帧图片进行语义分割，便于后期确定真实的闭环关键帧，克服工厂的仓库、墙白、工厂环境、工厂环境，解决工厂物流场景。该方法通过无人车采集工厂在移动过程中的图片。 获得图片的红-绿-蓝(RGB)图像。 利用训练U-net网络进行图像语义分割，得到语义标签。 在所述图片中对所述语义标签进行聚类。 对聚类后的语义标签进行相似度比较。 聚类后得到候选关键帧。 在检测到所述关键帧后进行循环检测过程。   6
本发明提供一种基于CycleGAN的个性字体生成方法。本方法从图像风格迁移的思想出发，基于循环生成对抗网络(Cycle Generative Adversarial Network，CycleGAN)搭建了用于字体风格迁移的模型，主要创新点是将图片风格迁移的方法运用到字体风格设计中，并对循环生成对抗网络的生成器进行了优化，将生成器中原本的Resnet结构替换为U‑net结构，选取了恰当的模型参数，并构建了属于自己的数据集，对数据集进行数据增强操作，最终获得了效果较好的生成风格字体图片。一种基于循环生成对抗网络(CycleGan)生成个人字体的方法。汉字个性字体可以作为图像风格迁移任务的一种变形生成，充分利用循环生成对抗网络(Cyclegan)网络，实现非配对图像之间的风格迁移。 对Cyclegan网络中的生成器结构进行了改进。 可以提高汉字风格的学习能力。 本发明采用的Cyclegan模型的训练不需要配对图像。该方法包括：收集图像数据集； 对图像数据组中的图像数据进行预处理， 构建实验研究所需的训练数据组， 通过使用训练数据组来生成风格图像， 生成用于训练所构造的循环的反型网络模型， 生成风格图片； 根据生成的风格图片效果，不破坏反模型网络模型的循环生成参数，修改模型的损耗函数，得到风格图片的更好效果，最终确定最佳效果参数，生成相应的结果图片。   6
本发明提供一种图像文献结构化解析方法、系统、电子设备、存储介质，所述方法包括：将图像文献内各页图像按顺序拼接，获得合成图；基于预定的待剔除的文本内容信息，对合成图中对应部分进行遮盖处理；对合成图进行版面整合，获得待解析图；将待解析图输入LX‑BioLayoutLM模型，获得带有结构化标签的解析文档；其中，所述LX‑BioLayoutLM模型基于BERT模型和LayoutLM模型，完成对待解析图中图像信息和文本信息的对齐。本发明实现批量地对图像文献进行结构化解析，便于对复杂场景下的文献数据进行结构化提取。一种对图像文件进行结构分析的方法。本发明可以方便地批量实现图像文档的结构化分析，以便于在复杂场景下对文档数据进行结构化提取。该方法包括顺序地拼接(100)图像文档中的每个页面的图像以获得合成图像。 基于要被删除的预定文本内容信息，对合成图像中的相应部分执行(200)掩蔽处理。 对合成图像的布局进行积分(300)以获得待分析的图像。 将待分析的图形输入(400)到LX-BiolayoutLM模型中，以获得具有结构化标签的已分析文档， 其中LxBiolayoutLM模型基于来自变压器(BERT)模型和LayoutLM模型的双向编码器表示，以完成待分析图像中的图像信息和文本信息的对准。本发明还涉及一种图像文件结构化分析系统。 (2)电子设备； 和(3)存储用于执行图像文档的结构分析的程序的非瞬态计算机可读存储介质。 14
本发明公开了一种库存自动化管理方法，包括下列步骤。接收历史销售状态，并根据历史销售状态对物品的未来销售量进行预测，以得到物品在下一个销售周期的预期销售状态的模拟结果。根据全品类物品的历史销售状态及各物品在下一个销售周期的预期销售状态的模拟结果，训练预训练模型的初始权重。以预训练模型的初始权重作为库存决策模块的权重进行训练，并自动产生符合物品在下一个销售周期的预期销售状态的进货量。根据物品的当期销售量、库存量以及上一个销售周期的进货量计算反馈误差，并将反馈误差及物品的销售状态输入至库存决策模块中进行物品的订货。用于自动库存管理的方法。该库存自动管理方法代替了人员手动设置参数，降低了库存成本和人员误判的风险。 该方法自动生成货物在下一销售期的预期销售状态的进口量。 库存决策模块将预训练模型的初始权重作为一个库存决策模块的权重进行训练，对所有货物的预期销售状态自动生成进口量。该方法涉及接收(S110)历史销售状态。 预测物品的未来销售金额。 根据所述历史销售状态得到所述物品在所述下一销售时段的所述预期销售状态下的模拟结果。 根据所有产品的历史销售状态和所述仿真结果，训练预训练模型的初始权重(S120)。 将所述初始权重作为一个库存决策模块的权重进行训练。 基于所述当前销售金额、所述进口量和所述最后销售期限计算反馈误差(S130)。 将所述反馈误差和所述产品的销售状态输入(S140)至用于订购所述产品的库存和决策模块。 自动生成各产品在下一销售时段的预期销售状态的进口量(S150)。包括一种用于库存自动化管理系统的独立权利要求。  11
本发明公开了一种基于深度学习的表格检索方法。包括接收用户输入的查询语句q，加载数据库中所有表格的行、列、单元格的特征信息集合F以及数据库中所有表的背景信息C，然后开始推断过程。本发明采用了比BERT效果更好的RoBERTa预训练模型，并在原有深度学习模型基础上加入了统计特征进行特征融合，使得相似度的计算时候利用了统计层面上相似度信息，具有全面性和准确性；同时在训练的时候，采用了BM25与增加难负例训练相结合的训练方法，让训练出来的模型对于易出错样本有更强的适应能力，提升了模型精度。一种基于深度学习的查表方法。本发明能够使用比Berteffect更好的Roberta预训练模型，并在原有的深度学习模型上加入统计特征进行特征融合，利用统计水平上的相似度信息进行相似度计算，以提高模型精度。该方法包括接收用户输入的查询语句。 对表格信息特征执行统计特征提取，其中由每个信息特征生成统计特征向量。 确定用户查询语句。 建立罗伯塔模型。 通过全连接线性层回归函数确定特征向量的相似度信息，用于计算相似度得分。 输出具有最大排序的相似性得分作为搜索结果。  12
基于大语言模型的人机对话处理方法及装置，当对话机器人的对话流程触发上下文理解/多轮入口策略进入上下文理解/多轮对话时，通过语言理解模型辅助上下文理解/多轮对话；获取用户的第一轮提问描述，通过语言理解模型对第一轮提问描述进行标准问句转换并输送到NLU引擎进行意图理解和回答；获取用户对对话机器人的第二轮提问描述，将第一轮提问描述和第二轮提问描述同时输送到语言理解模型，通过语言理解模型对第一轮提问描述和第二轮提问描述进行语义理解并输出合并后的提问描述；将第一轮提问描述和第二轮提问描述合并后的提问描述，输送到NLU引擎进行意图理解和回答。本发明降低了人机对话对NLU技术能力依赖程度和实现难度。基于大型语言模型的人机对话处理方法。该方法能够降低人机对话对NLU技术能力的依赖程度和实现难度。该方法包括：当对话机器人的dialog low触发上下文理解/多轮进入策略以进入上下文理解/多轮对话时，通过语言理解模型辅助上下文理解/多轮对话(S1)。 用户获得对话机器人的第一轮问题描述(S2)。 获取用户对对话机器人的第二轮问描述(S3)。 所述第一轮问题描述和所述第二轮问题描述被传达所述语言理解模型。 第一轮问题描述和第二轮问题描述的组合问题描述被传送(S4)到NLU引擎以用于目的理解和回答。本发明还公开了一种基于大语言模型的人机对话处理装置。 8
本发明实施例公开了一种线上业务断点提醒方法、装置、计算机设备及存储介质，涉及人工智能领域。所述方法包括：采集用户在办理所述线上业务过程中输入的文本数据；判断用户是否中断办理所述线上业务；若用户中断办理所述线上业务，获取用户的断点节点，并将所述断点节点以及所述文本数据储存；通过预训练的文本分类模型获取所述文本数据的分类标签；根据所述文本数据的分类标签匹配操作指引文本，并向用户发送断点提醒消息；若检测到用户点击所述断点提醒消息，跳转到所述断点节点，并向用户展示所述操作指引文本，从而可有效协助用户完成线上业务的办理。相比于人工电话指引的方式，具有效率高、成本低以及用户体验好的优点。一种利用计算机设备进行在线服务断点提醒的方法(索赔)。该方法通过在用户点击断点提醒消息的情况下，向用户显示操作引导文本从而有效地辅助用户完成在线服务的交易，实现了在线服务的高效、低成本和更好的用户体验。该方法包括采集用户在在线服务的交易过程中输入的文本数据。 判断所述用户是否中断办理所述在线服务。 获取所述用户的断点节点。 存储所述断点节点和所述文本数据。 通过预先训练的文本分类模型获取所述文本数据的分类标签。 向所述用户传递断点提醒消息。 当所述用户点击所述断点提醒消息时，向所述用户显示操作引导文本。独立权利要求还包括用于：在线服务断点提醒装置； 以及一种计算机可读存储介质，包括用于在线服务断点提醒方法的指令集。  11
本发明公开一种基于BERT、LSTM和宽度学习的跨领域情绪分类方法，包括以下步骤：(1)获取商品评论数据，并对这些评论数据进行预处理；(2)使用BERT对文本进行向量化表示；(3)采用LSTM对数据进行特征提取，获取领域不变特征和领域特有特征向量；(4)采用最大均值差异MMD来度量领域不变特征和分布之间的差异；(5)构建基于DIF的领域不变分类器和基于DSF的领域特有分类器；(6)将上述两种分类器进行协同训练，输出分类结果。本发明融合了BERT、LSTM和宽度学习的优点，使得系统能有效地获取源领域的特征，从而提高对目标领域的情绪分类效果。基于BERT，LSTM和宽度学习的跨域情感分类方法 用途包括但不限于快乐，爱，气，痛苦，恐惧感，恶臭和想要成为7种类型的愿望。本发明融合BERT，LSTM和Width学习的优点，使得系统能够有效地获取源场的特征，从而提高目标场的情感分类效果。所述方法包括：获取商品评论数据；对所述评论数据进行预处理。 通过使用来自变压器(BERT)的双向编码器表示来对文本执行向量化表示。 通过使用长短时存储器(LSTM)来执行数据的特征提取，以获得场不变特征和场特定特征向量。 最大平均差值(MMD)用于测量场的特征和分布之间的差值。 基于DIF和基于DSF的领域专用分类器构建领域不变分类器。 对两个分类器进行协同训练，输出分类结果。  12
本发明提供了一种文本相关性识别模型的训练方法及装置，所述方法包括：构建文本相关性识别模型；获取预先构建的语料库，基于所述语料库中多种类型的语料数据创建所述文本相关性识别模型训练的训练数据集；基于所述训练数据集中的语料数据对所述文本相关性识别模型进行预训练；所述预训练包括：利用所述文本相关性识别模型预测所述训练数据集中任一文本数据中的指定位置的词和/或预测任意两个文本数据的上下文关系。基于本发明提供的方案可通过不同训练方式的结合增强文本相关性识别模型的识别效率以及相关性识别的准确性。另外，增加实体名字补全训练，缩短预训练周期，节省训练成本。该方法可用于在计算机设备(要求保护)中训练文本相关性识别模型。本发明缩短了预训练周期，节约了训练成本。一种文本相关性识别模型的训练方法，包括：构建文本相关性识别模型； 获得预构建的语料库， 基于所述语料库中的多种语言数据创建由所述文本相关识别模型训练的训练数据集， 基于训练数据集中的语料数据对文本相关性识别模型进行预训练， 其中预训练包括使用文本相关识别模型来预测训练数据集中的任何一个文本数据中的指定位置的词和/或预测任何两个文本数据的上下文关系。本发明还涉及一种文本相关识别模型的训练装置。本发明还涉及一种文本相关识别模型的训练方法。 以及计算机存储介质，包括一组用于训练文本相关性识别模型的指令。  11
本发明涉及一种基于BERT的应急预案推荐方法，属于大数据分析技术领域。其中，该方法包括：对电网故障记录文本进行预处理后与词表进行特征匹配，得到故障类型、故障设备和故障描述。检索电网应急预案知识库，得到关联的关联电网故障预案。计算电网故障词集中的故障描述和关联电网故障预案中的故障描述的故障描述相似度。计算电网故障词集中的故障类型和关联电网故障预案中的故障类型的故障类型相关度。根据故障描述相似度和故障类型相关度得到电网故障相关度。将电网故障相关度最大值对应的处置方式作为最终推荐预案输出。使用基于BiGRU多层连接的BERT模型，加强了层级之间特征的获取和传递，提供更精确全面的决策支持，提升事故处理的效率。用于推荐用于大数据分析领域的基于BERT的应急方案的方法。该方法能够加强层次间特征的获取和传递，提供更加准确全面的决策支持，提高事故处理的效率。该方法涉及获取电网故障记录文本。 对所述电网故障记录文本进行特征提取，得到故障类型、故障装置和故障描述。 根据所述故障装置查找预先构建的电网应急预案知识库。 获取关联的电网故障方案。 对所述关联的电网故障预案计算电网故障的相关度。 将所述电网故障关联度的最大值对应的处理方式作为最终推荐方案输出。 0
本发明涉及视觉识别技术领域，提供一种基于预训练模型的视觉定位方法，所述预训练模型包括图像编码器和文本编码器，该方法包括：接收待查询语句和给定图像；利用所述图像编码器获取所述给定图像的一维特征，记为第一特征；利用所述文本编码器获取所述待查询语句的一维特征，记为第二特征；利用所述第一特征、第二特征作为软标签引导所述给定图像和所述待查询语句的标记化表达的开始位置，并引导位置标记的学习；基于所述位置标记预测视觉对象定位边框。本发明通过融合图像、语句双模态特征融合以及通过多模态蒸馏损失的计算能够实现多模态之间的知识迁移，解决了模态领域之间的差距问题，进而提高预测性能。基于预训练模型的视觉定位方法。通过融合图像、语句双模特征融合和计算多模蒸馏损失实现多模之间的知识迁移从而解决模场之间的差距问题，提高预测性能。该方法涉及接收要查询的语句和给定图像并且通过使用图像编码器来获取给定图像的一维(1D)特性。 将1D特性标记为第一特性。 利用文本编码器获取待查询语句的1D特征。 将1D特性标记为第二特性。 以所述第一特征和所述第二特征作为软标签引导所述给定图像和所述待查询语句的标注表情的起始位置。 指导位置标记的学习。 基于所述位置标记预测所述视觉对象定位框。 利用自适应平均池化将所述第一特征转换为与所述给定图像的标注表情特征相同的维度。 将所述维度记为第一转换特征。包括以下独立权利要求：1。 基于预先训练的模型的视觉定位装置； 2. 电子装置； 以及3。 一种非暂态计算机可读存储介质，其存储用于基于预先训练的模型进行视觉定位的程序。 14
本发明提供了一种视听结合的语音分离模型搭建方法及语音分离方法，属于语音分离技术领域，模型搭建方法为：获取若干说话人的视频和相应音频的原始数据，对获取的原始数据进行预处理，获取语音的语谱图、面部帧和嘴部动作帧构建数据集；基于U‑Net网络构建音频分离模块，基于ResNet‑18网络构建面部模块，基于ShuffleNet‑V2和TCN网络构建嘴部动作模块，三者结合组成新的网络模型，并对模型进行训练选取准确率最高的模型；模型搭建完成后用于混合音频分离。本发明提出的视听结合语音分离模型，与使用单一视频流的方法相比，取得了明显性能提升。在公开数据集上进行对比实验，验证了该方法的有效性。在助听器听力障碍者、智能家居语音控制、手机语音辅助辅助操作等语音交互设备中建立视听结合语音分离模型，辅助分析案例信息语音线索的方法。该方法实现了同时使用嘴部动作和面部信息两部分视觉特征辅助语音分离的过程，与单独使用语音分离构建模型和单纯的音频分离模型的一个视觉信息相比，使网络更好地利用视觉信息和音频信息的内在联系，实现更好的分离性能。 该方法改进了视觉特征的提取并考虑到视频进一步包含人脸信息，在人脸特征提取的过程中通过两层注意力机制帮助网络获取最关键的人脸区域，更高效地利用视觉信息。 传统U-net网络模型容易忽略数据细节的缺陷，该方法将残差连接机制引入U-net网络，在压缩的卷积块中加入残差连接该方法包括获得多个说话者的视频和相应音频的原始数据。 获取不同场景拍摄或下载中的原始数据。 对原始数据进行预处理。 视频被处理为一帧一帧的图像。 从原始数据中随机选取两个说话人数据。 混合语音频谱被输入到音频分离模块中。 面部框架被输入到面部模块中。 利用训练集和验证集对AV-ResUnet网络模型进行训练和验证。 选取训练过程中验证效果最好的选取模型作为最终的测试模型。 利用测试集中的数据对最终选择的AV-ResUnet网络模型进行测试。独立权利要求还包括：一种视听组合语音分离方法，用于在语音交互设备中构建视听组合语音分离模型； 以及视听结合语音分离装置，用于在语音交互设备中构建视听结合语音分离模型。 3
本发明提供一种联合注意力U形网络和多尺度特征融合的息肉分割方法，包括选择U‑Net作为主干网络，通过在U形主干网络结构的编码器和解码器阶段对应层的跳跃连接末端增加注意力门，以抑制不重要特征的同时加强重要信息；然后融合不同尺度特征获得丰富的全局语义信息特征图，特征图经过解码后得到全局映射图以作为后续步骤的初始引导区域；接着将平行高层特征传入到感受野模块中来增强网络深度表示；再在全局映射图指导下被送入多个以级联方式构建的反向注意力模块内，来更好挖掘目标区域特征和边界线索；最后通过精细化残差模块来精细化息肉目标区域和边界信息，得到更加高性能的息肉分割结果。本发明对于息肉图像数据集分割性能更加精准优异。联合注意力U形网络与多尺度特征融合polyp分类方法。该方法结合注意力机制和多尺度特征融合，得到性能更加优异的息肉分割结果。 该方法利用U型网络结构增加关注门，消除由于跳接导致的语义模糊，自动关注明显特征，并通过感受野模块融合不同尺度信息，增强网络特征表示。 采用前景擦除方法，通过反向注意机制更好地挖掘息肉目标区域和边界信息，同时，利用真值图像对网络进行深度监督，以减少梯度消失，避免网络收敛缓慢。该方法包括选择U-net作为主网络。 增加U型主网络结构的编码器级和解码器级之间的跳接端，以消除跳接带来的语义模糊。 主网络输出的三个并行的高层特征信息分别传输到三个感受野模块，增强网络深度表达。 一个全局映射图输出的高层特征和感受野模块被传递到多个以级联方式构建的反向注意力模块中。 将息肉粗分割结果图输入细化残差模块。 通过研究粗略结果图与一个真值之间的残差对息肉目标区域和边界信息进行细化，得到全面细化的息肉细化分割结果图。 通过细化残差模块对残差目标区域和边界信息进行细化处理。   6
本发明公开了一种基于深度学习的问答方法、装置及电子设备，方法包括：获取原始数据集；对所述原始数据集进行标注处理后，构建得到针对目标领域的知识图谱；获取所述目标领域的相关问题信息；其中，所述相关问题信息包括文字信息和图片信息；使用基于BERT的上下文建模对所述相关问题信息进行意图识别，得到目标实体和用户意图；根据所述目标实体和用户意图，构建数据库查询语句，并向所述相关问题信息反馈查询结果；根据所述查询结果的内容，进行前端信息显示。本发明能够提高效率和准确性，可广泛应用于计算机技术领域。基于深度学习的问答方法。该问答方法提高了效率和准确率，可广泛应用于计算机技术领域。 快速、准确地实现了与用户进行知识产权的问答交互。该方法包括获得原始数据集。 在对原始数据集进行标注之后，为目标领域构建知识图谱。 所述信息是关于所述目标区域中的相关问题获得的。 所述相关问题信息包括文字信息和图片信息。 基于来自变换器的双向编码器表示(BERT)的上下文建模被用于对相关问题信息执行意图识别，以获得目标实体和用户意图。 根据所述目标实体和用户意图构建数据库查询语句，并向所述相关问题信息反馈回查询结果。 显示所述前端信息，根据所述查询结果的内容。包括独立权利要求，用于：(1)一种基于深度学习的问答装置； (2)电子设备； (3)存储用于执行问题回答方法的程序的计算机可读存储介质； 以及(4)用于执行问题回答方法的计算机程序产品。  12
本发明提供的是一种基于TRANSFORMER特征融合的高光谱影像分类方法，通过将空‑谱信息特征与深层关联信息融合，更有效地利用影像光谱特征与空间特征，显著提高图像的分类精度。提出方法包括空‑谱信息挖掘、基于Transformer的特征融合、预测三个步骤。空‑谱信息挖掘是通过影像转置和三通道卷积神经网络的构建，充分挖掘影像中包含的空‑谱信息；基于Transformer的特征融合是将三通道获取的影像分别输入Transformer的三个编码器中，然后利用解码器将空谱特征进行融合，获取融合的空‑谱特征；预测是将Transformer融合的空谱特征输入到softmax中，从而得到分类器的分类精度。基于不同领域变压器特征融合的高光谱图像分类方法。 用途包括但不限于作物分析、地质测绘、矿产勘探、国防研究、城市测量和军事监测领域。该方法能够利用图像光谱特征和空间特征有效地融合空谱信息和深度相关信息，从而提高图像的分类精度。该方法包括对原始高光谱图像执行主成分分析(PCA)处理。 执行图像转置处理过程。 空间-频谱信息挖掘过程作为三通道卷积神经网络的输入进行，其中三个卷积神经网络由三维和二维卷积神经网络组成。 输入三个变换器的三个编码器，这三个编码器包括相同的结构，由多头自注意力(MSA)和多层感知模块(MLP)组成，以获得不同维度特征的更高级别的关联信息。 空间-频谱信息特征图是级联的。 利用所述变换器的解码器模块进行特征融合，得到融合后的特征。 从解码器获得融合特征。 直接输入预测模块进行分类。   5
本发明提供了一种基于AIGC的模糊行程规划系统，包括数据输入模块、第一行程规划模块、实时行程监测模块、第二行程调整模块和交互显示模块，所述数据输入模块用于采集模糊行程的要求信息，所述第一行程规划模块根据要求信息制定行程方案，所述实时行程监测模块用于监测用户的位置信息并判断是否符合既定行程，所述第二行程调整模块用于在与既定行程出现偏差时规划符合要求信息的新行程方案，所述交互显示模块用于显示规划的方案信息供用户进行选择；本系统能根据用户的需求信息生成多个行程方案供选择，并在实际旅行过程中进行监测，在突发情况下及时地调整行程方案来满足用户的模糊需求。一种基于人工智能生成内容(AIGC)的模糊行程规划系统，用于电数字数据处理领域。系统根据用户的需求信息生成多个出行解决方案供选择，在实际出行过程中进行监控，及时调整出行解决方案，满足用户在紧急情况下的模糊需求。该系统具有数据输入模块，该数据输入模块包括需求采集单元和条件匹配单元。 用户需求采集单元，用于采集模糊行程需求数据。 条件匹配单元，根据用户需求匹配现有出行资源并得到单元数据。 所述第一行程规划模块包括方案预生成单元、方案筛选单元和时间设定单元。 方案预生成单元，用于初步规划得到两个行程方案。 计划筛选单元，用于筛选行程计划。 时间设置单元，用于为行程计划中的每个单位数据设置对应的起始时间和结束时间。 所述第二行程调整模块包括接近度检索单元和行程方案调整单元。 附近检索单元，用于检索当前位置附近的单元数据。 行程计划调整部，基于调取的单位数据，调整行程计划。 1
本发明公开了一种无监督的基于表示学习的同名作者消歧方法及装置，包括：对科学文献数据进行预处理；利用Word2Vec预训练模型和SCIBERT预训练模型分别生成基于Word2Vec和基于SCIBERT的文本语义表示向量；通过对消歧数据的处理生成局部异质网络，指定元路径metapath并利用metapath2vec方法获取基于局部图结构的论文关系表示向量；针对上述三种表征向量分别生成相似度矩阵并进行加权求和；利用无监督聚类方法进行聚类；对聚类离散点进行簇指派，得到最终消歧结果。本发明利用论文的表征信息，结合多重混合的表征学习和聚类离散点指派方法，增强消歧算法的泛化能力与鲁棒性，提高了消歧准确度与消歧效率。一种基于表情学习的无监督作者消歧方法。本发明通过获取文章的表示信息，结合多种混合表示学习和聚类离散点赋值过程，提高了消歧算法的泛化能力和鲁棒性，有效提高了消歧精度和效率。该方法包括获得科学文献数据以获得多个结构化文本数据。 获得每个结构化文本数据的第一关键文本信息和第二关键文本信息。 根据第一关键文本信息将每个结构化文本数据转换为第一文章语义表示向量。 根据第二关键文本信息形成第一文章相似度矩阵。 将每个结构化文本数据转换为第二文章语义表示向量。 形成第二文章相似度矩阵。 根据结构化文本数据建立文章网络。 对分簇簇执行离散点分配处理。 获得预聚类结果以获得歧义消除结果。本发明涉及一种用于执行基于表达式学习的无监督作者歧义消除方法的电子设备，包括处理器和存储器。  12
本发明公开了一种基于图传播的主动学习异常检测方法及系统，涉及图像异常检测的技术领域，采集产品图像后进行预处理，构建预训练自动编码器并训练，通过训练得到的自动编码器获得不包含低级特征的图像编码，并进一步重构，不仅能取得更连续平滑的图像低维表示，还能获得更好的异常检测性能。基于k‑近邻传播矩阵的图传播更新图像标注信息，使得更新图像标注信息的耗时更低，而且在主动学习阶段同时考虑了图像样本的不确定性和代表性，并挑选最具代表性的图像样本，对图像样本分空间进行了充分的探索，有效提升了主动学习的性能，最后将待检测的产品图像输入异常检测模型中，得到待检测产品的异常得分，异常检测性能佳。用于检测自动化制造业中使用的产品图像预处理的基于图像传播的主动学习异常检测方法。训练得到的自动编码器得到图像编码无低层特性，进一步重构，不仅可以得到更加连续平滑的图像低维表示，还可以得到更好的异常检测性能。 更新图像标签信息的时间消耗更低，同时考虑主动学习阶段图像样本的不确定性和代表性，并选取最具代表性的图像样本，充分发掘样本空间，有效提升动作学习的性能。该方法涉及随机收集(S1)多个产品的图像，并且预处理以获得产品图像集。 构建预训练自动编码器(S2)。 采集所述待检测产品的图像数据。 使用自动编码器(S3)来获得产品图像集中的每个图像的编码和重建误差。 构建k相邻传播矩阵。 选取最具代表性的图像样本(S4)进行人工标记，利用人工标记和重构误差构建包含样本不确定度的信息矩阵。 通过试尿样本选择策略选择(S5)图像样本进行主动学习。 通过节点的不确定性和邻接关系，为每个图像样本计算训练权重(S6)。 最后，将该前处理输入到异常检测模型(S7)。 利用重构误差计算所述待检测产品的异常分值。包括一种基于图像传播的主动学习异常检测系统的独立权利要求。   6
本发明旨在提供一种流程精简、成本低、操作便捷的实现智能写作引擎的自动训练方法。本发明方法包括以下步骤：a.基于AIGC建立具有多个领域的能力模型的训练平台，用户根据实际情况，选择好对应的能力模型；b.选择好具体的能力模型之后，对语料数据格式进行调整以适应对应的能力模型，编辑该能力模型训练所需要的语料数据；c.在训练模型之前，将编辑好的语料数据上传到训练平台上，创建数据集，不断调整训练输出的结果数据；d.进入模型训练，直到训练进度达到100%；e.模型训练完之后，用户在训练平台上进行界面调试，确认对应的输入输出是否符合预期的标准。本发明可应用于计算机技术与人工智能领域。用于自动训练智能书写引擎的方法。该方法使得能够以简单的过程为实现智能书写引擎提供自动训练，降低成本，并且实现方便的操作。 该方法允许用户在训练平台上进行接口调试，训练模型后确认相应的输入输出是否符合预期标准。该方法涉及建立基于AIGC的具有多个领域的能力模型的训练平台。 用户根据实际情况确定需求。 在选择特定能力模型之后，配置能力模型的名称和参数。 编辑后的语料数据在训练模型之前上传至训练平台。 由用户在训练好模型后在训练平台上进行接口调试。 进行判断，检查相应的输入输出是否满足预期标准。 编辑语言材料。 重新输入训练，直到输出满足预期标准。 1
本发明公开了一种PDF文档处理方法、装置、可读存储介质及电子设备，该方法包括：通过OCR技术解析PDF文件，得到解析文本；将解析文本与任务目标提示词进行拼接，以得到输入文本；将输入文本输入至大语言模型中，以使该大语言模型对输入文本进行信息提取并输出结果，该大语言模型对输入文本进行信息提取的步骤包括：对输入文本进行分词处理，得到多个token数组；将各个token数组通过Embedding层映射成长度为4096的特征向量；将特征向量输入到GLMBlock块，并通过GLMBlock块处理后输出注意力分数；将注意力分数通过Lmhead层进行输出处理；将生成的所有的token进行解码后，整合输出。PDF文档处理方法。该方法使得通过OCR技术解析PDF文件得到解析文本，将解析文本与任务目标提示词拼接得到输入文本，并将输入文本输入到大型语言模型中从而保证简单高效的处理方法。本发明公开了一种利用光学字符识别技术分析可携式数据文件的方法，该方法包括利用光学字符识别技术分析可携式数据文件，以获得分析后的文本。 将解析文本和任务目标提示词进行拼接，得到输入文本。 将输入的文本输入到ChatGLM2-6B大型语言模型中。 ChatGLM2-6B大型语言模型对输入的文本进行信息抽取并输出结果。 对所述输入文本进行信息抽取，输出结果。 对所述输入文本进行分词处理，得到多个令牌数组。 令牌阵列通过Emedge层映射到长度为4096的特征向量中。 特征向量被输入到GLMBlock块。 在GLMBlock块处理之后输出注意力分数。 由GLMBlock块通过Lmhead层对注意力分数输出进行输出处理，以生成下一个令牌。 在解码所有生成的令牌之后执行注意力分数积分和输出处理。独立权利要求包括用于：(1)PDF文档处理装置； (2)可读存储介质，其存储用于处理PDF文档的一组指令； 以及(3)电子设备。  11
本发明涉及一种信创环境下基于机器学习实现数据资产知识图谱构建的方法，包括以下步骤：获取数据资产，对数据进行筛选、清洗、去重的预处理操作；进行数据资产预处理，对原始数据进行清洗、分词、词干提取、去除停用词的操作；进行实体识别；进行本体概念关系抽；体关系抽取方法结合了Q‑learning和BERT技术，充分利用了BERT的强大表示能力，并通过Q‑learning算法学习实体关系，从而在数据资产知识图谱的实体关系抽取任务上取得了显著的改进。然后进行实体识别操作，本发明提出了一种基于注意力机制和图卷积神经网络的实体识别方法，用于对数据资产知识图谱进行实体识别。信息创新环境下基于机器学习的数据资产知识图谱构建方法。该方法提出了一种基于注意力机制和图谱卷积神经网络的实体识别方法，用于数据资产知识图谱的实体识别。该方法涉及获得数据资产。 进行数据的筛选、清洗、去重的预处理操作。 对所述原始数据进行数据资产预处理、清洗、分词、词干、去除停用词。 提取主体概念关系。 标注语言学数据。 提取所述实体关系。 执行所述实体识别。独立权利要求还包括用于：一种信息创新环境中基于机器学习的数据资产知识图谱构建装置； 处理器，用于在信息创新环境中基于机器学习构建数据资产的知识图谱； 以及计算机可读存储介质具有用于在信息创新环境中基于机器学习来构建数据资产的知识地图的指令资产。  11
本发明实施例提供了一种参考弹幕展示方法、系统、装置及电子设备，应用于计算机技术领域，该方法应用于弹幕服务端，该方法包括：接收第一视频播放端在播放目标视频达到目标播放进度时所发送的参考弹幕获取请求；向第一视频播放端发送针对目标播放进度的目标参考弹幕，以使第一视频播放端展示目标参考弹幕；其中，目标参考弹幕为：将目标提示语输入至预先训练完成的大语言模型得到的；目标提示语，用于指示大语言模型以目标视频在目标播放进度的台词内容，和/或目标视频在目标播放进度的弹幕内容为参考，生成针对目标播放进度的弹幕。通过本方案可以降低弹幕所带来的风险。用于为弹幕服务端显示参考弹幕的方法。该方法降低了屏幕带来的风险。该方法包括：接收第一视频播放端在播放的目标视频达到目标播放进度时发送的参考屏幕获取请求(S101)。 向所述第一视频播放端传输(S102)针对所述目标播放进度的目标参考弹幕，以使所述第一视频播放端显示所述目标参考弹幕。 将目标提示输入预先训练好的大型语言模型，得到目标提示。 目标提示用于指示大语言模型以目标播放进度下的目标视频的语音内容和/或目标播放进度下的目标视频的弹幕内容为参考，生成针对目标播放进度的弹幕。独立权利要求包括以下内容：一种用于第一视频播放端的基准弹幕显示方法； 参考屏幕显示系统； 一种基准弹幕显示装置，用于弹幕服务端； 参考弹幕显示装置，用于第一视频播放端； 以及电子装置； 以及存储用于显示基准画面的程序的计算机可读存储介质。 9
本申请实施例提供一种语言模型微调方法、文本分类方法、装置及设备。微调方法包括：获取输入词向量，输入词向量包括：训练样本的训练样本词向量、第一模板词的第一模板词向量、掩码、第二模板词的第二模板词向量及单个标签词对应的标签词向量；训练样本、第一模板词及掩码构成第一文本句子，第二模板词和单个标签词构成第二文本句子；将输入词向量输入预训练语言模型得到词预测结果和针对第一文本句子和第二文本句子的相邻句子判断结果；基于词预测结果和真实标签词得到第一损失值；基于相邻句子判断结果和真实判断结果得到第二损失值；根据第一损失值和第二损失值训练预训练语言模型得到训练完成的语言模型。本申请可提升语言模型预测性能。一种用于由电子设备微调语言模型的方法(要求保护)。本发明提高了语言模型最终训练的性能。该方法包括获得输入词向量。 训练输入字向量以训练训练样本的样本字向量。 对应于单个标记字训练第一模板字向量，掩码，第二模板字和标记字向量。 训练该训练样本以形成第一文本句子和第二文本句子。 获得掩码的单词预测结果和相邻句子判断结果。 基于判断结果获得第二损耗值。 根据第一损失值和第二损失值训练预先训练的语言模型。 获得训练完成的语言模型。本发明还涉及一种文本分类方法； 语言模型微调装置； 文本分类装置； 如权利要求所述的计算机存储介质； 以及计算机程序产品。  12
本发明提出一种基于目标感知的立场检测方法，包括，获取用户社交文本数据集，对用户社交文本数据集进行数据预处理，得到预处理数据；将预处理数据转化为词共现图，并使用预训练的BERT模型构造词共现图对应的词特征矩阵；构建立场检测模型；立场检测模型包括门控图注意力网络层、目标感知图读出层、立场检测层；根据词特征矩阵对立场检测模型进行训练；获取待检测用户社交文本，输入训练完成的立场检测模型，输出检测结果。通过本发明提出的方法，充分利用了文本的词级信息，有效地提升了立场检测效果。一种基于目标感知的位置检测方法，用于从文本信息中自动检测人对个人、物体或事件的意见或态度。该方法充分利用了文本的词级信息，有效提高了位置检测效果。该方法涉及获得(S101)用户社交文本数据集。 所述预处理数据是从预先训练的用户社交文本的数据中获取的。 将预处理数据转换为单词共现图(S102)。 构建位置检测模型(S103)。 所述位置检测模型设置有选通图像注意力网络层、目标传感图像读取层和位置检测层。 根据所述词特征矩阵训练(S104)所述位置检测模型。 获取待检测用户的社交文本(S105)。 输入训练好的位置检测模型。 输出检测结果。独立权利要求包括如下：一种基于目标感知的位置检测装置； 计算机设备； 以及存储用于基于目标感知来检测位置的程序的计算机可读存储介质。  12
本发明提供一种区域入侵检测模型训练方法及区域入侵检测方法，涉及计算机技术领域，该方法包括：获取第一训练数据集，第一训练数据集包括多个第一样本行人图像、第一样本行人图像的第一标注信息和第一标签数据，第一样本行人图像是基于图像生成模型得到的，图像生成模型是基于第二样本行人图像和第二样本行人图像的第二标签数据训练得到的；基于第一训练数据集，对初始区域入侵检测模型进行训练，得到区域入侵检测模型。通过图像生成模型实现了多模态大模型生成样本图像，增强了样本数据，而且样本图像更加符合真实环境图像数据，使用增强后的样本数据训练模型，使得模型的性能较高，提升了模型的检测精度和泛化能力。用于建筑工地、小区安防和重点区域检测的区域入侵检测模型的训练方法。多模态大模型通过图像生成模型生成样本图像，增强了样本数据，样本图像更符合真实环境图像数据。 将增强后的样本数据用于训练模型，使得模型的性能更高，提高了模型的检测精度和泛化能力。该方法涉及获得第一训练数据集。 、所将方便涉及家后图、控的杀将最面上在将级从和将级涉及将最面上的电机。 所述第一样本行人图像基于图像生成模型得到，所述图像生成模型基于第二样本行人图像和所述第二样本行人图像的第二标签数据训练得到。 基于所述第一训练数据集对所述初始区域入侵检测模型进行训练，得到所述区域入侵检测模型。 获得第二训练数据集(201)。 基于所述第二训练数据集对所述初始图像生成模型进行训练(202)，得到图像生成模型，基于所述第二标签数据和所述图像生成模型得到所述第一训练数据集。本发明还涉及一种区域入侵检测方法。 14
本发明公开了基于智能问答关联垂直问题域于开发问题域的方法及系统，属于AI NLP智能客服领域，本发明要解决的技术问题为如何兼顾特定垂直领域问答和开发领域问答效果与部署可行性的需求，同时兼顾不同领域问答快速响应的需求，采用的技术方案为：将特征领域知识进行归集及结构化处理；将归集及结构化处理的数据输入到Sentence Bert模型进行微调训练，得到特定垂直领域知识智能问答模型，并将特定垂直领域知识智能问答模型私有化部署或者提供Saas服务；通过Saas服务获取得到开放问题域知识模型；将问题输入到特定垂直领域知识智能问答模型，并将该问题与特定垂直领域知识问答库中的相似问题进行相似度匹配，并将相似度值进行降序排序后，再与设定阈值进行比较。在人工智能(AI)自然语言处理(NLP)智能客户服务领域中，基于智能问答的垂直问题域与开发问题域关联的方法。该方法能够确定是否考虑特定垂直领域和发展领域的问答效果和部署责任的需求，能够关注不同领域的问答快速响应需求。该方法涉及向特定的垂直领域知识智能问答模型输入问题。 将所述问题与特定垂直领域知识问答库中的相似问题进行匹配。 计算相似度值。 所述相似度值按照从大到小的顺序进行排序。 将所述相似度值与预设阈值进行比较。 如果相似度值小于预设阈值，则通过开发问题领域知识模型API或Saas确定问题为非特定领域知识，以解决问题。 将所述问题确定为特定垂直领域，以通过所述特定垂直领域知识智能问答模型对所述问题进行回答。 基于开源1.0或ChatGPT(RTM：Large language model-based chatbot)得到开放的问题领域知识模型。度物质插无气环境该较-模块不快的提取指定优点且量指定和防治的密的路指定优点块 (2)一种电子设备，包括存储器和处理器，用于基于智能问答将垂直问题域关联到发展问题域； 以及(3)计算机可读存储介质，其存储用于基于智能问答将垂直问题域关联到发展问题域的一组指令。  11
本发明公开了一种基于自监督的预训练和面瘫分级的建模、分级方法及系统。面瘫分级评估方法主要包括视频序列预测的上游任务和面瘫分级评估的下游任务两个阶段。为进行视频序列预测，将面瘫的诊断视频中人脸对称地划分为左侧脸和右侧脸，将这些单侧脸的视频采样为若干个视频片段并打乱。然后利用3D‑CNN模型进行视频序列预测任务的预训练。预训练后的3D‑CNN模型就具有一定能够学习面部运动时序特征的能力。然后，将预训练后的模型迁移到面瘫分级评估的下游任务钟，利用面瘫诊断视频对预训练后的3D‑CNN模型进行微调。最后，利用3D‑CNN模型提取的时序特征的差异信息进行面瘫分级评估。此外，整个模型结合了面部整体的非对称性特征和局部非对称性特征进行面瘫分级评估。基于自监督预训练和面瘫分级进行建模和分级的方法。该方法：结合非对称特征和全脸局部非对称特征进行面瘫分级评估。该方法涉及获取人脸表情视频集。 对所述人脸表情视频集进行采样，得到视频段。 所述视频段是将所述人脸表情视频集作为人脸数据集进行采样得到的。 对所述面部数据集合进行预处理，得到面部视频序列集合。 面部视频序列集合中设置有多组左侧子视频段序列和多组右侧子视频段序列。 将所述人脸视频序列集作为自监督训练的训练集。 将训练好的三维卷积神经网络模型作为预训练模型。 建立三维卷积神经网络模式。 将对人脸表情视频集采样得到的视频段作为人脸数据集进行预处理。还包括用于基于自监督预训练和面瘫分级的建模和分级的系统的独立权利要求。 2
本发明涉及一种无源域数据的无监督领域适应方法，以有标签的源域样本训练模型，得到预训练好的源域模型；以源域模型初始化目标域模型；以源域模型的BN层存储的统计信息近似源域的特征分布，与目标域样本的特征分布显式对齐，最小化分布对齐损失，尽可能拉近源域和目标域特征分布空间；基于源域模型的分类器的预测对目标域样本的特征进行模糊聚类，以聚类隶属度作为目标域样本的软标签，计算软标签与模型分类器对目标域样本的预测之间的交叉熵损失，对目标域样本计算信息最大化损失；以所有损失函数共同训练目标域模型，实现无源域数据的无监督领域适应，纠正部分最初分类器分错的目标域样本，提高分类准确度。无源域数据的无监督域自适应方法。该方法实现了被动域数据的无监督域自适应，修正了部分初始分类器错误的目标域样本，提高了分类精度。无监督场自适应方法是利用标记的源域样本训练模型，得到预训练的源域模型。 通过源域模型对目标域模型进行初始化，其中，目标域模型包括特征提取器和分类器。 利用存储在源域模型BN层的统计信息逼近源域的特征分布。 对目标领域样本的特征分布进行显式对齐。 计算分布对准损耗。 计算目标领域样本的信息最大化损失。 14
本发明涉及通过随机初始化训练并结合ResNet作为基础网络实现小目标场景的识别与定位，具体为一种目标检测识别与定位的方法，其特征在于包括如下步骤：A.数据集的制作；B.系统框架的构建；C.模型的训练，发明是针对小目标场景设计的一套目标识别与定位系统，检测目标为一个识别范围为10m×10m的室内场景中运动的对象，每一个人带一顶帽子，每一顶帽子均有所差异。本发明可以通过不使用预训练模型，因为预训练模型虽然能加快收敛，但对于不同的任务无法改动相适应的特征提取网络来满足需求，本发明使用随机地初始化训练，在整个网络添加BN层来稳定梯度，并运用改进的ResNet作为基础网络来加强对小目标场景的识别与定位。一种目标场景检测，识别和定位方法。本发明加快了预训练模型的收敛速度，满足特征提取网络的要求，通过增加BN层稳定梯度网络，实现随机初始化训练，选择RESNET作为底层网络，增强目标场景的识别和定位。该方法包括构建数据集。 执行数据集获取和数据对象校准。 构建系统框架。 根据数据集的特性对系统帧模板进行校准。 根据训练数据进行模型训练和定位处理。 在识别范围内确定对象。 检测对象头带的可视对象。 确定两个相机的不同视角以收集数据集的图像。 校准所收集的图像数据。 执行初始学习速率设置过程。 待定位相机的目标检测结果。 14
本发明公开的属于自动化识别技术领域，具体为一种基于自然语言推理的关系抽取模型，其包括：DescriptionLayer(描述层)；EncoderLayer(编码器层)；InferenceLayer(推理层)；ClassificationLayer(分类层)。本发明在公开的数据集SemEval 2010Task‑8上与目前较为先进的四个模型进行对比试验：1)基于GCN的FAT‑RE模型，2)基于CNN和注意力机制的Att‑Pooling‑CNN模型，3)基于BERT的R‑BERT模型，4)基于BERT的KnowBERT模型，从而使该模型整合了知识库中的信息，且本模型的F1分数达到90.1％，高于其他四个模型，说明本模型通过构造关系描述和多损失函数叠加，有效地提升了模型的性能，向模型中注入了先验知识，并在推理的过程中，根据关系描述来选择目标句子中的关键信息和过滤目标句子中的噪音。该模型在自动识别技术领域中是有用的。所述模型：整合知识库中的信息； 达到90.1%，通过模型的F1评分高于其他四个模型； 可以通过构建关系描述和多损失函数叠加来描述模型； 能够有效提高模型的性能； 能够将先验知识注入到模型中，并在推理的过程中； 并可以根据关系描述选择目标语句中的关键信息和筛选后的目标语句中的噪声。该模型包括模型结构，该模型结构的最低层具有模板描述。 关系描述模板用于将目标句子映射到假设句子对。 编码器层被转换为固定长度向量，以获得假设句子对的向量表示。 利用对应于假设句子对的置信度得分的分类层。 分类层选择置信度最高的关系给出关系目标语句的预测。  11
本发明一种基于CNN与Transformer的超声图像分割方法，属于医学图像分割技术领域。解决超声图像分割精度低、鲁棒性不强的问题。技术方案：获取原始超声图像；将原始超声图像通过图像Unet编码器获取特征图；将原始超声图像通过图像SwinT编码器获取特征图进行输入图像序列化在随后的Swin‑Transformer块中；对两个通道的特征图进行特征融合经过Swin‑T编码器与U‑Net编码器进行特征提取后，得到了不同尺度的的特征，将不同层级不同模块的特征进行深度融合；将得到逐层的特征与得到的融合底层特征与解码器结合与U‑Net编码器模块对应层次所提取的特征进行拼接与双层卷积，批归一化与激活操作，得到分割结果。本发明具有超声图像分割精度高、鲁棒性强等优点。基于CNN和磁体的超声图像分割方法。该方法使得能够对得到的逐层特征以及得到的融合底层特征和解码器结合U-Net编码器模块对应层提取的特征进行拼接、双层卷积、批归一化和激活操作，得到分割结果，从而实现了超声图像分割精度高、鲁棒性强。该方法包括获得超声图像。 通过Unet编码器获取所述超声图像的特征图像。 对两个通道的特征图进行特征融合。 通过Swin-T编码器和U-Net编码器进行特征提取，得到不同尺度的特征。 通过GDFF模块对所述不同层次模块的特征进行深度融合。 在获得输出之后，下一层解码器再次对上层的特征和Swin-T编码器执行上采样操作。 再次与对应级别的U-Net编码器模块进行拼接卷积。 进行两次3x3卷积，得到结果。   5
本发明提供一种基于AIGC工具的医生AIGC工作平台，涉及医疗系统技术领域。该医生AIGC工作平台，包括基于AIGC技术的工作系统和嵌入该系统的基于AI GC技术的工作平台，所述基于AIGC技术的工作系统包括获取收集模块、前端处理模块、智慧分析模块、预设规则模块、辅端处理模块、AIGC工具模块和智能处理端，所述基于AIGC技术的工作平台包括医助端、后台系统端和数据端。通过AIGC工具模块和医助端选择模块的配合，使得系统能够根据特有特征关键词匹配相似度最高的关联方案内容，完成决策方案推荐，同时具有向特定的因素特征的倾向性，使得在确定好关键特征后，可以根据关键特征进行针对性的拓展和细化，有利于生成的决策方案具有更针对性和独特性，而且效率性更高。一种医疗系统中基于人工智能(AIGC)工具的医生AIGC工作平台。医生AIGC工作平台可以根据关键特性进行针对性的扩展和细化，有利于生成的决策解更具针对性和唯一性，效率更高。 系统可以根据特定的特征关键字匹配相似度最高的关联方案内容，完成决策方案推荐，同时具有特定因子特征的倾向，从而在确定关键特征后。所述平台具有通过连接端(12)与后台系统端(10)连接的医疗救助端(9)和数据端(11)。 获取采集模块(1)，与用户数据获取连接。 由数据关键字生成数据关键字。 所述数据关键字生成关键字关联。 关键词关联生成关联方案生成。 智能处理端与历史数据调用连接。 历史数据调用与历史数据判断相连接。 历史数据决策和最优方案排序。 1
本发明涉及一种基于深度学习的非侵入式负荷在线监控方法及其系统，该方法包括以下步骤：获取用电负荷历史数据；基于用电负荷历史数据，进行神经网络训练，得到非侵入式负荷监控模型；采集用电负荷实时数据，并对用电负荷实时数据进行预处理；利用非侵入式负荷监控模型对预处理后的用电负荷实时数据进行分解，得到监控结果并进行展示。与现有技术相比，本发明利用离线数据为深度学习模型提供学习标签预训练模型；通过后端Django框架实现采集数据处理及在线监控，并利用前端Vue‑ElementUI框架对负荷监控结果进行展示，能够充分考虑外界干扰因素，有效提高监测结果的实时性和准确性。一种基于深度学习的无创负荷在线监测方法，用于监测住宅楼总用电数据。该方法利用离线数据为深度学习模型提供学习标签预训练模型，通过后端DJANGO框架实现采集数据处理和在线监测， 并采用前端VUE-elementUI框架显示负载监测结果，充分考虑了外界干扰因素，有效提高了监测结果的实时性和准确性。该方法包括获得(S1)电力负载的历史数据。 执行(S2)神经网络训练以基于电力负荷的历史数据获得非侵入性负荷监测模型。 收集电力负荷的实时数据(S3)。 对电力负荷的实时数据进行预处理。 提供非侵入式负荷监视模型(S4)以分解预处理的电力负荷的实时数据。 获得监测结果并显示它们。本发明还涉及一种基于深度学习的无创负荷在线监测系统。 0
本发明提供一种基于法律数据的多任务学习语义标注方法和装置，该方法包括：获取对法律数据进行标注的预设需求；获取待标注法律数据导入语料库；根据标注的预设需求对待标注法律数据进行任务配置和服务器硬件配置；根据确定的任务类型、各任务类型对应配置的模型参数和获取的人工标注中的数据，构建对应的多任务学习模型；根据多任务学习模型对待标注法律数据进行标注，确定语义标注后的法律数据。本发明提供的相关联的多任务学习比单任务学习具有更好的泛化效果，且不需要依赖算法工程师完成选择预训练模型以及调整模型的参数，直接提高数据标注工作的效率和降低数据标注相关人员的学习成本。该方法可用于使用电子设备(要求保护)基于法律数据的多任务学习语义注释。该方法比单任务学习具有更好的推广效果； 不需要依赖算法工程师来选择预训练模型和调整模型的参数； 直接提高了数据注释工作的效率； 降低了数据注释相关人员的学习成本。一种基于法律数据的多任务学习语义标注方法，包括：获取预先设置的标注法律数据的要求； 获取待标注的法律数据； 导入语料库， 根据已标记的预设要求，对待标记的合法数据进行任务配置和服务器硬件配置； 其中任务配置包括划分任务类型和配置模型参数， 其中服务器硬件配置包括与CPU服务器对应的编号和硬件编号配置，或与图形处理单元服务器对应的编号和硬件编号配置， 根据确定的任务类型，每个任务类型对应的配置模型参数以及人工标注中得到的数据，构造对应的多任务学习模型，根据多任务学习模型对待标注的法律数据进行标注，确定语义标注后的法律数据。还包括独立的权利要求： 基于法律数据的多任务学习语义标注装置； 以及 包括用于基于法律数据的多任务学习语义注释方法的一组指令的非临时性计算机可读存储介质。  11
本发明公开了一种无监督的网络舆情垃圾长文本识别方法，其识别方法包括如下步骤：从现有的内部系统获取相应带有标记的舆情垃圾文本和正常文本的数据；分别构建两个模型，包括基于网络舆情文本训练的语言模型和基于网络舆情文本的BERT下一句预测模型，将待预测的网络舆情长文本分别输入到上述语言模型和BERT下一句预测模型中；本发明通过利用语言模型困惑度指标评价句子内部是否是垃圾文本，利用BERT下一句预测模型来评价文本的句子与句子之间的上下文连贯性，将两者相结合来完成长文本的垃圾文本识别任务，能够在自动识别出垃圾文本信息的同时，大大降低因获取监督数据所产生的成本，可以让一个没有监督数据的系统从一开始就能够识别出垃圾文本。一种无监督的网络意见兜售信息长文本识别方法。本发明大大降低了获取监管数据的成本，使得没有监管数据的系统能够从一开始就识别垃圾邮件文本。该方法包括从现有的内部系统模型训练中获得相应的标记的意见兜售文本和正常文本。 一种基于网络意见文本训练的语言模型和一种基于网络意见文本训练的语言模型，该语言模型表示来自基于网络意见文本的变压器(BERT)的下一句子预测模型的双向编码器表示，并将待预测的网络意见的长文本输入到上述语言模型中。 构建语言模型。 所述混乱评估指标的特征用于判断垃圾邮件文本的类型。 文本中的句子不流畅，并且包含一些凌乱的字符。 它用于判断两个句子是否为上下文敏感句子。  12
本发明公开了一种在CDN中应用的AI视频压缩方法，包括：记录用户向CDN节点发起视频点播请求的日志数据，筛出热度视频，并分析得到热度视频的特征向量；将向量输入到BERT模型中训练得到热度指标向量，热度指标向量与所有点播视频的带宽数据点积得到带宽指标值，根据带宽指标值对所有点播视频进行排序；选取队列头部的视频输入分类模型做智能场景识别，将分类结果输入压缩策略确定模型，获得压缩策略模板；使用视频处理增强算法先对队列头部的视频进行调整，再根据压缩策略确定模型输出的压缩策略指导编码得到压缩后的视频，将视频分发至对应的内容分发网络的边缘服务器中。本发明全流程可自动有效执行，无需人工干预。用于压缩CDN中的人工智能(AI)视频的方法该方法能够在无需人工干预的情况下自动且有效地执行AI视频压缩。 该方法保证CDN能够提高视频加载速度和用户体验，从而避免视频厂商带来的巨大流量损失。该方法包括记录由用户向内容分发网络(CDN)节点发起的视频点播请求的日志数据。 筛选出热度视频。 获取所述热度视频的特征向量。 通过热度指数向量和所有点播视频的一个带宽数据点得到一个带宽指数值。 根据带宽索引值对所有点播视频进行排序。 选取一个队头的视频输入分类模型作为智能场景标识。 将分类结果输入压缩策略确定模型，用于得到压缩策略模板。 利用视频处理增强算法对队头视频进行调整。 将所述高清低码的视频分发至对应的CDN的边缘服务器。 9
本申请公开了一种语音识别模型的生成方法、语音识别方法、装置及设备，涉及语音识别技术领域，生成的语音识别模型能够准确提取到较强表征能力的语音特征向量，提高语音识别用户身份的准确率。其中方法包括：获取多元语音样本数据组合；通过孪生神经网络的特征提取模块，对多元语音样本数据组合进行特征提取，得到表征不同样本类型的语音特征向量，通过孪生神经网络的相似计算模块，确定表征不同样本类型的语音特征向量之间的相似度，根据表征不同样本类型的语音特征向量之间的相似度对孪生神经网络进行训练，得到训练后的孪生神经网络，使用训练后的孪生神经网络的特征提取模块构建语音识别模型。用于使用计算机设备生成语音识别模型的方法(权利要求书)。生成的语音识别模型准确提取了表征能力强的语音特征向量，提高了语音识别用户身份的准确性。所述方法包括：获取多元语音样本数据组合(101)，所述多元语音样本数据组合包括多个不同样本类型的语音数据。 通过双胞胎神经网络的特征提取模块提取(102)多元语音样本数据组合的特征，以获得表示不同样本类型的语音特征向量。 通过双胞胎神经网络的相似计算模块确定表示不同样本类型的语音特征向量之间的相似度(103)。 根据表示不同样本类型的语音特征向量之间的相似度对双胞胎神经网络进行训练(104)，得到训练后的双胞胎神经网络。 利用训练好的孪生神经网络的特征提取模块构建(105)语音识别模型。独立权利要求还包括：一种用于识别语音的方法； 语音识别模型生成装置； 用于识别语音的装置； 以及包括用于识别语音的指令集的计算机存储介质。 3
本发明涉及人工智能领域，提供一种课程标签生成方法、装置、设备及介质，能够基于内容理解更准确的进行关键词的提取，间接提高了标签生成的合理性，以LSTM网络提取时序特征，使提取到的特征与待处理课程数据的自身属性更加匹配，然后以CNN‑Attention网络进行文字识别，能够更加关注于对重要字符的识别，再通过回归分析深度理解语义，更好的表达各个文本的段落信息，帮助提高文本表示的准确性，以实现更加准确的关键词提取，进一步通过清洗及校正处理，使生成的标签集合更加准确，实现课程标签的自动生成。本发明还涉及区块链技术，涉及到的模型可存储于区块链。一种使用电子装置产生课程标签的方法(权利要求)。所涉及的模型被存储在块链中。所述方法包括：响应于所述课程标签生成指令，根据所述课程标签生成指令来获取(S10)待处理课程数据。 提取处理对象过程数据中的声音(S11)作为处理对象声音。 对要处理的语音进行语音识别以获得第一文本数据。 基于LSTM-卷积神经网络(CNN)-注意算法翻译(S15)图像数据以获得第三文本数据。 基于来自变压器(BERT)模型的双向编码器表示来提取(S16)第三文本数据的关键字，以构造第二关键字集。 计算(S17)第一关键字集和第二关键字集的交集作为第三关键字集。 对第三关键字组执行(S18)清洁和校正处理，以获得待处理过程数据的目标标签组。独立的权利要求书被包括在以下内容中： 生成课程标签的装置； 以及 一种存储用于生成课程标签的程序的计算机可读存储介质。  12
本申请公开了一种音频流降噪方法、装置、设备及存储介质，该方法包括：针对待降噪的音频流的每一帧的音频数据：将其转换成频域数据，得到原始频谱数据；将原始频域数据输入至训练后的噪音识别模型，得到残差频谱数据；将原始频谱数据减去残差频谱数据，得到该帧的目标频谱数据；根据该帧的目标频谱数据，以及该帧的上一帧的目标频谱数据，获取该帧的目标音频数据；其中，该噪音识别模型为以带噪频谱数据作为训练样本、以噪音频谱数据作为样本标签训练得到。本申请在音频流的降噪处理过程中，以帧为单位实时地对每一帧数据进行处理，并结合上一帧的处理结果得到当前帧的降噪后的目标频谱数据，能够很好地处理直播等场景的音频流降噪问题。一种用于移动终端音视频应用的音频流降噪方法。音频流的音频流降噪处理过程以帧为单位实时处理每一帧数据， 结合前一帧的处理结果，得到当前帧降噪的目标频谱数据，可以很好地处理直播场景的音频流降噪问题。 将音频数据转换为频域数据，并将原始频谱数据输入到训练好的噪声识别模型以获得剩余频谱，从而能够降低音频数据中的噪声。该方法包括将帧的音频数据转换为频域数据。 获得原始光谱数据。 将原始频域数据输入到训练好的噪声识别模型中，得到剩余频谱数据。 从原始频域数据中减去剩余频谱数据以获得该帧的目标频谱数据。 根据所述目标频谱数据和所述目标频谱数据的最后一帧，从所述帧中获取所述目标音频数据。 对噪声谱数据执行噪声识别以训练训练样本。独立的权利要求书包括： 1. 一种具有频谱数据获取单元的音频流降噪装置。 2一种用于存储计算机程序的存储介质。 3
本发明提供了一种基于AIGC技术的文旅产品直播营销系统，包括分析模块、直播内容生成模块、直播界面、交互模块、观众信息收集模块、数据库；所述分析模块用于分析直播间观众的偏好产品和库存文旅产品得出直播间的文旅产品的可动营销序列；所述直播内容生成模块包括直播文案生成单元，所述直播文案生成单元用于基于AIGC学习模型和所述可动营销序列生成本次直播需要进行营销的文旅产品的营销文案。本发明通过计算得到暂定营销序列，通过AIGC技术生成相关的直播内容，并通过实时生成可动营销序列对暂定营销序列进行替换，从而让直播内容更加契合直播间观众的喜好程度，有利于提高直播营销的营销效果以及减少人力资源消耗。基于AIGC技术的文化旅游产品直播营销系统，用于节目的直播。 可用于事发现场的开发过程中。该系统通过计算得到试探营销序列，通过AIGC技术生成相关的直播内容，并通过实时生成可移动营销序列替换试探营销序列，从而能够生成适合直播中观众偏好程度的内容，因此提高了直播营销的营销效果，降低了人力资源消耗。该系统具有分析模块，用于分析直播间中观众的偏好产品。 直播内容生成模块，设置有直播文本生成单元、直播视频生成单元和直播语音生成单元。 直播文本生成单元，基于AIGC学习模型和可移动营销序列生成本次待营销文化旅游产品的营销文本。 一个交互模块实现人机交互功能。 观众信息采集模块，采集当前直播中观众的购物相关信息。 数据库，存储所述文化旅游产品的相关信息和每次直播的营销记录。 1
本发明公开了基于学习策略的预训练模型微调方法及系统，属于深度学习及迁移学习技术领域，要解决的技术问题为如何对深度网络模型对应的预训练模型进行微调。包括如下步骤：给定一个源任务的预训练网络模型，以及一组在目标域中具有相关标签的样本实例；构建决策网络，决策网络的输入为样本特征，输出为样本的迁移学习，对于预训练模型的每一层，规则网络用于根据样本实例决定当前层使用预训练网络模型的原始参数、还是使用预训练网络模型的微调参数；对于决策网络，基于样本实例、通过Gumbel Softmax采样方法来训练策略网络，进行测试时，训练后的策略网络决定来自一个层的特征是使用源预训练参数还是微调参数进入下一层。基于不同下游任务学习策略的网络预训练模型微调整方法。该方法能够实现深度网络模型对应的预训练模型的微调。该方法涉及给出源任务的预训练网络模型，获得目标领域的一组带有相关标签的样本实例。 基于采样结果构建决策网络。 形成所述决策网络的输入作为样本特征，用于输出所述样本针对所述预训练模型的每一层的迁移学习。 所述规则网络用于根据所述样本实例利用所述预训练网络模型确定当前层的原始参数，或者利用所述预训练网络模型的微调参数确定当前层的原始参数。 基于训练后的决策网络的样本示例，通过用于决策网络的Gumbel Softmax采样过程来训练策略网络。 确定检查该层的特性是使用源预训练参数还是在训练之后由策略网络微调到下一层中的参数。还包括基于学习策略的预训练模型微调整系统的独立权利要求。  11
本发明公开了一种基于平衡权重稀疏和GroupLasso正则化的自适应DNN压缩方法，属于模型压缩领域。该方法根据要满足的模型推理速度要求和模型部署时的存储大小限制，从而完成DNN的自适应模型剪枝。本发明结合多种剪枝方法并面向实时嵌入式系统对模型进行剪枝，主要包括以下步骤：引入模型参数，添加正则项定义模型优化问题，预训练神经网络模型，然后针对预训练模型的全连接层进行平衡权重稀疏剪枝，针对平衡权重稀疏剪枝后的模型卷积层进行结构化剪枝和节点剪枝，最后根据是否满足约束选择迭代剪枝或者结束剪枝得到压缩后模型。基于平衡权稀疏和群套索正则化的自适应深度神经网络(DNN)压缩方法。该方法结合了平衡权重稀疏剪枝、滤波剪枝、通道剪枝和节点剪枝四种剪枝方法，与单一剪枝方法相比，具有更大的求解空间，在保证网络正确率的前提下获得更高的模型压缩空间，从而实现更高的推理加速。该方法涉及构建神经网络每层权值矩阵的集合，加入正则项定义模型优化问题，对神经网络模型进行预训练。 将权重稀疏惩罚正则项加入损失函数中，对全连接层进行权重稀疏。 对所述预训练模型的全连接层进行所述平衡重稀疏修剪。 对所述平衡权重稀疏剪枝后的模型卷积层进行结构化剪枝和节点剪枝。 提高了模型的准确性。 确定是否满足模型推理速度和模型大小的约束。   4
本发明提供一种基于Bert的双通道Attention模型的文本情感分析方法，涉及人工智能技术领域，包括：对文本数据集进行预处理，并通过Bert模型转化为词向量；将词向量分别输入BiLSTM模型和BiGRU模型提取文本的全局特征信息和局部特征信息；将全局特征信息和局部特征信息分别输入注意力层，注意力层通过配置情感词的权重分值分别对全局特征信息和局部特征信息进行优化，得到全局特征向量和局部特征向量；融合全局特征向量和局部特征向量，输入全连接层；将全连接层的输出结果输入softmax层进行情感分类，得到情感分类结果。本发明充分挖掘文本的深层语义信息，提高了情感分类的准确率。基于Bert的双通道模型文本情感分析方法。该方法能够充分挖掘文本的深层语义信息，增加情感分类准确率。该方法涉及处理文本数据集。 通过使用双向编码器表示来自变换器(Bert)模型将文本数据集转换成词向量。 将词向量输入双向长短时记忆(BiLSTM)模型。 提取文本的全局特征信息和局部特征信息。 将所述全局特征信息和所述局部特征信息输入注意力层。 所述注意力层通过配置情感词的权重分数对所述全局特征信息和所述局部特征信息进行优化，得到全局特征向量和局部特征向量。 将所述全局特征向量和所述局部特征向量融合在一起。 将全连接层的输出结果输入softmax层进行情感分类运算，得到情感分类结果。  12
本发明具体地涉及使用诸如U‑net卷积神经网络的卷积神经网络来重建显微镜图像例如相衬显微镜图像的系统和方法。根据本发明的方法包括以下步骤：获得包括多个明视野显微镜图像和多个相衬显微镜图像的训练数据集，基于该数据集来训练神经网络，以从多个明视野显微镜图像中的每个明视野显微镜图像中提取呈干涉图案形式的相位信息，并且进一步使用所训练的神经网络来根据明视野显微镜图像重建相衬显微镜图像。根据本发明的系统包括存储器装置、处理装置、存储和检索装置以及显示装置。存储器装置存储数据集，处理装置基于该数据集来训练神经网络，并且进一步使得能够重建相衬图像。用于处理生物、医学和地质科学中的显微图像的明场图像到相衬图像转换方法。卷积神经网络被训练以顺序地更新参数，以使输入的明场显微图像与重建的相差显微图像相匹配，因此提供了一种简单得多、成本有效且快速的方式来将明场图像转换为相差图像。 该方法消除了与明视场显微镜图像相关联的干扰问题，提高了输入图像的质量。明场图像到相差图像的转换方法包括获得包括明场显微镜图像和相差显微镜图像的数据集。 利用所述数据集训练卷积神经网络，以从每个所述明场图像恢复出干涉图案形式的相位信息。 应用经训练的神经网络从明场显微图像重建相差显微图像。 通过最小化明场图像和重建图像之间的像素方面的平方差和来顺序地更新网络的参数。 更新参数以匹配图像。本发明还涉及一种用于将明场图像转换为相衬图像的系统。   4
本公开提供了生成式大语言模型训练方法、基于模型的搜索方法，涉及生成式模型、智能搜索等人工智能技术领域。该方法包括：基于用户查询文本与匹配的包含有接口调用指令的输出结果，构建第一训练集；利用第一训练集对预训练好的第一生成式大语言模型进行有监督微调训练，得到第二生成式大语言模型；基于相同用户查询文本与不同候选输出之间的用户偏好排序和预设模板集合，构建第二训练集；利用第二训练集对预训练好的第三生成式大语言模型进行有监督训练，得到奖励模型；将第二生成式大语言模型，基于奖励模型返回的得分，以强化学习方式进行训练。利用据此训练得到的生成式大语言模型可显著提升搜索场景下的搜索结果准确率和用户体验。用于通过使用例如聊天生成预扫描(Chat Generative Pre-Scan)的电子设备来训练生成型大型语言模型的方法。该方法能够明显提高搜索场景下的搜索结果准确率和用户体验。 该训练方案使得训练的目标生成类型大语言模型具有深入理解用户需求并自动构建相应的接口调用指令以查询返回的准确答案的能力，其能够根据自然语言输入和大模型参数中包含的知识生成自然语言输出，但使用用于提供专业能力的应用程序接口来调用相应的函数，并且在奖励模型的作用下，使得返回结果更加符合用户的实际需求和预期。该方法包括：基于用户查询文本的输出结果构建第一训练集，并进行包括接口调用指令的匹配。 服务接口由接口调用。 基于用户偏好排序和预设模板集构建第二训练集。 对第三代类型大语言模型进行训练，得到奖励模型。 基于所述奖励模型返回得分，以强化学习的方式进行训练，得到所述目标代类型大语言模型。 得到输出结果。 基于所述用户查询文本和所述匹配的输出结果组成的样本对构建所述第一训练集。独立权利要求包括：(1)基于所生成的大型语言模型的搜索方法； (2)生成型大型语言模型训练装置； (3)一种基于生成型大型语言模型的搜索装置; (4)一种非暂态计算机可读存储介质，包括用于通过使用电子设备来训练生成型大型语言模型的指令集； (5)—种计算机程序产品，包括用于通过使用电子设备来训练生成型大型语言模型的指令集。  11
本发明公开了一种图像处理模型的构建方法、装置、终端及可读存储介质，方法包括：获取基于卷积神经网络的预训练模型；对预训练模型进行迁移学习，以构建目标模型；其中目标模型包括输入层和至少一个卷积层；获取当前的待处理图像的通道数，并将输入层的输入数据中图像通道数配置为待处理图像的通道数；将最接近输入层的卷积层作为目标卷积层，将经输入层的配置后输入数据输入至目标卷积层；根据预训练模型，将目标卷积层对应第一权重中的输入通道数配置为待处理图像的通道数。这样，基于预训练模型可构建一个目标模型，保证了输入的待处理图像的通道数的数据的完整性，使得目标模型能够针对不同的待处理图像的通道数进行适应性调整和处理。图像处理模型构建方法。可以基于预训练的模型构建目标模型，保证了待处理图像的输入通道号的数据的完整性，从而可以针对待处理图像的不同通道号对目标模型进行自适应调整处理。该方法包括获取基于卷积神经网络的预训练模型。 对所述预训练模型进行迁移学习，以构建目标模型。 目标模型包括输入层和一个卷积层。 获取所述待处理图像的当前通道数。 提供输入层的输入数据中的图像通道的数量为待处理图像的通道的数量。 层的卷积层作为目标卷积层。 将所述输入层提供的输入数据输入至所述目标卷积层，根据所述预训练模型。 提供权重中的输入通道数作为待处理图像的通道数。独立权利要求包括如下：一种图像处理模型构建装置； 端子； 以及可读存储介质。   4
本发明公开了一种无源无监督域适应图像分类方法，使用源域图像及其标签训练一个源域预训练模型，并使用该预训练模型初始化一个目标模型；使用初始化的目标模型计算目标域图像的模型结构级别和数据结构级别的预测分数，将二者结合作为目标域样本的置信分数，并用于目标模型的交叉熵损失加权，引入信息最大化损失来辅助目标模型训练；将目标域样本的图像、伪标签、置信分数混合；计算双分类器的确定性差异距离用于目标模型的最大最小化训练；最后训练模型，计算相应损失并依次迭代更新优化相应的模型参数，从而明确地识别一些不确定分类的目标样本，再引入权重混合策略来充分利用目标域知识，进一步提高目标域分类准确率。被动非监督域自适应图像的分类方法。被动无监督域自适应图像分类方法涉及通过使用源域图像和标签训练源域预训练模型，并初始化目标模型，因此提高了目标域分类精度。被动无监督域自适应图像分类方法涉及使用源域图像和标签训练源域预训练模型。 用于对所述源域预训练模型进行训练的特征提取器和双分类器。 初始化所述目标模型，以进行目标领域样本的标识训练。 利用初始化后的所述目标模型计算所述目标样本的模型结构级别的预测分数。 对所述目标模型进行整体训练过程。 相应的模型参数被迭代地更新和优化。 模型的训练过程持续迭代交替进行，完成训练目标模型的训练，以最终对目标领域样本进行分类。 14
本发明提出一种小样本场景下的自然语言理解方法，所示方法提出预训练模型语言语义表示、意图识别和槽位识别、引入标签语义，使用线性空间映射方法拉远语义表示距离、建立门控网络并融合槽信息和意图信息以及运用抽象标签转移概率来达到在不同领域中也能快速学习理解的目的；本发明的方法能够在小样本的场景下更好的判断出问题的意图，并识别出问题的槽位，从而良好的解决任务型对话系统的自然语言理解任务下数据不足、数据标注成本和模型迁移代价过高的问题。小样本场景自然语言理解方法。该方法使得能够以简单的方式实现小样本场景自然语言理解过程，因此降低了数据标记成本和模型迁移成本。该方法涉及引入预训练语言模型来表示文本。 在不同层之间建立注意力机制。 层的语义表示向量被加权。 生成最终表示向量。 上下文用于消除歧义。 分析问句，所述问句包括意图标识和槽位标识。 建立门控网络。 得到融合时隙信息和意图信息。 学习抽象标签转移概率。 抽象标签转移概率在不同的领域进行扩展。  11
本发明公开了一种基于BERT的深度神经网络模型的自动评卷方法，在编码答案文本的微调BERT模型之上，构建一个语义细化层来细化BERT输出的语义，为BERT模型的隐藏状态提取相关的局部上下文。其次，引入一个多头注意力来融合从BERT输出中提取的全局上下文和局部上下文，作为学生答案和参考答案的句子对的最终表示。再者，本发明为简答题自动评卷提出了一种三重热点的策略，它将标准交叉熵损失函数中的计算标签从单独热点黄金分布改进为三重热点黄金分布。通过本发明实现端到端的简答题自动阅卷，以更有效的方法解决简答题自动评卷问题。用于基于来自变换器的双向编码器表示(BERT)自动评估深度神经网络模型的方法。该方法能够提供三重热点的策略进行答题自动评价，将标准交叉熵损失函数中的计算标签从个体热点分布改进为三重热点分布，实现了端到端的简单答题的自动审核，有效地解决了答题自动评分的问题。该方法包括将输入序列发送到BERT编码层中进行处理。 双向长短时记忆(Bi-LSTM)网络被用作BERT编码层的输出OBERT以提取精细全局上下文。 得到简单答案问题的连接语义表示。 多头注意力用于聚焦不同位置的信息。 执行最大池操作。 得到简单答题卡的最终语义表示。 计算评估区间的预测概率。 实施训练以最小化训练学生答案的丢失错误。  12
本发明公开了基于BERT‑BiLSTM‑GAM‑CRF的网络安全实体识别方法，本发明利用预训练的BERT模型获取上下文信息得到每个单词的表示向量，输入到BiLSTM后对单词序列进行编码获得更加全局和上下文感知的特征表示，而GAM是基于BiLSTM的输出进一步提取关键的上下文表示，减小不相关的上下文影响，CRF能够考虑当前标签状态与上下文之间的依赖关系，从而得到更加准确的标注结果。用于识别基于双向编码器表示的网络安全实体的方法，所述双向编码器表示来自变压器-全局注意机制-条件随机场(BERT-BiLSTM-GAM-CRF)。该方法利用预先训练好的BERT模型获取上下文信息得到每个词的表示向量，输入到BiLSTM后对词序列进行编码得到更加全局和上下文感知的特征表示，GAM根据BiLSTM的输出进一步提取减少无关上下文影响的关键上下文表示。 CRF考虑了当前标签状态与上下文的依赖关系，得到更准确的标注结果。网络安全实体识别方法涉及获取数据集文本数据。 提取文本特征。 对双向长短期记忆(BiLSTM)网络的输出执行加权池。 通过条件随机场(CRF)解码将每个字的特征向量映射到标签序列。 标记并输出处理结果。 所述数据集设置有第一数据集和第二数据集。 所述第一数据组与所述第二数据组连接。  12
本发明公开了一种基于生成数据分布对齐的预训练模型调优方法，包括：获取用于在下游任务训练预训练模型的真实图像标签文本、真实图像数据集和类别一致的生成图像数据集；利用真实图像标签文本、真实图像数据和生成图像数据对预训练模型进行训练，优化目标是真实图像特征与文本特征之间的交叉熵优化损失，生成图像特征与文本特征之间的交叉熵优化损失和真实图像特征与生成图像特征之间的Kullback‑Leibler散度损失之和最小；利用训练好的模型输出给定图像分类任务的预测结果。本发明的方法适用于小样本图像识别和新颖类别图像识别等任务，能够帮助预训练模型在更少地损失泛化能力的条件下，利用更少的数据资源迁移到下游任务中，获得更稳健的效果。基于生成数据分布对齐的预训练模型优化方法。该方法适用于小样本图像识别、novel type图像识别等任务，帮助预训练模型在损失较少泛化能力的情况下，利用较少的数据资源向下游任务转移，从而获得更稳定的效果。该方法涉及为下游任务训练预训练模型获取(S1)真实图像标签文本、真实图像数据集以及与真实图像数据集类型一致的生成图像数据集。 使用所述真实图像标签文本、所述真实图像数据和所述生成图像数据训练所述预训练模型(S2)。 图像编码器，用于基于所述预训练模型的文本编码器，对所述实景图像标签文本、所述实景图像数据和所述生成图像数据进行编码，得到所述文本特征、所述实景图像特征和所述生成图像特征。 将优化目标确定为实景图像特征和文本特征之间的交叉熵优化损失。 基于所述优化目标对所述预训练模型进行训练(S3)。 训练后的模型用于输出给定图像分类任务的预测结果。  11
本发明提出一种增强训练人工智能模型的优化方法，包括步骤依次为：获得原始数据组和预训练模型、利用三级的梯度优化生成方法以及变换算法函数生成两个对抗样本组、生成两个混合攻击样本组和进行差异性训练，直到获得防御性能符合要求的识别模型。本发明通过采用三级的梯度优化方法并结合变换算法函数可以生成攻击能力较强的两个对抗样本组，其中一组作为参照而另一组作为可进化的增强组，再加上预训练模型与对抗样本的关联度增强，大大提高对抗样本的攻击能力，有利于在差异性训练中获得防御性能较高的防御模型，最终达到人工智能模型增强训练的目的，设计合理，有利于高效获得防御等级较高的模型，适合大规模推广。该方法对于优化增强训练人工智能模型是有用的。方法：采用三级梯度优化方法，结合变换算法函数； 提高了对样品的攻击能力； 有利于获得差异化训练中具有较高防御性能的防御模型； 达到人工智能模型增强训练的目的； 合理，有利于高效获得更高防御水平的模型； 适合大规模推广。一种增强训练人工智能模型的优化方法，包括：基于待训练的神经网络模型获取样本特征提取的原始数据集； 训练识别模型的无阻力训练， 采用三级梯度优化生成过程生成电阻样本组， 利用预训练模型作为变换算法函数中变换概率的参数，调整梯度优化生成算法的迭代步长，得到变换算法中的变换概率Is。  11
本发明涉及一种基于迁移学习的晶粒图像分割方法及系统，涉及金属材料微观组织分析技术领域，主要包括以下步骤：S01，获取材料晶粒图像，对所述晶粒图像采取滤波的方式进行预处理；S02，采用改进的U‑net网络对所述晶粒图像进行分割；S03，对所述晶粒图像进行晶粒边界修复。本发明通过采用滤波图像预处理技术，消除了材料微观组织图片的采集与制作过程中的噪声干扰，提高了图像质量；采用基于same卷积的改进的U‑net网络算法对晶粒图像进行分割，采用孔洞填充，骨架提取和一种基于8邻域检测的断裂边界连接和伪晶界删除方法，消除了原图片中已存在的黑色噪声区域，解决了部分晶界存在断裂情况和部分晶界并不洁净的问题，从而提取出了准确清晰的晶界。面向金属材料显微组织分析技术的基于迁移学习的晶粒图像分割方法。该方法能够利用滤波图像预处理技术消除材料微组织图片采集和制作过程中的噪声干扰，提高图像质量，从而提高分析效率和分析精度，实现自动化和智能化分析。该方法包括获得材料晶粒图像。 通过滤波对晶粒图像进行预处理。 采用改进的U-net网络对谷物图像进行分割。 对所述晶粒图像进行晶界修复。 得到材料晶粒扫描电镜图样品。 得到高斯滤波的晶粒图像样本。 将二值化图像作为标签图像用于训练网络模型。包括以下独立权利要求：一种基于迀移学习的谷物图像分割系统； 存储用于基于迁移学习来分割谷物图像的程序的存储介质； 以及一种计算机设备。   6
本发明公开了一种基于BERT‑BLSTM‑RPEA‑LSTM的语义槽填充与意图检测联合方法，包括如下步骤：S1、构建一个由共享网络及两个分类网络组成的模型框架；S2、对S1所述的模型进行训练，更新除词嵌入层以外整个网络模型的参数，得到语义槽填充与意图检测模型；S3、基于S2所述语义槽填充与意图检测模型，实现对待检测对话文本句子中语义槽的填充和意图的检测。本发明可在不增加较多计算量的前提下会自动找到两个任务之间的平衡，获得更好的整体性能。基于BERT-BLSTM-RPEA-LSTM的语义凹槽填充与意图检测联合方法应用于个人语音助理和智能航空咨询领域。可以在不增加大量计算量的前提下，自动找到两个任务之间的平衡，从而获得更好的整体性能。 对Adam优化器调整模型中的参数进行迭代优化，减少损失，提高目标预测的精度。该方法包括构建由共享网络和两个分类网络组成的模型框架，该模型包括词嵌入层、编码器层、RPEA机制和解码双任务分类层。 共享网络由BERT-BLSTM-RPEA-LSTM组成。 两个分类网络分别对应神经网络时隙填充和意图检测的前馈。 对模型进行训练。 计算模型输出得到的两个预测向量和真实值的误差的损失。 对整个网络模型除词嵌入层外的参数进行更新。 得到语义凹槽填充及意图检测模型。 基于语义槽填充及意图检测模型，根据从对话系统中获取的待检测对话文本句，实现对待检测对话文本句中语义槽的填充及意图的检测。  12
本发明公开了一种融合预训练语言模型和图谱的变压器设备健康度评价方法，包括：对实时及历史运行评价数据分别对应处理得到实时和历史告警文本；构建动态状态评价模型；基于历史告警文本根据识图谱构建框架构建知识图谱；基于历史告警文本和动态状态评价模型训练得到电力短文本匹配模型；基于知识图谱构建框架提取实时告警文本的实体和属性信息；基于实时告警文本匹配动态状态评价模型和电力短文本匹配模型进行语义相似度匹配从而得到应扣分值；查询知识图谱确定应扣分值，并根据应扣分值和扣分系数计算更新健康度分数；采用改进mT5进行知识图谱构建，且采用了改进BERT+CoSENT进行文本匹配，通过告警触发的量化扣分机制来动态评价健康度。结合预训练语言模型和地图的变压器设备健康度评估方法。该方法采用改进的mT5构建知识图谱，采用改进的双向编码表示(BERT)+共发送匹配文本，通过报警触发的量化推演机制动态评估健康程度。该方法涉及基于mT5大语言模型的知识图谱提取实时告警文本的实体和属性信息。 基于实时告警文本的实体和属性信息匹配变压装置动态状态评估模型，判断是否基于电力短文本匹配模型对实体和属性信息与变压装置动态状态评估模型中的扣除内容进行语义相似度匹配，得到扣除后的数值。 基于实时告警文本的实体和属性信息查询知识图谱，确定实时告警文本对应的部件和部件分式，并根据变压器装置动态评估模型中的扣除值和扣除系数计算更新变压器装置的健康分式。 0
本发明提供了一种融合大语言模型的伪造语音检测方法、系统、设备及介质，涉及语音检测技术领域，通过获取待检测语音；通过预先训练的声学编码模块从待检测语音中提取声学特征序列，并对所述声学特征序列进行处理，得到声学编码序列和音素序列；通过预先训练的大语言模型模块对所述音素序列进行编码，得到音素编码序列；将声学编码序列和音素编码序列输入至预先训练的多模态融合分类模块中，得到语音检测结果。上述方法不仅将声学信息和音素信息进行融合，同时结合大语言模型强大的泛化性与模式识别能力，以使检测方法同时具有强鲁棒性和对于伪造语音类型的强泛化性。融合大型语言模型的伪造语音检测方法，用于检测合成语音或转换系统伪造语音的真假。该方法不仅结合了声学信息和音素信息，而且结合了大语言模型的强泛化性和模式识别能力使得该检测方法对伪造语音类型具有强鲁棒性和强泛化性。该方法涉及获得(101)待检测的语音。 通过预先训练的声学编码模块从所述待检测语音中提取(102)声学特征序列。 对声学特征序列进行处理，得到声学编码序列和音素序列。 通过预先训练的大型语言模型模块对所述音素序列进行编码(103)，得到音素编码序列。 将所述声学编码序列和音素编码序列输入(104)预先训练的多模式融合分类模块，得到语音检测结果。独立权利要求包括以下内容：一种结合大语言模型的伪造语音检测系统； 电子装置； 以及计算机可读存储介质，其存储有融合大语言模型的伪造语音检测程序。 3
本公开提供一种法律知识图谱构建方法及相关设备，该方法包括：通过对法律法规的法律内容进行分类，确定一级节点和二级节点，基于与每个所述二级节点相关联的法律法规，构建以该二级节点为根节点的子图谱；对所述子图谱的节点分别进行聚合计算和相似度计算，重构所述子图谱；基于所述一级节点、所述二级节点和经过重构的所述子图谱构建初始法律知识图谱；基于法律知识相关文件通过实体抽取得到游离节点；将所述初始法律知识图谱的节点作为第一类别标签，通过经过预训练的第一多类别分类模型对所述游离节点进行分类，并将所述游离节点关联到所述初始法律知识图谱的相应节点上，以得到所述法律知识图谱。利用电子设备构建法律知识图谱的方法(权利要求书)。所述法律知识图谱构建方法包括对法律法规的法律内容进行分类，并基于与每个第二级节点相关联的法律规则确定第一级节点和第二级节点，从而保证了简单高效的法律知识图谱构建方法。方法涉及对法律法规的法律内容进行分类。 确定第一级节点。 基于第一级节点确定根据相关法律和法规的次级节点。 基于与次级节点中的每一个相关联的法律和规定来构建子映射。 对所述子地图的节点进行聚合度计算和相似度计算。 构建初始法律知识图谱。 根据法律知识相关文件，通过实体抽取得到自由节点。 将所述初始法律知识图谱的节点作为第一类标签。 所述自由节点通过预训练后的第一多类分类模型对所述自由节点进行分类。 将所述自由节点与初始法律知识图谱的对应节点进行关联，得到所述法律知识图谱。独立权利要求还包括用于：一种利用电子设备构建法律知识图谱的装置； 以及一种非暂态计算机可读存储介质，包括用于利用电子设备构建法律知识图谱的指令集。  11
本公开提供了一种预训练语言模型的训练方法、装置、计算机设备和介质。该方法包括：获得使用不同语言表达相同语义的训练数据组合；将训练数据组合输入具备不同语言理解能力的预训练语言模型，以使得预训练语言模型对训练数据组合进行预训练后得到训练数据组合对应的输出数据组合，并根据输出数据组合计算训练数据组合的损失值；利用损失值更新预训练语言模型的模型参数，以提高输出数据组合的相似度。本公开提高了低资源语言场景下自然语言处理模型处理下游任务的性能和多语言场景下预训练语言模型所能适用的下游任务的种类范围。预训练语言模型训练方法。该方法能够处理下游任务性能和针对下游任务的类型范围的多语言场景预训练语言模型，并利用模型参数更新单元使用损失值来更新模型的模型参数，以提高输出数据组合的相似度。该方法包括：获取用于以不同语言表达相同语义的训练数据组合。 将所述训练数据组合输入至预先训练的具有不同语言理解能力的语言模型中，以使所述预先训练的语言模型对所述训练数据组合进行预训练，得到所述训练数据组合对应的输出数据组合。 根据所述输出数据组合计算所述训练数据组合的损失值。 利用所述损失值更新所述预先训练的语言模型的模型参数，以提高所述输出数据组合的相似度。包括独立权利要求：(1)一种预训练语言模型训练设备； (2)一种计算机设备，包括存储器和处理器，以执行预训练语言模型训练方法； 以及(3)用于存储计算机可执行代码以执行预训练语言模型训练方法的计算机可读介质。  11
本申请公开了一种播报内容的生成方法、装置、设备、介质及程序产品，涉及人工智能领域。该方法包括：获取第一预训练模型、第一样本数据和第二样本数据，第一预训练模型是通过多个领域的样本数据预训练得到的文本生成模型，第一预训练模型的模型参数中包括第一参数；向第一预训练模型配置待训练的第二参数；通过第一样本数据对第一预训练模型中的第一参数进行训练，得到第二预训练模型；通过第二样本数据对第二预训练模型中的第二参数进行训练，得到播报内容生成模型；其中，播报内容生成模型用于对输入的目标游戏状态进行内容预测，得到目标播报内容。该方法加快了整体的播报内容生成流程，提升了播报内容的生成效率。在人工智能(AI)中使用的生成广播内容的方法。该方法加快了整个广播内容生成过程，提高了广播内容的生成效率。 播放内容生成模型，用于对输入的目标游戏状态的内容进行预测，得到目标播放内容。该方法包括获得(210)第一预训练模型、第一样本数据和第二样本数据。 所述第一预训练模型的模型参数包括第一参数。 所述第一样本数据和所述第二样本数据为从所述游戏领域获取的样本数据。 样本数据包括游戏状态和播放内容资料对应的数据对。 将所述第二待训练参数配置(220)至所述第一预训练模型。 利用第一样本数据对第一预训练模型中的第一参数进行训练(230)，得到第二预训练模型。 利用(240)所述第二样本数据对所述第二预训练模型中的第二参数进行训练，得到播放内容生成模型。 广播内容生成模型，用于对输入的目标游戏状态进行内容预测，得到目标广播内容。 目标播报内容用于在目标游戏处于目标游戏状态时进行语音播报。包括以下独立权利要求：1。 广播内容生成装置； 2. 计算机装置； 3. 存储用于生成广播内容的方法的程序的计算机可读存储介质； 以及4。 一种用于生成广播内容的方法的计算机程序产品。  11
本说明书实施例提供了用户识别方法及装置，其中，一种用户识别方法包括：基于目标行业的特征关键词，获取待识别用户的多笔交易数据；根据交易数据和预设提示模板生成输入数据，输入预训练的商品分类模型，得到交易数据对应的商品分类结果；商品分类结果中包括表征交易数据中的商品是否属于目标行业的关联商品的预测值；根据交易数据的商品分类结果，确定待识别用户是否属于目标行业。用户身份识别方法。该方法通过基于目标行业的特征关键词获取待识别用户的多交易数据，并根据交易数据和预设提示模板生成输入数据，保证了用户识别过程简单高效。该方法包括基于目标行业的特征关键词获取待识别用户的多交易数据。 根据所述交易数据和预设的提示模板生成输入数据。 输入预先训练的商品分类模型，得到所述交易数据对应的商品分类结果，所述商品分类结果包括表示所述交易数据中的商品是否属于所述目标行业的关联商品的预测值。 根据所述交易数据的商品分类结果判断所述待识别用户是否属于所述目标行业。包括独立权利要求用于：(1)用户识别设备; 和(2)用于存储用于执行用户识别的指令集的存储介质。  11
本发明公开了一种企业业务数据分词权重优化方法、智能匹配方法及系统，采用Jieba进行分词并融合了符号分词结果，基于BERT进行分词结果的嵌入式表示。考虑到词向量本身具有的稠密特性和高维特性，采用余弦相似度算法来度量文本的相似性，鉴于文本的分词结果中存在的帕累托现象，提出了一种考虑采用帕累托原理初始化权重的不定粒子群算法，增强文本匹配能力，实现输入关键字与数据库中企业核心业务特征的有效匹配。本发明方法使用户能够根据自己熟悉或有合作意向的核心业务关键词，准确高效地挖掘出相关企业。进行企业业务数据分词权重优化的方法。该方法使得用户能够根据熟悉或具有合作意图的核心服务关键词，准确高效地挖掘相关企业。 提高了企业服务数据与输入关键词的语义匹配准确率。该方法包括对数据集中的每个数据的字数进行计数。 构造字数集合C。 数据集由多个企业服务数据组成。 对集合C中的每个元素总结出Q个不同服务类型的关键词作为输入词，从数据集中分别获取与输入词匹配的N个匹配结果，并将匹配结果按照匹配度排序。 对词权重进行初始化。 将初始化后的权值作为初始化粒子位置随机初始化粒子的速度v。 计算每个粒子的适应度值。 适应度值用于更新粒子速度和位置。 重新计算每个粒子的适应度最优值。 得到种群的最优适应度值。 判断条件是否满足，如果满足，则输出字数作为权重优化结果。独立权利要求包括：(1)一种企业智能匹配方法； (2)终端设备； 以及(3)计算机可读存储介质。  12
本发明是关于一种基于互联网社区的文本相似度确定方法及装置，方法包括：对互联网社区的海量语料库进行分词处理，得到分词后的语料库；统计分词后的语料库中每个词语对应的逆文档频率；根据每个词语对应的逆文档频率，计算同一帖子下每个评论文本对的第一分词向量和第二分词向量之间的第一相似度；根据第一相似度所属的目标相似度区间，按照预设比例采集评论文本对，组成标注集，并对标注集进行二次标注；对二次标注后的相似评论文本对进行数据增强处理，得到数据增强后的数据集；利用预设的Bert模型和数据集进行循环迭代训练，以得到目标文本相似度确定模型；利用目标文本相似度确定模型确定目标帖子下的任意评论文本对之间的相似度。一种数据处理领域的基于互联网社区的文本相似度确定方法。本发明解决了相似文本数据集构建困难，评分率低，常规计算文本相似度算法无法计算语义相似度，无法区分词序等问题。该方法包括对互联网社区的海量语料库执行(S111)分词以获得分词后的语料库。 计数与分段语料库中的每个词相对应的逆文档频率(S112)。 根据与每个单词对应的反文档频率，计算(S113)在同一文章下每个评论文本对的第一段向量和第二段向量之间的第一相似度。 按照预定比率收集评论文本对(S114)以形成标签集，并且对标签集执行二次标记。 在辅助注释之后，对相似注释文本对执行(S115)数据增强处理。 确定(S116)模型以获得目标文本的相似性。 通过使用目标文本相似度确定模型来确定(S117)目标文章下的任意一对评论文本之间的相似度。本发明还涉及一种基于互联网社区的文本相似度确定装置。  11
本发明公开了一种基于时序生成对抗网络的PMSM匝间短路诊断方法，首先，选用长短时记忆网络作为生成器搭建时序生成对抗网络，用来扩充样本，然后，在时序生成对抗网络的生成器的底层添加softmax层构建长短时判别网络，最后，使用长短时判别网络分别故障类型。该方法包括以下步骤：1)采集不同程度故障的电流信号组成真实数据集；2)构建时序生成对抗网络；3)将正常情况下的电流信号输入时序生成对抗网络进行预训练；4)将3)中的预训练模型迁移到故障数据上并进行样本扩张；5)在训练好的时序生成对抗网络的生成器底层加入softmax层来构建长短时判别网络；6)使用长短时判别网络进行故障类型的分类。经实验验证，该方法针对时序信号有更高的准确度。用于军工和航空航天领域的基于时序生成对抗网络的永磁同步电机匝间短路诊断方法。该方法使得能够利用长时短时的判断网络对经过实验验证的故障模式进行分类，使得该方法对于时序信号具有更高的准确性。该方法以十千赫的采样频率采集不同匝间短路程度的三相永磁同步电机的定子电流信号作为真实数据集。 构建时间序列生成对抗网络模型作为预训练模型。 当生成器和仲裁器达到纳什平衡时，训练完成。 得到长短时判断网络模块。 通过使用经训练的长度将故障模式模块的分类确定到测试集。   6
本申请实施例提供了上下位关系获取方法、装置、电子设备及存储介质方法，该方法包括：从多个数据对中获取目标数据对，数据对包括：第一对象、第二对象，目标数据对包括：目标第一对象、目标第二对象；将目标数据对输入到上下位关系判断模型中，得到指示目标第一对象与目标第二对象是否具有上下位关系的第一判断结果，上下位关系判断模型被配置为：利用预训练语言模型生成目标第一对象与目标第二对象之间的关系型表示；利用图神经网络基于预设图，生成目标第一对象的结构型表示和目标第二对象的结构型表示；基于关系型表示、目标第一对象的结构型表示、目标第二对象的结构型表示，生成目标数据对的目标表示，基于目标表示，生成第一判断结果。本方法用于获取对象之间的上下关系。提高了得到的对象之间的上下关系的准确性。该方法包括从多个数据对中获得目标数据对。 数据对具有第一对象和第二对象。 根据点击次数确定所述数据对中的第一对象与所述第二对象之间的边的权重。 基于预设图生成所述目标第一对象的神经网络结构类型表示。 结构类型表示基于所述目标图形的所述目标第二对象。 生成所述第一目标对象的结构类型表征和所述第二目标对象的结构类型表征。 根据所述目标表征生成第一判断结果。 将所述目标数据对输入上下关系判断模型，生成第一判断结果。包括独立权利要求：(1)上下关系获取装置； (2)电子设备； 以及(3)存储介质。  11
本发明属于医学影像分析技术领域，具体为一种基于双域U‑net判别器的生成对抗低剂量CT去噪方法。本发明以U‑Net判别器来学习正常剂量图像和生成图像在图像域和生成域之间的全局和局部差异；该判别器通过全局输出向去噪网络提供逐像素反馈，通过中间层在语义层面使去噪网络关注全局结构；图像梯度域中应用该判别器，以减轻低剂量CT中的伪影，增强去噪CT图像的边缘；使用CutMix技术使判别器逐像素输出，为放射科医生提供置信度图，以避免可视化去噪结果的不确定性，促进低剂量CT的筛查和诊断；本发明可有效提高去噪低剂量CT的质量，使生成的图像清晰度更高，具有更丰富的边缘并减小伪影的影响，提高医学影像分析过程中的准确度。基于双域U-net仲裁器的抗低剂量CT去噪图像生成方法。该方法能够有效提高低剂量CT去噪质量和医学图像分析精度。 该方法通过U-net的全局输出，仲裁器给去噪网络提供逐像素的反馈，通过中间层在语义层面形成网络兴趣全局结构，减少低剂量CT去噪图像中金属造成的伪影，增强去噪后的CT图像的边缘，为放射科医生提供置信度图，避免视觉去噪结果的不确定性，促进基于CT的筛查和诊断。该方法包括在图像梯度域中应用基于U-net的仲裁器以减少由金属引起的伪像。 一种生成器，用于生成低剂量计算机断层摄影(CT)去噪图像以提高图像质量的抵抗网络。 去噪过程作为学习生成器模型的过程完成。 生成器模型os用于将具有一定尺寸的低剂量CT去噪图像映射到正常剂量CT对应物，以去除低功率CT中的噪声图像。 将所述生成器模型作为去噪模型。 选择低成本CT图像作为输入。 定义梯度域中的鉴别器损失。 一致性损失被引入用于仲裁器的正则化。   6
一种基于生成对抗网络的油藏数值模拟增强方法、系统、设备及介质，方法包括：生成渗透率网格数据及其压力模拟结果并将其划分为训练集数据和测试集数据，将浅层数值特征提取模块、深层数值特征提取模块以及数值重构模块进行融合构建生成器网络模型，构建基于U‑Net结构的用于数值特征解码和编码的判别器网络模型，构建生成对抗网络模型并使用训练集数据对其进行训练，使用训练好的生成对抗网络模型对测试集进行流体压力细网格数据增强；系统、设备及介质，用于实现一种基于生成对抗网络的油藏数值模拟增强方法；本发明具有提取信息充分，模拟速度快，计算成本低，模拟精度高以及通用性良好的优点。用于储层数值模拟的基于生成式对抗网络的储层数值模拟增强方法。信息提取充分，仿真速度快，计算成本低。 仿真精度高，通用性好。该方法涉及构建用于聚合低频数值信息和高频数值信息的数值重构模块。 基于U-Net结构构建鉴别器网络模型，用于数值特征解码和编码。 将生成器网络模型和判别器网络模型相结合，得到完整的增强储层数值模拟的生成对抗网络模型。 利用训练集数据对生成对抗网络模型进行训练，得到训练后的生成对抗网络模型。 对测试集数据进行组合。 将流体压力粗网格数据和渗透率细网格数据输入训练好的生成对抗网络模型，得到增强后的流体压力细网格数据。包括以下独立权利要求：1。 一种基于生成式对抗网络的储层数值模拟增强系统； 2. 一种基于生成式对抗网络的储层数值模拟增强装置； 以及3。 一种计算机可读介质，其存储用于基于生成对抗网络的储层数值模拟的增强程序。   6
本发明提供了一种预训练语言模型的微调方法、装置及计算机可读存储介质，属于自然语言处理技术领域。所述预训练语言模型的微调方法包括：获得一预先训练好的预训练语言模型，确定所述预训练语言模型中每个编码层的梯度阈值；对所述预训练语言模型进行训练，并在所述训练过程中每次更新任一编码层的模型参数之前，计算所述任一编码层的梯度范数；根据所述任一编码层的梯度范数是否小于所述任一编码层的梯度阈值，确定本次是否需要更新所述任一编码层的模型参数。本发明能够在保留预训练语言模型的通用语言知识和训练获得适用于下游任务的模型中取得较好的折中，使得模型能够保留较多的通用语言知识，提高模型的性能。用于在图像处理领域中促进预训练的语言模型微调的方法。 可用于自然语言处理(NLP)中的预训练LMs的领域。该方法能够避免过多的模型参数调整，从而在保留预训练语言模型学习的常用语言知识和获得适合下游任务的模型之间达到很好的折中，使得模型能够保留语言知识，并且能够显著改善模型的性能。该方法涉及获得预训练的语言模型并确定预训练的语言模型中的每个编码层的梯度阈值(S201)。 对语言模型并且在训练过程中执行(S202)训练。 在每次更新任意一个编码层的模型参数之前，计算编码层的梯度范数。 在更新训练过程中的模型参数之前，当层梯度范数小于层梯度阈值时，确定是否需要对编码层模型参数进行更新(S203)。 基于模型参数的梯度来更新模型参数。 各个编码层的序号在从模型的输入层到输出层的方向上依次编号。独立权利要求还包括：一种用于在图像处理领域中促进预训练的语言模型微调的装置； 以及非暂时性计算机可读存储介质，其用于存储用于促进图像处理领域中的预先训练的语言模型微调的方法的指令集。  11
本申请实施例公开了一种模型训练方法、装置、设备及存储介质，属于机器学习技术领域。该方法包括：获取参与节点中的原始数据以及预训练模型；对原始数据处理得到第一增广数据和第二增广数据，第一增广数据和第二增广数据存在特征差异；基于第一增广数据和第二增广数据，调整预训练模型中的模型参数，将调整后的模型参数上报至主节点；接收主节点发送的全局模型参数，将全局模型参数更新至预训练模型得到分类模型。本申请实施例利用存在特征差异的第一增广数据和第二增广数据对预训练模型进行模型参数的调整，利用一个增广数据生成监督信号，来监督另一个增广数据的分类学习，从而实现对分类任务的更快速学习，无需人工标注图像，节省了人力资源。在参与节点中训练模型以实现联邦学习计算的方法。所述方法使得能够利用具有特征差异的所述第一增广数据和所述第二增广数据来调整所述预训练模型的模型参数。 该方法能够利用增广数据产生监控信号来监督其他增广数据的分类学习，从而实现分类任务的快速学习，无需人工标记图像，降低劳动强度。模型训练方法，该方法涉及获得参与节点中的原始数据和预训练模型。 对所述原始数据进行增广处理，得到第一增广数据和第二增广数据。 确定所述第一增广数据与所述第二增广数据之间的特征差异。 基于所述第一增广数据和所述第二增广数据调整所述预训练模型中的模型参数。 将调整后的模型参数报告给主节点。 对所述预训练模型更新全局模型参数，得到分类模型。 所述全局模型参数是所述主节点基于一参与节点上报的用于联邦学习计算的调整后的模型参数得到的。独立权利要求还包括如下：用于在参与节点中训练模型以实现联邦学习计算的装置； 以及一种电子设备，包括处理器和存储器，用于在参与节点中训练模型以实现联邦学习计算； 以及一种计算机可读存储介质，包括用于训练参与节点中的模型以实现联邦学习计算的指令集。  11
本发明适用于计算机领域，提供了一种QA知识库的知识分层编码方法和装置，所述方法包括：使用预训练的BERT模型对低层知识进行编码后，作为L0级知识点；将L0级知识点进行自适应聚类，合并为同类知识点，形成知识簇；通过大语言模型对主要的知识簇进行概念提取，作为L1级知识点；反复迭代上述过程，直至形成包括不同层级的知识点，不同层级的知识点至少包括L2层、L3层；将不同层级的知识点进行再次Embedding编码，将编码结果存储到向量数据库之中，本申请实施例的技术方案，可以直接检索出其高层级知识、低层级知识和同级相关知识，使得相关知识的检索效率大幅提升。一种应用于企业应用的问答知识库的知识分层编码方法。该方法能够直接对高层次知识、低层次知识和同层次的相关知识进行搜索，从而大大提高相关知识的搜索效率。该方法涉及利用(S1)预先训练的BERT模型将低级别知识点编码为L0级别知识点。 对L0级知识点进行自适应聚类处理(S2)，并将其合并为同类型的知识点，形成知识聚类。 通过大型语言模型提取主知识聚类的概念(S3)作为L1级信息点。 对不同层次的知识点进行再次编码。 编码结果被存储(S4)在矢量数据库中。本发明还涉及一种问答(QA)知识库的知识分层编码装置。  12
本发明提供一种文本生成方法及装置，所述方法包括：获取文本原句；将所述文本原句输入训练好的文本生成预训练模型，获取所述训练好的文本生成预训练模型基于所述文本原句和模式控制符输出的文本生成结果；其中，所述训练好的文本生成预训练模型是基于续写训练数据、改写训练数据、压缩训练数据、扩写训练数据以及所述模式控制符训练得到的。本发明通过续写训练数据、改写训练数据、压缩训练数据、扩写训练数据以及模式控制符，获取一个兼具续写、改写、压缩和扩写能力的文本生成预训练模型，实现较好的文本生成效果，具有良好的实用性。文本生成方法。该方法使得能够获得具有连续书写、改写、压缩和扩展能力的文本生成预训练模型，从而实现更好的文本生成效果，实用性高。该方法涉及获得(101)文本原始句子。 将所述文本原句输入(102)训练文本以生成预训练模型。 获取所述训练文本输出的文本生成结果。 所述预训练模型是基于所述文本原句和模型控制符号生成的，其中，所述训练文本生成所述预训练模型是基于连续书写训练数据。 重新写入训练数据。 对所述训练数据进行压缩。 对所述模型控制符号进行训练。独立权利要求还包括用于：1文本生成设备：2电子设备：3包括用于生成文本的指令集的非暂时性计算机可读存储介质：和4包括用于生成文本的指令集的计算机程序产品。  11
本发明公开了一种用于人物实体库的文本相似度实体消歧方法和系统，所述方法包括如下步骤：获取待消歧实体，根据待消歧实体从知识库中捞取候选实体；用余弦相似度粗召回与待消歧实体相似的候选实体；采用Bi‑LSTM模型计算待消歧实体和候选实体的文本相似度，分别采用Bi‑LSTM模型对所述待消歧实体和候选实体分别进行特征提取，获取待消歧实体文本序列表征和候选实体的文本序列表征；分别计算所述待消歧实体文本序列表征和候选实体的文本序列表征的特征向量，并将相同类型实体的文本序列表征和特征向量融合，根据所述待消歧实体和候选实体的特征向量融合结果计算文本相似度。该方法可用于字符实体库的文本相似实体消歧。一种用于文字实体库的文本相似实体消歧方法，包括：获取待消歧实体；根据所述待消歧实体从知识库中取出候选实体。 一种字2VEC (RTM)：用于产生词嵌入的相关模型组)向量由待消歧实体和候选实体的字符实体履历文本计算。 设定余弦相似度得分，粗调和消歧余弦相似度得分大于候选实体的余弦相似度得分。 根据待消歧实体与候选实体的特征向量融合结果计算文本相似度。本发明还涉及一种用于字符实体库的文本相似实体消歧系统。  12
本公开提供了一种产品名称识别方法、装置、电子设备和介质，涉及文本识别技术领域。其中，产品名称识别方法包括：获取待识别文本，并获取与待识别文本的字符匹配的候选产品名称；基于深度神经网络模型和预设的权重表对待识别文本进行编码，生成第一编码向量，基于深度神经网络模型和权重表对候选产品名称进行编码，生成第二编码向量，权重表包括预存产品名称中每个文字的文本语义权重和/或位置权重；检测第一编码向量和第二编码向量之间的语义相似度；基于语义相似度在候选产品名称中选取与待识别文本对应的产品名称。通过本公开的技术方案，在一定程度上纠正了由于大规模预训练导致的常用词偏差，从而能够有效地提高产品名称识别的准确率。通过使用电子设备(权利要求书)在文本识别领域中的产品名称识别方法。该方法能够在一定程度上纠正大规模预训练导致的常用词偏差，从而有效提高商品名称识别的准确性。该方法包括获取与待识别文本的字符匹配的候选商品名称。 基于深度神经网络模型和预设的权重表对所述待识别文本进行编码。 生成第一编码向量。 基于所述深度神经网络模型和所述权重表对所述候选商品名称进行编码。 生成第二编码向量。 检测所述第一编码向量和所述第二编码向量之间的语义相似度。 基于所述语义相似度在所述候选商品名称中选择所述待识别文本对应的商品名称。独立权利要求还包括：产品名称识别装置； 以及包括用于产品名称识别方法的指令集的计算机可读存储介质。  12
本发明涉及人工智能技术领域，具体公开了一种基于预测模型的文本匹配方法、装置、设备及存储介质。该方法包括：获取预训练样本；将预训练样本输入预构建好的预测模型中，得到各词语的语义向量，根据语义向量分别进行掩码标记预测以及文本样本的相似度预测，获得第一预测结果以及第二预测结果；根据第一预测结果和第二预测结果计算目标损失函数，采用目标损失函数对预测模型进行训练，得到目标预测模型；获取包含两个待匹配文本的待预测文本并输入目标预测模型中，获得两个待匹配文本的相似度预测结果，根据相似度预测结果确定两个待匹配文本是否匹配。通过上述方式，本发明能够提高模型的泛化能力、降低过拟合风险以及提高训练效率。一种基于预测模型的文本匹配方法，用于电话场景下的智能客服。 可应用于人工智能技术领域，用于文本匹配装置。本发明提高了模型的泛化能力，降低了过拟合风险，提高了训练效率。 本发明大大减少了训练时间，加快了模型在线速度，提高了迭代效率，提高了预测模型的准确性。该方法涉及从训练数据集中随机地获得(S101)包含两个文本样本的训练样本，并且预处理这两个文本样本以获得包含掩码标签和报头标签的预训练样本。 将预训练样本输入(S102)到预先建立的预测模型中，以获得预训练样本中每个词的语义向量。 根据掩码标签对应的语义向量对掩码标签进行预测，以获得第一预测结果。 基于反向传播算法调整(S103)训练的预测模型的参数以获得目标预测模型。 取得预测对象文本(S104)，将输入的预测对象文本输入到目标预测模型中。 获取待匹配文本的相似度预测结果，并根据相似度预测结果确定待匹配文本是否匹配。独立的权利要求书被包括在以下内容中： 1. 一种基于预测模型的文本匹配装置； 2. 计算机设备； 以及 3. 一种存储用于匹配文本的程序的计算机存储介质。  12
本发明公开了一种基于机器视觉的地铁公共地点人流量分析方法，包括以：S1、获取地铁摄像头拍摄的历史视频流数据，提取地铁人流训练数据集；S2、加载YOLOv3网络的预训练模型，初始化网络权重；S3、将INRIA行人数据集与地铁人流数据训练集输入YOLOv3网络进行训练，得到真实目标框标注；S4、增加N次上采样操作，获得N个更小尺度的特征图，改变输入图像的大小；S5、对混合后的数据集进行网络粗训练，优化目标框的个数和宽高；S6、对地铁人流训练数据集进行网络精训练；S7、利用训练后的网络模型对地铁人流测试数据集进行检测，统计人流量；并评价网络模型的性能。本发明检测精度高，由粗到精的策略训练网络，优化了边界框参数，控制了检测速度与精度的平衡。基于机器视觉的地铁公共场所人流分析方法。本发明提高了地下铁路公共场所人流检测分析的精度，实现了精细策略下网络模型的训练，优化了包围盒参数，从而保证了公共场所人流分析速度和精度的平衡。该方法包括获取摄像机拍摄的地下铁路历史视频流数据作为训练集。 建立预训练YOLOv3网络模型，用于初始化网络权值。 获得开源的INRIA行人数据。 执行上采样操作以获得特征图的较小尺度。 对混合数据集进行网络粗训练处理，以优化目标帧。 对所述地下铁路的人流数据集进行网络训练过程，以建立训练后的网络模型。 利用所述人流数据集统计人流量，用于评估训练后的网络模型的性能。   6
时序动作检测是一个重要并且具有挑战性的视频理解任务。此任务旨在推理未修剪的长视频中动作实例的开始，结束位置和动作类别。目前表现优异的模型大多数是anchor‑base类别的。Anchor‑base类别的方法严重依赖预定义anchor的大小和数量。在另一类anchor‑free的方法中，大多数方法都需要额外的分类模型，这使得模型不能端到端共享信息。上述的这些问题使得现有的时序动作定位模型不够灵活并且产生了大量的冗余参数。为了解决上述问题，本申请提出了一种基于全局信息的端到端的anchor‑free时序动作检测方法，包括：使用视频数据集kinetics对backbone网络进行预训练，充分利用预训练模型的优势；并构建特征金字塔网络和自注意力模块，通过该部分网络模块生成带有全局信息的视频特征。基于在视频理解领域中有用的全局信息检测端到端无主播时间序列动作的方法。该方法：使得能够构建无锚点类型的时序动作检测方法，使得方法更加灵活，减少方法冗余的产生； 允许训练得到完整的网络模型； 对新数据不产生信息差异； 并利用视频的全局信息，以准确的方式推断出推理动作实例在视频中的起止位置。该方法涉及使用视频数据集来预训练骨干网络。 充分利用了预训练模型的优势。 构建特征金字塔网络和自注意力模块。 通过所述部分网络模块利用全局信息生成所述视频特征。 构造发电模块的无锚式。 在多尺度特征金字塔上逐步返回最低层的特征向量。 前馈神经网络(FFN)用作最后的分类器。 识别上一步骤中生成的动作类型。 9
本发明提出了一种基于对比学习和多头自注意力机制的多模态情感分析方法，本发明采用预训练模型，对文本和图片进行序列特征提取，之后针对图像采用基于多头自注意力机制的Transformer‑Encoder结构进行二次序列特征提取，然后将文本序列特征和图像序列特征拼接后使用Transformer‑Encoder进行特征提取，得益于自注意力机制，可以帮助文本和图像特征更好的对齐和融合；最后采用多任务学习，辅助模型更好的进行情感分类任务；同时加入两种辅助对比学习任务，帮助模型更好的提取学习文本和图像融合后的特征，帮助模型提升数据情感的区分能力。基于对比学习和多头自我注意机制的多模态情感分析方法加入辅助对比学习任务，帮助模型在学习文本图像融合后更好地提取特征，帮助模型提高数据情感区分能力该方法包括获取用于多模态情感分析的训练样本。 将训练样本中的图像读入存储器中。 将所述文本图像序列与所述特征向量进行整合。 通过所述分句、所述图像读取、所述文本输入的初始表示、所述图像特征表示输入、所述文本特征表示拼接以及所述文本图像序列整合得到数据增强的文本图像融合特征向量。 将得到的最终文本图像融合特征向量和数据增强后的文本图像融合特征向量作为辅助任务用于Info-NCE的对比学习，并计算损失函数。 所述三个损失函数由获得的文本图像融合特征向量、使用获得的文本图像融合特征向量以及根据权重进行的数据增强相加而成，以优化整个多模态情感分析模型。包括以下独立权利要求：一种基于对比学习和多头自主注意力机制的多模态情感分析的电子设备； 以及存储有用于基于对比学习和多头自主注意力机制的多模态情感分析的程序的计算机可读存储介质   5
本发明提供一种面向大模型的通用工具协同和精细化学习系统及方法，提升大模型对复杂任务的处理能力。该系统包括不同工具的动态组合机制模块、基于语言指令的统一接口模块、通用工具精细化学习模块和执行过程和结果信息综合推理模块。不同工具的动态组合机制模块将待处理任务指令所对应的任务分解为若干个工具级子任务，基于语言指令的统一接口模块通过通用工具接口实现多类型通用工具之间的协同调用，实现不同工具之间的功能互补，并通过通用工具的精细化学习模块，充分发挥工具的专有技能，执行过程和结果信息综合推理模块对若干个工具级子任务的执行过程信息和处理结果进行整合推理以得到任务指令的最终答案，应用于智能问答场景效果显著。用于自然语言处理和人工智能领域的面向大型预训练语言模型(PLM)的通用工具协作和细化学习系统。基于语言指令的统一接口模块通过通用工具接口实现了多类通用工具之间的协同调用，从而实现了不同工具之间的功能互补，因此充分发挥了工具的特殊技能。 执行过程和结果信息综合推理模块对工具级子任务的执行过程信息和处理结果进行集成推理，得到任务指令的最终答案，因此提高了复杂任务大模型的处理能力。该系统具有与基于语言指令的统一接口模块的输入端和输出端连接的通用工具精细学习模块，用于根据基于语言指令的通用工具接口对应的相应通用工具处理多个工具级子任务。 统一接口模块的输入端与不同工具的动态组合机制模块(1)的输出端相连，用于根据工具级子任务、通用工具调用图和动态路由机制调用基于语言指令的通用工具接口。 执行过程和结果信息综合推理模块(4)，用于基于多个工具级子任务的处理结果，对所述执行过程信息进行综合推理，得到所述任务指令的最终答案。包括用于面向大模型的通用工具协作和细化学习方法的独立权利要求。  11
本申请属于群体智能优化技术领域，公开了一种分布式群体性能智能优化方法、系统及电子设备，由群体中的多个个体节点对最新的群体预训练模型进行进一步的微调训练以得到个体优化模型，然后由所有个体节点对每个个体优化模型进行评分，最后综合每个个体优化模型得到的所有评分分值，根据评分结果从这些个体优化模型中确定更优模型，以进行群体预训练模型的更新操作，如此循环多次，使群体预训练模型对于整个群体的绝对性能和应用泛化性能逐渐提高，最终得到对于整个群体具有更优的绝对性能和应用泛化性能的群体预训练模型；使用该方法可自动化地提升群体预训练模型的泛化性能和绝对性能，进而有利于提升客体群体的性能表现。利用电子设备实现中心节点分布式群组性能智能优化的方法(权利要求书)。 用途包括但不限于个人计算机(PC)、平板PC、机顶盒(STB)、个人数字助理(PDA)、便携式多媒体播放器(PMP)、web设备、网络路由器、交换机或桥接器。该方法使得能够自动提高组预训练模型的泛化性能和绝对性能，以提高对象组的表现性能。该方法涉及将组预训练模型发送到节点网络以供组的个体节点下载(A1)。 对所述群体预训练模型进行精调整训练，得到对应的个体优化模型。 在第一周期中选择群体预训练模型作为初始群体预训练模型。 为个体优化模型获得(A2)群体中个体节点的得分值。 根据得分从个体优化模型确定(A3)最优群体预训练模型。 根据阶段最优组预训练模型更新组预训练模型(A4)。还包括用于分布式群组性能智能优化系统的独立权利要求。  11
本发明设计一种计算机构建的嵌入式对齐方法，通过本方法，本发明通过计算机将知识图谱的实体名称，属性信息通过大规模预训练语言模型构建出来，能够全面利用知识图谱上的语义信息，另外本发明通过将实体的一阶邻居，二阶邻居分别使用图注意力网络建模，实现更远距离实体信息的利用，使得能够捕捉更复杂的邻居结构，并使用特征线性调制的方法，将词嵌入和结构嵌入进行有效结合。在不同数据集上的实验结果表明，本发明具有较强的鲁棒性。同时设置消融实验验证本发明的有效性。用于执行计算机构建的嵌入式对齐的方法。在不同数据集上提供的实验结果显示出很强的鲁棒性，同时，设置了消融实验来验证该方法的有效性。该方法涉及基于变换器设置双向编码器表示单元。 基于变换器的双向编码器表示单元的功能是通过将实体名称字嵌入均值为0且协方差矩阵为单位矩阵的向量来构建的。 自然语言处理中的语言模型和表示学习中使用词嵌入，将维数为词数的高维空间嵌入到低维的连续向量空间中，将每个词或短语映射到实数域。 所述向量通过基于变压器的双向编码器的表示单元中的大规模预训练语言模型得到两个知识图谱的一组实体名称的词嵌入。 两个矩阵和矩阵用于中心实体和相邻实体的变换。  11
本发明属于图像分割技术领域，具体涉及一种基于CHS‑Net网络的医学图像分割方法，包括如下步骤：数据采集、数据预处理、模型构建、模型评价，所述数据采集在公开的COVID‑19肺炎CT图像中采集相关数据；所述数据预处理对数据集进行预处理，包括数据切片、数据标注、数据缩放和数据划分四种方式；所述模型构建从融合的数据集中获得训练集和测试集，基于CHS‑Net分割网络模型通过将U‑Net、Inception、ResNet和Attention融合构造形成新的融合网络模型，将组建好的训练集与其对应标签输入网络，通过网络的的迭代优化，进行模型的训练；所述模型评价当损失函数不在下降且评价结果最优，则对模型进行保存和评价。一种基于CHS-NET网络的医学图像分割方法。本发明通过优化训练集和相应的标签输入网络，实现训练集和相应的标签输入网络的迭代优化。 本发明能够在不降低损耗函数的情况下实现模型评估，得到最优的评估结果，从而对模型进行存储和评估。该方法包括在公开的冠状病毒病2019(COVID-19)肺炎计算机断层(CT)图像中收集相关数据。 执行数据预处理过程。 从会聚数据集获得训练集和测试集。 使用社区卫生系统(CHS)网划分的网络模型，将U-NET，初始，RESNET和注意力融合结构组合起来以形成最新的融合网络模型。 训练集和相应的标签被输入到最新的融合网络模型中。 在损耗函数不下降的情况下进行模型评价处理。   6
本发明公开了一种基于Vision Transformer和强化学习的视频内容描述方法，包括步骤：视频数据分割，利用FFMPEG将视频随机切割为多个视频帧；特征提取，使用ResNet‑152网络和ResNeXt‑101网络提取视频帧的静态特征和动态特征，并统一所述静态特征和动态特征的特征维度；特征编码，利用Vision Transformer模型的编码器对所述静态特征和动态特征进行特征编码；特征解码，利用多层LSTM网络对编码后的静态特征和动态特征进行解码；强化学习优化；和生成视频内容描述。本发明克服了在编码阶段极易丢失大量中间隐藏信息，导致描述准确率低的问题，有效地提高视频描述的准确率，同时，本发明所生成的视频内容描述具有逻辑性强、可读性高的优点。一种基于视觉和增强学习的视频内容描述方法。本发明克服了编码阶段容易丢失大量中间隐藏信息，导致描述准确率低的问题，有效提高了视频描述的准确性，生成的视频内容描述具有逻辑性强，可读性高的优点。该方法包括通过使用视频数据分段(FFMPEG)将视频随机切割(S1)成多个视频帧，以将视频随机切割成视频帧。 通过使用RESNET-152网络和RESNEX-101网络来提取(S2)特征，以提取视频帧的静态特征和动态特征。 该特征通过使用视觉模型的编码器来编码。 使用多层长期短期存储器(LSTM)网络对静态特征和动态特征进行解码(S4)。 生成结束标识符。 建立策略梯度增强学习算法。 根据所生成的描述和真实描述来计算CIDER值。 9
本发明涉及输电线路巡检技术领域，具体涉及一种电力视觉多粒度预训练大模型的构建与训练方法，包括图像修复、图像分类、目标检测、图像描述四个粒度层级的视觉任务；采用多阶段的大模型训练方法，使得模型具有数据挖掘、增量训练和模型进化的功能；其中，第一阶段在海量公开数据集上训练，输出预训练大模型；第二阶段在大量无标签电力场景数据集上进行自监督训练，输出电力视觉多粒度预训练大模型；第三阶段利用大模型针对电力数据集进行隐患图像筛选，大大减轻了人工筛选代价，将隐患图像数据交由人工进行精细化标注，再次输入大模型进行迭代优化，使得视觉预训练大模型更加适配电力场景视觉任务需求。用于无人机输电线路巡检的动力视觉多粒度预训练大模型构建及训练方法。该方法能够降低人工筛选成本，实现对隐藏图像数据的人工精细标注操作，以将隐藏图像数据输入到实现迭代优化的大模型中，从而实现视觉预训练大模型适用于电力场景的视觉任务需求。该方法涉及收集与电力场景相关的公共图像数据集，形成覆盖电力领域多粒度视觉需求的大数据集。 针对屈光力视觉场景各领域需求建立屈光力视觉多粒度预训练模型。 对图像进行图像特征提取操作。 执行图像修复任务。 执行图像分类任务。 执行图像目标检测任务。 执行图像描述任务。 对所述屈光力视觉多粒度预训练大模型进行训练。 将所述动力视觉多粒度预训练大模型的无标签数据集输入所述模型，用于实现自监督训练操作。 对所述数据集的隐藏图像进行筛选，得到精标注数据集。 输入所述动力视觉预训练大模型，用于根据细化标注数据集实现对所述动力场景的各种视觉任务的微调操作。 0
本发明提供一种基于Swin‑Transformer的叶片计数方法，包括：获取拍摄图像；所述拍摄图像包括草莓叶片；将所述拍摄图像输入至Swin‑Transformer模型，进行草莓叶片识别；输出识别结果；所述识别结果包括草莓叶片分割结果、草莓叶片标注信息以及草莓叶片面积；基于计数器统计所述草莓叶片数量。本发明，通过改进的Swin‑Transformer算法执行草莓的叶片识别以及计数，并进行模型的优化训练等，从而使得模型得到的草莓叶片数量准确便于后续的基于叶片的对草莓生长状态的估测。一种基于SWIN-CARD对植物即草莓的叶片进行计数的方法。本发明通过改进的SWIN-算法对草莓进行叶片识别和计数，并对模型进行优化训练，使得模型得到的草莓叶片数量准确，便于后续基于叶片的草莓生长状态估计。所述方法包括获得拍摄图像，其中所述拍摄图像包括草莓叶。 拍摄的图像被输入到SWIN-模型以识别草莓叶并输出识别结果。 识别结果具有草莓叶片划分结果，草莓叶片标识信息和草莓叶片区域。 基于计数器对草莓叶的数量进行计数。本发明还涉及一种基于摆动的叶片计数系统； (2)用于存储程序的计算机存储介质。   5
本申请适用于人工智能技术领域，尤其涉及一种文本生成模型的自适应训练方法、装置、设备及介质。该方法通过定位每个待处理文本内的数据项文本的位置，确定内容项文本，掩盖每个待处理文本中内容项文本，形成对应的第一训练文本，掩盖的内容项文本为第一训练文本的标注，使用所有第一训练文本对文本生成模型进行预训练，将验证表中数据文本输入预训练好的文本生成模型，根据其输出与验证表中数据文本对应的内容文本进行相似度比较，根据比较结果对预训练好的文本生成模型再训练，使用定位的方式自动划分具有标注的训练集，采用验证表的形式自动对预训练的文本生成模型进行再训练，训练后的文本生成模型更加贴合使用场景，具备更高准确性、适应性。一种人工智能技术，财务管理应用，总结金融热点和趋势领域的自适应文本生成模型的训练方法。训练后的文本生成模型更贴近场景，具有更高的准确性和适应性。 提高了文本生成模型的准确性和适用性。 采用定位方式将文本自动划分为带有标签的训练集，训练集对文本生成器模型进行预训练，同时采用校验表的形式对预训练后的文本生成器进行自动重新训练。该方法包括获得N个待处理文本。 定位每个待处理文本中的数据项文本的位置。 在与待处理文本的位置相对应的数据项文本是上下文项文本之后确定文本。 内容项文本被覆盖在每个要处理的文本数据中。 形成相应的第一训练文本。 根据比较结果训练预先训练的文本生成模型。 获得训练文本生成模型。 验证表中的数据文本被输入到预训练文本生成模型中。 将预先训练好的文本生成模型的输出与校验表中的数据文本对应的内容文本进行比较，得到比较结果。还包括独立的权利要求： 文本生成模型自适应训练装置； 以及 包括一组用于训练自适应文本生成模型的指令的计算机可读存储介质。  11
本申请涉及计算机技术领域，提供一种基于生成式预训练模型的实时信息响应方法及其系统，该方法包括：加载具备通用知识生成能力的生成式预训练模型；通过目标服务应用领域的微调数据集对生成式预训练模型进行微调处理，得到目标服务应用领域的微调领域模型；在微调领域模型中开启领域模型服务和实时信息服务；若侦测到用户终端向领域模型服务发起知识请求，则基于领域模型服务根据知识请求返回服务应用领域模式下的文本；以文本为请求参数对实时信息服务发起请求，并获取实时信息服务返回的实时信息；利用Prompt将实时信息下达至生成式预训练模型，并获取生成式预训练模型返回融合后实时信息。本申请提高了信息获取的实时性。基于生成的预训练模型提供实时信息响应的方法。该方法能够提高信息获取的实时性。该方法包括加载生成的具有通用知识生成能力的预训练模型。 通过目标业务应用领域的微调数据集对生成的所述预训练模型进行微调，得到所述目标业务应用领域的微调领域模型。 在细调域模型中启动域模型服务和实时信息服务，即普通爬虫服务。 根据基于领域模型服务的知识请求，以服务应用领域的方式返回文本。 以所述文本为请求参数向所述实时信息服务发起请求。 获取所述实时信息服务返回的实时信息。 所述实时信息是所述实时信息服务基于所述请求搜索所述文本的关键词后得到的。该方法包括使用提示将实时信息发送到所生成的预训练模型。 其中，业务应用领域模式为生成的预训练模型对细调数据集进行细调后返回的模式，细调数据集为以JavaScript对象符号(JSON)(RTM：Computer data format)文本格式构建的目标业务应用领域的问答对话数据集。 包括独立权利要求：(1)一种用于基于所生成的预训练模型提供实时信息响应的系统； (2)—种电子设备，包括存储器和处理器，所述处理器用于执行指令集，所述指令集用于基于所生成的预训练模型提供实时信息响应； (3)一种非瞬态计算机可读存储介质，用于存储指令集并由处理器执行以基于所生成的预训练模型提供实时信息响应。  11
本发明属于智能服务技术领域，涉及一种金文语义识别方法，包括以下步骤：S1采用金文训练集对BERT模型进行预训练，得到金文增强语境向量；S2将金文增强语境向量带入BiLSTM模型，得到表征金文句子上下文信息的金文隐向量矩阵H；S3根据金文隐向量矩阵H对金文进行语义角色识别和语义依存关系识别；S4根据金文语义角色标签和语义依存关系建立金文知识图谱；S5将待识别的金文带入金文知识图谱中进行识别。其全面考虑并融合金文描述内容的因果关联以及语义要素之间的语义依赖关系，能够通过上下文信息理解金文含义，使识别结果更加准确。智能服务黄金文本语义识别方法。该方法能够充分考虑和融化合金文本描述内容的因果关联和语义要素之间的语义依赖关系，通过上下文信息理解黄金文本的含义，使识别结果更加准确。该方法使用金文训练集并采用预训练双向编码器表示(BERT)模型进行训练处理，得到金文增强上下文向量。 将所述金文增强上下文向量引入双向长短期记忆(BiLSTM)模型。 获取用于表示金文句子的上下文信息的金文隐式向量矩阵。 根据所述金文隐向量矩阵识别所述金文隐向量矩阵的语义角色识别和语义依赖关系。 根据所述金文语义角色标签和所述语义依赖关系建立金文知识图谱。 所述金文知识图谱中添加有标识金文。还包括一种智能服务黄金文本语义识别系统的独立权利要求。  12
本发明公开了一种基于自然语言处理及图像算法的文章自动生成系统和方法，涉及人工智能领域，包括操作终端，输入产品信息和用户信息、输出最终推文；基础标签提取系统，根据输入的产品信息和用户信息，利用BERT预训练模型提取关键字，建立多个标签；内容生成模块，根据标签信息生成相应的若干标题、若干文章内容和若干与文章内容相符的图片；智能筛选模块，包括文章筛选模块和图片筛选模块，对于多个文章内容与相符图片的组合，利用文章筛选模块和图片筛选模块进行筛选，得到符合要求的一组文章内容与相符图片；智能排版模块，对最终选择的文章及相符图片进行排版，得到最终推文。基于自然语言处理/图像算法的物品自动生成系统。提高了文章的撰写效率。 提高了文章的趣味性。 吸引了用户的注意力。 产生了更好的广告效果。 提供了良好的应用前景。该系统具有基本标签提取系统，其使用来自变换器的双向编码器表示(BERT)预训练模型来基于输入产品信息和用户信息提取关键字。 内容生成模块，设置有标题生成模型、短文章生成模型、图像生成模型，根据标签信息生成相应的标题、若干文章内容、与文章内容相匹配的若干图片。 一种智能筛选模块，设置有物品筛选模块和图像筛选模块。 文章筛选模块和图像筛选模块，用于对多个文章内容和匹配图片的组合进行筛选，得到一组文章内容并匹配出符合要求的图片。 智能排版模块对最终选择的文章和匹配的图片进行排版，得到最终的推文。  12
本发明公开了一种意图槽值双向交互的自然语言理解方法，采用BERT语义编码模块对用户输入的话语进行文本预处理，并进行语义编码，然后将意图表示向量输入到意图注意力模块，生成语义增强的意图表示向量，并通过自注意语义交互模块，双向交互语义增强的意图语义表示向量和槽语义表示向量，获得最终的意图语义表示向量和槽语义表示向量，然后将最终的意图表示向量和槽语义表示向量输入到CRF语义解码模块，获得最后话语的意图和槽值。本发明使用预训练知识显著提高意图识别和槽填充的识别效果，使得系统可以应用在高精度的NLU场景上，提高了系统的预测精度。意图槽值双向交互自然语言理解方法。本发明能够利用预训练知识提高识别效果，实现对高精度自然语言理解(NLU)场景的应用，提高预测精度。该方法包括在由用户输入的语音中执行文本预处理操作，并使用来自变换器(BERT)语义编码模块的双向编码器表示。 执行语义编码操作。 生成生成表示向量的语义增强意图。 将最终意图表达向量和时隙语义表示向量输入条件随机场(CRF)语义解码模块，得到最终语音的时隙值。 得到CRF语义解码模块中意图全连接神经网络的权重。 用意图语义表示向量执行矩阵乘法运算。 执行层标准化操作。  12
本发明是一个根据上下文及答案自动化生成问题的方法。该方法通过把文本的深度语义特征融合到大型预训练模型(BERT、ULMFit)中，进而获取文本的深层次的语义表示。该方法不仅考虑了典型的文本语言信息(如POS、NER)，还针对QG问题提出了一种新的语言学特征QAF。经过大量的实验，结果表明该方法达到目前最优水平。本发明的目的在于提供一种高质量的问题生成方法，促进问答技术等领域的发展，加速实现智能化的人机交互，进而促进社会发展和高效率运行。基于预训练模型深度特征表示生成高质量问题的方法。该方法能够提供高质量的问题生成过程，促进问答技术领域的发展，加速实现智能人机交互，从而促进社会发展和高效运行。该方法包括预处理QG数据集。 数据被分成单词、词性标记和实体标识(NER)。 通过使用预训练模型BERT来学习NER的语言的表示模型。 在与NER相比较的QGG数据集的POS任务中训练模型。 训练后强调每个词的语法效果。 模型的隐藏状态是动态表达的上下文信息，以解决多含义的问题。 引入QAF语言特征来表达段落。 建立答案和问题之间的关系。 QG模型主体架构采用传统的序列模型实现。 在特征输入中在QGF模型中获得深度语言。 产生模型输出问题。  11
本发明公开了一种面向限时红蓝对抗问题动作空间解耦的博弈决策方法，属于人工智能中的博弈决策领域。其包括步骤：1、将博弈问题进行抽象，完成博弈问题建模，想定结构化抽象以及基于语义的对抗场景的搭建；2、构建非完全信息下蓝方信息预测预训练模型，支持红方视角下非完全信息到完全信息的映射；3、构建单个团体的动作空间并设计评估函数，进行基于动作空间解耦的蒙特卡洛树决策；4、设计路径关联度及影响判别函数，进行基于团体影响程度的蒙特卡洛树决策后处理，完成高相关团体的动作空间设计及低相关团体的决策结果输出，最终得到博弈决策结果。本发明可求解时间受限下的复杂博弈问题，并针对大规模动作空间进行快速搜索，支持高效准确的博弈决策。本发明涉及人工智能(AI)技术游戏决策领域中的一种对限时红蓝对抗问题的动作空间解耦的游戏决策方法。该方法在时间限制下解决复杂的游戏问题，并且快速搜索大范围的动作空间，支持高效准确的游戏决策。 该方法大大减小了搜索空间，提高了搜索精度。 该方法通过对语义态势信息进行建模，能够实现战争伪装问题下的游戏阻力问题决策，能够简化应用于复杂对抗问题的动作空间。该方法涉及构建具有扰雾效应的红蓝对抗场景，提供红蓝双方在各编队视角下姿态的语义信息，同时进行基于建筑物的环境抽象，引入连通性和节点离散化地图，定义动作空间的制定原则。 在每个编队视角下分析出红蓝双方情况的语义信息。 基于得到的蒙特卡洛树决策结果进行后处理。 检查由每个组的蒙特卡洛树搜索结果产生的最终状态，确定结果是否可以相互影响，并且由相互影响的组形成新的组。 基于所述当前决策结果生成决策语义，并执行所述当前方案。  12
本申请实施例提供了一种调整方法、搜索方法、电子设备、存储介质及程序产品，语言模型的调整方法，包括：获得多个样本数据，样本数据包括多个样本字符串、每个样本字符串对应的多个样本命名实体、每个样本命名实体对应的匹配标记，匹配标记用于标识样本搜索字符串与命名实体的匹配结果；通过预训练的语言模型，将若干个样本命名实体与对应的样本字符串进行语义匹配，得到若干个样本命名实体分别与样本字符串的预测语义匹配结果；根据多个样本命名实体各自的预测语义匹配结果以及匹配标记表征的匹配结果之间的差异，调整预训练的语言模型。调整语言模型的方法。所述预训练语言模型根据所述匹配标记表示的每个所述样本命名实体预测与匹配结果的匹配结果之间的差异进行调整，并因此保证了所述目标命名实体与所述搜索字符串的匹配度，并准确定位到所述搜索字符串对应的命名实体，从而执行所述搜索操作，得到的搜索结果命中率高。该方法包括获取(S101)多个样本数据，其中，样本数据包括多个样本串、与每个样本串对应的多个样本命名实体以及与每个样本命名实体对应的匹配标记。 所述匹配标记用于识别样本检索字符串与候选命名实体的匹配结果(S102)。 利用预先训练的语言模型将多个候选命名实体与所述搜索字符串进行语义匹配。 获得所述候选命名实体的多个语义匹配结果(S103)。 根据所述语义匹配结果获取所述搜索字符串对应的目标命名实体。 通过所述候选命名实体获取所述搜索文本串的历史搜索结果。独立权利要求包括：搜索方法； 计算机存储介质； 以及计算机程序产品。  11
本发明公开了一种互联网医疗分诊方法及系统，包括以下步骤：接收用户主诉信息；将主诉信息用预先训练好的BERT模型转换成句向量，再将句向量在预先创建的分诊向量数据库中进行相似度搜索，得到结果一；将主诉信息用分词工具转换成分词后的主诉文本，再将主诉文本输入到预先训练好的FastText模型中，输出结果二；对结果一、结果二和主诉信息进行加权计算，得到推荐的分诊科室；将推荐分诊科室返回给用户。本申请提供的互联网医疗分诊方法及系统，用户只需提交主诉信息一步操作便可获得推荐就诊科室，使用上更加方便快捷，降低了用户使用门槛；综合使用了BERT向量搜索和FastText分类模型两种推荐结果，并考虑了用户性别和年龄的影响因素，提高了分诊的准确率。互联网医疗诊断方法，用于互联网医疗领域。该方法使得用户提交主诉信息一步操作获取诊断室，使得该方法使用方便快捷，降低了用户的使用门槛，扩大了受众群体。 该方法综合利用了BERT vector搜索和FastText分类模型两种推荐结果，并考虑了用户性别和年龄的影响因素，提高了诊断的准确性。该方法涉及接收(S1)用户主诉信息。 通过预先训练的BERT模型将所述主诉转换(S2)为句子向量。 通过所述语句向量在预先建立的分诊向量库中进行相似度搜索，得到第一结果。 利用分词工具，在使用所述主诉信息后，将所述主诉文本转换(S3)为组成词。 将所述第一结果和所述主诉信息进行加权计算(S4)，得到推荐的分支诊断科室。 将推荐子诊断部返回给用户(S5)。互联网医疗诊断系统包括一个独立的权利要求。  12
一种面向常识推理的生成式人机对话回复生成方法，属于自然语言处理技术领域。本发明通过上下文搜索引入知识实体，对知识向量与对话向量共同解码生成回复，这样的回复采用了已有的知识和推断技术对上下文进行判断，有效提升了对话的回复质量。面向常识推理的生成型人机对话回复生成方法，属于自然语言处理即人工智能和深度学习技术领域。通过上下文搜索引入知识实体，将知识向量和对话向量联合解码生成回复，回复利用现有的知识和推理技术进行上下文判断，有效提高了会话的回复质量。该方法涉及(S1)对会话上下文文本信息进行预处理； 对所述会话上下文的文本信息执行所述数据清洗处理； 将清洗处理后的上下文文本数据按照说话人的语句进行划分； (S2)编码会话上下文信息以获得所述上下文向量； (S3)对经过词表法预处理的会话策略信息进行知识推理； (S4)进行知识融合，得到知识向量； (S5)对所述上下文向量和所述知识向量进行解码； 获取用于编码向量化的上下文标识符序列； 利用自注意力机制进行计算，得到输出。 8
本申请提供一种智能问答方法、装置、设备和存储介质，方法包括：获取待处理问题；从问答库中选择出与待处理问题相似度符合要求的多个候选问题；利用语义匹配模型，对待处理问题和多个候选问题进行语义分析，以获得与待处理问题对应的目标问题，语义匹配模型是对预训练的大语言模型进行微调后获得的；根据目标问题，确定待处理问题对应的答案，提高了智能问答结果的准确性。另外，上述方案中，基于少量的训练数据对预训练的大语言模型进行微调后，就可以获得性能较好且具有很强的泛化性地语义匹配模型，那么利用语义匹配模型进行智能问答处理时，可以更准确地匹配出待处理问题对应的目标问题，进而提高了智能问答结果的准确性。智能问答方法，用于自助服务和智能客服领域。根据所述目标问题确定所述待处理问题对应的答案，提高了智能问答结果的准确性。 基于少量的训练数据对预先训练好的语言大模型进行微调后得到性能好、泛化性强的语义匹配模型。该方法包括获得(201)待处理的问题。 从问答库中选择(202)满足与所述待处理问题相似度要求的多个候选问题。 利用语义匹配模型(203)对待处理问题和多个候选问题进行语义分析，得到与待处理问题对应的目标问题。 对预先训练好的语言大模型进行微调后得到语义匹配模型。 根据所述目标问题确定(204)所述待处理问题对应的答案。独立权利要求包括以下内容：智能问答装置； 电子装置； 以及存储用于智能问答的程序的非临时机器可读存储介质。  11
本发明基于BERT‑BiLSTM‑CRF来解析中文地址要素的方法包括：将中文地址按照层级进行标注；将现有的中文地址和以此标注的中文地址标注语言进行扩充；它包括：同义词变换、缩略词替换、地址要素遮盖和地址要素位置交换；用中文地址和中文标注地址来训练BERT‑BiLSTM‑CRF，让其进行深度学习；将中文地址作为输入端输入BERT‑BiLSTM‑CRF中，在BERT‑BiLSTM‑CRF输出端得到中文地址的标注语言，本发明基于BERT‑BiLSTM‑CRF来解析中文地址要素的方法提升了中文地址的解析精度，节约了标注地址数据需要耗费大量的时间和精力，减轻了人工标注的成本。基于BERT-BiLSTM-CRF的中文地址要素分析方法。基于BERT‑BiLSTM‑CRF的中文地址要素分析方法，提高了中文地址的分析精度，节省了地址数据标注的时间和精力，降低了人工标注成本。该方法包括根据对作为标记元素语言的文本的级别标记中文地址。 所述中文地址作为一个BERT-BiLSTM-CRF的输入端获取。 基于中国行政区划的地址数据，通过同义词变换替换类似类型的地址元素。 建立地址元素的名称库。 在地址元素上覆盖了未明确的地址描述，该地址包括地址元素删除或重复情况，以删除中文地址中的部分地址元素，以提高数据的抗噪性。 利用扩展数据训练出BERT-BiLSTM-CRF中文地址分析模型。 计算所述中文地址的每个字符的类别概率值。  12
本公开的实施例公开了用于文本表征的特征向量生成方法、装置和电子设备。该方法的一具体实施方式包括：将知识特征序列中的知识特征与待表征文本进行拼接；将拼接特征输入预训练模型；将候选特征向量子序列中的每个候选特征向量，与预训练模型中的嵌入矩阵进行相乘处理；将目标特征向量与目标特征向量在词表中对应的词向量进行向量融合；将得到的融合向量序列中的融合向量输入第一特征降维网络；将目标候选特征向量输入第二特征降维网络；将第一降维特征向量序列中的第一降维特征向量和第二降维特征向量进行向量拼接，以生成待表征文本对应的文本表征向量。该实施方式提高了生成的特征向量的精准度。用于生成用于文本特征化的特征向量的方法。提高了生成的特征向量的精度。 知识特征的特征在于与待表征文本的关联关系，通过增加知识特征来增强或补充待表征文本的文本内容。 本发明生成的特征向量能够很好地表达和突出文本对应的特征，达到提高特征向量生成精度的目的。 减少了特征维度，降低了后续特征计算的复杂度。所述特征向量生成方法涉及获得要表示的文本。 知识特征序列中的知识特征与待特征文本拼接以生成拼接特征。 拼接的特征被输入到预训练的模型中以生成候选特征向量序列。 候选特征向量序列具有每个候选特征的量子序列中的候选特征向量。 将目标特征向量输入到第二特征降维网络以生成第二降维特征向量。 对第一降维特征向量执行向量拼接。 所述第二降维分量向量在所述第一降维向量序列中生成与所述文本相对应的文本表示向量。本发明还涉及一种用于文本特征化的特征向量生成装置； (b)电子设备，具有用于存储多个程序的存储装置； 和(c)计算机可读介质。  12
本发明提供了一种基于多摄像头的车辆重识别方法和设备。所述方法包括获取初始图像，进行目标检测，获取目标所属类别并提取初始图像中的目标车辆图像保存至目标图像库；将待匹配车辆图像保存至待匹配图像库；从目标图像库中选取目标车辆图像进行目标分割；引入多种车辆特征用于对目标车辆图像编码，得到编码信息；将编码信息输入基于Transformer的多尺度分层特征提取网络，获取全局特征；根据卷积神经网络和所述目标分割结果提取局部特征；根据全局特征和局部特征计算目标车辆图像与待匹配图像库中的所有待匹配车辆图像之间的近似程度，对目标车辆进行重识别。以此方式，实现了在多摄像头下的车辆重匹配，提高检测效率和质量，节省人力物力，节约成本和资源。基于多摄像头的车辆再识别方法。实现了多摄像头下的车辆再匹配，提高了检测效率和质量，节省了人力物力，节约了成本和资源。该方法涉及获取若干摄像机采集的初始图像，并利用目标检测算法对初始图像进行目标检测，并获取目标的类别提取初始图像中的目标车辆图像保存至目标图像库。 对所述目标图像库和所述待匹配图像库中的图像进行目标分割，得到目标分割结果。 将图像编码到目标图像库和待匹配图像库中，并引入各种车辆特征对车辆进行编码，得到图像的编码信息。 根据所述目标车辆图像的全局特征和局部特征计算所述目标车辆图像与所述图像库中所有待匹配车辆图像之间的近似度。本发明还涉及一种电子设备。 13
本发明公开了一种基于深度学习的染色体自动分割和分类方法，包括以下步骤：获取染色体图像并使用Attention U‑Net模型过滤细胞杂质；分割染色体并裁剪出各个染色体区域图像；对获取的染色体区域提取特征并训练支持向量机、随机森林、逻辑回归分类器，采用投票法进行模型集成，进而识别重叠\粘连染色体或单条染色体；对判别为重叠\粘连染色体分别设计单独的分割模块，针对重叠染色体，利用先分离再拼接的办法分割，针对粘连染色体，利用凸缺陷点检测的方法进行分割；将标注好类型的染色体训练数据分别输入到24分类模型ResNet20、ResNet32、ResNet44模型中进行训练，然后用堆叠法进行模型集成，输出最终的染色体分类结果以及染色体核型分析图，以便进行染色体异常识别。基于深度学习的染色体自动分割与分类方法。开发了一套可靠的染色体自动分割分类系统，以实现染色体核型分析的自动化和智能化。 从整体上提高了染色体分割分类的效率和准确率。该方法包括使用一个提取的关键特征来训练支持向量机、随机森林和逻辑回归分类器。 采用投票的方法，将三个分类器整合在一起，最终将一个染色体区域区分为重叠/粘连染色体或单条染色体。 针对重叠/粘连染色体设计了单独的分割模块。 对重叠的染色体采用先分离后剪接的方法。 对粘附的染色体采用凸缺陷检测的方法进行分割。 基于Resnet20、Resnet32、Resnet44构建24号染色体分类模型。 采用堆叠法进行模型整合，输出最终的染色体分类结果和核型分析图，供专业人员鉴定染色体异常。   6
本公开提供了用于生成预训练模型的方法、模型训练方法及装置，涉及人工智能技术领域，具体为深度学习、图像处理、计算机视觉技术领域，可应用于OCR等场景。具体实现方案为：获取视频集合；基于视频集合中第一视频的第一视频帧的图像特征，确定第一样本视频帧集合；基于视频集合中除第一视频之外的其他第二视频，确定第二样本视频帧集合；基于第一样本视频帧集合和第二样本视频帧集合中的视频间差异信息以及视频内差异信息，对待训练模型进行训练。本实现方式可以提高预训练模型的生成效率。用于生成预训练模型的方法。该实现方式提高了预训练模型的生成效率。该方法涉及基于视频集合中的第一视频的第一视频帧的图像特征来确定第一样本视频帧集合。 基于所述视频集合中除所述第一视频之外的其他第二视频，确定第二样本视频帧集合。 基于所述视频之间的差异信息，以及所述第一样本视频帧集合和所述第二样本视频帧集合中的视频中的差异信息，训练待训练模型。 基于所述图像特征确定相邻第一视频帧之间的图像差异参数。 基于所述图像差异参数将所述第一视频切分为视频片段。独立权利要求包括：(1)一种用于训练模型的方法； (2)动作识别方法； (3)视频检索结果的评价方法； (4)用于生成预训练模型的装置； (5)用于训练模型的装置； (6)行为识别装置； (7)视频检索结果的评价装置； (8)一种电子设备； (9)一种计算机程序产品； (10)一种非暂态计算机可读存储介质，所述非暂态计算机可读存储介质存储有用于实现所述用于生成预训练模型的方法的指令。 9
本公开提供了一种模板的生成方法、装置、电子设备及存储介质，涉及计算机技术技术领域，具体涉及自然语言处理、深度学习等技术领域。具体实现方案为：接收第一模板生成请求，并基于第一模板生成请求中包括的待生成模板的第一描述信息及每个参考模板的第一属性信息，确定候选模板，然后通过候选模板对应的元信息获取界面，获取候选模板所需的元信息，之后再基于获取的元信息，对候选模板进行更新，生成第一目标模板。由此，通过基于获取的描述信息及元信息，对候选模板进行更新，就可以生成第一目标模板，从而提高了候选模板的安全性，提高了模板的生成效率，且生成的目标模板更能符合大模型及用户需求。生成模板的方法。基于获取的描述信息和元信息对候选模板进行更新，生成第一目标模板，提高了候选模板的安全性，提高了模板生成效率，生成更符合大模型和用户需求的目标模板。该方法涉及接收(101)第一模板生成请求。 所述第一模板生成请求中包括所述待生成模板的第一描述信息。 基于每个参考模板的第一描述信息和第一属性信息确定(102)候选模板。 通过所述候选模板对应的元信息获取接口获取(103)所述候选模板所需的元信息。 基于所获得的元信息更新(104)所述候选模板以生成第一目标模板。独立权利要求包括用于：一种用于生成模板的装置； 用于生成模板的电子设备； 存储用于生成模板的计算机指令的非瞬时计算机可读存储介质； 以及包括用于生成模板的计算机程序的计算机程序产品。  11
本公开提供了内容推荐方法、装置及电子设备，涉及人工智能技术领域，尤其涉及深度学习、自然语言处理、大模型、智能搜索等技术领域。具体实现方案为：获取搜索图和推荐图；搜索图包括对象标识、搜索关键词以及搜索选中内容之间的关系；推荐图包括对象标识以及推荐选中内容之间的关系；对搜索图和推荐图进行游走处理，得到多个训练语料；多个训练语料用于对初始的词向量模型进行训练处理，以确定对象标识的对象表示向量、搜索关键词的关键词表示向量以及内容的内容表示向量，其中，训练语料能够体现搜索行为数据和推荐行为数据中未体现出来的信息，例如，潜在兴趣等，从而能够基于潜在兴趣等进行内容推荐处理，进一步提高内容推荐效率。所述方法和设备可用于推荐内容，例如电子设备(要求保护的)中的文章。该方法能够对搜索图和推荐图进行徘徊处理，得到一组训练语料，使得训练语料能够体现搜索行为数据和推荐行为数据中未体现的信息，从而基于潜在兴趣进行内容推荐处理，提高了内容推荐效率。该方法涉及获得(S101)搜索图和推荐图。 搜索图具有对象标记、搜索关键字和搜索选择内容之间的关系。 所述推荐图包括(S102)所述对象标记和所推荐的内容与所选择的内容之间的关系。 对所述搜索图和所述推荐图进行游走处理，得到多个训练语料。 根据多个训练语言数据对初始词向量模型进行训练(S103)，得到训练后的词向量模型。 根据所述训练好的词向量模型中的对象标识的对象表达向量查找所述关键词的关键词表达向量和内容的内容表达向量。 执行内容推荐处理(S104)。还包括独立权利要求，用于：内容推荐装置； 非瞬时计算机可读存储介质，其包括用于推荐例如文章的内容的一组指令； 以及计算机程序产品。  11
本发明公开一种基于模型预测的加速AI大模型分布式训练的方法及装置，方法包括，构建分层参数数据集；利用基于预测结果的评估方法，训练用于预测目标模型的模型参数的预测模型；计算节点更新目标模型的前面一些层的模型参数，然后将它们推送给参数服务器；在参数服务器，对所接收到的模型参数进行聚合，通过预测模型预测得到目标模型的剩余其他层的模型参数；预测出来和聚合后的模型参数被拼接成一个完整模型参数，并被推送给所有计算节点；计算节点使用接收到的完整模型参数替换本地的模型参数；所述预测模型采用“卷积+通道注意力机制+池化”结构，本发明能够保持目标模型的准确率不变的情况下，大量减少通信量同时不会引入大量计算开销。基于模型预测加速AI大模型分布式训练的方法。该方法能够保持目标模型的精度不变，减少通信量和大量的计算开销。该方法涉及构建分层参数数据集。 利用所述分层参数数据集，基于预测结果，通过评价处理，针对预测目标模型的模型参数，训练预测模型。 预测模型通过使用多维分层参数数据执行推理过程。 获取除外的一个目标模型的模型参数。 将预测模型参数和聚合参数数据进行拼接，得到完整的模型参数。 由PS参数服务器将完整的模型参数推送给多个计算节点工作器。 通过使用所接收的完整模型参数在计算节点工作器中迭代地替换局部模型参数。 进行多次迭代直至目标模型收敛后终止分布式训练。独立权利要求包括用于：(1)基于模型预测加速AI大模型分布式训练的系统； (2)一种计算机可读存储介质，用于存储基于模型预测加速AI大模型分布式训练的指令集。  11
本发明属于人工智能领域，本发明提供一种问题生成方法和装置，该方法包括：获取待处理语料及其对应的答案；根据该待处理语料及其对应的答案获取基于领域注意力的语料特征；将该语料特征输入预训练的问题生成模型得到对应的问题，其中，在获取语料特征时，考虑领域注意力，增加对领域知识的关注，结合问题生成模型，能自动从文章中生成问题，对于数据集和问答对的构建很有意义，解决问题模板化且类型单一、质量不高等问题。用于使用电子设备生成问题的方法(要求保护)。该方法解决了模板问题、类型单一和质量低的问题。所述方法包括：获取待处理的语言学数据和对应的答案，根据所述待处理的语言学数据和对应的答案，得到基于领域注意力的语言学数据特征，将所述语言学数据特征输入预先训练的问题生成模型，得到对应的问题，得到领域语言学数据集，根据所述领域语言学数据集，通过对所述领域语言学数据集进行分词、去停词和词频统计，得到领域词典。 以及根据所述词频统计结果获取所述领域词典。独立权利要求还包括用于：一种用于生成问题的装置； 以及包括用于生成问题的指令集的计算机可读存储介质。  11
本申请涉及了一种数据处理方法、装置和模型训练方法、装置和电子设备。该数据处理方法包括：获得训练数据集；确定训练数据集中至少部分训练数据各自的难度系数，以便基于至少部分训练数据各自的难度系数对训练数据集中至少部分数据进行难度分类；其中，训练数据包括分子数据，分子数据的难度系数是基于分子属性和/或模型训练属性来确定的。本申请能够提升预训练模型在目标任务中的精准度。该方法通过使用电子设备(要求保护)用于人工智能和计算机模拟。该方法提高了目标任务中预训练模型的准确性，提高了模型训练的效果； 允许用户从所需的难度分类中选择所需的训练数据用于例如模型训练的应用； 并且可以通过定义训练数据学习的难度系数，基于难度系数来分类训练数据的难度。该方法包括获得训练数据集。 确定训练数据集中的至少一部分训练数据的难度系数， 以便基于训练数据的至少一部分的各自的难度系数来分类训练数据集中的数据的至少一部分的难度。 训练数据具有分子数据，分子数据的难度系数基于分子属性和/或模型训练属性来确定。还包括独立的权利要求： 模型训练方法； 一种分子属性预测方法； 一种分子属性评估方法； 设计方法； 数据处理装置； 模型训练装置； 分子属性预测装置； 分子属性评价装置； 设计装置； 以及 一种计算机可读存储介质，包括一组用于执行数据处理方法的指令。  11
本发明提供了多语言BERT序列标注模型的压缩方法及系统，涉及BERT类模型的知识蒸馏技术领域，该方法包括：步骤1：基于Wordpiece算法从多语语料中抽取词表；步骤2：对多/单语言BERT教师模型、多语言BERT学生模型进行预训练；步骤3：基于人工标注的下游任务数据对多/单语言BERT教师模型进行微调；步骤4：利用多/单语言BERT教师模型对预训练后的多语言BERT学生模型进行残差知识蒸馏；步骤5：基于人工标注的下游任务数据对蒸馏后的多语言BERT学生模型进行微调。本发明通过残差学习和多对一的知识蒸馏方式，提高了学生模型的准确率和泛化程度，降低了多语言环境下BERT类序列标注模型部署所需的硬件资源。多语言BERT序列标记模型压缩方法。该方法通过残差学习和多对一的知识蒸馏方式，提高了学生模型的准确率和泛化度，减少了多语言环境下BER类型序列标签模型部署所需的硬件资源。该方法涉及基于单词片算法从多语言语料库中提取单词列表。 将一个词汇作为训练数据。 预先训练多语言BERT教师模型和多语言BERT学生模型。 基于下游任务数据对所述多语言BERT教师模型进行调整。 利用所述多语言BERT教师模型对所述预训练的多语言BERT学生模型进行残差知识蒸馏。 基于下游任务数据蒸馏后调整多语言BERT学生模型。  12
本发明公开了一种短文本实体情感分析方法、系统、电子设备及存储介质，该方法包括：根据训练文本每一个单词的词向量、位置向量、距离向量、情感向量、句法向量和词法向量得到单词的融合词向量；将融合词向量输入到TD_LSTM网络得到每一个训练文本的LSTM输出向量；将实体词对应的词向量输入全连接层得到每一个训练文本对应的编码后的实体向量；根据LSTM输出向量和编码后的实体向量得到相关性矩阵，并将相关性矩阵输入全连接层和softmax计算得到每一个训练文本对应的实体情感概率值；根据损失函数进行优化得到最优短文本实体情感模型；根据最优模型对待预测文本进行预测得到情感倾向。通过多维信息的共同作用来识别实体的情感倾向，提高了实体情感分析的准确度。短文本实体情感分析方法。该方法使用强大的深度学习模型能力，多个信息维度丰富文本特征表达，使得融合词向量与丰富的语义语法上下文信息融合，从知识角度和深度语义编码角度增强实体与情感词的关系。 该方法通过多维度信息的共同作用识别实体的情感倾向性，提高了短文本实体情感分析的准确率。该方法涉及获取每个训练文本中的词嵌入词、位置向量、距离向量、情感向量、句子向量和词法向量对应的短文本训练集。 所述位置向量用于表征所述词语在所述文本中的位置。 所述距离向量用于表示一个文本中所述词语与所述实体词匹配的情感词之间的距离。 得到待预测文本。 将所述文本输入至最优短文本实体情感模型，得到所述待预测文本的实体情感倾向结果。还包括以下独立权利要求：(a)短文本实体情感分析系统； (b)一种电子设备，包括存储器和处理器，所述处理器执行存储在所述存储器中的用于分析短文本实体情感的方法的指令； (c)一种计算机可读存储介质，包括用于分析短文本实体情感的方法的指令。  12
本发明公开了一种智能化路面病害识别检测方法及系统，该方法采用运动相机、GPS&北斗定位模块作为采集设备，采用改进的卡尔曼滤波算法、Crack‑QuickSort算法以及改进的Crack‑wnet算法进行定位数据和图像数据的预处理与处理操作，能够精确解算出道路病害的位置、长度、宽度和面积信息，结合上述信息进而求取得到路面表面破损状态指数PCI。该系统包括车辆位置获取模块，道路图像检测模块，道路图像特征提取模块，路面病害报表输出模块。本发明的优点在于实现了高精度路面病害检测，构建了整体性路面病害检测系统，此外，采用前景相机进行病害识别的方法使得路面检测设备与成本降低，增加了整个检测过程中的智能化程度。智能路面病害识别方法。该方法能够实现高精度的路面病害检测，构建一体化的路面病害检测系统，此外，病害识别方法采用前景摄像机，减少了路面检测装置，降低了成本，提高了检测过程的智能化程度。 该方法将目标检测器与跟踪器相结合，实现了疾病的快速检测和计数功能，并利用检测框中的图像进行语义分割，提高了疾病分割的精度和性能。该方法涉及获得车辆位置。 通过所述当前车辆位置和所述速度信息计算得到所述车辆的最优位置信息。 检测所述道路图像。 获取基于所述道路图像数据对应的道路图像的感兴趣区域。 基于所述道路图像的感兴趣区域获得对应的路面病害图像的特征。 利用所述车辆位置和所述速度信息使得对应的路面病害图像的特征输入，用于输出所述道路病害检测报告。一种智能路面病害识别检测系统。   6
本发明涉及一种基于深度学习的条码图像补正算法，算法包括下列步骤：要把图像解析成概率分布中的样本点；解析让深度学习如何产生伪图像，用语义分割相关的模型对模糊残缺条码图像进行建模，实现模糊残缺条码图像的补正，针对复杂场景下的模糊或残缺图像进行补正, 接着找到补全修复所需的最佳伪图像，基于U‑net的模糊残缺条码图像补正复原，此类神经网络为一个Encoder‑Decoder结构，其中Encoder是收缩路径，它是由卷积层和池化层组成，为了实现精准定位从三个角度进行模型的优化, 实现模糊残缺条码图像的补正，通过算法使得模糊残缺的条码图像变得完整清晰，从而改善条码图像的识别准确率，为电力仓储全自动无人作业系统保驾护航。一种基于深度学习的条码图像校正方法。本发明从三个角度对模型进行优化，以实现精确定位，并对模糊不完整的条码图像进行校正。 模糊，不完整的条码图像变得完整，清晰，提高了条码图像的识别精度，为电力仓储全自动无人值守系统提供了保障。该方法包括将图像分解为概率分布中的采样点。 本发明通过对深度学习产生伪图像的过程进行分析，利用模糊分割相关模型对模糊不完整条码图像进行建模，将像素级分类问题转化为像素级回归问题。 本发明实现了对模糊和不完整条码图像的校正，对复杂场景中模糊或不完整的图像进行校正。 基于U-网模糊不完全条形码图像校正和恢复，找到互补和修复所需的最佳伪图像。 本发明通过转置卷积使特征地图的尺寸变大，从而恢复原地图的尺寸，实现精确定位。   6
一种融合先验边界的脑肿瘤分割方法，针对现有卷积网络无法充分利用全局图像信息导致生成脑肿瘤分割边界粗糙和重建肿瘤容易假性问题等不足，从肿瘤先验知识中得到肿瘤真值的最优边界，构建最优边界生成网络，在多下采样通道的3D U‑net网络上加入最优边界为网络每层进行权重分配和边界增强，并将生成肿瘤边缘与肿瘤真值边缘的相似度作为损失项加到原来的损失函数中提高边缘分割的准确度。本发明通过多下采样通道利用不同模态核磁影像的肿瘤信息，将先验知识融合到网络和损失函数中，提高了肿瘤信息利用的全面性和肿瘤边缘分割的准确性。融合先验边界的脑肿瘤分割方法。该方法可以解决现有卷积网络不能充分利用全局图像信息生成脑肿瘤分割边界粗糙度，重建肿瘤容易出错的问题； 可提高全脸肿瘤边缘分割的准确性和肿瘤信息的利用率。该方法包括提取脑肿瘤先验边界特征。 肿瘤边界通过腐蚀算法得到。 随机取边界点。 最优边界点被连接以形成最优边界。 建立最优边界生成网络模型。 构建三维(3D)U网基础网络模型的多下采样通道。 获得两种模式的核磁图像。 同一层的边界在两种模式上重叠。 利用先验边界知识来增强模态边界。  7
本公开提供的政务标签库的生成方法、政务文本的标签确定方法和装置，涉及人工智能领域，具体涉及自然语言处理、深度学习、预训练模型技术，可应用在智慧城市、智慧政务等场景；该生成方法包括：获取待处理文本，并对待处理文本进行短语挖掘处理，得到挖掘后的词语；其中，挖掘后的词语的成词概率大于预设阈值；若初始政务标签库中不包含挖掘后的词语，则对初始政务标签库中的词语和挖掘后的词语进行层次聚类处理，得到聚类结果；聚类结果包括：词语的所属的类簇和词语的层级关系信息，根据聚类结果，对初始政务标签库进行更新处理，生成更新后的政务标签库。通过上述方法可以自动的对初始政务标签库进行更新，有利于提高政务标签库的生成效率。用于自然语言处理、深度学习、预训练模型技术领域的应用于智慧城市和智慧政务等场景中的政府标签库生成方法。该方法自动更新初始政府标签库，有利于提高政府标签库的生成效率。该方法涉及获得(S101)待处理的文本。 对所述待处理文本进行词组挖掘处理(S102)，得到挖掘词。 挖掘出的词语的成词概率大于预设阈值。 将初始政府标签库中的词语与挖掘出的词语进行层次聚类处理(S103)，得到聚类结果。 初始政府标签库中包括至少一个词。 所述聚类结果包括所述词语所属的聚类和所述词语的层级关系信息。 所述层级关系信息表征所述词语在所述词语所属聚类中的层级关系。 根据聚类结果对初始政府标签库进行更新(S104)以生成更新政府标签库。 更新后的政府标签库用于确定待标注文本对应的标签。包括以下独立权利要求：用于确定政府事务文本的标签的方法； 政府标签库生成装置； 用于确定政务文本的标签的装置； 电子设备； 存储用于生成政府标签库的计算机指令的非暂时性计算机可读存储介质； 以及用于生成政府标签库的计算机程序产品。  11
提供了一种信息抽取模型训练方法和装置以及信息抽取方法和装置。所述训练方法包括：针对多个联合信息抽取任务中的每个任务构建对应的结构化提示器模板，得到多个结构化提示器模板；获取第一训练样本数据和第二训练样本数据；基于所述第一训练样本数据和所述多个结构化提示器模板对基准模型进行预训练，得到训练好的预训练模型；基于所述第二训练样本数据和所述多个结构化提示器模板对预训练模型进行微调训练，得到训练好的信息抽取模型；其中，所述信息抽取模型用于基于所构建的结构化提示器模板的提示，从输入文本数据抽取与所述多个联合信息抽取任务分别对应的结构化语言。用于通过使用电子设备训练金融机构即中学中的信息提取模型的方法(要求保护)。 也可以用于证券行业和银行业。该方法使得与同一语料相关的信息抽取任务能够利用统一的结构化语言和结构化提醒模板，实现了同一训练数据、同一模型和同一训练过程来执行信息抽取任务，减少了多次训练带来的冗余和效率，从而省去了将模型抽取结果即文本、结构不统一重新结构化的操作，提高了模型的普适性，实现了更好地利用相关信息抽取任务之间的相关性。该方法涉及为多个联合信息提取任务中的每个任务构建相应的结构化提醒模板(S101)。 得到多个结构化提醒模板。 获得第一训练样本数据和第二训练样本数据(S102)。 基于所述第一训练样本数据和多个结构化提醒模板对参考模型进行预训练(S103)，以获得已训练的预训练模型。 基于训练样本数据和结构化提醒模板对预训练模型进行微调训练(S104)。 获取训练好的信息提取模型，所述信息提取模型基于构建的结构化提醒模板进行提示。 从输入的文本数据中提取与多个联合信息提取任务对应的结构化语言。独立权利要求还包括：一种信息提取方法； 信息抽取模型训练装置； 信息提取装置； 以及计算机可读存储介质，用于存储用于训练金融机构中的信息提取模型的指令集。  11
本发明公开了一种基于增强预训练文本匹配模型的文本匹配方法，构建增强预训练文本匹配模型对文本进行推断，输出结果；所述增强预训练文本匹配模型在预训练模型的基础上增加对齐掩码矩阵，所述增强预训练文本匹配模型以Align_Transformer为骨架，Align_Transformer是Transformer模型的改进，包括特征提取器和分类器；所述特征提取器使用堆叠的Align_Transformer模块对文本对进行编码得到文本特征。本发明解决了预训练模型在文本匹配任务中由于缺少对齐交互信息导致的短句匹配困难、鲁棒性不强问题。增强的基于预训练文本匹配模型的文本匹配方法。该方法解决了文本匹配任务中由于缺少对齐交互信息，导致预训练模型难以匹配短句，鲁棒性不强的问题。该方法涉及构建增强的预训练文本匹配模型。 采用预训练模型对增强后的预训练文本匹配模型中的相应参数进行初始化。 在增强后的预训练文本匹配模型中随机初始化一个添加参数。 构建损失函数。 采用不同的学习率对所述预训练模型参数和所述添加参数进行更新。 采用学习速率预热和衰减策略对所述增强型预训练文本匹配模型进行训练。 导出训练好的增强预训练文本匹配模型。 设定评价模式。 推导出待预测文本对。 输出结果。  11
本发明公开一种基于GPT3的问答系统文本生成方法及装置，该方法包括：将语料集合中的样本文本S转化为向量Is；对输入的语料集合按照步骤S1的方法生成字向量矩阵V；基于所述初始查询矩阵和键值矩阵构建注意力矩阵A；根据所述字向量矩阵V和注意力矩阵A计算样本矩阵P；将所述样本矩阵P作为输入，进行多层Performer编码计算后得到矩阵Px；基于步骤S5的方法，对所述样本矩阵P进行不断迭代训练，构建文本生成模型M；利用所述文本生成模型M自动生成文本。本专利可以通过该生成式问答系统，能够对答案库进行扩展，便于与用户进行无感交互，解决了现有业务知识库中业务问答对较多，但无法覆盖所有业务场景、无法覆盖用户问题的技术问题。基于GPT3的问答系统文本生成方法。该方法通过生成问答系统扩展答案库，便于与用户进行无感交互，解决了现有业务知识库中业务问答对较多，但不能覆盖所有业务场景和用户问题的技术问题。该方法涉及将一组语言数据中的样本文本转换成向量(S1)。 为所述语言学数据的输入集合生成词向量矩阵(S2)。 基于初始查询矩阵和键值矩阵构建注意力矩阵(S3)。 根据所述词向量矩阵和所述注意力矩阵计算样本矩阵(S4)。 样本矩阵被用作输入(S5)。 进行多层执行器编码计算，得到矩阵。 不断迭代训练样本矩阵，构建文本生成模型(S6)。 所述文本生成模型用于自动生成文本(S7)。还包括独立权利要求用于基于生成式预训练变压器三(GPT3)的问答系统文本生成装置。  12
本发明公开了一种城市事件预警管理系统及方法，包括模型训练模块对预训练模型调整得到风险预测模型，将实时事件数据输入风险预测模型得到事件预测结果；分析单元根据语义识别算法对实时事件数据分析得到语义分析数据；分类单元根据数据分类算法对语义分析数据进行分类，得到实体分类数据、类型分类数据和标签分类数据；数据聚合模块根据数据归类算法对实体分类数据、类型分类数据和标签分类数据进行重点数据归类得到重点类型数据；级别划分模块按照阈值划分规则对各重点类型数据进行级别划分得到风险级别；展示模块根据各风险级别生成可视化展示图，以及根据事件预测结果和重点类型数据生成完整性分析报告。本发明提升城市事件预警的精细度。城市事件预警管理系统。该系统提高了城市事件预警的精细化程度。 该系统实现了城市事件中的重要类型数据直观，明确，精细，完整的显示，提高了城市预警能力。该系统具有分析单元(31)，用于根据预设的语义识别算法对多个实时事件数据进行语义分析以获得多个语义分析数据。 分类单元(32)与分析单元相连，用于根据数据分类算法基于实体类型，事件类型和事件标签对语义分析数据进行分类。 数据汇总模块(4)与数据分类模块(3)相连。 显示模块(6)分别与层级划分模块(5)，数据聚合模块和模型训练模块(2)连接，用于根据每个关键类型数据的风险级别生成可视化显示图像。 根据事件预测结果和关键类别数据生成完整性分析报告。本发明还涉及一种城市事件预警管理方法。  11
本发明属于图像处理技术领域，公开了一种图像语义分割方法及系统，所述系统包括输入模块、数据预处理模块、多层级Swin Transformer编码器、瓶颈模块、多层级Swin Transformer解码器、Vision Transformer多尺度特征聚焦跳过连接模块、和预测输出模块，通过本发明能够捕获多尺度全局特征相关性信息，突出高阶语义信息的关键信息。图像语义分割系统，用于对具有不同语义的像素进行分类。该方法充分考虑了水下场景对象多尺度特征之间的相关性以及低阶表示信息与高阶语义信息之间的相关性，提高了水下场景图像分割效果，有效提高了水下场景图像中不同尺度对象的分割精度。该系统具有用于获取待分割水下场景图像的输入模块。 数据预处理模块，用于将所述输入图像切割或缩放为预处理图像，将所述预处理图像重叠切割为图像块，并将每个图像块在通道维度上展平，得到数据序列。 预测输出模块包括第二上采样模块和预测模块。 第二上采样模块与上采样解码模块中的上采样模块结构相同，预测模块由Softmax分类器构成。 第二上采样模块，用于调整特征图的分辨率和通道数，得到与预处理图像等高等宽的特征图。 预测模块，用于对特征图进行预测并使用Softmax分类器以像素为单位对每个像素的语义类别进行预测，得到最终的分割结果图。包括一种用于对具有不同语义的像素进行分类的图像语义分割方法的独立权利要求。   5
本申请公开了一种通用语言模型的训练方法、使用方法、装置、设备和介质，属于人工智能技术领域。该方法包括：获取至少一种模态的样本数据，至少一种模态的样本数据标注有标签信息，标签信息包括样本可信度；将至少一种模态的样本数据输入通用语言模型，通过通用语言模型中的目标判定网络，得到至少一种模态的样本数据对应的预测信息，预测信息包括预测可信度，目标判定网络用于使通用语言模型具备基于场景进行可信度判定的能力；基于预测信息和标签信息，对通用语言模型的模型参数进行训练。该方案可应用于大语言模型、多模态大模型领域中，可应用于自然语言生成、问答系统场景，能够实现对输入数据对应的预测数据在目标场景中的可信度进行判定。用于训练自然语言生成和问答系统中使用的大语言模型和多模态大模型等通用语言模型的方法。由于可以通过通用语言模型中的目标判断网络获取目标场景中预测数据的可信度，使得用户能够根据可信度进行后续决策，因此提高了目标场景中数据推理判断决策的效率。所述方法包括：将所述模态的样本数据输入(240)通用语言模型，通过所述通用语言模型中的目标确定网络获取与所述一个模态的样本数据对应的预测信息，所述预测信息包括预测可信度。 所述通用语言模型是包括所述目标确定网络的语言模型，所述目标确定网络用于使所述通用语言模型具有基于场景执行可靠性确定的能力。 基于所述预测信息和所述标签信息来确定(260)训练损失。 基于所述训练损失对所述通用语言模型的模型参数进行训练(280)。独立权利要求包括以下内容：(1)使用通用语言模型的方法； (2)通用语言模型的训练装置； (3)使用通用语言模型的装置； (4)计算机装置； (5)计算机可读存储介质，其存储用于训练通用语言模型或用于使用通用语言模型的程序； 以及(6)用于训练通用语言模型或用于使用通用语言模型的计算机程序产品。  11
一种基于深度学习的城市道路场景语义分割方法，包括以下步骤：1)、车辆前端的图像采集；2)、标注图像与原图像输入数据扩充：将图像随机裁剪、拼接或添加不同类型噪声，再通过图像仿射矩阵对图像变换，最后通过填充和裁剪等变换，保持图像的原有分辨率，得到数据集；3)、使用数据扩充后的图像和标注图像进行网络的训练，残差U‑net网络包括下采样部分、桥梁部分、上采样部分和分类部分；4)修改采集模块时间间隔T，将后续得到的图像输入训练好的深度学习模型中，输出预测的语义分割图像，并将图像中不同灰度回传给处理器。本发明使用较小数据集，同时可以防止梯度下降过快，并且能够保证在训练时不发生过拟合问题。基于深度学习的城市道路场景语义分割方法。方法使用小数据集，可以防止梯度下降过快，并且可以确保过拟合，这在训练期间不会发生。该方法涉及每隔一段时间采集城市道路图像，该图像设定时间间隔，分辨率设定输入图像检测模块对图像进行检测，得到有效图像。 图像输入标注模块，系统使用开放图像界面标注软件进行标注。 图像被提供在车辆、行人、自行车、交通灯和霓虹灯物体上，它们被框出并且被标记为不同的类别。 生成的标注图像通过不同的灰度级反映不同类型的物体，由标注图像的不同灰度级得到灰度列表和图像。 13
本发明涉及一种基于聚类和多尺度学习的无监督跨域行人重识别方法，包括：构建相同的两个原始卷积神经网络，对两个原始卷积神经网络分别采用不同的初始化参数利用源域训练集进行预训练，得到预训练完成的两个预训练学生模型，并分别复制得到两个预训练教师模型；构建图片特征记忆库；利用目标域训练集对两个预训练学生模型和两个预训练教师模型进行多轮目标域交互监督学习，直至达到得到预设的学习终止条件，得到跨域学习完成的两个学生模型和两个教师模型；利用跨域学习完成的任一个模型对目标域查询样本进行识别，找到目标域底库图片集中具有相同标签的图片，完成行人重识别。本发明的方法提高了无监督跨域行人重识别的识别精度。基于多类别和多尺度学习进行无监督跨领域行人再识别的方法。可以提高无监督跨域行人再识别的识别精度。 可以降低伪标签噪声。 提高了聚类的准确率。该方法涉及构建两个原始卷积神经网络。 采用不同的初始化参数对源域训练集进行预训练，得到第一预训练学生模型和第二预训练学生模型。 根据聚类结果构建图片特征存储库。 根据所述聚类结果在所述图片特征内存库中更新所述图片特征和一标签。 在每轮目标域交互监控学习时采用网络总损失更新所述第一预训练教师模型和所述第二预训练教师模型的参数。 利用跨领域学习完成的任意一个模型对目标领域样本查询进行识别。   4
本发明提供一种姿态识别方法、系统、设备及介质，包括：对无标签姿态序列图片进行自监督学习，生成预训练模型；将有标签姿态序列图片输入至所述预训练模型中进行迭代训练，并在迭代训练过程中对所述预训练模型进行参数调节，生成用于识别目标对象姿态的姿态识别模型。本发明可以在有标签数据较少的情况下，通过使用大量无标签数据，提升模型对于人体姿态的表征能力，提高行人行为识别任务的表现。而且本发明提出的自监督对比学习方式有效地利用了人体图像数据中的人物ID信息和时序帧间信息，特别是把相同人物ID、相邻时序的图片作为负例对，可以直接忽略掉相同人物ID内的人像信息，着重地关注于人体姿态的变化。一种行人姿态识别方法，用于计算机视觉和视频监控的行人姿态识别，深度神经网络特征化和人体图像学习。本发明能够提高人体姿态表示能力的模型，提高行人行为识别的性能。该方法包括对非标签姿势序列图像执行自我监督学习以生成预训练模型。 将标签姿态序列图像输入到预训练模型中进行迭代训练。 在迭代训练过程中对预训练模型执行参数调整过程，以生成针对目标对象姿态的姿态识别。 对目标视频执行对象检测和成帧处理。 生成多帧无标签姿态序列图片，得到每帧无标签姿态序列图片的对象编号和图片帧编号。本发明还涉及一种姿态识别系统(1)； (2)计算机设备； (3)用于存储行人姿态识别方法的一组指令的计算机可读介质 14
本申请涉及工业缺陷检测技术领域，具体而言，涉及一种缺陷检测中特征库的建立方法、缺陷检测方法和装置，一定程度上可以解决缺陷检测方法中的特征库存在冗余数据的问题。将正样本图像数据通过预训练的第一网络模型，提取第一初始特征向量，并根据第一初始特征向量建立初始特征库；触发第二网络模型拟合第一网络模型，通过拟合后的第二网络模型对正样本图像数据提取第二特征向量，基于第二特征向量与对应的第一初始特征向量的匹配程度，确定第一初始特征向量对应的频率程度；筛选出第一备选特征向量(频率程度大于第一程度或小于第二程度的第一初始特征向量)，并根据第一备选特征向量建立目标特征库，减少特征库中的冗余数据。利用终端设备在工业缺陷检测中建立特征库的方法(权利要求书)。该缺陷检测中缺陷检测特征库的建立方法提高了相应的缺陷检测效率。 该方法减少了特征库中的冗余数据。 缺陷检测模块，基于所述第一位置的异常分数，确定所述待检测图像的缺陷。该方法包括使正样本图像数据通过预训练的第一网络模型(S110)。 提取所述第一初始特征向量。 根据所述第一初始特征向量建立初始特征库。 触发所述第二网络模型拟合所述第一网络模型(S120)。 通过拟合后的第二网络模型提取正样本图像数据的第二特征向量。 基于第二特征向量与对应的第一初始特征向量的匹配度，确定第一初始特征向量对应的频度。 从第一初始特征向量中筛选第一备选特征向量(S130)。 根据所述第一备选特征向量建立目标特征库。 第一替代特征向量是频率度大于第一度或小于第二度的第一初始特征向量。独立权利要求还包括：一种使用终端设备的缺陷检测方法； 利用终端设备在工业缺陷检测中建立特征库的装置； 使用终端装置的缺陷检测装置； 以及一种计算机存储介质，具有用于存储用于在利用终端设备进行工业缺陷检测中建立特征库的指令集。 14
本发明提供了一种基于BART模型的正则表达式描述生成方法，包括以下步骤：(1)搜集高质量的正则表达式，对正则表达式人工标注对应的自然语言描述，针对数据进行预处理；(2)将分词输入嵌入层生成最终的特征向量X；(3)改进BART模型。本发明的有益效果为：该方法对输入的正则表达式生成高质量的自然语言描述，从而帮助计算机科学初学者以及开发人员更加快速的理解正则表达式。用于基于BART模型生成用于软件开发，软件维护和软件测试过程中的正则表达式描述的方法。 也可用于操作系统中，如窗户 (RTM : 操作系统)，Linux (RTM)：计算机操作系统和编程语言，例如自然铜 (RTM : 解释的高级通用编程语言)，C语言，Java (RTM)：高级，基于类和面向对象的编程语言)和PHP (RTM)：流行的通用脚本语言。该方法能够为输入的正则表达式生成高质量的自然语言描述，帮助计算机科学初学者和开发者快速理解正则表达式， 保证BART模型在资源较少的情况下生成自然语言描述的质量， 在自注意机制中，利用范数-注意机制代替原有的BART模型，使得该注意机制在不牺牲表达式的情况下，使得SoftMax函数不易产生饱和。该方法包括收集高质量的正则表达式。 手动标记所收集的正则表达式以获得相应的自然语言描述。 最后生成数据集。 将数据集中的每个实例的格式设置为正则表达式。 对数据集中的字正则表达式执行字节级字节对编码(BBPE)字分段处理。 数据集被细分为训练集和验证集。 基于双向和自回归变压器(BART)模型训练初始模型。 基于所述验证集来执行所述初始模型的微调。 最后基于BART模型的正则表达式构造描述生成模型。 生成相应的高质量文本描述。 利用SoftMax函数得到每个词产生的概率。 最后利用波束搜索算法来生成最终的文本描述。  12
本发明公开了一种多任务中文实体命名识别方法，包括以下步骤：(1)首先对数据进行预处理，划分数据集并进行标注任务设置；(2)通过BERT对输入的主任务数据和辅任务进行特征抽取；(3)对于主任务和辅任务分别采用双层的包括输入、隐藏和输出的LSTM神经网络模型对词向量进行分类训练；(4)将辅任务和主任务的训练好的隐藏层信息经过注意力机制层进行全连接(5)最后经过CRF层考虑了序列中的全局标签信息，输出最优的标签序列；(6)通过验证集对训练好的模型进行性能评估。本发明能够帮助研究者在海量的中文文本数据中高效地获取有价值的信息和知识，有效的缓解了人工抽取信息耗时耗力的问题，对进一步文本挖掘工作的具有重要意义。该方法可用于文本挖掘技术领域的多任务中文实体命名识别，也可用于多任务学习(MTL)领域。该方法有助于研究人员高效地获取海量中文文本数据中有价值的信息和知识，有效缓解了人工提取信息消耗时间消耗的问题。 该方法提供了提高实体的标准水平的高可用性。 一种高效的基于BERT和BiLSTM-AM-CRF的多任务中文实体命名识别方法，通过训练集建模来拟合数据样本，通过验证集调整模型的超级参数，通过测试集评估模型的泛化能力最终得到模型。该方法包括获取至少两个不同的标注中文句子数据集，并进行预处理。 双向编码器/解码器、双层长期记忆网络层、注意力网络、隐藏层和条件随机场层的双向编码器-BiLSTM-CRF网络结构，其中编码器、解码器、双向长期短期记忆(BiLSTM)网络层和条件随机场层包括两个并行的相同结构，两个双层长期记忆网络层输出到同一个隐藏层。 通过预训练单元BERT分别通过解码器和编码器对不同的数据集进行特征提取，得到词向量。 将得到的词向量输入双长期存储网络层。 提取包括健忘门、记忆门和输出门的神经网络层对词向量的信息。  12
本发明涉及自然语言处理技术领域，特别涉及一种专名识别方法，用于得到专名实体标签，方法包括以下步骤：获取输入文本并对输入文本进行编码，得到输入文本中每个实体的隐向量；将隐向量基于大量相似词组成的预训练词向量库得到每个实体的语义增强隐向量；将语义增强隐向量经过分类转换处理，得到每个实体对应的专名实体标签。本发明还提供一种计算机设备、可读存储介质和程序产品，解决传统的专名识别模型难以正确地抽取训练时未遇到的实体的技术问题。特殊名称的识别方法。每个实体的语义增强隐藏向量是基于由隐藏向量中的大量相似词组成的预训练词向量库获得的，因此能够通过对键值存储器中的关于任务的先验知识进行编码来减小直读文本与来自预训练词向量库的答案之间的差异，并且还能够为输入文本提供特殊识别模型灵活性来进行编码，并且能够更方便地预测实体之间的关系类型， 并保证特殊名称识别模型在训练时容易正确提取未遇到的实体。特殊名称识别方法包括获取输入文本，并对输入文本进行编码。 获取输入文本中每个实体的隐藏向量。 由所述隐藏向量基于预先训练的由大量相似词组成的词向量库，得到语义增强的隐藏向量。 对所述语义增强隐藏向量进行分类转换，得到每个实体对应的特殊名称实体标签。所述方法包括：(a)计算机设备具有存储在所述存储器上的计算机程序; (b)用于存储计算机程序指令的可读存储介质; (c)用于执行计算机程序指令的程序产品。  12
一种基于多任务学习的生物医学命名实体识别方法，属于实体识别技术领域，建立基于多任务加入依存句法信息的命名实体识别模型，通过图卷积神经网络提取依存句法信息加入到输入句子中，经过BERT编码后的标签信息利用共注意力交互机制得到交互矩阵，再通过边界检测任务和SPAN段分类任务进行实体识别，将生物医学命名实体识别任务由序列标注任务转化为多任务，具体为边界检测和跨度分类联合任务，解决了边界识别不清和实体嵌套问题；对数据集进行句法依存分析，并使用GCN对句法依存分析图进行编码并融入到多任务里，使模型充分学习了文本中的句法成分以及成分之间的关系，提高了命名实体识别性能。基于多任务学习的生物医学命名实体识别方法，用于识别化学品、疾病、基因和蛋白质等实体类型，用于人名、地名、机构名称、时间、货币等实体类型。该方法进行边界检测和跨度分类的组合任务，解决了边界识别不清晰和实体嵌套的问题。 对所述数据集进行句法依存分析。 图卷积神经网络(GCN)对句法依存分析图进行编码并融入多任务中，使模型充分学习文本中的句法成分以及成分之间的关系，提高命名实体的识别性能。该方法涉及基于依存句法信息的多任务添加建立命名实体识别模型。 通过图卷积神经网络提取所述依存句法信息。 将依存句法信息添加到输入句子中。 通过共同的注意力交互机制，将经过BERT编码后的标签信息，通过边界检测任务和跨度截面分类任务进行实体识别，得到交互矩阵。  12
本发明涉及样本处理技术领域，尤其涉及一种利用关键词对样本进行增强的方法、系统和电子设备，方法包括：得到并将待增强样本的拼音序列与拼音关键词词表进行匹配，得到命中关键词列表；使用bert模型中的embedding层获取待增强样本对应的第一向量，以及获取命中关键词列表对应的第二向量；将第二向量和第二向量进行拼接，得到第三向量；将第三向量输入到bert模型的transformer编码器层，得到用于分类的隐藏状态的cls向量。一方面，使待增强样本增加了关键词特征信息，能够提升样本分类准确率和召回率，另一方面，使用拼音匹配命中待增强样本对应的关键词列表，可以解决待增强样本中的同音变体问题。用于在电子设备中使用关键字增强样本的方法(要求保护)。采用本发明的方法，可以将样本加入关键词特征信息进行增强，从而提高了样本分类的准确率和召回率，避免了样本中出现同音变异的问题。该方法包括对待增强样本进行拼写，得到待增强样本的拼音序列。 将所述待增强样本的拼音序列与拼音关键词列表进行匹配，得到命中关键词列表。 利用bert模型中的电池层获取所述待增强样本对应的第一向量。 利用所述bert模型中的电池层获取命中关键字列表对应的第二向量。 将所述第二向量进行拼接，得到第三向量。 将第三向量输入到bert模型的主编码器层，得到用于分类的隐藏状态的cls向量。独立权利要求还包括：一种通过关键词增强样本的系统； 以及存储介质，用于存储一组使用关键字增强样本的指令。  12
本发明提供一种基于集成学习的多模态融合视线估计框架，包括如下步骤：进行特征提取，分别对摄像头下的视频信息和对应音频中的信息进行提取；采用多模态Transformer进行特征融合，在减少了参数的同时提取了更多的信息；使用集成学习组合多个个体学习模型，提高预测准确率。该基于集成学习的多模态融合视线估计框架具有的优点如下：(1)使用更高效的LMF‑MET框架处理视频和语音信息，使得模型可以完全利用视频信息和音频信息，并对多模态信息进行深入的交叉感知。(2)采取集成学习，利用多个个体学习器，将多个个体学习器结合成强的学习器，使得模型对数据的准确度得到了提升，并加快模型学习速度，从而提高视线估计预测效率。基于集成学习的多模态融合视线估计框架。多模态融合视线估计框架采用更高效的LMF-MET帧处理视频和语音信息，使得模型能够完全利用视频信息和音频信息，以及多模态信息进行深度交叉感知。 提高了模型数据的准确性，并加快了模型学习速度，从而提高视线估计预测效率。进行特征提取的框架，分别提取摄像头下的视频信息和对应音频中的信息。 采用多模态互感器进行特征融合，减少了参数，提取的信息更多。 所述集成学习用于组合多个个体学习模型，以提高预测精度。 9
本发明涉及光学自干涉数字全息技术领域，尤其涉及一种基于深度学习的光学自干涉数字全息重构方法及系统。本发明提出了一种以U‑Net为基础的端对端的神经网络直接实现菲涅尔非相干相关数字全息单次曝光相位重构的方法，其中，菲涅尔全息图通过光路采集，可以提高成像速度，加快网络的训练速度，同时，训练得到的全息重构模型，能够在单幅菲涅尔全息图的条件下，实现样品的相位重构，因此减少了环境的干扰以及振动的影响，提高了动态测量下的可用性。基于深度学习的光学自干涉数字全息重建方法。该方法通过基于神经网络U‑Net的端到端直接实现菲涅尔非相干相关数字全息单次曝光相位重建，菲涅尔全息图采用光路采集，可以提高成像速度，加快网络训练速度，得到全息重建模型，从而实现在单张菲涅尔全息图的条件下对样品进行相位重建，减少环境的干扰和振动的影响，提高动态测量的可用性。该方法涉及构建(S1)基于U-Net卷积神经网络的端到端。 通过菲涅尔非相干自干涉光路采集(S2)多组不同相移的菲涅尔全息图。 通过三步相移算法对不同相移量的菲涅尔全息图进行处理(S3)，得到复值全息图。 根据训练数据集来训练(S4)卷积神经网络，其中在卷积神经网络的处理中，训练数据集和测试数据集被改变(S5)作为卷积神经网络的输入。 组合训练误差曲线和测试误差曲线(S6)。 对卷积神经网络进行优化调整。 菲涅耳全息图被输入(S7)到菲涅耳非相干相关数字全息图重建模型中。 得到对应的菲涅尔全息图相位重建模型。包括独立权利要求用于基于深度学习的光学自干涉数字全息重建系统。   6
本发明提出一种使用综合技术降低多机多卡训练和微调大语言模型成本的方法。通过采用零冗余优化、优化器卸载、模型分布式加载、数据Auto‑Parallelism方法进行训练和微调，相比传统方法，可以大幅减少显存开销，降低硬件成本。分布式计算环境下综合技术降低多机多卡训练和微调整大型语言模型成本的方法。该方法通过采用零冗余优化、优化器卸载、模型分布式加载、数据自动流水处理进行训练和微调，降低了多机多卡训练的成本，并对大型语言模型进行了微调整，同时降低了显示内存成本和硬件成本。该方法涉及将大型深度学习模型划分为多个独立的子模型。 每个子模型被划分成适合于视频存储器容量的小数据块。 模型参数被切片并分配到不同的图形处理单元(GPU)。 通过使用自动并行技术将数据块并行地加载到显示存储器。 每个GPU上的梯度在主GPU上进行计算和聚合。 通过通信帧将反向发送结果和模型发送给计算设备。 显存资源的分配和释放是动态管理的。 根据需求及时释放计算出的数据块的显存资源。  11
本发明提出一种基于生成对抗网络的姿势引导人体图像生成及面部优化方法，其中图像生成模块通过导入预训练模型，生成前期的人体图像和人脸图像；姿势引导生成模块将人体图像转换为需要的目标姿势；面部定位模块定位出需要优化的人脸部分，优化模块对定位区域进行三个目标的联合优化最终输出目标图像。通过使用本发明所述的方法，可以生成拥有高清面部的目标姿势人体图像。基于生成对抗网络的姿态引导人体图像生成及人脸优化方法，用于创建虚拟角色、虚拟试衣、运动传递和视图合成，用于基于合成图像的人脸编辑、电影制作和图像检索领域，用于计算机视觉和人工智能领域。可以生成具有高清人脸的目标姿态人体图像。 生成高清晰度、高质量的全身图像。该方法涉及在DeepFashit数据集和FFHQ数据集上引入StyleGan2-ADA网络，用于预训练全身图像生成器、人脸生成器和VGG16模型以及facenet-pytorch。 将随机生成的潜码导入人体和人脸生成器，生成高清全身图像和高清人脸图像。 将所述人体图像和所述姿态点位置信息作为输入，将所述人体图像转换为所述目标姿态。 利用facenet-pytorch定位网络对人脸图像和人体图像进行人脸区域定位，以便后续进行人脸替换和优化。 建立优化函数，对随机生成的潜在码进行联合优化。 将给定的人脸图像插入到生成的人体图像中，实现人脸质量与姿态的提升匹配功能，实现图像的全局协调。 2
本发明公开一种基于预训练的搜索问答系统，包括噪音判断模块、QA问答模块、知识匹配模块和响应输出模块；噪音判断模块对用户问题是否属于噪音进行判断，QA问答模块包括规则录入单元和规则解析单元，知识匹配模块对问题与问答库中的知识进行索引并作出相似度排序，知识索引包括倒排索引和Annoy索引两种方式，响应输出模块用于输出响应，响应包括相似问题列表、准确答案、无答案、推荐热门问题四种类型。本发明可以有效解决知识泛化迁移、噪音判断和QA定制的问题，在改善用户体验的同时，极大的提高问答效率。用作基于预训练的搜索和回答系统。该系统能够解决知识泛化转移、噪音判断和问答定制的问题，提高了用户体验，大大提高了问答效率。基于预训练的搜索回答系统包括噪声判断模块，通过行业词库和排除词库判断用户的问题是否属于噪声。 当用户问题包含行业词且不包含排除词时，则视为非噪音，进入问答模块进行分析。 规则分析单元，用于分析所述规则录入单元录入的用户问题，并判断所述解析出的用户输入是否必须准确返回答案，若是，则响应输出模块输出所述问题对应的标准答案，若否，则将所述解析出的问题发送至所述知识匹配模块。 知识匹配模块，对所述问句数据库中的知识进行索引排序。 应答输出模块，用于输出应答。 3
本发明涉及一种基于大模型抽象事理图谱构建的事件预测方法，属于人工智能、大数据领域。本发明首先基于大模型chatGLM2抽取事件信息，构建抽象事理图谱；再者，基于抽象事理图谱筛选出候选事件，形成新的事件链条；最后，将新的事件链条作为图神经网络事件预测模型的输入，预测出候选事件。本发明提出了融合候选事件转移概率的注意力机制，一方面，学习候选事件和已发生事件上下文的相关性；另一方面，也学习了候选事件本身的概率信息。本发明提出的模型不仅增强了可解释性，也学习到了上下文信息。基于构建大模型抽象事件图的事件预测方法。该方法不仅增强了可解释性，而且还学习了上下文信息。事件预测方法包括基于抽象事务图进行事件预测，以及基于抽象事务图筛选候选事件。 基于转移概率注意力机制提出图神经网络事件预测模型，对抽象事件图结构进行网络表示学习，预测事件。 基于所述抽象事件图进行候选事件的筛选。 抽象事件图显示事件的因果演化关系。 如果同一领域发生新事件，则通过与构建的高度泛化的抽象事件图进行对比，发现新事件可能的演化方向。 融合事件转移概率注意力机制的图神经网络事件预测模型。  12
本公开提供了一种基于自然语言理解的文本要素提取方法、神经网络的训练方法、装置和设备，涉及人工智能领域，具体涉及自然语言处理、深度学习技术，可应用在智慧城市、智慧政务场景下。文本要素提取方法包括：在目标文本中确定目标下位词；构造目标输入，目标输入至少包括目标文本；利用预训练模型对目标输入进行处理，以得到中间特征，其中，中间特征表征目标文本的语义信息，并且表征目标下位词的语义信息和目标下位词在目标文本中的位置中的至少一个；以及利用上位词确定子网络对中间特征进行处理，以得到与目标下位词对应的上位词。用于诸如膝上型计算机、台式计算机、工作台、个人数字助理、服务器、刀片服务器和大型计算机等电子设备(要求保护的)的基于自然语言理解的文本元素提取方法。利用文本的语义信息更好地判断下位词属于哪一个上位词，提高了模型输出结果的准确性。该方法涉及确定(S201)目标文本中的目标低位词。 构建(S202)所述目标输入，并将所述目标输入与所述目标文本一起提供。 利用所述预训练模型对所述目标输入进行处理(S203)，以获得所述中间特征。 所述中间特征表示所述目标文本的语义信息，表征所述目标低词的语义信息以及所述目标低词在所述目标文本中的位置。 利用所述上位词(S204)确定子网络对所述中间特征进行处理，以得到所述目标下位词对应的上位词。 将所述目标下词与所述目标文本进行拼接，从而得到所述目标输入。以下包括独立权利要求：(1)一种用于训练神经网络的方法； (2)一种基于自然语言理解的文本元素提取装置； (3)用于训练的神经网络； (4)电子设备； (5)一种非暂态计算机可读存储介质，存储用于使计算机执行文本元素提取方法的计算机指令； 以及(6)—种计算机程序产品，包括用于执行文本元素提取方法的计算机程序。  11
本发明涉及提示学习训练方法的技术领域，特别是涉及一种基于用户数据的提示学习训练方法、装置和介质，其通过进行自动化标签词构建，从输入信息中提取关键词k；接着，通过设计自注意力机制计算用户模板中用户原始信息和用户前期交互信息的权重参数，基于迁移学习方法生成模板并拼接用户模板，然后结合模板与用户模板形成最终的Prompt输入到LLM，最后实现利用原始预训练参数完成新的下游任务；包括以下步骤：关键词抽取、用户原始信息和用户前期交互信息复用、模板生成与拼接和输出。本发明还包括运行所述方法的装置和介质。本发明能能够提升输出内容精确度的同时实现对于不同用户的个性化内容输出。基于用户数据的提示学习训练方法。该方法能够提高输出内容精度，实现针对不同用户的个性化内容输出。该方法包括提取文本关键词。 获取所述用户原始信息和所述用户前期交互信息。 通过自关注机制计算用户原始信息和用户与LLM前期交互信息权重。 构建具有代表性来源提示的提示库。 从具有代表性的源生成任务中学习到源提示，然后将该提示作为目标提示进行传输，从而执行目标生成任务，其能够有效地从具体数据实例的源提示中学习到最适合的提示表达，进而拼接出适合具体任务的新提示。 将用户模板和作为LLM输入的模板进行拼接。独立权利要求包括以下内容：(1)基于用户数据提示学习训练的装置； 以及(2)计算机可读存储介质，其存储用于基于用户数据提示学习训练的程序。  11
一种共时与跨域异步融合驱动的行为识别方法，包括：获取多人人体彩色图像作为图像序列；从截取图像中估计二维人体姿态，计算二维人体姿态的关键点热图作为姿态序列；建立表观网络，以图像序列作为输入并提取图像特征；同时，建立姿态网络，以姿态序列作为输入并提取姿态特征；以图像特征和姿态特征作为输入，将图像特征和姿态特征进行缩放、对齐和融合；将融合后的图像特征和姿态特征归一化，拼接归一化后的双流特征得到全局特征，输入到分类器中求解概率最大的行为类别；采集多人人体彩色图像序列、二维人体姿态及其对应的类别标签作为训练数据集，对表观网络、姿态网络、共时缩放单元和跨域融合单元进行预训练优化。共时跨域异步融合驱动动作识别方法。该方法能够以高稳定性和普适性降低场景动作和独立动作的普适性识别问题。 该方法采集多人人体彩色图像，捕捉人体的身体姿态，将彩色摄像头安装在机器人本体上距离地面1.7m的高度位置，调整拍摄角度，获得高质量的图像。 该方法使得能够利用图像特征和姿态特征提取模块来建立表观网络，并且选择姿态序列作为用于提取姿态特征的输入。该方法包括获得人体彩色图像作为图像序列。 利用目标检测网络从多人人体彩色图像中检测出二维人体围框。 计算所述二维人体姿态的关键点热点图，作为姿态序列。 建立表观网络，用于选择图像序列作为输入并提取图像特征。 共时缩放单元和跨域融合采用共时和跨域异步融合策略进行。 将融合后的图像特征和姿态特征使用用于划分归一化双流特征的全局池层进行归一化，得到全局特征。 采集作为训练数据集的多人人体彩色图像序列、二维人体姿态和对应的类别标签。 利用表观网络、姿态网络、共时缩放单元和跨域融合单元进行预训练优化。包括独立权利要求用于：(1)共时和跨域异步融合驱动动作识别设备；以及(2)存储用于共时和跨域异步融合驱动动作识别的指令集的计算机可读存储介质。   6
本发明属于多模态信息处理技术领域，具体涉及一种基于多模态大模型的用户个性化服务策略及系统。包括如下步骤：步骤1：多模态数据采集及模型自适应训练；步骤2：多模态数据融合；步骤3：用户画像构建；步骤4：个性化策略生成；步骤5：用户画像优化。本发明的有益效果在于：相比于传统的个性化策略，本发明的运用多模态大模型提取用户多模态信息，从而生成全方位立体化的用户画像，并将之运用到后续的交互系统中，用户画像的精确性：相较之前单一模态(如仅依赖文本或语音等)的用户画像构建方式，本方法引入了多模态大模型，能够融合和处理来自文本、语音、图像、视频等多种模态的用户数据。基于多模式大模型的用户个性化服务策略方法，用于各种行业和行业。该方法使得利用多模态大模型提取用户多模态信息生成全方位的三维用户画像，并将用户画像的准确性应用于后续交互系统。该方法涉及包括多模态数据收集和模型自适应训练。 进行多维数据融合。 构建用户画像。 产生个性化策略生成并实现用户图像优化。 所述多模型数据集合设置有多层数据集和多光谱数据集。 将多方向数据集与所述多级数据集连接以生成多静态数据集。本发明还公开了一种基于多模式大模型的用户个性化服务策略系统。  11
本申请实施例公开了一种基于迁移学习的深度神经网络的训练方法和装置，涉及人工智能技术，尤其涉及迁移学习、深度学习和神经网络技术领域。具体实现方案为：获取待训练的深度神经网络，所述深度神经网络包括预训练的图像特征提取网络和未训练的图像处理网络；对所述图像特征提取网络和图像处理网络进行训练；在训练过程中，对所述图像处理网络的训练后参数进行重新调整。本申请实施例可以提高特征提取网络的特征提取能力。一种基于迁移学习的深度神经网络训练方法。本发明能够提高特征提取网络的特征提取能力。所述方法涉及获得待训练的深度神经网络，其中所述深度神经网络包括预训练的图像特征提取网络和未训练的图像处理网络。 预训练图像特征提取网络和未训练图像处理网络用于训练图像特征。 在训练过程中重新调整未训练图像处理网络的训练参数。 初始化训练参数。 将训练参数调整为自定义值。 反向传播算法用于训练预训练图像特征提取网络和未训练图像处理网络。独立的权利要求书被包括在以下内容中： 一种基于迁移学习的深度神经网络训练装置； 一种电子设备，包括处理器和存储器，用于实现基于迁移学习的深度神经网络训练方法； 以及 一种用于存储计算机程序以执行基于迁移学习的深度神经网络训练方法的非瞬时计算机可读存储介质。   4
本发明公开了一种文本清洗方法、装置、设备与计算机可读存储介质，该方法包括：当检测到针对第一数据源的清洗指令时，获取清洗指令指示的第一数据源中的源文本数据；从预训练的清洗模型库中选取与第二数据源对应的目标清洗模型，其中，清洗模型库是由根据不同数据源的样本文本数据训练得到的清洗模型组成，第一数据源与第二数据源不同；基于目标清洗模型对源文本数据进行清洗处理，以得到第一数据源的目标文本数据。采用本申请，避免了因为仅通过文本数据的同源清洗模型对文本数据进行清洗而导致的清洗效果差的问题，能够将噪音数据较好的清除，提高文本清洗效果。一种文本清洗方法，用于数据处理技术领域。该文本清洗方法涉及到避免仅通过文本数据的同源清洗模型对文本数据进行清洗而导致的清洗效果不佳的问题，有效地对噪音数据进行清洗，从而提高了文本清洗效果。该文本清理方法包括当检测到针对第一数据源的清理指令时，获取用于指示第一数据源的源文本数据指令。 从预先训练的清洗模型库中选取与所述第二数据源对应的所述目标清洗模型。 所述清洗模型库为不同数据源的样本文本数据训练得到的清洗模型提供，所述第一数据源与所述第二数据源不同提供。 基于所述目标清洗模型对所述源文本数据进行清洗，得到所述第一数据源的目标文本数据。包括独立权利要求：(1)一种具有存储器的文本清理装置； (2)一种计算机可读存储介质，用于存储文本清理程序，所述文本清理程序被处理器执行以实现方法的步骤。  11
本发明涉及一种基于时效性辅助任务驱动的个性化论文推荐方法，包括以下步骤：构建学术HIN图，并用HIN子图提取函数提取长时间跨度和短时间跨度内的HIN子图。对BERT经典语言模型的输出添加全连接层进行微调来获取论文关键词语义特征，通过自注意力机制聚合关键词语义特征获取论文内容特征，通过自注意力机制聚合论文内容特征得到当前用户研究方向特征。在两种时间跨度的HIN子图中嵌入GNN网络，捕获用户阅读偏好特征和论文受众偏好特征。通过本发明中cfLSTM预测器进行多时间跨度下相关特征捕捉。计算用户研究方向与论文内容的匹配度以及计算用户阅读偏好和论文受众偏好的匹配度，将两种匹配度线性融合得到推荐概率值。基于时效性辅助任务驱动的个人论文推荐方法。该方法能够捕获多个时间跨度下的相关特征，计算用户研究方向与论文内容的匹配度以及用户阅读偏好与论文受众偏好的匹配度，并对两个匹配度进行融合，得到推荐概率值。该方法涉及建立学术异构信息网络图。 添加用于输出的全连接层，以根据学术异构信息网络图学习关键词语义特征。 对多个时间跨度下的特征进行动态挖掘。 获取预测的用户研究方向特征、预测的论文观众偏好特征和用户阅读偏好特征。 将论文内容特征和用户研究方向特征相乘。 获取用户阅读偏好与纸质观众偏好的匹配度。 通过线性融合时效性评分和偏好匹配度评分得到推荐论文阅读概率。  12
本发明公开了一种在对话策略中响应情感类别预测方法。所述方法包括以下步骤：知识增强的对话上下文编码模块通过分层Transformer网络将前M‑1轮的对话历史信息V1 : M‑1编码为上下文向量表示X1 : M‑1，并融合对话中的对话特征；潜在情感响应学习模块采用变分网络学习语料中从上下文向量表示X1 : M‑1到情感响应的映射，从而建模得到潜在分布z；交互情感预测模块将对话上下文编码模块输出的上下文向量表示X1 : M‑1和潜在分布z作为输入，预测响应情感E′Y。本发明提出的方法实现响应情感类别的预测，赋予对话代理自适应地进行多样化情感表达的能力，缓解目标文本缺失导致的推断合理性问题。用于预测对话策略中的响应情感类别的方法。本发明实现了对应答情感类型的预测，提高了会话代理自适应地进行多样化情感表达的能力，减少了目标文本删除带来的推理合理性问题。该方法包括通过使用具有增强知识的对话上下文编码模块，通过分级变压器网络转换先前匝的对话历史信息。 对上下文矢量表示进行编码。 融合对话特性。 本发明提高了上下文编码模块的语义表示能力。 潜在情感响应学习模块采用变异网络从上下文向量学习语言数据表达对话，映射到情感响应，并建模潜在分布，从语料库中学习情感对话的交互方式。 交互式情感预测模块用于通过激活SoftMax激活的线性网络处理对话上下文编码模块输出的上下文向量，并预测响应情感。 8
本发明属于自然语言处理技术领域，尤其是涉及一种基于prompt的表格事实检测方法。本发明首次在表格事实检测任务上使用Prompt方法，在小样本或零样本情况下有效的提高判断效果。首先是将表格事实检测任务形式改造成和预训练表格模型一致，不需要在预训练模型的基础上做过多训练；其次是定义了一个多组的映射关系，可以方便的将prompt的预测结果转化为表格事实检测结果。一种自然语言处理领域中基于提示的表格事实检测方法。本发明在预训练模型的基础上，将表格事实检测任务形式改进为与预训练的表格模型一致，无需训练，定义映射关系，便于将预测结果转化为表格事实检测器结果，有效提高了小样本或零样本条件下的判断效果，优化了使用方式，无需耗费大量资源重新训练。该方法包括处理用于表格事实检测的数据集以获得第一数据，其中第一数据的格式被选择为表格、文本或标签。 从所述第一数据中提取表格数据。 选取所述表格数据作为拉平后的第二数据。 从所述第一数据中提取文本数据输入模块。 获得第三数据。 将所述第二数据和所述第三数据拼接后的每个数据输入预训练预测模型。 得到预测结果。 根据映射关系使用得到的预测结果，得到表格事实检测结果。  11
本申请提供一种城市动态地理画像生成方法，包括：获取城市的地理数据，将所述地理数据按照预设大小的网格进行划分；为所述网格设置多个时间窗口，获取每个所述时间窗口时期的地理画像数据，并将所述地理画像数据按照所述时间窗口的时间顺序生成特征向量；根据所述预测目标建模并进行模型训练，利用均方误差和拟合优度来进行模型评估，获得预训练模型；将所述特征向量输入到所述预训练模型中，获得预测结果。本申请通过训练图神经网络模型的方式，可以只通过有限的数据，即可准确的进行地理动态画像的生成。本申请还提供一种城市动态地理画像生成装置。用于生成城市的动态地理图像的方法。该方法能够精确地生成动态地理图像。该方法包括获得城市的地理图像数据(S101)。 将所述地理影像数据按照预设大小网格进行划分。 设置网格的时间窗(S102)。 获取所述地理图像数据的窗口周期。 根据所述地理图像数据的时间窗口的时间顺序生成特征向量。 建立预训练模型(S103)。 将所述特征向量输入(S104)到所述预训练模型中，以用于获得预测结果。 调用时空动态关联捕获模型。本发明还涉及一种用于生成城市的动态地理图像的装置。   6
本说明书实施例公开了一种基于大模型的信息检索方法、装置及设备。所述方法包括：基于大模型对原始Query进行变换，获得新Query集合；基于更新的Query集合，采用子Query的形式从全文搜索引擎获取所述更新的Query集合对应的检索结果集，所述更新的Query集合是对所述新Query集合去重后获得的；基于原始Query的参考答案，对所述更新的Query集合对应的检索结果集进行语义距离计算，形成语义近似优先的优化检索结果集，其中，所述原始Query的参考答案是利用所述大模型获得的参考答案；输出所述优化检索结果集，作为所述原始Query的检索结果。基于大模型的信息检索方法。该方法能够快速准确地从大量的信息集中查找出与用户需求相匹配的信息。该方法包括基于大模型转换原始查询以获得新查询集(S201)。 基于所述更新后的查询集，以子查询的形式从全文搜索引擎中获取与所述更新后的查询集对应的检索结果集(S203)，其中，所述更新后的查询集是对所述新查询集进行去重得到的。 基于所述原始查询的参考答案对所述更新查询集对应的搜索结果集进行语义距离计算(S203)。 生成具有语义近似优先级的优化搜索结果集。 将所述原始查询的参考答案作为所述大模型得到的参考答案。 输出优化的搜索结果集(S207)作为原始查询的搜索结果。独立权利要求包括：(1)基于大型模型的信息检索装置； (2)一种电子设备，包括处理器和存储器，用于基于大模型的信息检索。  11
本发明属于医学图像处理技术领域，具体为一种基于集成交叉伪标签的肿瘤图像半监督分割方法。本发明方法通过训练差异较大的三个分割模型：基于Transformer架构的UNETR模型，基于CNN的注意力U‑Net，基于CNN的多尺度特征信息的注意力分割网络模型CSA‑U‑Net，来生成无标注数据的伪标签；然后使用带伪标签的无标注数据扩展训练数据，通过伪标签数据交替监督约束输出结果的一致性。最后集成多个模型的输出结果，以提升分割模型的精度。本发明方法可以更好地通过结合无标注数据和有标注数据的信息直接提升模型分割性能。一种基于集成交叉伪标签的肿瘤图像半监督分割实现方法。 可用于医学图像处理，特别是用于肿瘤图像半超监督分割。该方法通过结合未标记数据和已标记数据的信息，能够直接提高模型的分割性能。 该方法使得能够使用尽可能大的三个模型同时训练，得到的伪标签差异较大，伪标签数据能够更好的扩充训练数据，约束多个模型输出的一致性，以保证更紧凑的特征空间。 可以最大限度的降低伪标签中的噪声，并对三个模型进行反向传播迭代优化。该方法包括预处理MRI图像，其中对图像执行强度归一化和直方图均衡。 整幅图像被分割成一定数量的像素小块。 进行非线性拉伸处理，使局部灰度直方图均匀分布。 将预处理后的图像输入分割模型U-Net进行粗分割。 定位目标区域。 将图像作为输入图像中的中心以增加前景像素的比率。 训练划分后的网络模型。 综合多个模型的输出结果，得到高精度的分割结果。  7
本申请实施例提供的基于多模态信息的电池数据处理模型的训练方法，通过大模型，基于多模态信息的电池数据进行电池状态预测，结合多模态信息的融合以及对比学习完成对大模型的无监督训练。该模型可以获取电池的潜在信息，并生成电池数据的嵌入式表示，为下游任务提供精准有效的数据基础。在面对不同任务时，只需对模型进行微调训练即可，从而极大的简化了模型，降低了模型复杂性。利用计算机设备训练基于多模态信息的电池数据处理模型的方法(权利要求书)。该方法能够在面对不同任务时，对模型进行微调训练，从而大大简化模型，降低模型的复杂度。 该方法使得模型能够获取电池的潜在信息，生成电池数据的嵌入式表示，为下游任务提供精确有效的数据基础。该方法包括分别对原始电池数据和比较电池数据进行特征提取。 通过对比学习模块得到第一融合特征和第二融合特征。 基于所述第一融合特征和所述第二融合特征获取所述电池数据的电位信息。 根据所述潜在信息和交叉隐藏变量信息得到所述原始电池数据的嵌入表示。 基于所述第一融合特性和所述第二融合特性确定损失函数。 基于所述损失函数对大模型进行优化训练，得到训练后的电池数据处理模式。包括独立权利要求，用于：(1)一种基于多模态模型的电池数据处理方法； (2)一种基于多模态信息的电池数据模型训练系统； (3)一种计算机设备，包括存储器和处理器，用于基于多模态信息训练电池数据模型； (4)一种计算机可读存储介质，其存储有基于多模态信息训练电池数据模型的指令集。  11
本发明涉及基于情绪类别描述的微博情绪分类方法，属于自然语言处理技术领域。本发明首先提出情绪类别描述策略，将待分类微博的所有情绪类别都扩展为形式化的类别描述；其次，将微博文本与类别描述拼接成一个问答对，输入到预训练的BERT模型中；其次，将问答对经过BERT模型编码后得到的隐状态输入到两层全连接神经网络中，输出整个问答对的融合语义表示；最后，将问答对的融合语义表示输入到Softmax层中，输出归一化的情绪类别概率分布，实现微博的情绪分类，本发明相比基线方法BERT，宏平均和微平均F1值分别提升了1.77％和1.71％，证明了本发明方法的有效性。基于情感类别描述的微博情感分类方法。宏观平均值和微观平均值分别提高了1.77%和1.71%, 证明了该方法的有效性。该方法涉及提出情感类别描述策略，并将微博(RTM：新浪公司开发的中文微博网站)的所有情感类别扩展到正式类别描述中。 微博文本和类别描述被拼接成问答对，并被输入到预训练的双向编码器表示(BERT)模型中。 将经过BERT模型编码后的问答对的隐藏状态输入到两层全连接神经网络中，输出整个问答对的融合语义表示。 将问答对的融合语义表示输入Softmax层，输出归一化的情感类别概率分布，实现微博的情感分类。  12
本发明涉及人工智能伦理技术领域，尤其涉及一种基于预训练模型的伦理行为抽取方法，首先以涵盖伦理道德和人类行为的社会新闻为数据源，构建社会新闻数据集，并使用众包方法对数据集进行标注，再利用具有双向Transformer结构的中文预训练语言模型ERNIE，经过微调的模型编码了实体知识信息，从大量的社会新闻数据中准确的抽取伦理行为，此外预训练模型在标记数据稀缺时准确提取数据的重要特征，能够提高任务的整体性能，解决了中文语境下单词边界和组成成分的不确定性。本发明用于基于预训练模型的民族行为提取。该预训练模型在标注数据稀缺时准确提取数据的重要特征，可以提高任务的整体性能，解决汉语情境中词边界和成分的不确定性。一种基于预训练模型的民族行为提取方法，包括构建数据集， 对任务数据进行预处理，映射到索引，将常用知识嵌入到词向量中，生成文本的特征向量序列，将行为编码到文本特征向量序列中，训练得到所需的行为判断模型，实现模型预测模块。  11
本发明涉及一种利用大语言模型增强的生成式跨语言事件抽取方法，属于计算机人工智能和自然语言处理技术领域。本方法首先使用大语言模型，将各语言的文本信息进行事件预抽取，得到各种语言的大模型事件抽取结果，并将其解析为可用的文本提示为模型训练做准备，然后构建训练所需的文本提示，将输入的文本提示向量化表示，最后使用得到的隐藏层计算二元损失，解码隐藏层向量，将解码损失和二元损失加权相加反向传播，并将向量转化为文本。本方法有效解决了模型跨语言事件抽取困难的问题，提升了知识提示的正面效果，做到了知识提示程度的可控管理，显著增强了生成式跨语言事件的抽取性能。生成的跨语言事件抽取方法，用于计算机人工智能和自然语言处理。该方法能够有效解决模型跨语言事件提取困难的问题，提高了知识提示的积极效果，实现了知识提示程度的可控管理并增强了生成的跨语言事件的提取性能。该方法涉及利用语言大模型对每种语言的文本信息进行预提取，得到该语言的大模型事件提取结果。 构建训练所需的文本提示。 所述文本提示是基于训练文本构建的，所述文本提示包括事件类型、事件类型提示词和事件角色。 利用mT5解码器对构建的根据注意力机制的文本提示进行编码。 得到训练数据的隐含层向量。 利用得到的隐含层计算二进制损失。 添加解码器丢失和二进制丢失权重。 向量被转换成文本输出。  11
本发明公开了一种半监督特征融合的对象分类方法及系统。该方法包括步骤：通过卷积神经网络预训练模型分别提取视频帧与音频的场景描述特征；针对场景识别的特点进行视频级特征融合；将融合特征通过深度信念网络进行无监督训练，并通过加入相对熵正则化项代价函数进行有监督调优，通过模型输出进行对象分类。本发明系统与上述方法相对应。在天气环境恶劣、光线条件差等不利条件下，本发明可有效提升监控场景分类精度，通过对比多模态融合特征与传统单模态特征下的场景识别方法，本发明所提方法的半监督模型在针对纯净与含噪监控视频条件下，正确识别率可分别提高2.35％和12.09％。半监督特征融合对象分类方法。该方法在纯净噪声监控视频条件下，通过多模态融合特征与传统单模态特征的比较，能够有效提高恶劣天气、光线条件差等不利条件下的监控场景分类准确率，提高模型的正确识别率2.35%和12.09%。该方法涉及通过卷积神经网络预训练模型提取视频帧和音频的场景描述特征。 融合特征无监督训练过程通过深度置信网络进行。 通过添加相对熵正则化项代价函数来执行监督整定过程。 执行对象分类处理。 将VGG16-places365模型的全连接层进行反向转换，得到4096维的视频帧特征描述矩阵。还包括用于半监督特征融合对象分类系统的独立权利要求。 9
本发明提供一种图像预训练模型到视频人脸表情识别的方法，在Vision Transformer模型的基础上插入模态互补模块和时间建模模块，基于人脸表情的图片数据集和视频数据集，提取并引入人脸关键点辅助引导模型关注人脸上与表情更加相关的区域；首先训练出具有图像表征能力的图像预训练模型再扩展到视频模型，训练出具有动态识别能力的人脸表情识别模型。本发明采用了预先在静态表情数据集上训练然后在动态视频数据集上微调的方法，通过静态数据弥补了视频数据集在数量上的不足；通过模态互补模块对人脸表情特征和人脸关键点做模态融合，并通过时间建模模块学习时间维度信息；同时在视频模型训练阶段基于表情锚的自蒸馏损失提高监督信号，减少了噪声样本的干扰。识别图像预训练模型对视频人脸表情识别的方法用于人机交互、医疗辅助和疲劳驾驶检测应用。该方法在视频模型训练阶段基于表情锚点的自蒸馏损失对监测信号进行改进，降低噪声样本的干扰。该方法涉及基于人脸表情图片数据集提取并引入(S1)人脸关键点。 训练具有图像表征能力的图像预训练模型。 将所述图像预训练模型扩展(S2)到所述视频模型。 基于所述人脸表情视频数据集提取并引入人脸关键点。 对人脸表情识别模型进行动态识别能力的训练。 插入在标准视觉模型基础上的模式互补模块(S11)，得到初始图像训练模型。 2
本发明公开了一种基于实体识别和属性抽取模型的学校领域知识图谱构建方法。首先对学校领域问答对数据集预处理得到实体识别模型标注数据集EntityData；利用数据集EntityData训练基于BERT‑BiLSTM‑CRF的实体识别模型，得到学校领域实体识别模型SchoolEntityModel；然后对学校领域问答对数据集预处理得到属性抽取模型标注数据集AttributeData；利用数据集AttributeData训练基于BERT的属性抽取模型，得到学校领域属性抽取模型SchoolAttributeModel；最后分别通过SchoolEntityModel和SchoolAttributeModel抽取出问句对数据集中的实体、属性和属性值，从而建立知识三元组，构建学校领域知识图谱。本发明方法可有效构建学校领域知识图谱。基于实体识别和属性抽取模型的学校领域知识图谱构建方法。该方法能够有效构建学校领域知识图谱。该方法包括预处理关于学校领域问题的数据集(1)。 得到实体识别模型标注数据集EntityData。 利用数据集EntityData训练(2)基于BERT-BiLSTM-CRF的实体识别模型，得到学校领域实体识别模型SchostentityModel。 得到属性抽取模型标签数据集AttriteData(3)。 基于BERT的属性提取模型由数据集AttributeData训练(4)得到学校领域属性提取模型SchoolAttributeModel。 从文本数据上的问题数据中提取实体、属性和属性值。 建立(5)知识三元组，构建学校领域知识图谱。  12
本发明公开了基于U‑Net多尺度神经网络的图像压缩感知重建方法，包括以下步骤：S1、压缩采样：利用光学系统编码孔径调制HSI信号，并将其压缩成二维测量；S2、重建过程：采用本方法提出的基于U‑Net多尺度扩展卷积神经网络重建算法将2D压缩图像重建为3D高光谱图像。本发明使用多尺度扩展卷积神经网络重建算法解决压缩感知高光谱图像重建问题，通过训练网络学习二维压缩测量数据到原始数据的逆变换，进一步使用训练好的模型重建压缩感知高光谱图像，实现了压缩感知高光谱图像的快速、精确重建，与传统迭代重建算法相比，在重建质量上有所提高，并且在重建高光谱数据上的计算时间上有显著提高，远快于传统算法。计算机视觉图像处理领域的基于U-Net多尺度神经网络的图像压缩感知重建方法。该方法利用训练好的模型对压缩感知高光谱图像进行重建，实现了压缩感知高光谱图像的快速准确重建，并且提高了重建高光谱数据的重建质量和计算时间，比传统算法速度快很多。该方法包括对原始高光谱图像进行编码以获得相应的二维测量值。 构建多尺度神经网络。 将原始高光谱图像对应的二维测量值输入多尺度神经网络。 进行特征提取和融合。 得到对应的特征图。 注意力机制网络构建。 将所述特征图像输入注意力机制网络。 提取特征图像并融合特征图，得到最终的特征图。 将最终的特征图输入解码器，得到重建后的高光谱图像。   4
本公开提供了目标模型生成方法、图像处理方法和装置，涉及人工智能、计算机视觉、深度学习、大模型、自动驾驶、智能交通等技术领域。具体方案为：基于掩码图对样本图像进行掩码处理，得到掩码后的样本图像；将掩码后的样本图像输入预设模型，得到掩码区域的特征和未掩码区域的特征；根据掩码区域的特征，得到掩码特征信息；基于掩码特征信息和未掩码区域的特征，得到掩码区域的重建特征；基于掩码区域的重建特征对应的重建损失和未掩码区域的特征对应的蒸馏损失，对预设模型进行预训练，得到训练后的目标模型。用于由在自动驾驶和智能交通领域中使用的车辆(全部要求保护)中使用的电子设备生成目标模型的方法。 用途包括但不限于人工智能、计算机视觉、深度学习和大型模型技术领域。该方法涉及基于掩膜图像对样本图像进行掩膜处理，得到掩膜处理后的样本图像，所述掩膜处理后的样本图像包括掩膜区域图像和非掩膜区域图像。 将掩膜码后的样本图像输入预设模型，得到预设模型输出的掩膜码区域和非掩膜码区域的特征，掩膜码区域和非掩膜码区域的特征分别对应于掩膜区图像和非掩膜区图像。 根据所述掩码代码区的特征获取掩码特征信息。 基于所述掩码特征信息和所述非掩码代码区域的特征，获得所述掩码代码区域的重构特征。 基于掩码代码区域对应的重建特征对应的重建损失和非掩码代码区域的特征对应的蒸馏损失对预设模型进行预训练，得到训练后的目标模型。独立权利要求书包括用于：(1)下游任务目标模型生成方法； (2)一种图像处理方法； (3)目标模型生成装置； (4)下游任务目标模型生成装置； (5)图像处理装置； (6)非瞬时计算机可读存储介质，其存储用于生成目标模型的一组指令； 以及(7)计算机程序产品，其包括用于生成目标模型的一组指令。 14
本发明公开了一种基于贴图表情的情感检测方法以及系统，方法包括：采集带有贴图表情的文本数据；对所采集来的数据进行预处理，转换为词向量数据集；将数据预处理单元生成的数据集输入一个已经训练好的网络模型，该网络模型输出相应的情感检测结果。本发明可以实现对用户评论等的情感检测；进一步地，结合了多重神经网络跟注意力机制，从而提高了对于各种情绪相关的贴图表情的辨识度；通过迭代器的方式来训练模型从而节省了内存；通过迁移学习, 并且逐步解冻可以训练的参数, 尽可能降低了迁移学习之后过拟合的风险, 充分保留了预训练模型的特性。基于表情映射的情感检测方法。该方法将多个神经网络与注意力机制相结合，通过迁移学习提高了情感相关映射表达的分辨率，节省了记忆，降低了过拟合风险后的迁移学习，充分保持了预训练模型的特性。该方法涉及利用表达式映射收集文本数据。 对采集到的文本数据进行预处理，转换为词向量数据集。 将数据预处理单元生成的数据集输入到训练好的网络模型中。 通过训练后的网络模型输出对应的情绪检测结果。 由所述已训练的网络模型中的输入层接收输入数据集，以输出到嵌入层中。 兴趣数据集和权重由分类层接收。 将最终训练好的网络模型保存为hdf文件。本发明还涉及一种基于映射表达式的情绪检测系统。  12
本申请涉及一种基于通识大模型和迁移学习的私有知识内容生成方法。所述方法包括：获取结构化数据库，对结构化数据库中的结构化关系型数据进行表之间的外键关联得到表关联数据；分别对表关联数据进行处理得到文本数据集和指令数据集，利用文本数据集以及指令数据集对通识大模型进行lora微调得到私有知识大模型；获取实时私有数据，根据实时私有数据对应的若干分段文本向量构建参考材料向量库，从参考材料向量库中选取与用户输入对应的输入向量最相近的参考材料向量得到对应的参考材料；将用户输入和参考材料按照指令模板进行拼接，将拼接后的结果输入私有知识大模型以得到对应的生成内容。采用本方法能够提高生成内容的实时性和有效性。基于通用识别大模型和迀移学习的隐私知识内容生成方法。该方法使得将拼接后的结果输入到隐私知识大模型中得到对应的生成内容，提高了生成内容的实时性和有效性。所述方法包括：获取当前服务模式所需的企业隐私数据对应的结构化数据库，对所述结构化数据库中的结构化关系类型数据进行表间外部键关联，得到表关联数据。 结构化查询语言(SQL)转文本方法和SQL转指令方法分别用于处理表关联数据。 获取文本数据集和指令数据集，将拼接结果输入隐私知识大模型，得到对应的生成内容。  11
本发明公开了一种液体浓度测量系统的模型现场重构方法，通过设定五个参考样本点以及五个现场测量点，基于五个参考样本点处浓度的变化、现场测量点T1、T2、T4和T5的三维数据点与当前模型的参考样本点N3的三维数据点所在的线段与当前模型在三维坐标系中形成的曲面的角度、更新步长以及五个现场测量点处的绝对浓度测量误差和实现模型的参数变量系数A、B、C、D、E和F的迭代更新；优点是只需要测量五个现场测量点即能实现模型的先现场重构，在保证测量精度的基础上，工作量较小，效率较高。液体浓度测量系统模型场重建方法。该方法能够测量现场测量点，并且保证工作量小、效率高。该方法包括获得绝对浓度测量误差。 确定测量点绝对浓度和测量误差。 得到参数变量系数。 更新参数可变系数。 利用测速系统和参数变系数得到当前速度值和加热后的样品溶液。 得到线段三维数据点和现场测量点。 获得生成模型的测量误差的绝对浓度。 获取重建模型的当前值。   6
本发明公开了一种意图识别和问答方法、装置、电子设备及存储介质，包括：基于待回答问题对应的本地知识生成图结构数据，基于图结构数据构建本地知识库，并生成本地知识库的图结构信息；根据图结构信息，通过大语言模型构建待回答问题对应的思维链；基于思维链在本地知识库中执行图查询，得到待回答问题的回答结果。本发明实施例的技术方案，解决了现有的知识问答系统，当用户问题格式多样时，向量召回准确率下降的问题；在用户提出跨主题问题，召回内容与问题不匹配的问题；以及，复杂问题大模型推理过程与推理结论不匹配的问题，实现了减少用户提问方式的限制，提高知识问答系统的鲁棒性，以及对复杂问题的理解与推理总结准确率。意图识别和问答方法。该方法避免了复杂问题的大模型推理过程与推理结论不匹配的问题，降低了用户提问方式的局限性，从而提高了知识问答系统的鲁棒性，提高了对复杂问题的理解和推理汇总的准确性。该方法涉及基于与待回答问题对应的局部知识生成图结构数据。 基于所述图结构数据构建本地知识库。 生成所述本地知识库的图结构信息。 根据所述图结构信息通过大型语言模型构建所述待回答问题对应的思维链。 基于所述思维链执行所述本地知识库中的图查询，得到所述待回答问题的回答结果。 分析本地文档以获得所述图结构数据。包括独立权利要求，用于：(1)意图识别及问答装置； 以及(2)一种计算机可读存储介质，用于存储计算机程序，以执行意图识别和问答方法。  11
本发明公开了一种基于AIGC的智能客服应答系统，该智能客服应答系统从用户需求信息中提取需求特征，并将该需求特征转化为需求图像，根据需求图像确定出应答图像，再根据应答图像确定应答信息，能够将使用场景中多种类型的用户需求信息通过需求图像表示，有利于对用户需求信息进行归一化处理，对交互信息包括多种信息类型的使用场景具有适用性。用于响应基于合成智能生成内容(AIGC)的智能客户服务的系统通过需求图像来表示使用场景中多种类型的用户需求信息，有利于对用户需求信息进行归一化处理，交互信息包括具有适用性的使用场景的多种信息类型，对于使用场景中的多种信息类型具有更好的效果。 所述控制器，用于从所述历史任务中调整执行与所述历史需求信息对应的目标工作任务。系统有用户需求信息接收端和响应信息输出端分别与控制器电连接，控制器与数据平台基于公网通信连接。 所述控制器获取通过所述用户需求信息接收端输入的用户需求信息。 所述控制器从所述用户需求信息中提取需求特征，并将所述需求特征转换为需求图像。 所述控制器根据所述响应图像生成与所述用户需求信息匹配的响应信息并控制所述响应信息输出端输出所述响应信息。 1
本发明公开的基于轻量化骨干网络的目标检测方法，具体按照以下步骤实施：步骤1、准备预训练数据集Tiny‑Imagenet和VOC格式的训练数据集；步骤2、搭建特征提取网络LBNet；步骤3、搭建由LBNet的多层输出特征构成的特征金字塔结构，并且在通过步骤1得到的Tiny‑Imagenet数据集中进行预训练，得到预训练权重。步骤4、设计anchors生成容器算法，生成区域推荐网络所需的anchors尺寸。步骤5、完成模型的训练和预测。该方法解决了现有检测技术中存在的检测效率低和边界框定位不准的问题。一种基于轻量主干网的自动驾驶目标检测方法及人脸。 也可用于自动驾驶和人脸识别领域。本发明解决了现有检测技术中检测效率低，边界帧定位不准确的问题。该方法包括准备训练前数据集和训练数据集的VOC格式。 构建特征提取网络LBNET。 基于LBNET的多层输出特性构建特征金字塔结构。 获得预训练的微小冰块数据集以获得权重。 生成容器算法(CFA)被设计成生成所需大小的区域推荐网络。 完成模型的训练和预测。   6
本发明提供了一种基于bert的字音混合纠错模型，包括检测网络；检测网络后级有纠错网络，纠错网络采用BERT模型；检测网络指出可能存在错误的字符，纠错网络对可能存在错误的字符进行校正。本发明能够有效对字符所组成语句中的错别字进行纠正，且便于用于工业界的语法纠错、词性标注等任务中，准确率高、通用性强。基于BERT的声韵混合纠错模型。该系统能够有效纠正由字符组成的句子中的错别字，便于在行业内的任务中使用，准确率高，通用性强。语音混合纠错模型具有在检测网络后面的纠错网络。 纠错网络采用BERT模型。 检测网络指出可能存在错误的字符。 纠错网络对可能存在错误的字符进行纠错。 所述纠错网络为序列多标签模型。 纠错网络接受原始输入作为输入。 原始输入与检测网络的输出一一对应。  12
本公开提供了一种文本识别模型的训练方法、文本识别方法及装置，涉及人工智能技术领域，具体为深度学习、计算机视觉技术领域，可应用于光学字符识别等场景。方案为：对获取到的第一样本图像中的部分图像进行掩码预测，得到与第一样本图像对应的预测完整图像，对获取到的第二样本图像中的部分文本进行掩码预测，得到与部分文本对应的预测文本内容，根据预测完整图像和预测文本内容训练得到预训练模型，并根据预训练模型生成文本识别模型，文本识别模型用于对待识别图像进行文本识别，使得预训练模型学习到较强的图像视觉推理能力和文本语义推理能力，从而当基于预训练模型生成的文本识别模型进行文本识别时，提高文本识别的准确性和可靠性。人工智能领域文本识别模型训练方法。 用途包括但不限于教育领域、金融领域、医疗领域、交通和保险领域。提高了文字识别的准确性和可靠性。 基于文本识别的预训练模型生成文本识别模型，以提高文本识别的准确性和可靠性。该方法包括对第一样本图像中的获取的零件图像进行掩膜预测，以获得第一测试图像对应的预测完整图像。 对得到的所述部分文本在第二样本图像中进行掩膜预测。 根据预测完整图像和预测文本内容训练得到预测文本内容，得到预训练模型。 根据所述预测的完整图像和所述预测的文字内容训练预训练模型。 根据预训练模型生成文本识别模型，所述文本分类模型用于进行识别。独立权利要求还包括：文本识别的训练装置； 文字识别装置； 以及包括用于训练文本识别模型的指令集的非瞬时计算机可读存储介质。 14
本申请公开了一种主动式对话大模型构建装置、方法、设备及存储介质，涉及模型构建领域，包括：模型确定模块用于基于生成式预训练Transformer模型确定预设提问模型和预设诊断模型；训练集构建模块用于将用户真实病历信息输入预设提问模型以生成假样本，基于假样本和真样本构建第一训练集；控制器训练模块用于将第一训练集输入初始控制器，以利用对抗训练方法并基于预先构建的目标函数对初始控制器的参数进行梯度更新得到目标控制器；大模型构建模块用于基于预设提问模型、预设诊断模型和目标控制器构建主动式对话大模型以进行问诊对话。本申请通过构建主动式对话大模型，以对用户进行主动提问获取更多用户信息，提高问诊结果的准确性。主动对话大模型构建装置。该装置能够利用构建主动对话大模型对用户进行主动质疑以获取用户信息，提高咨询结果的准确性。该装置具有模型确定模块，用于基于生成的预训练模型，确定预设问题模型和预设诊断模型。 训练集构建模块，将用户的真实病历信息输入所述预设问题模型，生成对应的假样本，并基于所述假样本和真实样本构建第一训练集。 控制器训练模块，将第一训练集输入初始控制器，以通过对抗训练方法基于预先构建的目标函数更新所述初始控制器的参数的梯度，得到目标控制器。 大模型构建模块，基于所述预设问题模型、所述预设诊断模型和所述目标控制器构建主动对话大模型，以利用所述主动对话大模型进行咨询对话。独立权利要求包括用于：(1)主动对话大模型构建方法； (2)一种电子设备，包括存储器和处理器，所述处理器用于执行用于进行主动对话大模型的构建的指令集； (3)一种计算机可读存储介质，用于存储一组指令，并由处理器执行，用于进行主动对话大模型的构建。 8
本申请涉及文本处理技术领域，提供了一种基于小语言模型的多种任务下的语料扩充方法及装置。该方法包括：获取大语言模型和小语言模型，大语言模型的模型规模大于小语言模型的模型规模；基于自回归语言任务分别对大语言模型和小语言模型进行预训练；基于多种自然语言任务对预训练后的大语言模型进行多任务训练；将多任务训练后的大语言模型作为教师模型，将预训练后的小语言模型作为学生模型，进行从教师模型到学生模型的知识蒸馏；通过知识蒸馏后的小语言模型以上下文学习的方法进行多种自然语言任务下的语料扩充。采用上述技术手段，解决现有技术中，利用模型进行数据增强，产生的数据质量差，且只能进行一种自然语言任务下的数据增强的问题。基于小语言模型实现多任务下语言素材扩展的方法。该方法能够在自然语言任务下使用该模型进行数据增强，以提高数据增强的质量，从而能够提供多个自然语言任务下的数据增强。该方法包括获得大型语言模型和小型语言模型，其中大型语言模型的模型规模大于小型语言模型的模型规模。 所述大语言模型和所述小语言模型是基于自回归语言任务预先训练得到的。 基于多个自然语言任务对所述预训练的大语言模型进行多任务训练。 将所述多任务训练后的大语言模型作为教师模型。 将所述预训练后的小语言模型作为学生模型。 从所述教师模型到所述学生模型进行知识蒸馏。 多个自然语言任务下的语言素材通过知识蒸馏后的小语言模型在上下文学习方法中进行扩展。包括独立权利要求：(1)一种基于小语言模型实现多任务下语料扩展的装置； (2)一种电子设备，包括存储器和处理器，用于执行基于小语言模型实现多任务下的语料扩展的指令集； (3)一种计算机可读存储介质，用于存储由处理器执行的用于实现基于小语言模型的多任务下的语料扩展的指令集。  11
本发明涉及自然语言处理领域，具体涉及一种基于BERT‑FLAT的中文命名实体识别方法，包括：将任意中文句子输入训练好的实体识别模型中，输出训练集中每个句子的词性标注结果，得到命名实体识别结果。本发明基于BERT‑Flat‑Lattice‑CRF的实体识别模型，BERT预训练语言模型和Flat‑Lattice结构，从大规模语料库中学习的BERT预训练语言模型可以通过上下文计算单词的向量表征，可以表征单词的多义性，增强句子的语义表征；Flat‑Lattice结构引入了词汇信息，充分地挖掘出文本中潜在的隐藏信息，达到词汇增强效果，显著地提升了中文命名实体识别的准确率。基于双向编码器表示(BERT)平面的中文人名实体识别方法。该方法能够增强句子的语义表示，有效引入词汇信息，充分挖掘文本中潜在的隐藏信息，保证更好的词汇增强效果，增加中文命名实体识别的准确率。该方法包括对数据集进行预处理，以获得预处理后的数据集，并将预处理后的数据集划分为训练集、验证集和测试集。 将所述训练集输入到用于处理所述训练集以生成输出序列向量的BERT模型中。 将BERT层的输出作为字符嵌入输入到平面点阵模型中进行编码，得到编码序列。 平格层的输出结果输入CRF模型进行分词序列预测。 建立训练好的实体识别模型。 利用所述测试集对训练后的实体识别模型进行测试，以评估实体识别的效果。  12
本发明公开了一种基于模板序列或词序列的BERT异常检测方法及设备，本发明首先将原始日志消息转换为模板序列或词序列，通过模板序列或词序列作为BERT模型的输入，实现BERT模型的训练，最后利用训练完成后的BERT模型实现对待检测模板序列或词序列的异常检测，只需要较少的训练标签就能实现好的异常检测效果，相较于现有技术，极大的缩短了训练成本，提高了异常检测效果。基于模板序列或字序列从变压器(BERT)异常中检测双向编码器表示的方法该方法使得能够实现较好的异常检测效果，降低训练成本，提高异常检测效果。该方法涉及获取多个原始日志消息。 对获取的每个原始日志消息进行日志分析，得到分析后的每个原始日志消息对应的日志事件。 通过窗口划分方法将所述日志事件划分为相应数量的模板序列。 将划分后的模板序列输入预设的BERT模型进行训练。 通过完成训练后的所述BERT模型对待检测对象进行日志异常检测。 通过所述带有标记的模板序列调整一个精调模型的参数。独立权利要求包括如下：一种基于模板序列或词序列检测BERT异常的装置； 以及计算机可读存储介质，其存储用于基于模板序列或字序列来检测BERT异常的指令集。  12
本发明公开了一种基于深度语义匹配的在线评论自动回复方法，结合句向量余弦相似度和多维度情感匹配度，找到数据库中与输入评论语义最为接近的在线评论。具体做法是利用Canopy+Kmeans聚类获取不同主题的特征词，在此基础上利用基于先验知识的主题模型CorEx进行主题特征词扩充。同时，构建BERT‑BiLSTM情感分析模型，根据聚类得到的主题特征词，并利用依存句法分析，对在线评论进行多维度情感分析。结合句向量余弦相似度和多维度情感分析结果来匹配数据库中语义最为接近的在线评论，将该评论的商家回复进行数据增强EDA操作，选取与原句句向量余弦相似度最高的句子作为自动回复内容。本发明能方便、高效、精准地为商家提供自动回复在线评论。基于深度语义匹配的在线评论自动回复方法。该方法能够方便、高效、准确地为商家提供自动回复在线评论。该方法，涉及爬取电商平台某一领域的评论数据，获取网上评论、商家回复、星级数据、商品名称和商家名称，提取有商家回复的网上评论，构建回复数据库。 对在线评论进行聚类分析，得到在线评论的不同主题的特征词。 该算法利用Canopy+Kmeans clustered对在线评论进行聚类分析，然后结合基于领域知识的主题模型CorEx对每个主题的特征词进行扩展，得到在线评论不同主题的特征词。  12
本申请公开了一种多轮对话改写方法、装置和电子设备，该方法和装置具体为获取用户与系统的基础对话内容和待改写对话内容；将基础对话内容和待改写对话内容输入基于Transformer结构的神经网络模型，得到改写内容和改写位置；根据改写位置判断是否需要改写；如果需要改写，则将改写内容拼接于改写位置，得到改写后的目标语句。通过最终的拼接改写，使得到的目标语句避免了信息缺失和指代有歧义，避免了在多轮对话时对机器理解语言的影响，从而提升了多轮对话的效果。应用于电子装置的多轮对话改写方法(权利要求书)。该方法通过最终拼接改写得到目标语句，避免了信息的删除和歧义的含义，从而避免了多轮对话时机器理解语言的影响。 该方法提高了多轮对话效果。该方法包括获取(S1)用户与系统之间的基本对话内容以及要重写的对话内容。 将基本对话内容和要重写的对话内容输入(S2)至基于变换器结构的神经网络模型，以获得重写内容和重写位置。 根据重写位置判断是否重写(S3)。 将改写后的内容拼接(S4)到改写后的位置，得到改写后的目标语句if需要改写。包括以下独立权利要求：用于重写多轮对话的设备； 以及电子设备。 8
本发明提供一种基于AIGC技术的幻灯片自动生成方法及系统，包括：对幻灯片的文本信息使用自然语言处理技术进行识别和分析，得到文本分析结果；基于AIGC技术，对文本分析结果处理，重新生成新的文本信息；根据新的文本信息，基于AIGC技术，选择或生成与新的文本信息匹配的幻灯片模板；根据新的文本信息，基于AIGC技术，生成幻灯片内容；利用机器学习技术，将文本分析结果、幻灯片内容结合幻灯片模板，自动编排和排版幻灯片，生成最终的幻灯片成品。本发明通过利用自然语言处理技术和机器学习算法，自动分析和提取用户输入的文本信息，利用AIGC技术生成高质量的幻灯片，提高幻灯片制作的效率和质量，降低制作成本和错误率。用于在商业和教育领域中显示和演示信息的基于人工智能生成上下文(AIGC)技术的自动幻灯片生成方法。该方法使得能够利用自然语言处理技术和机器学习算法对用户输入的文本信息进行自动分析和提取，并使用AIGC技术高质量地生成幻灯片，提高了幻灯片制作的效率和质量，降低了制作成本和出错率。该方法包括使用自然语言处理(NLP)技术识别并分析幻灯片的文本信息，并获得文本分析结果(S100)。 文本分析结果包括关键词、主题、段落和章节。 基于人工智能生成上下文(AIGC)技术，处理文本分析结果并重新生成新的文本信息(S200)。 根据所述新文字信息，基于AIGC技术，选择或生成与所述新文字信息相匹配的幻灯片模板(S300)。 基于新文本信息和AIGC技术生成幻灯片内容(S400)。 使用机器学习技术(S500)。 将文字分析结果和幻灯片内容结合幻灯片模板对幻灯片进行自动排列布局，生成最终的成品幻灯片。以下包括独立权利要求：1。 一种基于AIGC技术的玻片自动生成系统； 2. 端子； 3. 一种计算机可读存储介质，其存储用于自动载玻片生成方法的程序。 1
本说明书一个或多个实施例公开了一种问题应答方法，首先获取针对目标账户的第一账户问题；然后基于第一账户问题，利用预先训练的提示模型生成与当前业务场景以及目标账户相匹配的第二账户问题，且第二账户问题中包含与第一账户问题相关的提示信息，其中，该提示模型是基于历史第一账户问题、与历史第一账户问题相关的历史提示信息以及历史账户问题标签进行模型训练得到的模型；最后将第二账户问题输入语言大模型，得到第二账户问题对应的答案，并将答案作为第一账户问题对应的答案。问答方法。该方法能够通过预先训练的提示模型，获得针对目标账号的第一账号问题，并获得针对目标账号的第二账号问题，因此，问答过程简单高效。该方法包括：获取目标账户的第一账户问题。 利用预先训练的提示模型，基于所述第一账号问题，生成当前服务场景与所述目标账号匹配的第二账号问题，所述第二账号问题包括与所述第一账号问题相关的提示信息。 基于历史第一账号问题确定提示模型。 将第一账号问题输入语言大模型，得到所述第一账号问题对应的答案。 答案作为第二账号问题对应的答案。包括独立权利要求，用于：(1)问答装置； 以及(2)一种电子设备，包括处理器和存储器，用于执行问答方法。  11
随着影像技术的发展，各种成像设备的出现为现代医学的进步作出了巨大的贡献，但由于成像原理的限制，单一模态的影像技术通常只能提供单一且有限的信息，因此为了提高诊断的准确性和治疗的有效性，医生往往需要融合不同模态图像的信息以了解病变组织或器官的综合信息。为了实现对脑部图像进行的高效、快速配准，便于医生进行治疗，提出了一种基于基于生成对抗网络的配准方法。在生成器中采用U‑Net的编码器‑解码器结构，编码器获取浮动图像到固定图像的变换参数，解码器恢复特征图尺寸，通过在相似度测度上使用基于归一化互信息的医学图像配准，以梯度下降法作为图像配准的优化算法，分别在CT单模态和CT‑MRI多模态序列图像中分别进行试验，对比使用原始的归一化互信息计算方法与改进的归一化互信息方法得到的配准结果。本发明能够通过自动学习同一数据集之间的映射联系，增强模型的泛化能力。本发明能实现精确、快速的配准。用于临床诊断，疾病诊断，手术规划，手术导航和疗效评估的基于GAN的多模态脑图像配准方法。本发明自动学习同一数据集之间的映射关系，增强了模型的泛化能力，方便地实现了脑图像的准确，快速配准。该方法包括使用磁共振数据处理软件Freesurfer对原始图像进行颅骨剥离和重采样。 通过生成器中的U-网的编码器-解码器结构来提取数据的特征。 用全局空间信息训练所提取的特征以训练网络模型。 在训练过程中不断调整模型参数。 在Pycharm中进行实验。 获得数据集。   6
本发明公开了一种基于视觉Transformer的洪涝灾害监测与灾情分析，包括步骤：(1)构建基于视觉Transformer的双时相图像变化检测模型；(2)选取双时相遥感影像，制作洪涝灾害标签；(3)根据步骤(1)构建的双时相图像变化检测模型，进行洪涝监测与灾情分析。本发明结合深度学习中基于先进视觉Transformer的双时相图像变化检测模型和不受时间、天气影响且穿透能力强的雷达数据，能获取洪涝发生时的数据和提高识别精度。基于视觉检测的灾情分析和洪水灾害监测方法。 可用于各个行业，而洪水最为频繁，洪水范围广、频发、突发性强且损失大，洪水造成了大面积洪水动态变化，实时监测洪水区域至关重要。该方法能够在洪水发生时，不受时间、天气影响、穿透能力强的情况下，结合基于先进视觉和雷达数据的双阶段深度学习变化检测模型获取数据并提高识别精度，从而有效、准确地为洪水灾害的防洪减灾提供有效的决策依据，具有较好的社会和经济效果。该方法包括构建双时相图像的变化检测模型，其中双时相检测模型设置有CNN框架、语义标记和模块。 所述模块设有编码器和解码器。 选取双时相遥感影像。 制造洪涝灾害标签。 根据构建的双时相影像变化检测模型进行洪水监测与灾害分析过程。 利用CNN帧进行特征提取。 得到变化水体双时相所述遥感影像。 得到像素级的预测结果。   5
本申请涉及数据处理技术领域，尤其涉及一种基于大模型的智能文档实现方法、装置、设备及介质，基于用户需求选择目标基础模型，并利用用户的私有训练数据对所述目标基础模型进行微调，得到定制模型；基于构建的向量数据库对用户问题进行相似度匹配，找出与所述用户问题匹配的若干文档；通过提示词将所述若干文档作为上文下文并输入所述定制模型，得到所述用户问题对应的问题答复。一方面以大语言模型为基础的问答服务，使得准确率和查询效率更高；另一方面在其他实施例中，采用阶段性的微调训练和实时的向量数据库更新相结合，使得文档的更新能够实时的体现在对用户的答复中，让用户可以无缝的查询到文档最新进展。用于在数据处理领域中基于大模型在电子设备中实现智能文档的方法(要求保护)。基于大语言模型的问答服务使得准确率和查询效率更高。 该方法采用周期性细调训练和实时向量数据库更新相结合的方式，使得文档的更新能够实时地反映在回复用户的同时，用户能够无缝地查询文档的最新发展。该方法涉及基于用户需求选择目标基本模型。 利用用户的隐私训练数据对所述目标基本模型进行微调，得到定制模型。 基于构建的向量数据库进行对用户问题的相似度匹配处理。 查找出与所述用户问题匹配的多个文档。 以所述文档为上下文，通过提示词输入所述定制模型，得到与所述用户问题对应的问题答案。 根据用户的使用场景从一组基本模型中选择目标基本模型。包括独立权利要求，用于：(1)一种基于大模型的智能文档实现装置； (2)一种计算机可读存储介质，包括执行智能文档实现方法的一组指令。  11
本发明提供了一种准确获取离线数据的指标关系的方法，该方法包括：从离线数据集中获取历史数据；依据历史数据并应用特征融合和方差膨胀因子算法获取若干预训练模型，并输出若干预训练模型的运算式；获取增量数据，并将增量数据输入至所述若干预训练模型，以获取第一结果数据；将增量数据作为运算式的变量数值，并获取第二结果数据；判断第一结果数据是否等于第二结果数据；若第一结果数据不等于第二结果数据，获取第一结果数据和第二结果数据中的不同的异常数据；将所述异常数据关联的预训练模型推送至专家以供专家进行修正；接收修正结果，并再将增量数据输入至未修正的异常数据关联的预训练模型中。本发明提高了工作效率。用于金融技术领域的准确获取离线数据的指标关系的方法。该方法准确获取离线数据的指标关系，因此提高了系统的工作效率。该方法包括从离线数据集中获取历史数据，根据历史数据并应用特征融合和方差膨胀因子算法得到多个预训练模型，输出预训练模型的运算公式，运算公式包括多个运算公式。 获取增量数据，将增量数据输入至预训练模型，得到第一结果数据。 将所述增量数据作为所述计算公式的变量值，得到第二结果数据。 接收所述修正结果，将所述增量数据输入与所述异常数据关联的未修正的预训练模型，得到结果数据。包括以下独立权利要求：(1)一种用于准确获取离线数据的索引关系的计算机设备； (2)一种计算机可读存储介质。  11
本发明公开了一种基于新型U‑Net结构生成器的对抗网络图像隐写方法，包括：利用卷积策略和反卷积策略构建大小对称的U型网络，利用shortcut连接策略将U型网络逐层连接作为生成器；构建隐写分析网络作为判别器及构建秘密信息嵌入模拟器；输入载体图像，构建损失函数对生成器和判别器进行对抗训练，基于秘密信息嵌入模拟器进行秘密信息的嵌入，生成嵌入概率图像；根据率失真原理构建基于最小失真的隐写框架，基于嵌入概率图像对载体图像进行信息的嵌入和提取，完成对抗网络图像隐写。本发明降低了隐写算法嵌入的难度，提高了算法的实用性；具有更高的隐写安全性；避免了针对性的隐写分析；具有较强的可拓展性以及继续提高隐写安全性的可能性。基于U-Net结构生成器实现抗网络图像隐写的方法。该方法降低了隐写算法的嵌入难度，提高了算法的实用性。 该方法提供了更高的隐写安全性，并且避免了相关的隐写分析。 该方法扩展性强，具有不断提高隐写安全性的可能性。该方法涉及利用卷积策略和反卷积策略构建大小对称的U型网络。 构造隐写分析网络作为仲裁器，用于将秘密信息嵌入模拟器中。 根据隐藏通信中的率失真原理，基于最小失真构造隐写帧。 基于嵌入概率图像嵌入并提取载体图像的信息。 利用所述结构将所述载体图像与对应大小的卷积运算和反卷积运算进行连接。   6
发明公开了一种基于BERT和相似度算法的医疗知识图谱问答系统构建方法，包括：利用Python爬虫爬取网络公开医疗百科信息，存储至图数据库Neo4j中，构造医疗知识图谱；对公开的医疗问答数据集进行数据处理，利用CNN‑BiLSTM‑CRF算法实现命名实体识别；通过BERT‑TextCNN算法实现关系抽取；匹配预设定的问题查询语句；利用TF‑IDF算法对医疗问答数据集建立相似度模型。用户输入医疗相关关键字或语句调用算法获取相关医疗实体数据和相似病历回答，将查询数据返还WEB应用程序。本发明通过ECharts渲染医疗实体属性数据和实体间关系数据，实现医疗实体关系可视化以及医疗自动问答系统。该方法可用于构建基于BERT和相似度算法的医学知识图谱问答系统。所述方法：使得能够通过ECHART渲染医疗实体属性数据和实体关系数据； 实现医疗实体关系可视化和医疗自动问答系统。基于BERT和相似度算法构建医学知识图谱问答系统，包括：爬行动物爬取医学部信息; 引入Neo4j构建知识图谱G; 构建命名实体识别实验数据集和关系提取实验数据集; 构建BERT-Texteen神经网络算法; 提取问题查询语句; 分析输入问题与公共数据集的相似度; 识别命名实体并提取输入问题SEQ的关系; 匹配问题模板; 打开病历推荐系统接口(API); 实现一种医疗实体关系可视化及医疗自动问答系统。  12
本申请公开了一种证型推荐方法、装置、电子设备及非易失性存储介质。其中，该方法包括：获取原始文本信息，其中，原始文本信息包括：问诊文本信息和病历文本信息；依据预训练模型，对原始文本信息进行向量化处理，得到目标向量数据，其中，目标向量数据包括：问诊向量数据和病历向量数据；采用第一神经网络对病历向量数据进行特征提取，得到第一特征数据，以及采用第二神经网络对问诊向量数据进行特征提取，得到第二特征数据；依据第一特征数据和第二特征数据，确定目标证型。本申请解决了由于目前的中医辨证系统大多未采用自然语言处理技术，造成辨证系统的证型推荐准确率差的技术问题。目标证书类型推荐方法。本发明通过建立预训练模型，并对不同类型的原始文本数据应用不同的神经网络，以达到保证辨证系统可靠性的目的，从而提高分析的准确性，从而有效解决证候系统的证候推荐准确性的技术问题。所述方法包括获取原始文本信息，所述原始文本信息包括查询文本信息和病历文本信息。 根据预训练模型对所述原始文本信息进行向量化处理得到目标向量数据，所述目标向量数据包括诊断向量数据和病历向量数据，所述诊断向量数据为对所述诊断文本信息进行向量化处理得到的目标向量数据，所述病历向量数据为对所述病历文本信息进行向量化处理得到的目标向量数据。 利用第一神经网络对所述病历向量数据进行特征提取处理。 得到第二特征数据。 根据第一特征数据和第二特征数据确定目标证书类型。独立权利要求包括用于：(1)目标证书类型推荐设备； (2)—种电子设备，包括存储器和处理器，用于执行目标证书类型推荐方法; 以及(3)非易失性存储介质，用于存储用于执行目标证书类型推荐方法的指令集。  12
本申请涉及一种基于大语言模型的机器人任务规划的知识蒸馏方法和系统，其中，该方法包括利用预先构建的提示语构造器对种子库中的数据进行处理，得到提示语；基于大语言模型，对提示语进行处理，得到答案列表；基于本体知识库，对答案列表进行过滤，得到第一目标数据；基于分类策略对第一目标数据进行分类，得到目标分类数据；将目标分类数据存储至对应的图数据库中；基于筛除策略对图数据库中的目标分类数据进行进一步过滤，得到第二目标数据；将第二目标数据用于机器人的任务规划，通过本申请，解决了现有技术中使用知识库预制机器人任务分解的泛化能力较差问题，提高了使用知识库预制机器人任务分解的泛化能力。用于数据处理领域的基于大型语言模型的机器人任务规划知识蒸馏方法。该方法解决了现有技术中利用知识库对装配式机器人进行任务分解的泛化能力差的问题，提高了利用知识库对装配式机器人进行任务分解的泛化能力。该方法包括：(a)通过使用预先构造的提示语言构造器处理种子库中的数据以获得提示语言。 (B)基于所述大型语言模型对所述提示语言进行处理以获得答案列表。 基于所述本体知识库对所述答案列表进行过滤，得到所述第一目标数据。 根据分类策略对第一目标数据进行分类(C)以得到目标分类数据。 将所述目标分类数据存储在对应的图数据库中。 基于筛选策略在图数据库中进一步筛选(D)目标分类数据，以获得第二目标数据。 第二目标数据用于(E)机器人的任务规划。包括以下独立权利要求：1。 一种基于大语言模型的机器人任务规划知识蒸馏系统； 2. 电子装置； 以及3。 一种计算机可读存储介质，其存储有用于蒸馏知识的程序。  11
本公开提供了一种基于生成对抗网络的正面人脸合成方法及系统，从输入图像中检测并分割出人脸部分，进行人脸对齐，以获取待合成的人脸图像；根据人脸关键点估计其头部姿态，根据头部旋转自由度将人脸数据集划分为正面人脸集和非正面人脸集；利用人脸识别深度神经网络的预训练模型，提取输入人脸图像的身份特征进行监督网络的训练；根据输入的侧面人脸图像，基于生成对抗网络合成其相应的正面人脸图像。通过人脸对称性约束和身份特征约束使得合成的正面人脸更加自然且更好的保持其身份特征。该方法可用于基于生成对抗网络的正面人脸合成。该方法使得合成的正面人脸更加自然，更好地保持其身份特征。基于生成对抗网络的正面人脸合成方法包括从输入图像中检测并分割出人脸部分，对齐人脸得到待合成人脸图像，根据人脸关键点估计头部姿态，根据头部旋转自由度将人脸数据集合划分为正面人脸集合和非正面人脸集合， 利用人脸识别深度神经网络的预训练模型和提取输入的人脸图像的身份特征来监督基于生成对抗网络的网络训练以根据输入的侧脸图像合成对应的正脸图像。还包括独立权利要求：基于生成对抗网络的正面人脸合成系统； 以及计算机可读存储介质，包括一组用于基于生成对抗网络的正面人脸合成方法的指令。 2
本发明公开了一种基于遗传算法优化神经网络的露天矿知识图谱构建方法，属于露天矿山稳定性评估技术领域。包括：获取露天矿灾害相关数据并对其进行处理构建命名实体识别数据集；利用遗传算法对现有BERT‑BILSTM‑CRF模型进行优化，并利用命名实体识别数据集中的数据训练优化的BERT‑BILSTM‑CRF模型，获得命名实体识别模型；构建关系抽取标注数据集；利用遗传算法对现有BILSTM模型进行优化，并利用关系抽取标注数据集中的数据训练优化的BILSTM模型，获得关系抽取模型；将待抽取的露天矿灾害相关数据依次输入到命名实体识别模型和关系抽取模型进行实体关系抽取得到三元组，并存入Neo4j图数据库，构建露天矿知识图谱。该方法能够兼顾上下文信息，能够搭建露天矿稳定性领域高质量的知识图谱。基于遗传算法优化神经网络的开放矿山知识图谱构建方法，用于开放矿山稳定性评价技术领域的露天采矿领域研究。该方法能够进行模型超参数自动优化选择，有效提高模型精度，高效构建高质量的露天矿物稳定性场知识图谱。该方法涉及获得露水灾害相关数据。 对露天矿山灾害相关数据进行处理。 构建命名实体识别数据集。 利用遗传算法对BERT-BILSTM-CRF模型的结构和超参数进行优化。 得到命名实体识别模型。 构建关系提取标签数据集。 得到关系抽取模型。 将待提取室外矿山灾害相关数据输入所述命名实体识别模型和所述关系提取模型，用于进行实体关系提取，得到三元组。 构建户外矿山知识图谱。  12
本发明提供了一种高分辨率遥感影像小样本高精度建筑分割提取方法及装置。获取样本集，包括标记样本和未标记样本；划分训练集和验证集；基于带约束的正样本学习算法构建UNet++改进模型并初始化c值；训练模型，得到正样本概率，通过c值将正样本概率转换成标记样本概率，计算损失函数，根据损失函数优化模型参数，同时通过验证集进行验证，当损失函数或迭代次数满足预设条件时，训练完成，训练好的模型为双分支建筑物分割模型；将待测试影像输入训练好的建筑物分割模型进行建筑物分割提取。结合UNet++和带约束的正样本学习算法，可以自动通过人工标记样本的特征调整得到正样本的特征，同时通过双分支模型提高了对粘连建筑边缘检测的局部准确性。高分辨率遥感影像小样本高精度建筑物分割提取方法。通过人工标记样本的特征自动调整正样本的特征并通过双分支模型提高粘附建筑物边缘检测的局部精度。该方法包括获得样本集。 样本集包括标记样本和未标记样本。 样本集分为训练集和验证集。 UNet改进模型是基于约束正样本学习算法构建的。 训练集用于训练UNet改进模型，得到正样本概率并通过c值将正样本概率转换为已标注样本的概率。 计算得到损失函数。 根据所述损失函数对所述模型参数进行优化。 当所述损失函数或迭代次数满足预设条件时停止训练并得到训练好的建筑物分割模型。 将待测高分辨率遥感影像输入训练好的建筑物分割模型并输出建筑物分割提取结果。包括独立权利要求用于高分辨率遥感影像小样本高精度建筑物分割提取装置。   6
本发明公开了一种Linux主机恶意软件检测方法、系统、设备及介质，涉及网络安全技术领域，包括：基于预设规则集对待检测文件进行静态文件分析，得到待检测文件的静态分析特征；待检测文件为运行于Linux主机上的文件；在预设环境中对待检测文件进行动态文件分析，得到待检测文件的动态分析特征；以静态分析特征和动态分析特征作为输入，基于训练好的支持向量机模型进行分类，得到分类结果；基于训练好的大型语言模型对静态分析特征、动态分析特征和分类结果进行分析，得到待检测文件的检测结果。本发明缓解了现有技术中存在的准确性差和误报率高的技术问题。网络安全中Linux主机恶意软件检测方法。该方法解决了常规技术中准确性差，误报率高的技术问题。所述方法包括：基于预设规则集对待检测文件进行静态文件分析，得到所述待检测文件的静态分析特征。 在预设环境中对所述文件进行动态文件分析处理，得到动态分析特性。 将所述静态分析特征，以及所述动态分析特征作为输入。 基于训练好的大规模语言模型对所述静态分析特征、动态分析特征以及所述分类结果进行分类得到分类结果，得到所述检测结果。独立权利要求包括用于：(1)Linux主机的恶意软件检测系统； (2)电子设备； (3)一种计算机可读存储介质。  11
本发明涉及数据处理技术领域，是关于一种法律文书命名实体识别方法、装置及存储介质，方法包括：获取法律文书的初始有标注文本和无标注文本；通过预设的规则库对所述无标注文本进行命名实体标注，得到第一标注文本；对所述初始有标注文本进行数据增强，得到数据增强后的标注文本；对所述数据增强后的标注文本和所述第一标注文本进行预处理，得到处理后的标注文本；利用所述处理后的标注文本和BERT模型进行迭代训练，得到命名实体识别模型；使用所述命名实体识别模型对待识别的无标注法律文书进行命令实体识别，得到命名实体识别结果。通过该技术方案，降低获取数据的人工成本，提高领域适配性，更好地适配细粒度的应用场景。用于识别文本中的法律文档命名实体并对诸如名称、机制、时间、货币和百分比等实体进行分类的方法，用于信息抽取、问答系统、语法分析、信息检索和情感分析。该方法能够降低获取数据的人工成本，提高现场适应性，更好地适应细粒度的应用场景。该方法包括获取法律文档的初始标注文本和未标注文本，所述初始标注文本标注有命名实体，所述未标注文本未对所述命名实体进行标注。 通过预设规则库对所述未标注文本的命名实体进行标注。 获得第一标注文本。 对初始标注文本进行数据增强。 经过数据增强后得到标注文本。 所述数据增强后对所述标注文本和所述第一标注文本进行预处理。 得到处理后的标注文本。 通过使用处理的标记文本和来自变换器(BERT)模型的双向编码器表示来执行迭代训练，以获得命名实体识别模型。 所述命名实体识别模型用于识别未标注的待识别法律文档。 得到命名实体识别结果。包括独立权利要求：(1)一种法律文档命名实体识别装置； 以及(2)计算机可读存储介质，用于存储用于识别文本中命名实体的法律文档并对实体进行分类的指令。  11
本发明专利提出了一种针对直播营销商品质量感知分析的网购助手构建方法，旨在帮助用户深入了解直播营销商品的质量、评论真实性、商家信誉等信息，从而做出合理的购物决策。该方法首先综合多维度数据(包括商品评论信息、店铺信息和直播间信息)，并采用BERT模型与图神经网络(GNN)相结合的方式提取关键质量特征，进而训练一个多任务学习(Multi‑taskLearning)模型，以评估商品质量、识别虚假评论等任务。接下来，将训练好的多任务学习模型与现有的自然语言模型进行集成。设计贪婪解码方法，基于预训练模型针对特定任务(如商品质量评价、虚假评论识别等)进行任务适应性调整，使生成模型能够理解和处理商品、店铺和直播间信息。最后，将集成后的模型部署到直播营销网购平台上的智能助手中，实现有关商品质量分析结果的自然语言呈现及与用户的交互功能。该网购助手能够为用户提供更丰富、更直观的商品质量信息，提升用户购物体验，降低购买风险，提高消费者的满意度。一种直播营销商品质量感知分析的网络采购辅助构建实现方法。 可用于电子商务技术领域。该方法利用网上购买助手为用户确定直观的商品质量信息，提高了用户的购物体验。 该方法降低了购买难度，提高了消费者的满意度。该方法包括当BERT模型与图形神经网络(GNN)组合时提取关键质量特征。 训练多任务学习模型以评估商品质量并识别虚假评论。 将所述已训练的描述性结构化文本的多任务学习模型的输出结果转换为自然语言模型。 将集成模型部署到直播营销网络购买平台上的智能助理，实现商品质量分析结果的自然语言呈现以及与用户的交互功能。 确定商品质量、虚假评论、目标信息和购物决定。  12
本发明公开了一种兼顾话题发现和情感分析的网络舆情分析方法及系统，所述方法包括以下步骤：步骤1，基于训练好的基于ELMo词向量的BiMPM话题发现模型或LLDA主题模型，获取待分析网络舆情文本的话题；步骤2，基于向量空间模型对步骤1获取的话题进行情感分析。本发明针对不同舆情载体的特性，采用LLDA和基于ELMo词向量的BiMPM话题发现模型进行长短文本的话题发现；并引入大规模的人工标注语料及训练建模，生成准确率、召回率等性能指标较为优秀的训练模型，实现高效的话题发现。网络舆情分析方法。该方法能够生成准确率、召回率等性能指标优异的训练模型并实现高效率的主题发现。该方法包括基于训练好的BiMPM主题发现模型或基于ELMo词向量的LLDA主题模型，获取待分析的网络舆情文本的主题。 基于向量空间模型对所述话题进行情感分析。 基于感知网络情感词典对不同话题下的情感词进行细粒度划分。 将情感词处理与话题标签的网络情感词典相结合进行处理。 在话题发现过程中引入了话题标签集。包括一种网络舆情分析系统的独立权利要求。  12
本申请提供了一种数据处理方法、装置、电子设备及存储介质。包括：获取问话数据及所述问话数据对应的场景领域；基于所述场景领域确定所述问话数据对应的数据补充策略，以及，基于所述场景领域确定所述问话数据对应的领域知识图谱；基于所述数据补充策略对所述问话数据进行补充处理，得到对应的补充结果；基于所述领域知识图谱对所述问话数据进行推理，得到对应的推理结果；将所述补充结果和所述推理结果输入至大语言模型，以由所述大语言模型输出所述问话数据对应的回答数据。从而提高大语言模型在该场景领域上进行数据处理的时效性和准确性，改善模型处理效果。用于处理数据的方法。该方法能够提高场景领域的大型语言模型的数据处理的及时性和准确性以及模型处理效果。该方法涉及获取提问数据和与提问数据对应的场景字段。 基于所述场景字段确定与问题数据相对应的数据补充策略。 基于所述场景领域确定与所述问题数据对应的领域知识图谱。 基于所述数据补充策略对所述问题数据进行补充处理，得到对应的补充结果。 基于所述领域知识图谱对所述问题数据进行推理，得到对应的推理结果。 补充结果和推理结果被输入到大型语言模型。 通过所述大型语言模型输出与所述问题数据对应的答案数据。 所述数据补充策略中设置有参数提取策略和参数配置策略。独立权利要求包括用于：(1)用于处理数据的装置； (2)一种电子设备，包括存储器和处理器，所述处理器用于执行用于处理数据的一组指令； (3)一种计算机可读存储介质，用于存储一组指令并由处理器执行以处理数据。  11
本发明提供了一种长视频专注度预测方法及装置，包括：获取视频，提取所述视频中具有人脸的帧生成具有n帧图像的输入视频；在所述输入视频中抽样r次，每次挑选T个帧生成r个视频序列；将所述视频序列按照预设置的视频块分割为多个目标视频块，进而根据所述目标视频块生成视频矩阵x；获取预设置的矩阵E，将视频矩阵x经过乘以矩阵E生成块嵌入向量xe；将所述块嵌入向量xe输入预训练的类注意力视频Transformer预测模型，通过所述类注意力视频Transformer预测模型确定输出的所述视频中人脸的专注度。本发明在视频生成的r个视频序列上训练类注意力视频Transformer(CavT)预测模型，测试阶段使用视频的第1个视频序列，在训练好的预测模型上计算学生的专注度，实现端对端的专注度预测，不仅便于训练，而且提高了预测的准确度。长视频关注度的预测方法。该方法使得能够在视频生成r视频序列上训练注意力视频(CavT)预测模型，测试阶段使用视频的第一视频序列，在训练好的预测模型上计算学生的注意力程度，实现了端到端的特殊注意力预测，不仅方便训练，而且提高了预测的准确性。该方法包括获得(S1)视频，并提取视频中具有面部的帧以生成具有n帧图像的输入视频。 对输入视频中的时间进行采样(S2)。 产生每次产生视频序列的帧。 将所述视频序列按照预设视频块划分(S3)为若干个目标视频块，并生成按照所述目标视频块的视频矩阵。 获取所述预设矩阵(S4)。 将所述视频矩阵乘以所述矩阵以产生块嵌入向量。 将所述块嵌入向量输入(S5)到预先训练的类别注意力视频变换器预测模型中。 通过类注意力视频变压器预测模型确定输出视频中人脸的焦点。一种长视频关注度预测装置，包括独立权利要求。 9
本申请公开了一种用于色情图片的图像数据处理方法及装置。该方法包括生成训练数据集，其中，训练数据集包括：预设人体关键点标签；根据所述训练数据集训练得到预训练模型；输入待检测图片；以及根据预训练模型判断所述待检测图片是否属于色情图片。本申请解决了对于色情图片的检测处理效果较差的技术问题。通过本申请的方法采用改进的生成对抗网络可批量生成一批包含有正常、色情/性感两种类别的图片集。可大大减少人力成本，并且非常高效。得到的图片集可快速区分待测图片是否属于色情/性感图片。一种情趣图像的图像数据处理方法。可以批量生成包含正常、色情/性感两大类的批量图片，使得人工成本大大降低，效率非常高。 由此得到的集合能够快速区分待测图像是否色情/性感。所述方法涉及生成(S102)训练数据集，其中所述训练数据集包括预置的身体关键点。 根据训练数据集训练(S104)预训练模型。 输入要检测的图像(S106)。 执行所述确定以根据所述预训练模型来检测(S108)所述待检测图像是否属于性爱图像。本发明还涉及一种图像数据处理装置。 14
本发明公开一种基于大模型微调的视频摘要生成方法。视频摘要生成是使用文字对原有视频内容进行总结与概括，在多模态领域应用广泛。本发明提出的基于大模型微调技术的视频摘要生成方法包括以下步骤：(1)利用MACAW‑LLM大模型多模态融合的特点，将视频特征与文本特征进行跨模态交互；(2)采用CLIP、WHISPER完成对视频和音频特征提取；(3)使用GPT‑3.5Turbo生成指令辅助摘要生成算法；(4)使用注意力机制算法完成模态对齐，并与指令进行融合；(5)采用LoRA微调技术进行模型训练，最小化负对数似然函数对大模型参数进行迭代更新并生成视频摘要。本发明使用少量训练数据就可完成零样本迁移学习，最终生成的视频摘要答案准确、条理清晰、内容丰富。基于多模式和语言大模型域中大模型微调的视频摘要生成方法。该方法利用少量的训练数据即可完成零样本迁移学习，最终生成的视频摘要答案准确，规则清晰，内容丰富。该方法涉及收集特定领域的相关视频。 通过人工文本结合领域知识和专业术语对视频进行标注，形成视频摘要数据集。 从原始视频数据中提取视频音频和视频帧。 读取已公布的Macaw-LLM大型模型。 利用剪辑模型提取视频特征。 利用耳语模型提取所述视频特征的音频特征和所述音频特征。 一种多头自关注机制，用于将视频模式和音频模式的特征对齐。 将对齐后的两个模式特征与MACAW-LLM大模型的令牌矩阵对齐。 对Macaw和LLM小模型进行微调，使模型具有理解特定领域知识的能力。 9
本申请提供一种图片识别方法、装置、电子设备及存储介质，该方法包括：计算多模态数据中的文本数据与多模态数据中的图片数据之间的相似度值；对图片数据进行修改识别，获得修改结果；根据相似度值和修改结果识别出图片数据的类别，图片数据的类别包括：人工智能生成内容AIGC图片、用户生成内容UGC图片和原始采集图片。在上述方案的实现过程中，通过计算出多模态数据中的文本数据与图片数据之间的相似度值，并根据该相似度值和该图片数据的修改结果来确定图片数据的类别，改善了通过图片数据的修改结果来进行图片识别的准确率较低的情况，有效地利用了文本数据与图片数据之间的相似度值来提高图片识别的准确率。一种图片识别方法，应用于图像处理和图片识别技术领域。该方法通过对图像数据的修改结果，改善了图像识别准确率低的问题，有效利用了文本数据与图像数据之间的相似度值，提高了图像识别的准确率。该方法涉及计算(S110)多模态数据中的文本数据与多模态数据中的图片数据之间的相似度值。 对所述图片数据进行修改识别(S120)并获得修改结果。 根据所述相似度值和所述修改结果来识别所述图像数据的类别(S130)。 图片数据的分类有：人工智能生成内容(AIGC)图片、用户生成内容(UGC)图片和原始收集图片。包括独立权利要求，用于：(1)图片识别装置； (2)电子设备； 以及(3)存储用于识别图片的程序的计算机可读存储介质。 14
本公开提供英文文本的方面层情感分类方法及系统。其中，该方法包括对英文文本所包含的单词进行词性分析，得到单词的词性向量；初始化英文文本所包含的所有单词，得到单词的词嵌入向量；通过查找单词与情感的对应关系情感表，得到各个句子的情感向量，再将单词的词嵌入向量与句子的情感向量进行连接后输入至TD‑LSTM模型中，输出单词的情感向量；将单词的词性向量、单词的情感向量和单词的词嵌入向量进行连接合成，并输入至多头位置自注意力模块，得到上下文和方面的隐藏向量；再将上下文和方面的隐藏向量输入至共注意力模块中，得到上下文的特征表示和方面的特征表示并组合起来并输入至SoftMax函数中输出英文文本的方面层情感类别。一种英文文本表层情感分类方法。该方法包括将词的词嵌入向量与句子的情感向量连接，并输入到TD-LSTM模型以输出词的情感向量。 将词的语音向量、词的嵌入向量和嵌入向量的词连接并输入到注意力模块的头部位置，以获得隐藏向量的上下文和方面。 将隐藏向量的上下文和方面输入到共同关注模块以获得上下文和方面的表示。 将所述上下文的特征表示和所述方面的特征表示合并后输入至SoftMax函数，以输出所述英文文本的表层情感类别。独立权利要求还包括：一种用于对英文文本的表层情感进行分类的系统一种计算机设备，该计算机设备包括用于对英文文本的表层情感进行分类的存储器和处理器一种用于存储用于对英文文本的表层情感进行分类的指令集的计算机可读存储介质。  12
本发明公开了一种基于全卷积神经网络的三维图像分割方法及系统，包括以下步骤：步骤1，采集获取序列图像并进行标注，获得训练样本数据；步骤2，将步骤1获得的训练样本数据进行归一化预处理；步骤3，应用步骤2处理后的样本数据对预构建的3‑D全卷积残差U‑net网络模型进行有监督的训练，训练至预设收敛条件，获得训练好的三维图像分割模型；步骤4，将待分割的序列图像数据归一化处理后，输入步骤3训练好的三维图像分割模型中，获得序列图像分割结果。本发明可充分利用序列的连续性信息，能够在三维图像分割中获得一个相对较好的结果。该方法包括收集序列图像数据。 对所述序列图像数据进行标注，以得到训练样本数据。 对所述训练样本数据进行归一化处理。 建立三维图像分割模型和全卷积残差U-net网络模型，训练至预设收敛条件。 在归一化处理之后对序列图像数据进行划分。 将所述序列图像数据输入三维图像分割模型，得到序列图像分割结果。 在二维平面上对序列图像数据进行标记。   4
本发明公开了一种大语言模型知识增强方法、系统、电子设备及介质，其方法包括获取输入内容，对所述输入内容进行分析并挖掘，获得回答所述输入内容所需的背景知识query；根据挖掘得到的所述背景知识query，在领域数据或知识库中进行知识搜索，获得所述背景知识query对应的背景知识结果；将所述背景知识结果作为所述输入内容的背景信息，将所述输入内容和所述背景知识结果通过prompt设计工程生成目标prompt模板；将生成的所述prompt模板输入到大语言模型中，得到回答所述输入内容的推理结果。本发明可以为大语言模型提供推理所需的知识，减少大语言模型推理中的事实类错误；可以充分发挥大语言模型强大的理解和推理能力；减少对搜索部分的过度依赖和要求。用于大语言模型的知识增强的方法。该方法能够为大语言模型提供推理所需的知识，从而减少语言模型推理中的事实类型错误，发挥大语言模型较强的理解和推理能力。该方法涉及获得输入内容。 对所述输入内容进行分析和挖掘，得到回答所述输入内容所需的背景知识查询，得到回答所需的背景知识查询。 根据挖掘出的背景知识问题在所述现场数据或知识库中进行所述知识搜索。 与所述背景查询的背景信息对应获取所述背景知识结果。 将生成的背景知识结果作为所述输入信息的背景。 所述输出提示模板为针对大语言模型设计工程设计的目标提示模板生成，并将生成的提示模板输入所述大语言模型，得到输入内容的信息的推理结果，所述信息从输入数据中获取。包括以下独立权利要求：(1)大型语言模型知识增强系统； (2)电子设备； 以及(3)存储用于大型语言模型的知识增强的指令集的存储介质。  11
本发明公开了一种基于Bert的中文文本纠错方法、设备及存储介质，所述中文文本纠错方法采用的文本纠错模型包括纠错网络和检测网络，纠错网络由Bert模型构成，检测网络包括Bert模型和连接在Bert模型后的全连接层；将训练文本分别作为纠错网络和检测网络的输入；将纠错网络的损失和检测网络的损失加权计算后作为文本纠错模型的损失，根据文本纠错模型的损失优化所述文本纠错模型。通过引入检测网络，提升了文本纠错模型对文本错误位置的检测能力。此外，在预训练Bert的过程中，采用全词掩码及N‑gram掩码的方式，并以被遮蔽单词的相似词代替传统的遮蔽字符，能够减小预训练与微调之间的差距。基于Bert的中文文本纠错方法。采用全词掩码和Ngram掩码的方法，在预训练Bert的过程中用掩码词的相似词代替传统的掩码字符，减小了预训练和微调的差距。该方法涉及预训练(S1)Bert模型。 训练文本纠错模型(S2)。 纠错模型包括纠错网络和检测网络。 所述纠错网络由所述Bert模型构成，所述检测网络包括所述Bert模型和与所述Bert模型连接的全连接层。 将训练文本分别作为纠错网络和检测网络的输入。 将所述纠错网络的损失和所述检测网络的损失进行加权计算，作为所述文本纠错模型的损失，根据所述文本纠错模型的损失对所述文本纠错模型进行优化。 将待校正到的文本输入(S3)训练好的纠错网络，纠错网络输出校正后的文本。独立权利要求：一种基于Bert的中文文本纠错装置和存储有用于中文文本纠错的程序的计算机可读存储介质。  12
本发明公开了一种跨领域细粒度情感分析方法、装置及存储介质，其中方法包括：构建目标领域的细粒度情感分析模型；将无标注样本输入BERT编码器预训练语言模型获得每个单词的语法知识向量表示；基于图卷积网络，通过卷积相邻节点的特征来捕获常识关系结构特征并映射到与BERT编码器相同的单词层级维度向量空间中从而获得常识知识向量表示；拼接语法知识向量表示和常识知识向量表示作为单词的最终特征表示；优化模型的参数。本发明通过结合语法知识和常识关系知识来缩小同一分布空间内的不同领域的领域差异，对资源较少的目标领域具有较强的适应性，提高目标领域的方面抽取以及情感分析的预测效果。本发明可广泛应用于自然语言处理技术领域。一种跨域细粒度情感分析方法。跨域细粒度情感分析方法优化了模型参数， 通过将语法知识与普通知识关系知识相结合，减小了同一分布空间中不同领域的领域差异， 对资源较少的目标领域具有较强的适应性，提高了目标领域的方面提取和情感分析的预测效果，广泛应用于自然语言处理技术领域。所述跨域细粒度情感分析方法涉及在目标域中构建细粒度情感分析模型。 预训练语法知识特征向量表示模块具有图卷积网络(GCN)。 将源字段和目标字段中的未标记文本输入到BERT编码器。 将单词的语法知识特征向量和常用知识特征向量表示为单词特征表达式。 将词特征表示输入到训练分类器中。 输出通过最后拼接形成的单词特征表示向量的预测标签作为分类任务。 在所述目标字段和所述方面词的情感极性中完成方面词的识别。本发明还涉及一种用于分析超细粒度情感的方法，该方法包括以下步骤：(a)提供一种具有处理器的超细粒度情感分析装置； (b)用于存储可由处理器执行的程序的计算机可读存储介质。  12
本发明公开了一种基于BERT语义增强的因果关系抽取方法。所述因果关系抽取方法包括：因果关系候选词库、BERT预训练、因果关系抽取。该方法是一种快速提取文本中存在的因果关系的信息抽取技术，核心任务是在LeakGAN对抗神经网络模型的架构下建立基本模型和增强模型进行对抗学习获得高区分度的特征，分析评论文本中存在的因果关系，实现语义增强下的深层次抽取。该方法基于对抗神经网络的对抗性学习更有区分度的特征，提高因果关系抽取的准确度，可应用于事件预测、问答系统以及情景生成等方面。一种基于BERT语义增强的因果关系提取方法。本发明将BERT预训练与Leakgan网络相结合，由Leakgan对抗神经网络学习得到包含语义的词向量，得到高区域索引特征，提高了果实关系提取的准确性。该方法包括选择因果关系候选词库的候选词库， (b)进行BERT预训练， 和(c)进行果实关系提取， (d)通过候选词库学习每个字段中的特殊术语， (e)学习BERT预训练中的特殊术语的特征， (f)将预先训练好的词向量输入B-LSTM网络提取文本特征；(g)进行多特征融合；(h)最后通过神经网络进一步提取特征；(i)将CRF的输出序列化；(j)实现因果关系的提取。  12
本发明公开了一种视频和无线融合的大规模人群分析方法，包括：获取视频和WiFi两种模态的原始数据；对两模态原始数据分别进行时空对准并得到两模态第一数据；对所述两模态第一数据进行特征提取得到两模态特征数据；对两模态特征数据进行特征融合并得到融合数据，对融合数据解码并输出人群统计结果；利用视频模态原始数据标注对所述WiFi模态原始数据进行标记；子模型及总体模型的训练。本发明针对视频数据创新地采用了结合注意力机制的CNN模型进行特征提取；利用兼顾时间单向和空间四向的2D‑RNN结构来建模二维输入特征数据，提高了人群分析精度；使用子模型预训练和单模态有限标注监督迁移的方法，解决大模型训练以及多模态标记数据获取成本过高的难题。同时，各子模型采用不同的有针对性的数据源进行预训练，整合后的模型通过微调进行优化。视频与无线融合的大规模人群分析方法。本发明实现了视频数据中特征提取的创新的结合注意力机制的卷积神经网络(CNN)模型，利用2D-RNN维输入特征数据对2D输入特征数据进行建模，考虑了时间单向和空间四个方向，提高了人群分析精度，子模型预训练和单模有限标记监测迁移过程，避免了大模型训练和多模标记数据获取代价的问题，采用不同的有针对性的数据源进行预训练，通过微调优化集成模型。该方法包括获取原始数据，其中原始数据包括视频模式原始数据和无线保真(Wi-Fi)模式原始数据。 对原始数据进行时空对齐，以获得两种模式的第一数据。 对所述第一数据进行特征提取，得到两个模态特征数据。 对所述特征数据进行特征融合，用于输出融合数据。 对所述融合数据进行解码，用于输出人群统计结果。 确定所述视频模式的原始数据。 监测所述Wi-Fi模式的原始数据的迁移标记。 建立模型，得到标签的双模原始数据。 对所述视频模式和Wi-Fi模式进行训练。 9
本发明涉及一种基于神经网络的改进分层序列标注联合关系抽取方法，包括：将文本输入模型，通过预训练模型获取文本特征向量；将文本特征向量通过CNN模块进行解码，输出主体的头位置标记序列；将主体的头位置标记序列与文本特征向量融合，通过CNN模块解码，输出主体的尾位置标记序列；将主体的先验信息与文本特征向量融合形成新的文本特征向量，通过CNN模块解码，输出对应主体所有关系下的客体的头位置标记序列；再将客体的头位置标记序列与文本特征向量融合，形成新的文本特征向量，通过CNN模块解码，输出对应主体所有关系下的客体的尾位置标注序列，同时完成关系与客体的解码；根据主客体的头尾位置标记序列输出文本包含的三元组。基于神经网络的分级序列标记联合关系抽取方法。该方法使得能够在对应主体的所有关系下输出对象的尾部位置标记序列，完成关系和对象的解码，并根据主体对象的头尾位置标记序列输出文本中包含的三元组。该方法涉及通过预训练模型获取文本特征向量。 通过卷积神经网络(CNN)模块对文本特征向量进行解码。 输出主体的头部位置标记序列。 将所述主体的头部位置标记序列与所述文本特征向量进行融合。 输出所述主体的尾部位置标记序列。 将所述主体的信息与所述文本特征向量进行融合，形成当前文本特征向量。 将所述对象的头部位置标记序列与所述文本特征向量进行融合，用于形成所述当前文本特征向量。 根据一个主对象的头尾位置标记序列输出所述文本中包含的三元组。  12
本发明公开了一种端到端的说话人聚类方法，包括以下步骤：S001：收集至少两人的说话人语音数据；S002：提取语音数据的声学特征；S003：设计一个说话人聚类神经网络模型，用于聚类和分类；S004：设计一个说话人识别神经网络模型，用于预训练模型；S003：采用已知标签信息的说话人语音数据训练说话人识别神经网络模型；S004：采用说话人识别模型参数初始化说话人聚类神经网络模型；S005：采用未知标签的说话人语音数据训练说话人聚类神经网络模型；S006：说话人聚类神经网络模型收敛，输出未知标签的说话人语音数据的标签信息。本发明可以大大减少人工参与数据标定的工作量，也有助于提高说话人识别模型的精度。端到端的说话人语音数据聚类方法。该方法能够减少人工参与数据校准，并提高说话人识别模型的准确性。该方法包括收集两个人的说话者语音数据。 提取所述语音数据的声学特征。 建立说话人聚类神经网络模型进行聚类分类。 针对预训练模型设计说话人识别神经网络模型。 利用已知标签信息的说话人语音数据训练说话人识别神经网络模型。 利用说话人识别模型参数对所述说话人聚类神经网络模型进行初始化。 利用未知标签的说话人语音数据训练说话人聚类神经网络模型。 输出所述未知标签的说话人语音数据的标签信息，并通过所述说话人聚类神经网络模型进行收敛。本发明还涉及一种端到端说话者语音数据聚类系统。 3
本申请提供了一种文本分类模型、文本分类的方法以及装置，该文本分类模型包括嵌入层、BiLSTM层、注意力层、胶囊网络层、Flatten层、全连接层以及Softmax函数层，其中，嵌入层用于将文本的多个词语转换为词向量；BiLSTM层的输入端与嵌入层的输出端连接；注意力层的输入端BiLSTM层的输出端连接；胶囊网络层的输入端与注意力层的输出端连接；Flatten层的输入端与胶囊网络层的输出端连接；全连接层的输入端与Flatten层的输出端连接；Softmax函数层的输入端与全连接层的输出端连接。该文本分类模型的训练时间较短，训练效率较高。文本分类模型。该模型训练效率高，减少了文本分类模型的训练时间。该模型具有用于将文本的单词转换成单词嵌入双向长短期记忆(BiLSTM)层的嵌入层。 所述BiLSTM层的输入端与所述嵌入层的输出端连接。 attention层的输入端与BiLSTM层的输出端相连。 胶囊网络层的输入端与注意力层的输出端连接。 扁平层的输入端与胶囊网络层的输出端连接。 全连接层的输入端与平坦化层的输出端连接。 Softmax函数层的输入端与全连接层的输出端相连。还包括以下独立权利要求：文本分类方法； 以及文本分类装置。  12
本发明公开一种对高比例负荷缺失数据的恢复与评估方法，所述方法对在U‑Net网络建立将负荷缺失数据恢复转化为负荷图像修复的图像处理模块，所述图像处理模块包括如下步骤：步骤(1)获取负荷数据；步骤(2)对负荷图像进行归一化处理，构建训练集；步骤(3)对原始U‑Net进行改进；步骤(4)训练改进U‑Net数据恢复网络；步骤(5)基于图像的结构相似性指标评估缺失数据恢复方法；本对于提高高比例缺失甚至长时间连续缺失情况下的负荷缺失数据恢复精度，全面评估负荷数据恢复效果有重要意义。高比例负荷损失数据的恢复和评估方法。该方法提高了高比例删除甚至长时间连续删除条件下的负荷丢失数据恢复精度，提供了负荷数据恢复效果的综合评价。该方法包括收集U-Net网络中的图像的历史数据。 选取一个完整的载荷数据，构建二维载荷矩阵。 对每个载荷矩阵进行归一化处理，形成载荷图像。 采用结构相似度评价提高负载图片与U-net网络恢复的完整负载图片之间的相似度。 指示了网络恢复效果。   6
本申请公开了一种数据协同能力评价的建模方法及装置，建模方法包括：构建变量获取模型，变量获取模型用于依据采集的工艺数据获得多个变量的值，变量包括过程精密度和过程准确度；构建变量的能力评价模型，能力评价模型用于依据变量的值计算相应的变量的能力评价得分；构建协同能力获取模型，协同能力获取模型用于依据多个变量的能力评价得分计算数据协同能力得分；将变量获取模型、变量的能力评价模型以及协同能力获取模型组合形成数据协同能力评价预训练模型；对数据协同能力评价预训练模型进行训练，获得数据协同能力评价模型。本申请采用多个变量对数据协同能力进行评价，客观、科学且准确地描述生产过程中的数据协同能力。该方法对于数据协同能力评价建模是有用的。利用多变量评价数据协同能力的方法，客观、科学、准确地描述生产过程中数据协同能力。方法包括：根据采集的过程数据，构建变量获取模型，用于获取多个变量的值，所述变量包括过程精度和过程准确度。 构建变量能力评价模型，用于根据所述变量的取值计算对应变量的能力评价得分。 构建协作能力获取模型，用于根据所述多个变量的能力评价得分计算数据协作能力得分。本发明还公开了一种数据协同能力评估建模装置。  11
本发明公开了一种多标签文本分类方法及模型，分类方法包括标签预适应任务，根据多标签文本分类的输入数据，得到预适应嵌入的特征表示，进而进行相似度匹配；共享特征获取，根据多标签文本分类的输入数据，以及对标签预适应任务中的预训练语言模型进行权重加载，得到共享特征表示；并行分类任务，利用共享特征表示作为并行任务的输入，并行任务包括篇章‑标签分类任务、关键词‑标签分类任务以及标签‑标签相关性判断任务；分类模型包括标签预适应模块、共享特征获取模块、关键词抽取模块、标签采样模块、篇章‑标签分类模块、关键词‑标签分类模块、以及标签‑标签相关性判断模块。本发明增加了并行任务，提升了模型的性能。多标签文本分类方法，用于基于标签的文本分类技术领域。 可用于信息领域，情感分析，标签推荐，意图，识别不同于传统的单标签分类任务，多标签分类任务中文本与标签的对应关系不同。由于在标签预适应任务中预训练预训练语言模型进行权重加载，根据多标签文本分类的输入数据进行共享特征获取，增加了并行任务，提高了模型的性能。该方法涉及扩展多标签文本分类的输入数据。 输入数据设有文本和标签。 在标签预适应任务中对预训练语言模型进行加权。 将所述共享嵌入式表示输入到加载的预训练语言模型中。 获得共享特性表示。 执行并行分类任务。 辅助话语-标签分类任务和关键词-标签分类任务更好的信息标签利用标签-标签相关性判断任务。还包括用于多标签文本分类模型的独立权利要求。  11
一种基于深度学习的舱门低质量图像优化方法，包括以下步骤：采集舱门对接图像，制作高质量‑低质量图像数据集；基于U‑net架构编码器‑解码器和单尺度通道结构，构建三阶段架构的深度学习网络；在所述深度学习网络的每个阶段之间引入注意力机制；在所述编码器‑解码器之间、所述编码器‑解码器与所述单尺度通道结构之间分别引入图像细化模块；训练所述深度学习网络。本发明的方法，基于深度学习，对舱门对接过程中采集的低质量图像进行优化，使图像特征将更加清晰，从而使得舱门与廊桥的整个对接过程更加流畅、准确。基于深度学习的舱门低质图像优化方法。基于深度学习的舱门低质量图像优化方法基于舱门对接过程中采集到的深度学习网络质量图像进行优化，可以使图像特征更加清晰，使得舱门与廊桥的整个对接过程更加流畅准确。 图像特征更加清晰，便于对接工作的顺利进行。舱门低质量图像优化方法涉及采集舱门贴靠图像，制造高质量-低质量图像数据集。 深度学习网络阶段架构是基于U-net架构编码器-解码器和单尺度通道结构构建的。 在深度学习网络的每个阶段与编码器-解码器之间引入注意力机制。 图像细化模块中分别引入了编码器-解码器和单尺度通道结构。 对所述深度学习网络进行训练。 从所述端口对接视频中提取低于所述预设像素值的低质量帧图像。   6
本申请提供了一种问答处理方法、系统、设备和存储介质，涉及人工智能技术领域。主要技术方案包括：获取用户请求，利用用户请求得到针对目标垂直领域的第一问题文本；从目标垂直领域的知识库中获取与第一问题文本满足预设相关度要求的N个知识，N为正整数；利用N个知识和第一问题文本构建第二问题文本；利用问答模型针对第二问题文本生成答复文本，问答模型基于大语言模型实现。本申请能够提升大语言模型在垂直领域的问答任务上的效果。医疗(索赔)等电子设备对目标垂直领域的问答进行处理的方法。该方法能够提高大型语言模型在垂直领域对问答任务的效果。该方法涉及获得用户请求。 利用所述用户请求，针对目标垂直领域，获得第一问题文本。 从所述目标垂直领域的知识库中获取与所述第一问题文本满足预设相关度要求的N个知识，其中，所述N确定为正整数。 利用所述N个知识和所述第一问题文本构建第二问题文本。 利用问答模型生成针对所述第二问题文本的回复文本。 所述问答模型是基于大型语言模型实现的。 获取所述第一问题文本的嵌入表示。独立权利要求包括用于：利用电子设备处理医疗领域的问答的方法。 一种利用电子设备进行目标垂直领域问答处理的系统。 计算机可读存储介质，用于存储执行一种电子设备对目标垂直领域的问答处理方法的指令集合。  11
本发明公开了一种基于双层交互联合模型的情绪分析方法及系统，进行数据集采集与预处理，包括收集时事热点相关的网络舆情数据，去除文本无效信息；数据标注，包括构建标注平台，按照标注规范进行有效性及情绪标签标注，交叉检验后存入数据集；文本特征提取，包括将文本转成单词序列并输入到BERT模型得到文本字编码，经过GRU获得用于方面提取和情感分类两个子任务的隐藏状态；语义级交互，包括不同特定任务特征进行有选择性地组合，通过学习共最佳组合，实现两个任务在语义级上的浅层交互；任务级交互，包括使用线性分类器预测方面项，引入AOA模型实现情感分类，再利用交互信息最大化，使方面提取和情感分类在输出层共享信息，实现任务级的交互平衡。基于双层交互联合模型的情感分析方法。该方法实现简单方便，实用性强，解决了相关技术中存在的实用性低，不便于实际应用的问题，能够提高用户体验，具有重要的市场价值。基于双层交互联合模型的情感分析的方法，涉及：(S1)采集各大社交平台上与当前事件相关的网络舆情数据，去除文本无效信息； (S2)构建标记平台，按照标记规范标记有效性和情感标签，将标记后的有效性和情感标签进行交叉校验后存入数据集； (S3)将所述(S2)中处理后的所述数据集中的文本转换为词序列并将所述词序列输入到双向编码器表示从变压器模型中得到文本词编码，然后将文本词编码经过门控循环单元得到隐藏状态进行方面提取和情感分类这两个子任务。基于双层交互联合模型的情感分析的方法，涉及：(S1)采集各大社交平台上与当前事件相关的网络舆情数据，去除文本无效信息； (S2)构建标记平台，按照标记规范标记有效性和情感标签，将标记后的有效性和情感标签进行交叉校验后存入数据集； (S3)将所述(S2)中处理后的数据集中的文本转换为词序列并将所述词序列输入到双向编码器表示从变压器模型中得到文本词编码，然后将文本词编码经过门控循环单元得到隐藏状态进行方面提取和情感分类这两个子任务； (S4)将所述(S3)得到的方面提取和情感分类的不同具体任务的特征进行选择性组合，通过学习共享表示和具体任务表示的最优组合，实现两个任务在语义层面上的浅层交互； 以及(S5)利用线性分类器预测方面项，引入注意力-过度注意力模型实现情感分类，然后利用交互信息最大化模式，使方面提取和情感分类在输出层共享信息，实现任务级交互平衡。 本发明还涉及一种情感分析系统。  12
本发明属于深度学习技术领域，特别涉及一种图像处理优化方法。一种Vision Transformer模型结构优化方法，包括以下步骤：S1.将图片数据利用图片块映射层，先切割为图片块后再分别处理为高维向量；S2.利用级联的优化的Transformer编码器，将所述高维向量进行建模。本发明通过有效结合卷积神经网络与Transformer中的多头注意力层，向Vision Transformer中有效的引入的归纳偏置，提高了模型对图片/图像数据的建模性能。相较于原始的Vision Transformer模型，本发明能够更加高效地给出图片/图像数据的建模结果。同时，本发明还公开了一种Vision Transformer模型结构优化系统及介质。视觉模型结构优化系统，用于深度学习技术领域，用于图像处理优化过程。 可用于不同行业，以及热门行业，如自然语言处理、图像处理等。该系统有效地将卷积神经网络与卡片中的多头注意力层相结合，有效地引入了对视觉的诱导偏差，提高了模型对图片/图像数据的建模性能。该系统具有映射单元，用于对图片数据进行分块操作，完成图片块的高维映射过程的卷积层。 池层过滤多余的高维量。 建模单元被提供有包括优化编码器的优化级联编码器。 优化后的编码器包括归一化层、多头注意力层、卷积层和全连接层。 建模单元，用于对映射单元生成的高维向量进行建模。独立权利要求包括：(1)视觉模型结构优化方法； 以及(2)用于存储用于操作视觉模型结构优化系统的指令的非暂时性计算机可读介质。   5
本发明公开了一种无听障障碍的文字讲述内容的生成方法及相关设备，所述方法包括：获取目标视频的音频，多模态大型语言模型进行识别生成带时间轴的音频内容文本；获取目标视频的图像，识别获得图像内容文本；获取目标视频的字幕，根据字幕和图像内容文本比对出音频内容文本的独有内容并标注；获取目标视频的剧本和演员信息，将图像内容文本、剧本和演员信息进行对比得到角色识别结果，对每条音频内容文本标注出对应角色；根据标注后的音频内容文本生成提示词，根据提示词引入已有内容生成文字讲述内容；将文字讲述内容添加到所述字幕中。本发明生成对听障人士无障碍的讲解文本内容，充分解析音频中的信息，便于听障人士获取更丰富的视频信息。无听力障碍的文字描述内容的生成方法。该方法能够对听力障碍者无障碍地生成讲解文本内容，并且能够以方便的方式对音频中的信息进行充分分析，以获得丰富的视频信息。该方法涉及生成没有听力障碍的单词描述内容。 获取目标视频的音频(S10)。 采用多模式大型语言模型对音频进行识别，生成具有时间轴的音频内容文本。 获取目标视频的图像(S20)。 多模式大型语言模型用于识别图像。 获取图像内容文本。 获取目标视频的剧本和演员信息(S40)。 利用多模式大语言模型对所述图像内容文本、所述脚本和所述演员信息进行比对，得到角色识别结果。 根据标记的音频内容文本生成提示词(S50)。 采用多模式大语言模型，根据提示词引入现有内容，生成字符描述内容。 将单词描述内容添加(S60)到字幕中。独立权利要求包括用于：(1)用于生成无听力障碍的词描述内容的系统； (2)用于生成无听力障碍的文字描述内容的终端； (3)一种计算机可读存储介质，其存储有一组用于生成无听力障碍的单词描述内容的指令。 9
本发明公开了一种基于布局感知提示的文档视觉语言推理方法，该方法利用大型语言模型进行视觉信息丰富的文档推理，将文档图像的文本信息与视觉信息集成的提示，通过提示学习引入布局信息，引导大型语言模型能够理解问题中的文本与视觉内容之间的关系，并使用该信息改善上下文学习生成答案，让单模态大语言模型也能处理多模态文档视觉问答任务，帮助大型语言模型在少样本学习上达到理想的效果，并在3种不同的文档视觉问答数据集测试方法的泛化性。文档视觉语言推理即基于版面感知提示的视觉问答(VQA)方法，用于计算机视觉、自然语言理解和人工智能。该方法使得利用该信息改进上下文学习生成答案，使得单模式的大语言模型也对多模式的文档视觉问答任务进行处理，有助于大语言模型在较少的样本学习上达到理想的效果，以及文档视觉问答数据集三种不同测试方法的可推广性。该方法涉及对数据进行预处理。 得到数据集。 通过光学字符识别算法对数据集中的文档图像进行预处理操作，以提高后续处理的精度和效率。 选取一个示例样本，用于帮助大型语言模型理解任务所需的数据格式和问答形式。 将搜索数据集中的所有搜索样本的问题组成集合。 提取测试数据集中任意一个测试样本的问题。 设计了布局感应提示。 所述提示为采用特定的文本或语言提示，引导所述大型语言模型生成特定的输出。 将所设计的提示传输给所述大语言模型，以执行所述小样本文档视觉问答推理任务，生成所述答案。  11
本公开提供了一种目标检测任务模型的训练方法、装置、设备及存储介质，涉及机器学习、图像处理等等技术领域。具体实现方案包括：获取预训练模型在已完成的图像分类任务的训练中使用的训练图像以及训练图像的类别；基于至少一种深度学习可解释性算法、所述训练图像以及所述训练图像的类别，获取所述训练图像中目标对象的标注框的坐标信息；所述目标对象为所述训练图像中对所述类别的识别做出贡献的对象；基于所述训练图像以及所述训练图像中所述目标对象的标注框的坐标信息，对所述预训练模型进行目标检测任务的训练，得到目标检测任务模型。本公开的技术，能够有效地提高目标检测任务模型的准确性。用于在使用电子设备的机器学习中训练计算机目标检测任务模型的方法(权利要求书)。有效提高了目标检测任务模型的准确性。该方法包括获得在通过预训练模型训练完成的图像分类任务中使用的训练图像和训练图像的类型(S101)。 基于可解释解释算法的至少一种深度学习获得训练图像中目标物体的标记框的坐标信息(S102)。 目标对象是对训练图像中的类别的识别有贡献的对象。 基于所述训练图像以及所述目标对象的标记框在所述训练图像中的坐标信息。 将所述目标检测任务训练至所述预训练模型，得到所述目标检测任务模型(S103)。独立权利要求还包括用于：一种用于使用电子设备训练机器学习中的计算机目标检测任务模型的设备； 一种非暂态计算机可读存储介质，具有用于使用电子设备训练机器学习中的计算机目标检测任务模型的指令集； 以及计算机程序产品。 14
本申请提出一种基于图卷积网络的社交文本分类方法，包括步骤：获取社交文本数据，社交文本数据包括用户和用户的文本内容；对每个用户的文本内容进行计算，应用训练好的BERT‑attention模型获得用户文本向量；以用户文本向量为节点，以用户间发送的文本内容的数量为边，构建用户关联图；基于用户关联图进行图卷积运算，获得关联文本向量；基于关联文本向量以及用户文本向量，获得用户的文本内容的分类标签。本发明的方案以BERT、图卷积神经网络为技术基础，不仅关注于人物自身的聊天文本，还从人物的整体社交内容进行信息挖掘与建模，对人物之间的关联进行量化，提高了社交文本分类的准确性。基于图卷积网络进行社交文本分类的方法。该方法以BERT和图卷积神经网络为技术基础，不仅关注人的聊天文本，从人的整个社交内容中挖掘和建模信息，量化人与人之间的关联，提高社交文本分类的准确性。所述方法包括：获取社交文本数据，所述文本数据包括用户和用户的文本内容。 对每个用户的文本内容进行计算，得到用户文本向量。 将用户文本向量作为节点。 以所述用户之间发送的文本内容的数量为边，构建用户关联图。 基于所述用户关联图进行图卷积运算，得到所述用户的关联文本向量。 基于相关文本向量得到分类标签，以对所述用户文本内容进行分类。独立权利要求还包括用于：(1)基于图卷积网络的社交文本分类系统； (2)计算机装置； 以及(3)计算机可读存储介质，用于存储基于图卷积网络进行社交文本分类的指令集。  12
本发明公开了一种融合深度语言生成模型的语言表达能力评价方法和系统。系统包括第一模型和第二模型，第一模型的输出层连接第二模型的输入层，第一模型的训练过程包括：音频数据特征的提取、评语的分词和词向量化处理，以及音频特征和词向量的训练。第二模型的训练过程包括：词向量和评语的训练。评价方法包括：第一模型和第二模型的训练，然后将待测音频经第一模型和第二模型计算，得到测评结果。本发明构造简单，构建成本低，能对学习者的语言表达进行客观、准确、快速地评价。作为与深度语言生成模型相结合的语言内容表达能力的评价方法。该系统结构简单，造价低廉，能够客观，准确，快速地评价学习者的语言表达。结合深度语言生成模型的语言内容表达能力评估方法， 包括(i)对音频数据样本进行特征提取以获得音频特征， 对音频数据对应的评论进行分词，并对分词进行词向量化，得到词向量，将音频特征和对应的词向量输入到LSTM模型中进行训练； (ii)将词向量和相应的注释输入到LSTM模型中进行训练； 以及(iii)将待评估的音频数据依次通过训练好的模型以获得评估结果。本发明还涉及一种集成了深度语言生成模型的语言内容表达评估系统。 3
本发明公开了融合实体类型的BERT知识图谱补全方法及系统，将实体信息的外部知识即实体类型作为实体信息的补充，更好地获取实体的语义信息，提高模型输入端的文本增强表示，使用多头注意力机制的Transformer编码器实现特征获取和序列编码，使用少量的标注三元组进行微调，有效实现隐含关系的挖掘，实现快速、准确的对多源异构数据进行清洗。针对融合实体类型的BERT知识图谱补全方法。该方法实现了特征获取和序列编码，并有效实现了隐藏关系的挖掘，实现了对多源异构数据的快速准确清洗。所述BERT知识图谱补全方法包括构建BERT知识图谱模型，所述BERT知识图谱模型包括输入层、编码层和输出层，所述输入层用于构建输入文本的头部实体，所述编码层用于对输入序列进行编码。 编码后提取输入序列不同层次的语义特征。 计算模型预测概率与期望概率之间的距离，以调整BERT知识图谱模型的网络参数。 采用训练好的模型对输入文本进行分类预测。一种计算机系统，其包括用于所述融合实体类型的BERT知识图谱补全方法的处理器。  12
本发明属于自然语言处理领域，具体涉及一种基于常识扩展的角色一致性对话生成方法；包括：获取常识扩展数据集并进行人物角色语句提取和对话历史语句的有效语句提取，得到第一对话数据集和第二对话数据集；组合第一对话数据集和第二对话数据集，对组合后的数据集和常识扩展数据集进行训练，直到两数据集相互收敛，对收敛后的组合数据集中的人物角色语句和对话历史语句进行嵌入编码；将编码后的结果输入到GPT‑2模型中进行训练，得到初始对话回复；将初始对话回复和编码后的人物角色语句输入到一致性理解解码器中进行训练，得到最终的一致性对话回复；本发明有效提高了对话生成模型的角色一致性和回复多样性。基于常识扩展的角色一致性对话生成方法。该方法能够有效提高对话生成模型的角色一致性和回复多样性。 该方法能够通过公共标识扩展数据集使用常识扩展字符角色语句进行数据抽取，以删除与给定字符角色信息相矛盾的大规模非对话推理数据集的数据。 对改写后的角色语句进行标注扩展，得到人工扩展数据组，并使用预先训练好的翻译模型和反向翻译模型。该方法包括获得对话数据组。 对所述数据组进行公共标识扩展，得到公共标识扩展数据组。 利用角色提取模块提取所述公共标识扩展数据组的字符角色语句。 获得第一对话数据组。 将所述第一对话数据组和一个第二对话数据组进行合并，得到合并数据组。 数据在收敛后被嵌入并编码到组合数据组中。 将初始会话回复和特定角色角色语句输入一致性理解解码器进行训练，得到最终的一致性会话回复。 8
本申请公开了一种模型训练方法、装置、电子设备及存储介质；该方法包括：基于预先构建的数据集接收用户发送的模型训练请求；其中，该模型训练请求包括：内部模型训练请求或者外部模型训练请求；若模型训练请求为外部模型训练请求，则通过代理服务器在第三方平台中获取第三方平台的大模型；通过可视化界面对第三方的大模型进行训练，得到第三方的大模型的训练结果，并通过可视化界面对第三方的大模型的训练结果进行管理。本申请实施例不仅可以针对第三方平台的大模型进行训练，还可以降低模型训练的技术难度，从而可以提高模型训练效率，提升用户使用体验。用于在电子设备中训练机器学习模型的方法(要求保护的)。该方法使得能够对第三方平台的大模型进行训练，降低了模型训练的技术难度，从而提高了模型训练效率和用户体验。该方法包括接收用户基于预先构建的数据集发送的模型训练请求，所述模型训练请求包括内部模型训练请求或外部模型训练请求。 若所述模型训练请求为所述外部模型训练请求，则由代理服务器获取第三方平台大模型。 通过可视化界面对所述第三方平台大模型进行训练，得到所述第三方平台大模型的训练结果。 通过可视化界面对第三方平台大模型的训练结果进行管理。还包括独立权利要求：(1)模型训练装置； 以及(2)存储介质，其包括用于训练电子设备中的机器学习模型的指令集。  11
一种基于卷积神经网络的视频编解码环路内滤波器及其实现方法，以视频编解码算法编码并解码得到的视频作为训练数据，使用监督学习的方法训练一卷积神经网络并得到预训练模型，然后在视频编解码环路内对每一个重建帧划分为若干个子图，采用所述预训练模型以每一个子图作为输入，输出一张与输入图像大小相同的图像，并根据输出图像的质量提升与否，有选择地使用输出图像更新原图像。本发明能够提升编解码过程中的重建帧的图像质量，并对后续编码过程提供增益，最终提升编码算法的效率。基于卷积神经网络的视频编解码环路滤波及实现方法该方法能够提高重构帧解码过程中的图像质量和算法的编码效率。该方法涉及通过使用视频编码/解码算法对视频训练数据进行编码和解码。 利用监督学习技术得到卷积神经网络建立预训练模型。 将多个重构帧划分为多个子图。 使用预训练模型输出图像。 计算输出图像的质量。 通过使用输出图像来更新原始图像。 利用监督学习技术确定卷积神经网络的参数，以优化某些过程。 在预设网络结构的主体上固定有引导器和多个可选择分支。 每个分支上固定有多个基本单元块，用于最终输出输入视频帧的图像大小。 训练数据生成模块与卷积神经网络连接。本发明还涉及一种基于卷积神经网络的视频编解码环路滤波实现系统。 9
本公开提供一种构建对话模型的方法、装置、设备及存储介质，其中，方法包括：获取中文闲聊语料数据集；基于中文闲聊语料数据集对第一预训练模型进行训练，以确定初始对话模型；获取训练样本集；其中，训练样本集包括原始对话集合样本和扩充对话集合样本，原始对话集合样本包括目标角色对应的多个原始对话样本，扩充对话集合样本包括目标角色对应的多个扩充对话样本；基于训练样本集，对初始对话模型进行训练，以确定目标角色对应的目标对话模型。本申请得到的目标对话模型可以实现带有目标角色风格的回答，以便于用户基于目标对话模型实现与目标角色的对话体验，以提升满足用户的个性化求。对话模型的构建方法。用户可以基于目标对话模型实现与目标角色的对话体验，提高用户的个性化需求。该方法包括获得(S110)中文空闲聊天材料的数据集。 基于所述中文聊天素材数据集对第一预训练模型进行训练(S120)，以确定初始对话模型。 得到训练样本集(S130)。 训练样本组中设置有原始对话组样本和扩展对话组样本。 所述原始对话组样本中设置有与一个目标角色对应的多个原始对话组。 所述扩展对话组样本为与所述目标角色对应的多个扩展对话组样本，所述初始对话组模型为基于所述训练样本集对所述训练样本组进行训练，以确定与所述目标角色对应的目标对话模型。包括独立权利要求，用于：(1)对话模型的构建装置； (2)一种存储介质，包括一组程序，用于执行一种对话模型的构建方法。 8
本申请涉及一种训练文本数据的扩增方法、装置、电子设备及计算机可读介质。该方法包括：获取任务描述数据、标签描述集合、样例文本集合；将所述任务描述数据、所述标签描述集合、所述样例文本集合拼接生成任务标签文本集合；将所述任务标签文本集合输入预训练过的语言模型中，生成多个扩增样例文本；通过所述多个扩增样例文本集合生成训练文本数据；利用所述训练文本数据对机器学习模型进行模型训练。本申请能够方便快捷的生成大量的用于自然语言模型训练的文本数据、节省人力时间和成本，而且生成的文本数据多样性高，提高下游模型的训练效果，提升用户数据安全度。用于通过电子设备训练文本数据的放大方法(要求保护)。该方法能够方便快捷地生成大量文本数据进行自然语言模型训练，节省了人力时间和成本，提高了下游模型的训练效果和用户数据安全性。该方法涉及获取任务描述数据、标签描述集合、样本文本集合、任务标签文本集合和样本文本集合。 将所述任务描述信息、所述标签描述组和所述样本文本组进行拼接，生成任务标签文本集合。 将所述文本集合输入预先训练的语言模型，生成多个扩增样本文本。 根据所述多个放大文本集生成所述训练文本数据，以训练机器学习模型。独立权利要求还包括：一种用于训练文本数据的放大装置； 以及一种计算机可读介质，包括一组用于训练文本数据的放大方法的指令。  11
本发明涉及一种基于全卷积网络的遥感影像地表覆盖分类方法，包括以下步骤：步骤S1：对数据数量有限的数据集进行数据增强，生成数据数量和质量达到训练要求的训练集；步骤S2：融合改进的全卷积网络FCN4s与改进的U型全卷积网络U‑NetBN，建立遥感影像地表覆盖分类模型；步骤S3：通过随机梯度下降来最小化交叉熵损失，学习模型的最优参数，得到训练好的遥感影像地表覆盖分类模型；步骤S4：利用训练好的遥感影像地表覆盖分类模型对待预测的遥感影像进行像素级别的分类预测。该方法综合考虑了FCN和U‑Net两种不同结构的全卷积网络的特点，有利于提高遥感影像地表覆盖分类的性能。基于全卷积网络的遥感图像地表覆盖分类方法。该方法能够实现全卷积网络和U形全卷积网络的特性，用于提高遥感图像分类面覆盖分类过程的性能。该方法涉及对数据集执行数据增强，其中数据集包括有限数量的数据。 将全卷积网络FCN4s与U形全卷积网络融合，建立遥感影像地表覆盖分类模型。 通过使用一个训练集和所述遥感影像地表覆盖分类模型来最小化交叉熵损失。 利用所述训练好的遥感影像地表覆盖度分类模型对待预测遥感影像进行像元级分类预测。   6
公开了一种基于2D图像的人体语义预测模块、虚拟换衣模型及方法。所述人体语义预测模块由一个改进后的U‑Net网络组成，改进后的U‑Net网络是将传统U‑Net网络的基本单元改为残差块；人体语义预测模块的输入为平面化服装图像和由人体模特图像提取的人体姿态特征，输出包括所述人体模特图像每个像素点的分类概率；人体姿态特征包括densepose特征；人体语义预测模块依据所述分类概率预测换衣后的人体语义信息。虚拟换衣模型包括一个服装变形的外观流模块、人体语义预测模块和换衣生成模块。虚拟换衣方法包括构建虚拟换衣数据集、设计虚拟换衣模型和设计虚拟换衣模型的训练策略的步骤。本发明具有较高的网络提取特征的能力，提升了最终换衣图像的真实性。人体语义预测模块，用于虚拟更衣模型中，用于基于二维(2D)图像预测人体语义信息。该模块可以充分利用密集的姿态特征信息以及其他与人体内衣物无关的特征，生成最终着装图像中每个位置像素点的类型预测信息。 该模块具有较高的网络提取特征的能力，提高了最终换衣图像的真实性。该模块具有人体语义预测模块，该人体语义预测模块设置有改进的U-Net网络，其中改进的U-Net网络是将传统U-Net网络改变为残差块的基本单元。 人体语义预测模块的输入端生成平面化服装图像和人体模型图像提取的人体姿态特征，其中，输出人体模型图像各像素点的分类概率，人体姿态特征包括密集姿态特征。 所述人体语义预测模块根据分类概率预测更衣后的人体语义信息。独立权利要求还包括：虚拟布料变化模型； 以及一种虚拟布料变更方法。   6
本公开提供了一种基于深度学习的物体宏观物理属性预测方法及系统，包括：基于给定的变形方式及几何微结构，获得变形后的等效基材料属性以及体素化微结构单元；基于预先训练的深度学习模型及获取的变形后的等效基材料属性和体素化微结构单元，获得每个微结构单元体素在受到多方向单位应变下的位移；基于所述位移，获得变形几何微结构的物理性质指标；其中，所述深度学习模型基于U‑Net网络结构，包括顺序连接的卷积块、上采样块以及卷积层，所述卷积块包括顺序连接的第一卷积层、第一归一化处理模块、激活函数、第二卷积层、第二归一化处理模块及激活函数；所述模型的输入为四维向量，第一维为变形后的等效基材料属性，其余三维为体素化微结构单元。一种利用电子设备在机械、航空航天、土木工程和增材制造领域中基于深度学习预测物体宏观物理属性的方法。该方法能够获得数百倍时间的宏观尺度的物理特性，从而实现实时的材料特性预测。该方法涉及基于给定的变形模式和几何微结构，获得变形后等效基材属性和体素微结构单元。 基于用于获取变形后的等效基材料属性和体素微结构单元的预深度学习模型，获取多向单元应变下微结构单元的位移。 计算均质本构矩阵，用于获得变形后的几何微结构的物性指标。 确定检查三维是否为体素微结构单元。包括独立权利要求：(1)通过使用电子设备在机械、航空航天、土木工程和增材制造领域中基于深度学习预测物体宏观物理属性的系统； (2)一种计算机可读存储介质，具有用于通过使用电子设备在机械、航空航天、土木工程和增材制造领域中基于深度学习来预测物体宏观物理属性的指令集。  11
本发明涉及验证共有子词对XLM翻译模型效果影响的实验方法。本发明包括：对XLM翻译模型预训练的语料库进行预处理；验证XLM翻译模型性能是否退化：用预处理后的语料库对XLM翻译模型进行预训练，用预训练后的模型初始化翻译模型，观察新的翻译模型的BLEU值。预处理包括如下：首先获取英语和法语子词中的共有子词及所有子词词频；然后根据分离比例，随机对共有子词进行分离；随后读取所有英法子词的词表保存在词典中，用于后续生成分离子词文件；使用生成的分离子词文件初始化词典，最后使用初始化后的词典来结构化模型语料库文件。本发明验证了共有子词对BLEU值的影响，且本发明对非同源语言的低资源神经机器翻译研究有帮助。通用子词对XLM翻译模型效果的验证方法。该方法验证了公共子词对BLEU值的影响，有助于非同源语言的低资源神经机器翻译研究。该方法包括获得英语和法语子单词中的共同子单词频率。 根据分离比例随机分离所述共有子词。 读取所述英文单词的单词表，并存储至词典中，用于后续生成子单词文件。 利用生成的子词文件初始化字典。 初始化的字典用于结构化模型语料库文件。 获取所述英文中的共有子词和子词频。  11
本发明涉及推荐系统技术领域，具体涉及一种基于标签语义相似度的短视频推荐方法，步骤一：收集用户观看视频的行为记录；步骤二：基于步骤一中得到的交互行为记录，人为构建一系列评分规则，构建用户‑视频评分矩阵U；步骤三：对步骤二中的评分矩阵，计算用户对每个视频的喜好分布；它使用bert预训练模型将每个视频的标签表征为句子特征向量，再利用余弦距离计算向量之间的相似度从而得到视频标签的相似度，有利于相似视频的推荐，还可以实时且不受限制的加入新标签，不需要过多的人为干预，很适用于快速构建一个推荐系统。方法用于自然语言处理技术，结合基于内容的短视频推荐算法，完成更准确、个性化的推荐。该方法包括收集用户观看视频的行为。 得到的交互行为记录在人体内构建了一系列评分规则。 还构建用户-视频评分矩阵并计算每个视频的用户偏好简档。 每个视频的用户喜好分布需要对每个用户的视频喜好分数进行归一化处理。 将得分归一化为零到一的区间，作为反向计算的偏好，即体现为行归一化矩阵。 9
本发明公开了一种图像处理方法、系统、设备及存储介质，方法包括：基于Resnet+U‑Net++模型训练得到图像分割模型；其中，Resnet+U‑Net++模型包括下采样模块、多个输出上采样模块以及与多个输出上采样模块连接的回收梯度模块；图像分割模型以下采样模块为输入模块，以回收梯度模块为输出模块；获取待处理图像的处理等级；将待处理图像输入图像分割模型；选取与处理等级对应的目标个数的输出上采样模块的输出结果输出至回收梯度模块；通过回收梯度模块输出与待处理图像对应的分割处理结果。本申请的图像分割模型在使用剪枝来节约测试时参数量时，不会增加模型及算法复杂度，同时还能确保图像处理的精度。一种图像处理方法。本发明在通过剪枝节省测试时的参数数量的同时，不增加模型和算法的复杂度，保证了图像处理的精度。该方法包括基于模型训练获得(10)图像分割模型。 该模型包括下采样模块，多个输出上采样模块和与多个输出上采样模块相连的恢复梯度模块。 所述图像分割模型以下采样模块为输入模块，以恢复梯度模块为输出模块。 获得待处理图像的处理级别(20)。 将待处理的图像输入(30)到图像分割模型中。 选择(40)与处理级别相对应的目标号码。 上采样模块的输出结果输出到恢复梯度模块。 通过恢复梯度模块输出(50)与要处理的图像相对应的分割处理结果。独立的权利要求书被包括在以下内容中： 1. 用于处理图像的系统； 2. 电子设备； 以及 3. 一种存储用于处理图像的程序的计算机可读存储介质。   6
本发明公开了一种基于BERT‑CNN的金融文本分类方法及系统，该方法包括以下步骤：对金融文本数据进行预处理操作，预处理操作包括去除噪声信息、文本处理、分词处理、去除停用词；将所得到的输入向量输入BERT层得到的初始特征向量；将所得初始特征向量使用卷积神经网络提取高级特征向量；将所得高级特征向量和初始特征向量进行特征融合；通过线性全连接层和softmax分类层得到金融文本类别。本发明将BERT提取的初始特征与卷积神经网络层提取高级特征进行融合，通过融合特征挖掘金融文本的信息，解决了模型训练中存在着过拟合现象，有效提高模型分类准确度，同时避免BERT全部层的特征组成矩阵进行二维卷积，进而忽略不同层的特征分辨率之间存在的差异对模型性能的影响。该方法对于由分析与投资分析相关的大量文本的股票投资的研究人员和金融从业者基于来自变压器卷积神经网络的双向编码器表示(BERT-CNN)来分类金融文本是有用的。该方法解决了模型训练中存在的过拟合现象； 高效提高了模型分类精度； 避免二维卷积用BERT所有层的特征组成矩阵忽略不同层特征分辨率差异对模型性能的影响； 并对不同层次提取的特征进行融合，以获得更准确的分类效果。该方法包括对金融文本原始数据进行预处理，得到金融文本输入数据。 将得到的高层特征向量与初始特征向量进行特征融合。 通过线性全连接层和softmax分类层得到文本的分类类型。 对所述初始特征和高级特征进行特征融合，得到融合特征。 将所述特征融合特征作为输入。 输出一个金融文本分类的概率分布。 选取最大概率值对应的文本类型作为最终的财务文本类型。包括独立权利要求的一种基于BERT-CNN的金融文本分类系统。  12
本发明公开了一种夜间车辆检测方法及存储介质。所述夜间车辆检测方法采用SSD模型，包括如下步骤：S1、通过车载摄像头采集车辆夜间行驶过程中的图像，并采用光照增强算法对获取的图像进行预处理，得到预处理图像；S2、获取KITTI数据集中的车辆数据，并采用所述车辆数据对SSD模型进行训练，得到预训练模型M0；再使用人工标注的夜间车辆图片对预训练模型M0进行修正，生成终预测模型M1；S3、使用终预测模型M1对预处理图像进行检测，输出图像中车辆位置。本发明能够实现夜间车辆检测，并且检测率高、检测速度快。使用固态驱动器(SSD)模型的夜间车辆检测方法。该方法使得能够使用光照增强算法对图像进行预处理，因此改善了夜间车辆图像的光照分布，并且提高了局部对比度，增强了低、中强度像素而避免了高强度像素的增加，因此有效地提高了识别的准确性。 该方法允许使用经典的目标检测模型SSD，利用KITTI数据集对SSD模型进行预训练，并利用人工标注的夜间车辆图片对模型进行修正，得到最终的预测模型，以提高模型的精度，从而实现夜间车辆快速、准确的检测。该方法通过车载摄像头采集车辆夜间行驶过程中的图像。 利用光照增强算法对获取的图像进行预处理，得到预处理图像。 获取KITTI数据集中的车辆数据。 通过使用减速(SSD)模型来训练车辆数据。 建立预训练模型。 利用人工标记的夜间车辆图片对所述预训练模型进行校正。 生成最终预测。 利用所述最终预测模型对所述预处理后的图像进行检测，以输出所述图像中的车辆位置。还包括一个独立权利要求用于一种存储介质，包括一组用于夜间车辆检测方法的指令。 13
本发明涉及智能教学领域，具体公开了一种基于概率图模式推断的文本智能教学评价方法，其结合教学评价量表来源多维的特点将多源数据(包括教学文案、教学过程、技术应用、教师素养、教学质量、创新应用等指标)先进行整合，然后将整合后的多维数据放入LEX‑BERT模型中训练以提取教学评价量表的文本特征并加以适当推理，而后给文本特征加之以权重并放入到PGM模型中，通过PGM模型推断得出教师素养和教学质量的正负概率，最后将推断概率进行归一化处理之后输出最终基于文本的智能教学评价分数。本发明基于多源的教学评价量表数据，结合LEX‑BERT模型与图概率模型的信度推断优势，可获得更可靠的教学评价。本发明可用于基于概率图模式推理的智能文本教学评估。该方法：能够将Lex-BertModel与置信度推理的图概率模型相结合； 获得更可靠的教学评价。一种基于概率图模式推理的智能文本教学评价方法，包括以下步骤：采集专家预设或基于经验的教学评价量表数据； 分析反馈评论数据， 提取相应的教师评价策略和教学质量评价策略， 进行多维数据集成处理，优化概率图模型，将提取的文本特征作为先验概率加权平均到概率图模型中进行概率估计，得到相应的教师素食评价得分和教学质量评价得分。  12
本发明提供了一种预训练模型的模型训练方法和装置、存储介质及电子设备，其中，该方法包括：获取训练掩码序列集，其中，训练掩码序列集中的每个训练掩码序列是对一个抗体序列中的部分序列进行掩码处理得到的序列，在每个训练掩码序列中，重链序列的开始位置插入有重链符号，轻链序列的开始位置插入有轻链符号；依次将每个训练掩码序列作为输入序列对待训练的预训练模型执行多轮训练，得到训练好的预训练模型，其中，预训练模型包括编码器和解码器，编码器用于将输入序列的序列向量编码为对应的特征编码向量，解码器用于基于编码器输出的特征编码向量解码出编码器的输入序列中被掩码的部分序列；能够提高预训练模型的特征表征准确性。用于通过电子装置训练用于识别和攻击诸如病毒或细菌的异物的人体内的抗体序列的预训练模型的方法(权利要求书)。该方法使得解码器能够基于编码器输出的特征编码向量对编码器输入序列中的已masked部分序列进行解码，从而提高预训练模型的特征表示精度。所述方法包括获取训练掩码序列集，其中，每个所述训练掩码序列为对抗体序列中的部分序列进行掩码处理得到的序列。 重链序列的起始位置插入有重链符号。 轻链序列的起始位置插入轻链符号。 预训练模型设置有编码器和解码器。 编码器用于将输入序列的序列向量转换为对应的特征编码向量。 所述解码器被配置为基于所述编码输出的所述特征编码向量来解码所述编码器的输入序列中的所述序列掩蔽的所述部分。独立权利要求书包括用于：(1)用于预训练模型的模型训练装置； (2)一种计算机可读存储介质，其包括用于训练人体内抗体序列的预训练模型的指令集。  11
本说明书实施例提供预训练语言模型的训练方法以及装置，其中预训练语言模型的训练方法包括：对样本文本中第一设定数值个字符进行掩码处理，获得掩码训练样本，然后基于掩码训练样本中非掩码字符的位置处的权重确定各个字符的增强语义向量，之后根据各个字符的增强语义向量，确定预训练语言模型的损失值，对预训练语言模型进行训练，从而完成语言模型的预训练过程。如此，计算掩码训练样本的各个字符的增强语义向量时，可以忽略被掩码字符位置处的权重，提高了预训练语言模型的收敛速度，避免了过度训练，并且提高了模型迁移能力，避免了被掩码字符较多时与下游任务不匹配的问题，从而提高下游任务的处理准确率。一种用于计算机技术领域的预训练语言模型的训练方法。提高了预训练语言模型的收敛速度，避免了过度训练。 提高了模型迁移能力。 避免了掩码字符与下游任务不匹配的问题，从而提高了下游任务的处理精度。该方法包括对样本文本中的第一组数字字符执行(102)掩码处理，以获得掩码训练样本。 掩模训练样本被输入(104)到预训练语言模型中，并且通过预训练语言模型中的自注意层来确定掩模训练样本中的每个字符的增强语义向量。 基于掩蔽训练样本中的非掩蔽字符的位置处的权重来确定每个字符的增强语义向量。 根据损失值调整(106)预训练语言模型的模型参数，并返回以对样本文本中的第一组数字字符执行掩蔽处理。 获取掩模训练样本，直到达到训练终止条件，得到预训练后的预训练语言模型。本发明还涉及一种用于该方法的装置。 一种文本处理模型的训练方法； 2. 预先训练语言模型的训练装置； 3. 文本处理模型训练装置； 4. 计算设备； 和5。 一种存储用于预训练语言模型的程序的计算机可读存储介质。  11
本发明涉及营销策略技术，公开了基于大模型的自动化营销策略生成方法及系统，其通过对现有的数据库中收集自动化营销策略数据；对收集的自动化营销策略数据进行处理和提取，从而建立自动化营销策略数据模型；对于自动化营销策略数据模型通过深度学习技术，使用GPT大型智能模型，对处理后的数据进行训练，从而建立自动化营销策略数据智能模型；输入用户需求，通过自动化流程策略生成模型生成自动化策略方案；自动化营销策略的形成，通过智能模型输出最优的自动化流程方案，从而形成自动化营销策略。本发明通过利用大型智能模型的自动化营销流程方案生成能力，克服了传统方法的局限性，提高了自动化营销流程策略生成的效率和质量。基于大模型的自动营销策略生成方法。该方法使得利用大智能模型的自动营销流解决方案的生成能力，提高自动营销流策略的生成效率和质量。 该方法允许自动流动策略生成模型通过智能模型生成最优的自动流动解，从而形成自动营销策略，因此提高了营销策略的质量和效率。该方法包括采集现有建立自动营销数据模型的数据库中的自动市场策略数据，以对采集到的自动营销策略数据进行处理和提取，以建立自动营销策略数据模型，以通过深度学习技术对处理后的数据进行训练，以建立自动广告策略数据的智能模型，从而生成自动策略解决方案。 生成的自动流策略生成模型s，用于通过所述智能模型生成最优的自动流解，以形成所述自动策略。本发明还涉及一种基于大型模型的自动营销策略生成系统。  11
一种基于交叉注意力蒸馏Transformer的花粉图像分类方法，利用两个网络训练数据，两个网络互为对方的老师；网络一将图片编码为图片令牌，并加入Class令牌和蒸馏令牌；利用再注意力Transformer模块计算所有令牌的全局关联性；采用动态令牌稀疏化模块修剪掉冗余图片令牌，提高吞吐量；网络二将图片通过卷积运算编码为图片令牌，增加对图片令牌内部信息的建模，并加入Class令牌和蒸馏令牌；利用卷积投影以动态的卷积注意力机制来实现图片令牌的局部和全局像素信息的融合；本发明使两个网络通过各自的蒸馏令牌在蒸馏损失部分与老师网络的输出空间进行交互，学习老师网络的特征空间表达，最后输出分类结果。基于交叉注意蒸馏的花粉图像分类方法。该方法使得能够通过相应的蒸馏令牌在蒸馏损失部分与教师网络的输出空间交互，学习教师网络的特征空间表达，并输出分类结果。该方法包括使用网络分割输入花粉图像。 将蒸馏令牌和类令牌相加，得到令牌序列。 利用重注意力转换模块的重注意力机制消除令牌序列中的注意力相似性问题。 对令牌序列中的类令牌和蒸馏令牌进行加权，以进行预测和分类。 将第一和第二网络的最大准确度作为预测分类结果。 第一和第二网络的损失函数形成交叉关注蒸馏模块。 第一和第二网络由交叉注意力蒸馏模块训练。   5
本申请提供了一种基于FAQ的无监督式检索方法、系统及介质，通过BM25算法计算用户查询信息与每一个问答对的相似度，得到第一候选问答对；通过maximum‑passage算法计算用户查询信息与每一个问答对文档的相似度，得到第二候选问答对；将第一候选问答对输入第一预训练BERT模型，得到第三候选问答对以及对应相似度得分；将第一候选问答对输入第二预训练BERT模型，得到第四候选问答对以及对应相似度得分；将第二、三和四候选问答对对应的相似度得分进行融合，得到相似度融合得分以及对应排序的最终候选问答对。本申请不需要将用户查询和问答对间的匹配标记，并对三个排序结果使用线性加总合并算法和集合重排算法进行融合，进一步提升泛用效果。基于FAQ进行无监督检索的方法。该搜索模型不需要让用户查询和一个问答组进行匹配标记，只使用一个问答组数据进行无监督训练，在保证广泛应用的前提下，突破了数据获取困难带来的限制，降低了服务人员标记数据的依赖性，提高了普适性效果。该方法包括通过BM25算法计算用户查询信息与每个问答对的最佳匹配(BM25)相似度，并根据BM25相似度对所有问答对从高到低进行预排序(S101)，得到第一候选问答对序列。 将所述第一序列按照maxpsg相似度从高到低进行排序，得到第二候选问答对序列。 将第一候选问题-答案对序列输入第二预先训练的双向编码器表示(BERT)模型，以获得第四候选问题-答案对序列和对应的相似性分数。 将所述第二、第三和第四候选问答对序列与所述序列对应的相似度分值进行融合，得到相似度融合分值和按照所述相似度融合分值排序的最终候选问答对序列。独立权利要求包括：(1)无监督搜索系统； (2)基于无监督的常见问题(FAQ)的搜索设备; 以及(3)存储用于执行基于FAQ的无监督检索的程序的计算机可读存储介质。  11
本说明书一个或多个实施例公开了一种大模型预训练方法及装置。首先通过大模型的第一输入通道获取第一模态数据集，并通过大模型的第二输入通道获取第二模态数据集；然后将第一模态数据集中的模态数据输入到大模型中的第一编码器，得到第一表征信息，将第二模态数据集中包含的多种模态数据分别输入到大模型中的第二编码器，并将第二模态数据集对应第二编码器的输出结果进行表征融合处理，得到第二表征信息；最后将第一表征信息和第二表征信息映射到预设的特征空间，并基于特征空间的映射信息和预设的对比学习损失函数对大模型进行对比学习训练，得到预训练后的大模型，对比学习损失函数基于实体之间的表征相似性确定。预训练大模型的方法。大模型预训练方法涉及通过大模型的一个输入通道获得第一模态数据集，通过另一个输入通道获得第二模态信息集，因此保证了大模型训练方法的简单高效。该方法涉及通过大型模型的第一输入通道获得第一模态数据集。 通过所述大模型的第二输入通道获取第二模态数据集。 将所述第二模态数据集中包含的模态数据输入到所述大模型中的第二编码器。 对所述第二编码器对应的第二模式数据集的输出结果进行特征化融合处理，得到第二特征化信息。 将所述第一特征化信息和所述第二特征化信息映射至预设特征空间。 基于所述特征空间的映射信息和预设的比对学习损失函数对所述大模型进行比对学习训练。 经过预训练后得到一个大模型。 所述比较学习损失函数是基于实体之间的表征相似度确定的。独立权利要求书包括用于：(1)大模型预训练装置； 以及(2)电子设备。  11
本申请的实施例提供一种组合视觉推理方法及装置、计算机可读存储介质、电子设备，组合视觉推理方法通过将获取的组合输入任务拆解为m个子任务，形成视觉推理路径；利用大语言模型按照从上游到下游的顺序依次对子任务进行解析并验证；经验证，当前的子任务有任务解时，循环执行利用大语言模型按照从上游到下游的顺序对当前子任务的下游子任务进行解析并验证的步骤，直至得到视觉推理路径的末端子任务的任务解，将末端子任务的任务解作为组合输入任务的解析结果；经验证，当前的子任务无任务解时，循环执行将获取的组合输入任务拆解为m个子任务，形成视觉推理路径的步骤。该方法节省标注成本，还可以提高任务解的准确性，从而提升视觉推理效果。结合视觉推理法。该方法能够节省标记成本，提高任务解算的准确性从而提高视觉推理效果。该方法涉及将得到的组合输入任务拆解(S110)为m个子任务，形成可视化的推理路径。 利用所述大语言模型(S120)按照从上游到下游的顺序对所述子任务进行有序的分析和验证。 循环执行(S130)利用所述大语言模型的步骤，以按照从上游到下游的顺序，对所述当前子任务的下游子任务进行分析验证，验证后，当所述当前子任务有任务解算。 将所述终端任务的任务解作为所述组合输入任务的解析结果，直至得到所述可视化推理路径的结束子任务的任务解。 循环执行(S140)将得到的组合输入任务拆解为子任务，以在验证后形成可视化推理路径的步骤，当当前子任务没有任务解时。独立权利要求包括以下内容：组合的视觉推理装置； 电子装置； 以及计算机可读存储介质，其存储用于推理组合视觉过程的程序。  11
本申请提供一种基于自然语言处理技术的电力操作票设备识别与勘误方法，可对电力操作票里的电力设备正确性进行校核。本申请中，获取基于历史电力操作票微调的BERT预训练模型，得到设备识别引擎和设备匹配引擎；将待识别操作项输入设备识别引擎，识别出待操作电力设备；若待操作电力设备不存在于设备台账数据库里，则确定待识别操作项为书写出错操作项，基于待操作电力设备，在设备台账数据库里进行检索，得到候选电力设备集；通过设备匹配引擎，在候选电力设备集进行匹配判断，得到候选电力设备集中各候选电力设备的得分；按待操作电力设备在待识别操作项中的位置，将候选电力设备集中的各候选电力设备分别嵌入待识别操作项中，得到正确操作项列表。基于NLP技术的电力操作票装置识别及纠错方法。该方法能够检查电力操作票中电力设备的正确性。该方法涉及获取基于历史电力操作票精调的BERT(RTM：open source machine learning framework for NLP)预训练模型，得到设备识别引擎和设备匹配引擎。 将当前电力操作票的待识别操作项输入所述设备识别引擎，以识别所述待识别操作项中的待操作电力设备。 如果所述待操作电力设备不存在于设备账户数据库中，则将所述待识别操作项确定为写入错误操作项。 基于所述待运行电力设备查找所述设备账号数据库以获得候选电力设备组。 通过所述设备匹配引擎对所述候选功率器件组进行匹配判断，得到所述候选功率器件组中的候选功率器件的得分。根据所述待操作电力设备在所述待识别操作项中的位置，将所述候选电力设备组中的所述候选电力设备嵌入所述待识别操作项以获得正确操作项列表。 独立权利要求包括：(1)一种基于NLP技术的电力操作票装置识别与更正装置； (2)一种计算机设备，包括处理器，用于执行基于NLP技术的电力操作票设备识别与修正方法； 以及(3)一种计算机可读存储介质，包括执行基于NLP技术的电力操作票设备识别与纠错方法的指令。 0
为了缓解单词拼写错误、顺序错误以及情绪混合问题对最终把握评论整体情感得分的影响，可以有针对性地按顺序分步处理这些噪声和情绪混合问题，本发明设计一种综合深度胶囊网络分类模型，模拟人类阅读逻辑步骤，通过分别在单词层面、短语层面和句子层面捕获特征信息，对评论进行建模的方案，具体来说是将单词层面和短语层面的建模与拼错错误、词序错误等噪声问题对应，将句子层面的建模与情绪混合问题对应，也就是将每个短句子当作义群，动态考量不同义群对最终整体情感态度的影响。实现上可通过BERT WordPiece向量和卷积作为单词级别和短语级别特征，再用胶囊网络获取句子层面最终的向量表示来进行分类。基于综合深度胶囊网络的复杂评论文本整体情感智能分类方法。该方法使得能够利用BERT词片向量和卷积作为词级别和短语级别的特征，并通过使用胶囊网络获得句子级别的最终向量表示进行分类。该方法包括从开源库中获取多个情感分类数据集。 根据情感分类数据集中的噪声和情感的混合选择目标数据集。 目标数据集分为训练集和验证集。 根据词级别、词组级别和句子级别之间的逻辑关系，设置词级别对应的向量模块、词组级别对应的卷积模块和句子级别对应的胶囊网络模块。 将所述数据集输入综合深度胶囊网络分类模型进行模型训练。 利用最终分类模型对待分类文本进行分类。  12
本发明公开了一种基于改进U‑Net网络的锌浮选泡沫图像分割算法，针对现场设置的工业相机所获得的泡沫图像，提出一种适应于复杂泡沫图像分割的改进U‑Net架构，在传统U‑Net网络的基础上，做出如下改进：在U‑Net网络第一层部分对称引入Inception与批量归一化模块，在U‑Net网络的编码模块末端加入金字塔池化模块，同时在网络的编码模块与解码模块对应层间的跳跃连接处引入改进的注意力门控机制。本发明实现了对泡沫图像中的每个泡沫的分割，有效弥补了传统的泡沫图像分割对单个泡沫分割不彻底、不精细的缺陷，从而可以提升效率，为后续的泡沫特征提取奠定坚实基础。基于U-Net网络的矿石分选锌浮选泡沫图像分割算法。该算法能够实现泡沫图像中泡沫的分割，且不存在单个泡沫的细微缺陷，提高了泡沫图像的分割效率，为提取泡沫特征奠定了坚实的基础。该算法对锌快速粗选过程中的泡沫图像进行采集得到原始泡沫图像的规则进行了设定。 在数据放大处理中获得样本图像。 在U-Net网络的编码器模块末端增加金字塔池化模块，完成泡沫图像的下采样处理。 训练图像分割网络以分割训练集图像。 利用U-Net神经网络模型对测试集中的泡沫图像进行识别和分割，得到网络的分割结果。   6
本发明的一种基于改进BERT模型的知识图谱构建方法，获取多源异构数据，存储获取的多源异构数据至大数据平台；基于本体针对获取的多源异构数据进行知识建模；基于BERT‑BiGRU‑CRF模型进行知识获取；基于词向量的知识融合，将获取的异类数据源进行实体融合和属性融合；采用图形数据库进行知识储存。本发明采用企业知识图谱突破传统的计算模式，深度整合企业经营管理领域的内外信息和数据，后期能够更加有效地挖掘预警潜在风险，提高企业经营管理的效率，有利于提升后续的企业经营管理风险智能诊断的准确性。基于增强型BERT模型的知识图谱构建方法。本发明采用企业知识图谱突破传统的计算模式，深度整合企业管理和企业管理领域的内外信息和数据，有效挖掘预警潜在风险，提高企业管理的效率，增强后续企业管理风险智能诊断的准确性。该方法涉及获得多源异构数据。 将获取的多源异构数据存储在大数据平台中。 基于获取的多源异构数据进行知识建模。 知识获取基于BERT-BiGRU-CRF模型进行。 基于获取的异构数据源的词向量、实体融合和属性融合进行知识融合。 知识图谱存储在图形化数据库中，所述多源异构数据源包括外部舆情、内部物资管理、廉政建设、法律事务、企业文化。  12
本说明书公开了一种基于托卡马克核聚变智能控制本体的数据构建方法，可以可以获取与托卡马克核聚变相关的预设知识领域、预设用途和预设问题，从而确定数据源和个人信息来源，进而通过数据源和个人信息来源，确定与预设知识领域相关的各术语，将每个术语作为一个类的类名称，以构建各类和各类之间的层次结构，而后，可以针对每个类，构建该类对应的数据属性和对象属性，根据获取到的与托卡马克核聚变相关的实验数据，对各类对应的数据属性和对象属性进行修正，得到各类对应的修正后的数据属性和对象属性，从而提高了构建本体数据的效率和准确性，并便于从大语言模型或维基百科中获取所需知识。基于托卡马克核聚变智能控制本体的数据构建方法。还可以通过常识共识约束条件对构建的本体数据进行修改，因此提高了构建本体数据的效率和准确性。 构建的本体数据可以引导用户构建查询或提示，因此便于从大型语言模型或维基百科(RTM：Online encyclopedia)获取所需知识。该方法涉及使用(S106)每个术语作为类名称来构建各种类和类之间的分层结构。 针对每个类构建(S108)与类对应的数据属性和对象属性，其中，数据属性用于表示类的实例的状态，对象属性用于表示类的实例之间的关系。 得到托卡马克核聚变相关的实验数据。 对所述各种对应的数据属性和对象属性进行修正，得到各种对应的修正后的数据属性和对象属性，根据所述实验数据，得到构建的本体数据，所述构建的本体数据用于构建知识查询系统和/或知识图谱。独立权利要求书包括如下内容：(1)一种基于托卡马克核聚变智能控制本体的数据构建装置； (2)存储有基于托卡马克核聚变智能控制本体的数据构建程序的计算机可读存储介质； 以及(3)电子设备。  11
本申请提供了一种商标检索方法、其装置以及电子设备。该方法包括：获取训练商标样本，训练商标样本是对训练商标进行标注得到的；采用预训练的第一检测网络对商标图像进行特征提取，得到商标图像特征；采用预训练的第二检测网络对商标文本进行特征提取，得到商标文本特征；采用特征融合检测网络对商标图像特征和商标文本特征进行特征融合处理，得到融合图像特征和融合文本特征；采用损失函数对预训练的第一检测网络、预训练的第二检测网络和特征融合检测网络进行反向传播处理，得到训练后的第一检测网络、训练后的第二检测网络和训练后的特征融合检测网络；采用训练后的网络对待检索的商标进行检索，解决了现有技术中商标检索的准确率低的问题。用于在商标库中搜索商标的方法。本发明能够采用训练好的网络对待搜索商标进行搜索，解决了现有技术中商标搜索准确率低的问题。该方法包括获取训练商标样本，所述训练商标样本通过对训练商标进行标注得到，所述训练商标样本包括商标图像和商标文本，所述商标文本包括商标文本描述和商标标注文本。 通过预先训练的第一检测网络提取所述商标图像的特征，得到所述商标图像的特征。 通过预先训练的第二检测网络对所述商标文本的特征进行提取，得到所述商标文本的特征。 利用特征融合检测网络对所述商标图像特征和商标文本特征进行特征融合处理，得到融合图像特征和融合文本特征。该方法包括利用损失函数对预训练的第一检测网络、预训练的第二检测网络和特征融合检测网络进行反向传播处理，得到训练后的第一检测网络、训练后的第二检测网络和训练后的特征融合检测网络。 利用训练好的所述第一检测网络、训练好的所述第二检测网络和训练好的所述特征融合检测网络对所述待搜索商标进行搜索。 包括独立权利要求：(1)一种用于在商标库中查找商标的装置； (2)一种计算机可读存储介质，用于存储在商标库中查找商标的指令集； (3)一种电子设备，包括处理器和存储器，用于在商标库中查找商标。  11
本发明提供了多语种端到端OCR算法及系统，克服并绕过现有技术分片上的缺陷，在字符粘连、中英、中数混合数据上表现优良；通过自蒸馏transformer模块，保留位置关系，减少参数和模型复杂度，同时并行输出结果，切断节点之间的依赖，对多语种，多字体场景具备了更强的鲁棒性，结构、性能也得到优化。算法包括：获取待识别图片的特征图；将特征图通过基于自蒸馏transformer模块的关系注意力模块训练，获取字符矩阵；对字符矩阵做并行注意力解码，获取预测结果；根据预测结果，基于词汇句表，获取与词汇句表的语种相符的OCR模型。多语言端到端光学字符识别(OCR)算法。多语言端到端光学字符识别算法通过自蒸馏模块保持位置关系，降低参数和模型复杂度，切断节点之间的依赖关系，获得鲁棒性更强的多语言，多字体场景，优化结构和性能。所述多语言端到端OCR算法涉及获得将由一组指令识别的图像的特征图像。 通过关系关注模块训练特征地图。 获得字符矩阵。 所述关系关注模块为基于自蒸馏模块的关系关注模块。 对字符矩阵执行并行注意解码。 获得预测结果。 基于预设的词汇句表获取OCR模型，OCR模型与词汇句表的语言相匹配。 获得特征图像。本发明还涉及一种多语言端到端OCR系统。  12
本发明公开了一种具有类人连续学习能力的图像目标识别系统及方法，其包括神经网络预训练模块、图像输入模块、神经网络模块、正交权重修改模块和分类器模块；本发明具有可以有效提高神经网络模型的连续学习能力，能够适应多类别的小样本连续学习，为后来得出的网络权重分类更加精确；本发明还可以对需要进行多种单一类别样本的训练学习的目标识别方法精度进行提高，应用本发明的正交权重修改算法实现了对网络现有知识的有效保护，并且与现有的梯度反向传播算法完全兼容，在连续学习任务中精度得到很好地提升。用作图像目标识别系统。该系统提高了神经网络模型的连续学习能力，适应小样本的多个样本的连续学习，对后得到的网络权值进行分类更加准确，对于需要训练学习多个单类样本的目标识别方法具有提高的准确性，实现了对网络现有知识的保护，并且与现有的梯度反向传播算法完全兼容，提高了连续学习任务中的准确性。具有类人持续学习能力的图像目标识别系统包括神经网络预训练模块通过深度学习神经网络即VGG16或ResNet对一类图像进行学习训练后得到一个神经网络模型权值。 一个神经网络模块，是根据预先训练好的神经网络模型，提取图像同一类别中每个对象的特征，然后通过池化层将图片大小恢复为原始输入图片大小。 正交权值修改模块是在学习新类别图像任务时，在与旧任务的输入空间正交的方向上修改神经网络模型的权值。 分类器模块是使用分类器网络即Softmax对深度学习后的神经网络模块和正交权重修改模块的图片中的每一类对象进行分类，找到每一类对象在图片中的位置并用边框标记。本发明还提供了一种使用具有类人连续学习能力的图像目标识别系统的方法。   4
本发明涉及一种无监督的文本相似度计算方法，其中，包括：步骤一：进行嵌入层模型预训练，对问题集合中的所有词进行预训练，生成满足模型需要的词向量；步骤二：编码层网络，挖掘句子的语义信息；步骤三：进行基于TFIDF融合的模型改进，包括：在每条问句输入到神经网络的同时，对输入的每条问句进行TFIDF的计算，并将计算好的权值输入到神经网络中，控制最后的句子向量表示，采用了归一化的TFIDF计算方法，并将其融入到编码层和表示层。本发明将深度神经网络模型(Bi‑LSTM)用于语料库的无监督训练，得到语言模型，通过无监督的训练方式，可以充分地利用大规模的语料库的信息，从而提高文本匹配的准确率，提升信息检索的精度。无监督文本相似度计算方法。该方法使得能够利用深度神经网络模型(Bi‑LSTM)对语料进行无监督训练，通过无监督训练建立语言模型，提高文本匹配的准确率和信息检索的准确率。该方法涉及预训练嵌入层模型。 生成所述嵌入层模型的词向量。 获取编码层网络中句子的语义信息。 问题被输入到神经网络。 为每个输入的问题计算TFIDF值。 计算的权重被输入到神经网络中以控制最终的句子向量表示。 采用归一化TFIDF计算，并集成到编码层和表示层中。 在所述句子中输入分词结果的问答集合。 为集合中的每个问题获取标记词集合。  12
本发明涉及数据对话问答技术领域，尤其涉及表格数据问答方法、装置、设备及存储介质，所述方法包括：获取历史表格数据并提取其中的历史名称信息，以微调预构建的大语言模型；获取待处理表格数据并提取其中的待处理名称信息，将待处理名称信息输入至微调后的大语言模型中，得到三元关系预测结果；基于三元关系预测结果构建无向图，以获取元概念；基于待处理表格数据、三元关系预测结果和元概念构建知识图谱；获取实时反馈的问题并进行预处理，得到预处理信息，基于预处理信息匹配搜索所构建的知识图谱，根据匹配结果获取预设的问答大语言模型反馈的、问题的回答；本发明公开的方法，可提升大语言模型对表格数据的提取能力，减少大语言模型的幻觉。表数据问答方法。表格数据问答方法能够提高大型语言模型对表格数据的抽取能力，减少大型语言模型的幻觉。表格数据问答方法涉及到获取历史表格数据。 提取所述历史表数据中的历史名称信息。 基于所述历史名称信息对预先构建的大规模语言模型进行微调。 从所述历史表格中提取所述待处理表格数据的名称信息。 将所述信息输入到可微调整的大型语言模型中，得到三元关系预测结果。 基于三元关系预测结果构建无向图，根据构建的非结构化图得到元概念。 构建知识图谱。 实时获取反馈的问题。 对所述问题进行预处理，得到预处理信息。 对构建的基于预处理信息的知识图谱进行匹配搜索，得到辅助信息。 对应所述问题获取所述问题反馈的预设答案。独立权利要求包括用于：(1)表格数据问答器； (2)一种计算机可读存储介质，所述计算机可读存储介质存储有用于实现所述表格数据问答方法的指令。  11
本发明提供了一种模型训练方法、中文文本纠错方法、电子设备和存储介质，该模型训练方法包括：获取训练中文语料和字音字形混淆集；根据字音字形混淆集构建字音模型和字形模型；根据训练中文语料确定字符嵌入；将训练中文语料输入字音模型和字形模型，分别得到拼音嵌入和字形嵌入；将字符嵌入、拼音嵌入和字形嵌入输入深度双向预训练语言模型并利用掩码策略进行预训练；对预训练后的深度双向预训练语言模型进行微调，得到中文文本纠错语言模型。根据本发明实施例提供的方案，实现了中文文本纠错语音模型能学习到近音字信息和形似字信息，能够利用近音字信息和形似字信息纠正错别字，提高中文文本纠错结果的准确率和可解释性。在自然语言处理和人工智能领域训练模型的方法。提高了中文文本纠错结果的准确性，提高了可解释性。 输入精度是自然语言处理领域上层任务的前提，因此文本纠错是提高上层任务性能的关键，是自然语言处理领域的巨大挑战。该方法涉及获得(110)训练中文语料库以及语音和字体混淆集合。 根据所述语音和字体混淆集合构建(120)语音模型和字体模型。 根据所述训练中文语料确定(130)所述字符嵌入。 将训练中文语料输入(140)到语音模型和字形模型中，以分别获得拼音嵌入和字形嵌入。 将所述字符嵌入、所述拼音嵌入和所述字形嵌入输入(150)到深度双向预训练语言模型中，并且使用掩码策略进行预训练。 对所述预训练的深度双向预训练语言模型进行微调(160)，得到中文文本纠错语言模型。包括以下独立权利要求：一种中文文本纠错方法； 电子设备； 以及存储用于实现所述模型训练方法的程序的计算机可读存储介质。 3
本发明公开了一种基于多示例感知的软件漏洞检测方法及相关设备，所述方法包括：获取包级代码片段，使用预训练模型对所述包级代码片段进行训练，得到表征向量；将表征向量分别映射到不同的线性空间中，得到包级代码片段的注意力表征向量；将第一标志向量与表征向量结合，得到包级代码片段中的每个函数代码片段的第二表征向量，将每个函数代码片段的第二表征向量拼接，再进行卷积和拆分操作，得到函数级第二标志向量和目标表征向量，并通过最大池化层计算得到文件级标志向量，根据函数级第二标志向量和文件级标志向量检测漏洞。本发明捕捉示例本身的局部信息和不同示例之间的全局信息，同时检测判断文件级代码和函数级代码是否包含漏洞。基于多实例感知的软件漏洞检测方法，采用终端(Seart)。该方法能够捕获实例的局部信息和不同实例之间的全局信息，并以高效的方式检测和判断文件级代码和功能级代码是否包含漏洞。该方法包括将查询向量、键向量和值向量输入自注意力机制，计算包级代码片段的功能级代码的注意力表示向量。 将预定义的功能级第一标志向量与包级代码片段的功能级代码的注意力表示向量组合(S400)。 对所述第一注意力表示向量执行卷积运算(S500)。 对所述第二注意力表征向量进行拆分，得到函数级别的第二标记向量和目标表征向量，计算所述目标表征向量。 根据函数级第二标志向量得到包级代码片段中各函数是否包含漏洞的第一判断结果(S600)，根据文件级标志向量得到文件级代码片段是否包含漏洞的第二判断结果。包括以下独立权利要求：(1)一种基于多实例感知的软件漏洞检测系统； (2)一种终端，包括存储器和处理器; (3)一种计算机可读存储介质，其存储有用于检测软件漏洞的程序。  12
本申请提供了一种大语言模型的评估方法、装置及电子设备。该方法包括：获取待评估模型的多个对话数据组；各个对话数据组中包含输入信息以及对应的应答信息；各个对话数据组中应答信息由待评估模型基于输入信息生成；多个对话数据组中存在至少两组的输入信息相同而应答信息不同；以多个对话数据组作为评估模型的输入，通过评估模型对多个对话数据组执行矩阵预算采样处理，得到多个对话数据组的评估分数；对多个对话数据组的评估分数进行一致性分析；若一致性分析结果满足预先设置的可靠性条件，以多个对话数据组的评估分数，作为待评估模型的目标评估分数。该方法能够自动评估大语言模型的对话质量，提高模型评估准确性，提高模型评估效率。评估大型语言模型的方法。该方法自动对大型语言模型的对话质量进行评估，提高了模型评估精度和模型评估效率。该方法涉及获取待评估模型的多个对话数据组。 模型被评估为大型语言模型。 每个对话数据组中设置有输入信息和对应的应答信息。 每个对话数据集中的应答信息由待评估模型基于输入信息生成。 通过所述评价模型对所述对话数据集进行矩阵预算采样处理，得到所述对话数据集的评价分数。 所述评价得分与各对话数据集的对话质量成正比。 对所述多个对话数据组的评价得分进行一致性分析。独立权利要求书包括用于：(1)大型语言模型的评估装置； (2)一种电子设备。 8
本发明公开了一种多特征双向门控领域专家实体抽取方法及系统。该方法首先通过构建领域专家语料库以训练实体抽取模型；接着，使用BERT方法进行字嵌入表示，对语料库专业领域词汇构造要素进行特征分析并提取边界特征；然后，利用双向门控神经网络和注意力机制有效获取特定词语长距离依赖关系；最后，结合条件随机场模型实现命名实体识别，将抽取后的信息建立高质量的实体信息索引项返还WEB应用系统。本发明方法可有效抽取领域专家信息实体，充分利用文本字嵌入特征、边界特征以及上下文特征以获得更好的NER性能，从而解决人工特征提取成本高和专业新词无法识别等问题。多特征双向门控域专家实体提取方法。该方法能够有效提取领域专家信息实体，充分利用文本字符嵌入特征、边界特征和上下文特征，获得更好的NER性能，从而降低人工特征提取成本和专业新词识别问题。所述多特征双向门控域专家实体提取方法涉及获取单领域专家文本，所述单领域专家文本为语言学数据大小。 构建全分词语料。 获取领域关键词实体的正反面特征。 利用二进制公共词组构建边界特征向量矩阵。 通过所述边界特征向量矩阵将所述全分词语料映射到向量空间。 建立最终可用的中文领域专家实体提取模型。 得到所述现场专家实体的识别结果。包括独立权利要求用于具有全分词标注语料构建模块的多特征双向门控域专家实体抽取系统。  12
本发明涉及提示词构建方法的技术领域，具体涉及一种基于AIGC的提示词构建方法，包括以下步骤：控制模块根据用户搜索时对应当月的搜索总次数计算用户搜索前的历史记录总次数，根据相关信息计算提示词大类最大值，根据提示词大类最大值计算提示词大类参考信息的选择函数，并将提示词大类参考信息传输至通信模块；通信模块将提示词大类参考信息传输至数据端。通过控制模块得出提示词大类参考信息，便于用户从提示词中筛选对应的目标提示词，从而能提升用户使用该搜索引擎时的体验感。一种基于人工智能生成内容(AIGC)的提示词构建方法。控制模块获取提示词的大类参考信息，便于用户从提示词中选择对应的目标提示词从而提高用户使用搜索引擎时的体验感。该方法包括通过信息设置模块设置(S1)历史记录的个体名词的参考索引。 所述信息被传输(S2)到所述控制模块。 控制模块根据用户搜索时当前月对应的搜索总数计算(S3)用户搜索前的历史记录总数。 根据相关信息计算提示词类的最大值。 基于所述最大值计算提示词参考信息的选择函数。 将提示词的大类参考信息传输(S4)到通信模块。 所述通信模块将所述提示词的大类提示词参考数据传输至数据端。 1
本发明公开了一种面向问句匹配任务的数据增强方法，本发明从字词、句两种角度实现数据增强，具体而言，为了应对问句文本中常出现的同义词混淆、实体混淆问题，从字词粒度出发，实现了基于命名实体识别的实体替换增强算法与利用预训练模型强大的语义表达能力实现的基于掩码语言模型的同义词替换及随机插入算法，扩充了样本空间；提出了字词粒度噪声增强算法，通过添加噪声，提高了模型的学习能力；从句子粒度，实现了基于回译方法的数据增强，利用文本生成的思想，提高了样本的多样性。通过在BUSTM数据集上进行对比实验与消融实验，验证了本文提出数据增强方法的有效性与先进性。问题匹配任务的数据增强方法。该方法验证了本文提出的数据增强方法的有效性和先进性。该方法包括使用来自变换器(BERT)的双向编码器表示作为编码器来获得单词嵌入表示的输入文本。 利用双向长短期记忆(BiLSTM)计算每个待选标签的字符输出概率。 通过条件随机场(CRF)层得到最终的序列标签结果。 从所述语句粒度对所述待匹配文本进行所述数据增强处理。 命名实体识别方法用于对文本语素和特殊名词进行识别和注释。  11
本发明公开了一种基于级联深度学习模型的公平竞争审查方法，采集大量措施方案文本，针对措施方案文本进行数据预处理，对措施方案文本内部标记的相关词汇进行替换，构建Bert语言模型，提取Bert语言模型预训练的措施方案文本特征，采用深度学习算法设计市场主体判断模型、文件类型模型、违规判断模型，将市场主体判断模型、文件类型模型、违规判断模型级联组合形成完整的措施方案文本公平竞争审查模型，旨在采用多任务级联的深度学习算法应用于措施方案文本公平竞争审查任务，将多个模型级联使用，提高措施方案文件的公平竞争审查整体性能，有效地解决了措施方案文件的公平竞争审查问题，有助于保障市场经济的健康发展。基于级联深度学习模型的公平竞争考试方法，针对市场环境下不同测度的市场测度文本进行考试，如文本分类、分析、关系筛选等任务。措施解档公平竞争考试整体成绩提高。 保证了市场经济的健康发展。 现有的考试方法对市场环境中不同措施的市场措施文本进行逐一考试存在人工考试复杂、效果不明显的缺陷。该方法包括收集(S1)大量测量解决方案文本。 对所述测量解文本进行数据预处理处理。 标记的相关词汇在度量方案文本中被替换(S2)。 构建Bert语言模型对标记的测度解文本的相关词汇进行预测。 利用深度学习算法提取(S3)所述预训练的计划文本特征的文本特征。 通过Bert语言模型提取预训练的度量方案的文本特征(S4)。 将标记的测度方案文本句子按句子划分(S5)。 将所述市场主体判断模型、所述文件类型模型和所述违规判断模型进行级联组合(S6)。 对输入测度方案文件层进行分层分析、确定和筛选。 对所述措施方案文本进行公平竞争考试，得到所述措施方案文本是否具有公平竞争性质。  12
本公开提供了网页相似度模型的训练方法、装置、电子设备及介质，涉及计算机技术领域，具体涉及自然语言处理和深度学习等技术领域。一种具体实现方案为：获取样本网页的网页数据；根据无回放抽样策略，从所述网页数据中抽取正文句子，以获得句子数据；根据所述句子数据和网页数据，获得样本数据；根据所述样本数据，对预训练语言模型进行训练，以获得所述网页相似度模型，用于对待测网页的相似度进行预测。一种网页相似度模型的训练方法。本发明增强了预测的网页信息完整性，提高了网页相似度预测结果的可靠性。训练方法包括获取样本网页的网页数据。 根据非回放采样策略，从网页数据中提取文本句子以获得句子数据。 根据句子数据和网页数据获得样本数据。 训练预先训练的语言模型以获得网页相似度模型，该网页相似度模型用于根据样本数据预测待测网页的相似度。 根据预训练语言模型的非重播采样策略和输入阈值，对网页数据中的文本进行句子提取，得到文本句子。 根据文本句子的顺序标识对文本句子进行排序。 根据排序处理的结果获得句子数据。独立的权利要求书包括： (a)具有获取单元的网页相似度模型的训练装置； (b)具有处理器的电子设备； (c)用于存储计算机指令的非临时性计算机可读存储介质； (d)用于由处理器执行计算机程序的计算机程序产品。  11
本发明公开了一种基于有监督对比学习的开放服务意图检测方法，首先使用BERT进行语义编码得到初始词向量表示，然后利用标签信息通过线性分类层和有监督对比学习表示层同时学习，获得丰富且有区分度的句向量特征表示。表示学习完成后，该模型就变为下一步联合训练的特征提取器。为了获得更多的开放类事件文本帮助训练，使用数据增强方式Mix‑up生成新的开放类样本。最后将获取的样本和合成的样本同时输入到具有两个分支的联合训练模型中进行训练优化。判断意图事件文本属于哪个已知类，如果不属于任何已知意图事件类，就认为它是开放类意图事件。本发明构建的已知意图事件分类和开放类意图检测检测方法具有推理速度快、解释性强、准确率高的特点。一种基于监督对比学习的开放服务意图检测方法。本发明能够实现推理速度快，可解释性强，特征性强，提高了IND分类的性能，并将学习置信度估计与每个输入事件文本的IND分类器相结合。该方法包括对原始数据集中的意图事件文本进行分类。 基于预处理的INA样本，数据集被划分为域内样本(INA)和外维样本(OD)。 删除文本中的冗余空间和标点符号。 获得整个文本的句子嵌入向量表示。 利用交叉熵损失函数Softmax-loss进行优化，得到任务损失。 获得属于新事件的样本的置信度损失。 将损失的两部分相加，得到开放意图检测模型。 冲击压杆动态实验加载岩石试件。  12
本发明提供的一种基于情感领域深度挖掘的情感咨询对话方法，所述对话方法包括：描述情感专业度；描述个性化回复；描述共情能力；描述回复多样性；描述文本生成过程；描述敏感词检测。使用情感领域知识库，来提高回复的专业性，使用Lora微调大语言模型和设定虚拟人格，来提高机器人回复的共情能力和同理心。基于情感领域深度挖掘的情感咨询对话实现方法。该方法利用情感域知识库提高回复的专业表现，利用低秩自适应(Lora)微调大语言模型和设置虚拟角色提高共同感受能力和机器人的回复常识。该方法包括描述某种程度的情感特殊性。 描述了个性化回复。 描述了共同爱情的能力。 描述了应答分集。 描述了文本生成过程和敏感词检测。 构建知识库。 知识库中的问题被转换为向量以匹配向量相似性。 更新知识库。 会话历史和实体信息被记录。 个性化信息被存储。 检索所述个性化信息。 构建一个mutualcondition问答对。 8
本发明公开了一种基于U‑Net网络的工业缺陷语义分割方法及存储介质，涉及计算机视觉技术领域。所述方法包括：获取目标图像集；对分割图像进行分类，划分为无缺陷类图像或有缺陷类图像；将无缺陷类图像转化为不带有缺陷信息的第一掩模图；将有缺陷类图像输入语义分割网络，得到带有缺陷信息的第二掩模图；其中，所述语义分割网络基于U‑Net网络构建，并引入PPM模块；合并第一掩模图和第二掩模图，得到关于工业产品的完整掩模图。相较于现有技术，本发明通过在U‑Net网络中引入PPM模块，可有效聚合不同区域上下文信息，避免了语义分割中误判、未判和错判等问题，特别适用于工业产品表面缺陷检测领域。基于U-Net网络和存储介质对玻璃面板缺陷、钢板缺陷等工业产品表面缺陷进行语义分割的方法。该方法能够对分割后的图像进行分类，减少了无目标训练图像造成的资源浪费，降低了后续图像语义分割的计算复杂度，放大了缺陷语义特征，从而提高了工业产品表面缺陷检测领域的效率和准确率。 本发明通过在U-Net网络中引入PPM模块，有效地聚合了不同区域的上下文信息，扩大了感受野，提高了获取全局信息的能力，达到了全局语义信息和局部细节信息的目的，避免了语义分割中的误判、漏判和误判，以及由于网络的深入导致的梯度消失和梯度爆炸问题。该方法包括获得目标图像集。 目标图像集包括用于对同一工业产品成像的分割图像。 划分的图像被分类，并且划分为无缺陷图像或类似缺陷的图像。 将所述无缺陷图像直接转换为不含缺陷信息的第一掩模图形。 将所述缺陷图像输入所述语义分割网络，得到带有缺陷信息的第二掩模图案。 语义分割网络引入基于U-Net网络构建的PPM模块。 将所述第一掩膜图形和所述第二掩膜图形进行合并，得到所述工业品的完整掩膜图形。一个独立权利要求包括用于一种存储用于分割工业缺陷语义的程序的计算机存储介质。   6
本发明公开了消息处理方法及其在互联网问诊中的应用，本方案巧妙性通过在用户接入时，根据用户信息和预设场景生成模板对话以供用户应答，使得用户可以在获取相关对话消息后，进行输入表明其诉求的第一对话消息，而第一对话消息在经过语义识别、意图判断处理后，被转换成便于应答反馈的第二对话消息，从而是的服务器可以根据第二对话消息来更为可靠、准确地反馈应答结果以供用户获取，该方案用于互联网问诊时，能够方便用户进行相关问题诉求的解答，同时也可以通过在服务器端加载经AI训练的自然语言处理工具(例如ChatGPT等)进行常规问题的解答，本方案不仅响应效率高、且应答人性化、可靠性佳，应答结果参考性强。一种互联网咨询中的消息处理方法。该方法响应效率高，人源化响应，可靠性好，响应结果参考性强。该方法包括收集(S01)用户信息和用户信息集。 基于所述用户信息集合生成并输出所述模板对话消息(S02)。 获取用户主动输入或响应所述模板对话消息而生成的第一对话消息(S03)。 根据用于生成语义结果的预设条件对第一对话消息进行分析(S04)。 当意图判断结果满足第一条件时，获得意图判断结果(S06)。 获取第二对话消息并传输至服务器，根据预设条件响应第二对话消息生成响应结果(S07)。 获得响应结果(S08)并输出给用户。包括以下独立权利要求：(1)一种互联网咨询信息处理方法； (2)消息处理系统; 以及(3)计算机可读存储介质，其存储用于处理消息和用于处理互联网咨询信息的程序。 8
本发明涉及滑油磨粒检测技术领域，特别涉及一种发动机滑油磨粒图像分析方法及装置、介质、设备，其方法包括获取铁谱图像并构建数据集，再将数据集划分为训练集和验证集；构建U‑net网络模型，再通过数据集的训练和验证以得到训练好的滑油磨粒检测模型；将待分析的铁谱图像输入至滑油磨粒检测模型中以获取识别到的磨粒图像；再使用Canny算子对铁谱图像的边缘进行检测，并结合识别到的磨粒图像进行分割；最后对分割后的磨粒图像进行轮廓检测，以获取磨粒的轮廓信息。本发明提供的分析方法采用U‑net网络模型和Canny算子对图像进行处理，能够有效识别并提取图像中的磨粒信息，不仅简化了铁谱分析流程，还大大提高磨粒分析的精准度。用于通过使用电子装置分析发动机润滑油磨粒图像的方法(权利要求书)。该方法使得能够利用U‑net网络模型和Canny算子对图像进行处理，能够有效地识别和提取图像中的磨粒信息，从而简化铁谱分析过程，提高磨粒分析的精度。该方法包括获得铁谱图像以构建数据集。 数据集分为训练集和验证集。 构建U-net网络模型。 将所述训练集输入所述U-Net网络模型进行训练，得到训练后的润滑油磨粒检测模型。 将验证集输入训练好的润滑油磨粒检测模型，用于测试和评估训练效果。 对待分析的铁谱图像进行预处理。 将预处理后的铁谱图图像输入到润滑油磨粒检测模型中，得到识别出的磨粒图像轮廓。 利用canny算子对所述铁谱图像进行边缘检测，得到边缘像素。 对分割后的磨粒图像进行轮廓检测，得到图像上磨粒的轮廓信息。独立权利要求包括用于：发动机润滑油磨粒图像分析装置； 用于存储用于通过使用电子装置分析发动机润滑油磨料粒子图像的指令集的计算机可读存储介质； 以及电子设备。   6
目标定位与语义分割相结合的超广角眼底图像视盘提取方法，包括以下步骤：步骤1：建立YOLOv4模型，进行视盘区域的粗定位；步骤2：根据视盘区域的粗定位结果，提取包含视盘区域，除去眼周区域；步骤3：通过活动轮廓模型Snake模型交互式分割视盘区域，构建U2‑Net模型训练所需的具有视盘标签的数据集；步骤4：使用U2‑Net模型进行视盘区域提取。本发明不仅有效提升了视盘提取精度，同时还能得到用于监督式学习分割方法所需的视盘标注数据。整个方法的视盘定位准确率达到99.7%，为后续分割环节提供稳定可靠的输入；分割精度高于广泛使用的PCNN、U‑Net、DeepLabV3以及SegNet模型，具有很好的应用价值。该方法用于结合目标定位和语义分割进行超广角眼底图像视盘提取。整个方法的视盘定位精度达到99.7%，为后续分割环节提供稳定可靠的输入。 分割精度高于广泛应用的PCNN、U-Net、DeepLabV3和SegNet模型，具有很好的应用价值。 有效提高了影碟提取精度，也可以得到监控类型学习划分方法所需要的影碟标记数据。 有效降低了整个超广角眼底图像中视盘面积所占比例较小给后续分割带来的困难。结合目标定位和语义分割的超广角眼底图像视盘提取方法，包括建立YOLOv4模型，粗定位视盘区域，根据视盘区域粗定位结果提取包含视盘区域，去除眼周区域，通过可移动轮廓模型Snake模型交互划分视盘区域，构建U2-Net模型训练所需的视盘标签的数据集，利用U2-Net模型提取视盘区域。   6
本发明提出了一种基于自适应知识蒸馏的数据源自动扩充方法，运用通用爬虫技术，抓取已知类别的网页文本信息；对网页文本信息进行预处理，将其转化为对应的词列表，将词列表及其所属类别作为训练与测试数据，构建训练与测试数据集；构建Attention‑BiLSTM作为数据源分类模型，通过自适应知识蒸馏算法实现模型压缩，并改善模型的收敛速度和识别能力；对采集的未知类别数据源下的文本信息进行预处理，输入构建的模型预测相应类别，根据分类结果，记录并存储各数据源的url及其对应的标签，实现数据源的自动积累与扩充。本发明能够配合通用爬虫技术自动扩充各类数据源。基于自适应知识蒸馏的自动扩展数据源的方法。该方法通过自适应知识蒸馏算法实现模型压缩，提高了模型的收敛速度和识别能力，从而得到准确、高效的光量化数据源分类模型。 该方法使得能够允许数据源自动扩展系统通过与通用爬行动物技术相匹配来自动扩展数据源，从而以有效的方式实现数据源的自动累积和扩展。该方法涉及获取网站文本信息。 使用爬虫技术捕获已知类别的网页文本信息。 对网页文本信息进行预处理，将网页文本信息转换为对应的词表。 构建双向长短期存储器(BiLSTM)的轻量级单层作为数据源分类模型。 双向编码器表示(BERT)模型被用作数据源分类模型。 将BiLSTM模型的单层配置为学生模型。 文本信息在所收集的未知类型数据源下被预处理。 输入通过知识蒸馏训练得到的数据源分类模型，预测对应的类型。 根据分类结果，记录并存储每个数据源的统一资源定位符(URL)和对应的标签。 实现了数据源的自动积累和扩展。包括独立权利要求：(1)一种基于自适应知识蒸馏自动扩展数据源的系统； (2)计算机装置； 以及(3)计算机可读存储介质。  12
本发明涉及一种面向文书领域的基于预训练模型的事件抽取方法，属于文书智能技术应用领域。本发明利用爬虫技术爬取公开文书语料，并对数据进行清洗和预处理；根据专业知识构建事件触发词和论元信息表并完成进一步拓展；根据触发词表和对应事件论元信息制定问题对模板，并按照指定格式完成模板数据标注；搭建触发词识别和事件论元信息抽取任务联合的神经网络模型Bert+Softmax，通过加载模型参数对预测数据集进行预测得到事件抽取结果。本发明将事件抽取任务转化为机器阅读理解任务，提升了事件抽取的准确性，使模型具有类人一样的理解力，且模型泛化能力和灵活性更强，在文书事件抽取应用中取得了较好的结果。一种基于文档字段预训练模型的事件提取方法。提高了事件提取的准确性。 在文档事件抽取应用中，模型泛化能力和灵活性更强，取得了更好的结果。该方法包括攀爬公共文件，并利用爬行动物技术进行去噪处理。 根据触发词表和事件讨论表构造模板。 本发明基于BERT预训练语言模型，构建了一种触发词识别与事件Arguta识别相结合的神经网络模型。 采用ADAM算法对神经网络模型进行训练和验证。 优化模型参数，使模型达到收敛状态。 通过使用该模型提取获得结果的结果来预测触发词和事件断言信息。  11
本发明公开了一种基于卷积神经网络的图像分类方法，包括以下步骤：A、图像采集器采集图像并保存至存储器中并进行加密处理；B、将采集的图像调整为统一大小后，输入预训练模型；C、对图像进行训练，计算出训练集中的平均图像，把图像训练集中的每幅图像减去平均图像后进行网络参数的训练，得到卷积神经网络模型；D、将训练后的图像进行分类操作，即完成对图像的分类，本发明提供的图像分类方法效率高，能够有效提高图像分类准确性和效率。基于卷积神经网络的图像分类方法。该方法能够有效提高图像分类效率。该方法包括通过使用图像收集器收集图像。 将采集到的图像进行存储。 对存储器中的采集图像执行加密处理。 将采集到的图像调整为统一尺寸。 输入预训练模型。 对采集到的图像进行训练。 计算平均图像训练集。 在训练过程之后减去平均图像训练集。 得到卷积神经网络模型的网络参数。 训练过程结束后对训练好的图像进行分类，以完成图像的分类。   4
本发明公开了一种基于自监督学习的放疗靶区自动分割方法，涉及图像处理技术领域，包括：1)数据准备：收集原始CT数据，分出有标签数据集和无标签数据集，并对有标签数据集进行勾画；2)特征提取：构建出基于自监督学习的预训练网络，将无标签数据集输入预训练网络进行迭代训练，选出最优预训练模型；3)分割模型生成：构建出分割网络，将训练好的自监督预训练模型载入分割网络，然后将有标签数据集输入分割网络进行迭代训练选出最优模型，最后对模型分割性能进行测试和评估。本发明使用CT数据自带的坐标标签来进行自监督任务预训练，不需要额外设计新的标签；预训练模型含有CT图像的浅层特征，因此在执行分割任务时具有较快的收敛速度。基于自监督学习的放射治疗靶区自动分割方法。该方法使得能够利用CT数据的坐标标签来执行自监督任务预训练，而无需额外设计新标签。 预训练模型中包含了CT图像的浅层特征，使得该方法在执行分割任务时具有更快的收敛速度。该方法包括收集原始计算机断层摄影(CT)数据。 标签数据集和无标签数据集是分开的。 基于自监督学习构建预训练网络。 将非标签数据集输入预训练网络进行迭代训练。 选取最优预训练模型。 构建分割网络。 将训练好的自监督预训练模型加载到分割网络中。 将采集到的CT数据输入分割模型。 输出自动分割后的CT数据。   6
本申请公开了一种图像处理方法及相关设备，其中，所述方法包括：获取目标人脸的N张第一人脸图像，N为不小于3的整数；将所述N张第一人脸图像输入到预设的人脸图像超分辨率放大模型，合成所述目标人脸的一张第二人脸图像，所述第二人脸图像的尺寸为所述第一人脸图像的尺寸的预设倍数，所述第二人脸图像的分辨率大于所述第一人脸图像的分辨率。可见，通过本申请提供的技术方案，能够将小尺寸、低分辨率的人脸图像合成大尺寸、高分辨率的人脸图像，有利于实现人脸精确识别。图像处理方法。提供小尺寸、低分辨率的人脸图像可以合成大尺寸、高分辨率的人脸图像，有利于实现准确的人脸识别。该图像处理方法包括获取目标人脸的第一人脸图像，将第一人脸图像输入至预设的人脸图像超分辨率缩放模型。 合成所述目标人脸的第二人脸图像，所述第二人脸图像的尺寸为所述第一人脸图像的尺寸的预设倍数。 所述第二人脸图像的分辨率大于所述第一人脸图像的分辨率。 将所述第一人脸图像输入至预设的人脸图像超分辨率和速率放大模型，合成所述目标人脸的第二人脸图像。对于以下包括独立权利要求：一种具有处理单元的图像处理设备； 具有处理器的图像处理芯片； 具有处理器的电子设备； 以及计算机可读存储介质，存储有计算机程序，所述计算机程序被处理器执行以实现所述方法。 2
本发明公开一种基于LDA和BERT融合改进模型的文本情感识别方法，该方法包括以下步骤：(1)获取社交网络文本，进行预处理；(2)融合文本的语义特征和主题特征，输出词向量矩阵；(3)将特征输入双向Transformer编码器，连接以梯度优化改进后的Softmax层，输出分类模型；(4)向分类模型投入正式语料，微调参数，改良模型。使用得到的最终分类模型，对社交网络文本进行情感识别，得到更精准识别结果。该方法涉及使用潜在狄利克雷分配(LDA)主题分析来获得社交网络文本主题特征。 使用来自变换器的双向编码器表示(BERT)模型来获得文本语义特征。 将两个词向量拼接成情感分类模型，使得情感分类模型准确识别文本情感。 输出优化后的分类模型，用于识别所述文本情感。 得到社交网络文本语料。 将预处理后的文本语料输入BERT预训练模型，提取语义特征。 将预处理后的文本语料输入LDA模型提取主题特征扩展。 构建情感分类器。 将深度测试的社交文本语料输入分类器进行深度预训练。 评估模型性能。 进行参数微调。 得到训练好的分类模型。  12
本发明涉及信息检索方法技术领域，公开了基于预训练语言模型的对话式信息检索方法。通过筛选介词相关的历史查询信息，通过双塔式细粒度语义交互模型，解决了现有技术的检索容易无视语义关系，造成查询结果正确性不足的问题。基于对话助手预训练语言模型的对话型信息检索方法。 用途包括但不限于Alexa、Siri、Cortana、Bixby和Google(RTM：美国跨国技术公司名称)。该方法提高了信息检索结果的正确率，并且降低了对模型引入的噪声，因此提高了对话型信息检索的检索结果的准确性。该方法涉及使用文本来表示模型BERT以获得文档的编码表示。 计算所述文档所表示的语义相似度。 文档按照大小从大到小进行排序。 利用对比学习方法构建双塔型细粒度语义交互模型。 利用测序损失的交叉熵损失计算模型。 利用所述训练好的模型对所述测试集query进行搜索，得到排序结果。 8
本发明提供一种基于少量强标注数据的声音事件检测方法和装置，该方法包括：S1、构建在大量弱标注数据下的音频预训练模型；S2、采用少量强标注数据训练得到初步的声音事件检测网络；S3、通过音频预训练模型获取强标注数据的特征；S4、将强标注数据的特征输入初步的声音事件检测网络中进行训练，得到训练后的声音事件检测模型；S5、将待预测的音频输入到训练后的声音事件检测模型中，检测待预测的音频中的声音事件。解决强标注数据收集和标记困难，尤其针对一些特殊应用领域，难以利用少量数据实现声音事件检测模型训练的问题。一种基于少量强标记数据检测声音事件的方法。该方法使得能够以简单的方式通过使用少量数据来实现声音事件检测模型训练。该方法涉及基于大量弱标记数据建立(S1)音频预训练模型。 使用少量的强注释数据(S2)来训练以获得初步的声音事件检测网络。 通过音频预训练模型获取(S3)强标注数据的特征。 将强标注数据的特征输入(S4)到初步声音事件检测网络中进行训练，得到训练后的声音事件检测模型。 将所述待预测音频输入(S5)训练好的声音事件检测模型，在所述待预测音频中检测出声音事件。本发明还公开了一种基于少量强注释数据的声音事件检测装置。 3
本发明涉及研发管理技术，揭露了一种软件开发的需求文档构建方法，包括：利用预训练的功能实体识别模型对客户方案进行功能识别，得到客户期望功能集合，从预构建的行业涉及功能图谱中提取所述客户期望功能集合中的关联功能，得到关联功能集合；查询所述客户期望功能集合及所述联动功能集合的数据参数，并对数据参数列表安全性审查，得到受限数据集合及未受限数据集；对受限数据集合进行编码加密，得到加密数据集合；根据加密数据集及所述未受限数据集，配置客户期望功能集合中各个期望功能，得到需求文档。本发明还提出一种软件开发的需求文档构建装置、电子设备以及存储介质。本发明可以提高需求文档内容丰富度及准确度，提高软件开发的效率。一种使用电子装置构建软件开发需求文件的方法。 例如，产品管理者和专家人员使用诸如移动电话，个人数字助理(PDA)和平板计算机之类的电子设备来满足对软件开发的讨论。本发明能够提高需求文档内容的丰富性，提高软件开发的准确性和效率。 本发明允许客户端在修改软件时直接执行与关联函数集对应的函数删除或调用，无需进行安全检查，大大缩短了开发过程。该方法包括获得客户端解决方案。 使用预先训练的功能实体识别模型对客户机方案进行功能识别，以获得客户机期望的功能集。 从与功能图相关的预先构建的行业中提取客户机功能集中的关联功能。 获取客户端任务集的查询参数和链接函数集。 获得数据参数列表。 对数据参数列表进行数据安全检查，以获得受限数据集和非受限数据集。 根据预设的加密策略对受限数据集和非受限数据集进行编码和加密，以获得加密数据集。 根据加密数据组和限制数据组来配置每个所需功能，以获得所需文档。还包括独立的权利要求： 一种软件开发的需求文件构建装置； 以及 一种计算机可读存储介质，包括一组用于构造软件开发的需求文档的指令。  11
本公开提供了一种图像处理模型的训练方法，涉及人工智能、深度学习、计算机视觉和图像处理技术领域。具体实现方案为：根据预训练模型的参数初始化多个待训练模块中的至少一个待训练模块的参数，得到待训练模型；将样本图像分别输入预训练模型和待训练模型，得到预训练模型的第一输出和待训练模型的第二输出；根据第一输出和第二输出，确定待训练模型的损失；以及根据损失，调整多个待训练模块中除至少一个待训练模块以外的其余待训练模块的参数，并返回将样本图像分别输入预训练模型和待训练模型的步骤，直至待训练模型符合预设条件，得到经训练的图像处理模型。本公开还提供了一种图像处理方法、装置、电子设备和存储介质。用于计算机视觉和深度学习领域的图像处理模型的训练方法。该方法使得能够利用图像处理设备根据模型的训练方法获取训练图像处理模型，从而能够以高效的方式训练模型。 该方法允许用户将样本图像输入到预训练模型和待训练模型中，直至该模型满足预设条件，从而以有效的方式得到训练模型。该方法包括根据预训练模型的参数初始化待训练模块的参数。 得到待训练模型。 将样本图像输入所述预训练模型和所述待训练模型。 输出所述预训练模型的第一输出和所述待训练模型的第二输出。 根据所述第一输出和所述第二输出确定所述待训练模型的损失。 获取训练图像处理模型，直至所述待训练模型满足所述预设条件。本发明还涉及一种图像处理方法，用于获得待处理的图像; (b)一图像处理模型训练装置，具有一初始化模块，用以初始化待训练模块的参数; (c)图像处理装置，具有获取模块，用于获取待处理图像; (d)电子设备，具有存储器，用于存储指令; (e)用于存储计算机指令的非暂时性计算机可读存储介质; (e)用于存储计算机程序的计算机程序产品; 14
本申请公开了一种基于多头注意力语义聚焦和语义增强的分析方法及装置，方法包括：获取文本序列，以及文本序列中的方面词序列；在词嵌入层，将文本序列与方面词序列输入BERT模型，以获取BERT模型的输出；在语义聚焦层，根据BERT模型的输出获取注意力矩阵，以及注意力权重矩阵；在语义增强层，对注意力矩阵以及注意力权重矩阵进行增强处理，以得到第一增强结果与第二增强结果；在特征提取层，通过GRU对第一增强结果进行提取，以获取第一提取结果；在特征融合层，对于第二增强结果与第一提取结果进行拼接，并将拼接结果输入到pool层，以获取池化结果；在输出层，将池化结果输入softmax函数中，以输出情感极性结果。用于社交，购物，食品和旅游平台的基于多头关注语义聚焦和语义增强的分析方法。 也可用于自然语言处理领域。该方法减少了不重要信息对增强语义信息的影响。 语义聚焦和增强是通过使用多头注意机制来执行的。 该方法可以结合BERT预训练模型来分析单词的情感极性。 可以对局部特征，全局信息和句子信息的焦点进行聚焦，并对聚焦后的信息和文本序列进行语义增强。该方法包括获得文本序列。 获得文本序列中的方面词序列。 得到词嵌入层，语义聚焦层和语义增强层。 根据BERT模型的双向编码器的输出获得关注矩阵。 特征融合层用于拼接第二增强结果和第一提取结果。 将拼接结果输入到池层以获得池结果。 将输出层中的池结果输入到软最大函数中以输出情感极性结果。本发明还涉及一种基于多头关注语义聚焦和语义增强的分析设备。  12
本发明属于情感计算的技术领域，涉及一种基于增强注意力机制的多模态情感识别方法，通过多头注意力机制得到语音编码矩阵和预训练的BERT模型得到文本编码矩阵；将语音与文本的编码矩阵分别进行点乘，得到语音与文本相互的对齐矩阵，再将此对齐矩阵通过与原有模态编码信息进行校准，得到更多的局部交互信息，最后将各模态的编码信息、语义对齐矩阵、交互信息作为特征进行拼接得到各模态的特征矩阵；使用多头注意力机制对语音特征矩阵、文本特征矩阵进行聚合；经注意力机制将聚合后的特征矩阵转化为向量表示；将语音与文本的向量表示进行拼接，使用全连接网络得到最终的情感分类结果。本发明解决了多模态间交互的问题，提升了多模态情感识别的准确率。基于增强注意力机制的多模式情感识别方法。该方法能够减少多模式交互问题，提高多模式情感识别的准确性。该方法包括在语音编码层中提取语音信息的FBank声学特征。 采用多头注意力机制对FBank声学特征进行编码，用于建立语音信号的编码矩阵。 通过局部对齐层和编码矩阵进行点乘运算，建立语音和文字的对齐矩阵。 利用全局连接层中的多头注意力机制对语音特征矩阵和文本特征矩阵进行聚合运算。 特征矩阵通过聚合后的多头注意力机制在一个预测识别层中转换为向量表示。 将所述语音和所述文本的向量进行拼接，以组合成融合语音信息和所述文本信息的特征向量。 利用全连接网络得到最终的情感分类结果。  12
本发明公开了一种文档分类方法、装置、设备和存储介质，所述文档分类方法包括：抽取待分类文档自身的关键词，形成关键词知识库，再通过改进后的Bert模型获取待分类文档的词嵌入向量和所述关键词知识库的词嵌入向量；然后将待分类文档的词嵌入向量和所述关键词知识库的词嵌入向量通过注意力机制融合，增强待分类文档和关键词知识库的相关性，为文档分类器提供更加有效特征信息，减少无效信息的干扰，提高长文档分类的准确性。自然语言处理文档分类方法。该方法使得能够增强待分类文档与关键词知识库的相关性，为文档分类器提供有效的特征信息，减少无效信息的干扰，提高长文档分类的准确率。 该方法能够降低独立元素的干扰影响，突出关键信息对文档分类的影响，从而提高文档的分类精度。该方法包括提取待分类文档的关键词。 构建关键词知识库。 获取所述待分类文档的词嵌入向量和所述关键词知识库的词嵌入向量。 通过注意力机制将所述文档的词嵌入向量与所述关键词知识库的词嵌入向量进行融合，得到融合向量。 将所述融合向量作为全连接层的输入。 从所述全连接层的输出获取所述待分类文档的分类结果。包括独立权利要求：(1)文档分类装置； (2)—种计算机可读存储介质，包括用于执行文档分类处理的指令集。  12
本申请提出了一种基于大语言模型的任务处理方法、装置及电子设备，在获得针对待处理任务的第一提示词后，先依据预设隐私合规要求，对第一提示词进行隐私检测，得到相应的隐私检测结果，从而依据隐私检测结果，确定是否将第一提示词发送至云端的大语言模型进行任务处理，以得到待处理任务的目标处理结果。基于机器学习和自然语言处理(NLP)技术的基于电子设备的大型语言模型处理任务的方法(权利要求)。该方法能够根据预设的隐私合规性需求获取待处理任务的提示词，并对该提示词进行隐私检测，因此保证了任务处理过程的简单高效。该方法包括：获取针对待处理任务的提示词。 根据预设的隐私合规要求对所述提示词进行隐私检测得到对应的隐私检测结果。 根据所述隐私检测结果确定是否将所述提示词传输至云端的大型语言模型执行任务处理功能。 执行所述任务处理函数，得到云端的所述待处理任务的目标处理结果。 确定是否将所述提示词传输至云端的大语言模型以用于执行任务处理，本发明还涉及一种用于处理基于大型语言模型的任务的设备。  11
本发明提供了一种多模态的自动化脑室分割系统及其使用方法，包括：收集已手动分割的厚层扫描数据集D1和未分割的薄层扫描数据集D2；导入预训练模型构建编码器ER，通过亚像素卷积层构建解码器DR，结合编码器ER和解码器DR构建多模态的脑室分割模型M；使用厚层扫描数据集D1中的已分割信息生成监督信号S；将厚层扫描数据集D1及薄层扫描数据集D2作为输入，提取特征F，和监督信号S一同，输入解码器DR；联合厚层扫描数据集D1产生的损失函数L1和薄层扫描数据集D2产生的损失函数L2，得到脑室分割模型M的损失函数L；根据损失函数L，不断训练优化脑室分割模型M；使用训练好的脑室分割模型M，对多模态不同扫描方法的脑部图像进行自动分割。用于脑图像的多模式自动心室分割系统。利用训练的心室分割模型自动分割多模式不同扫描过程的脑图像的系统。该系统具有用于收集人工划分的厚层扫描数据集和未划分的薄层扫描数据集的收集模块。 构造模块被配置为引入预训练模型以构造编码器。 监控模块被配置为使用厚层扫描数据集中的划分信息来生成监控信号。 训练模块被配置为连续地训练优化心室分割模型。 分割模块被配置为使用训练的心室分割模型。本发明还涉及一种多模态自动心室分割系统的使用方法。   6
本发明涉及人工智能技术领域，公开了一种话术推荐方法，该方法包括对获取的音频数据进行语音识别，得到文本数据；通过GPT模型中的文本特征提取层对文本数据进行特征提取，得到文本特征；通过GPT模型中的语音特征提取层对音频数据进行特征提取，得到音频特征；通过GPT模型中的情绪识别层对文本特征和音频特征进行情绪识别，得到情绪识别结果；基于情绪识别结果对音频数据进行话术推荐，得到目标话术。本发明应用于保险或金融业务中的话术推荐。本发明通过GPT模型对文本特征和音频特征进行情绪识别，实现了精准识别音频数据中的情绪，提高了情绪识别结果的准确率，进而提高了话术推荐的准确率。一种口头特技推荐方法，用于解决现有技术中用于保险或金融服务的情感识别和口头特技推荐准确率低的问题。该方法能够通过GPT模型对文本特征和音频特征进行情感识别，实现了对音频数据中的准确情感识别，因此提高了情感识别结果的准确性，提高了口头推荐的准确性。该方法涉及获得(S10)音频数据，并对音频数据进行语音识别以获得文本数据。 将文本数据输入(S20)到生成的预训练变换器(GPT)模型，并且由GPT模型中的文本特征提取层提取文本数据的特征以获得文本特征。 将音频数据输入(S30)至GPT模型，由GPT模型中的语音特征提取层提取音频数据的特征，得到音频特征。 通过所述GPT模型中的情感识别层对所述文本特征和所述音频特征进行情感识别(S40)，得到情感识别结果。 基于所述情绪识别结果对所述音频数据进行推荐(S50)，得到所述目标语音。独立权利要求包括以下内容：(1)语音推荐装置； (2)计算机装置； 以及(3)计算机可读存储介质，其存储用于推荐口头特技的程序。 3
本发明公开了一种基于改进型3D‑UNet的MRI图像脑肿瘤分割方法，具体包括：1)对数据集中脑部MRI图像进行预处理获得训练集；2)结合空洞卷积、通道注意力机制、残差卷积的方法构建改进型3D‑UNet框架；3)利用训练集数据训练改进型3D‑UNet，脑肿瘤分割网络；4)将待分割的脑部MRI图像测试数据导入脑肿瘤分割网络，得到分割后的结果。本发明提供了一种自动、准确、可重复的肿瘤分割算法，能够有效解决传统手工分割方式耗时较长且过于依赖专家的主观经验的问题，并具有比基于UNet的脑部MRI图像分割方法更高的分割精度，同时本发明提出的方法可进一步应用于其他医学MRI图像分割任务中。基于改进的3D-UNet的磁共振成像(MRI)脑图像肿瘤分割方法该方法提供了一种自动、准确、可重复的肿瘤分割算法，可有效解决传统人工分割方法分割时间较长、过于依赖专家主观经验的问题，具有更高的分割精度。该方法涉及将三维(3D)磁共振成像(MRI)图像与Z轴一起切片并去除头骨单元。 从切片后的图像的左侧的中间位置作为起点向右开始直线搜索。 空腔特征提取模块用于替换3D U-NET的桥接单元。 下一阶段的卷积结果在下采样过程中进行采样，与上层结果拼接组合后输入3D U-NET work解码单元的拼接模块。 信道关注模块用于改进解码单元的信道选择。 引入脑肿瘤分割3D U-NET work，将待分割的脑肿瘤重建图像划分为脑肿瘤分类U-NET work。 对脑肿瘤组U-NET work进行处理，得到脑肿瘤分割结果。  7
本发明公开了一种文本聚类的方法及装置，涉及数据处理技术领域，为解决现有技术中实际特征相似的文本不能实现聚类的问题而发明。该方法主要包括：根据预训练BERT模型，提取待分类文本中每个句子的原始特征向量；计算所述待分类文本中的当前句子与所述待分类文本中其他句子之间的欧式距离；采用预置注意力机制算法，计算所述待分类文本中每个句子与所述待分类文本中其他句子相比的注意力特征；根据所述注意力特征，采用K‑means聚类算法，将所述待分类文本进行聚类。本发明主要应用于文本聚类的过程中。用于通过使用计算机设备进行文本聚类的方法(权利要求书)。该方法能够实现具有相似实际特征的聚类过程。该方法包括根据预训练的双向编码器表示从变换器(BERT)模型提取要分类的文本中的句子的原始特征向量。 计算所述待分类文本中的当前语句与所述待分类文本中的语句之间的欧式距离。 采用预设注意力机制算法计算所述待分类文本中每个句子与所述待分类文本中的句子相比的注意力特征。 采用聚类算法根据所述注意力特征对所述待分类文本进行聚类。独立权利要求包括如下：一种用于通过使用计算机设备进行文本聚类的设备； 以及计算机可读存储介质，其存储有用于利用计算机设备执行文本聚类的指令集。  12
本发明提供了一种基于图注意力网络的文本情感分析方法，包括：步骤1，从Semeval 2014 Task 4数据集中获取文本集合和感情标签集合；步骤2，按比例在文本集合和感情标签集合中进行随机选取，得到训练集和测试集；步骤3，通过Biaffine依赖解析器对训练集中的句子进行句法依存关系分析，根据句子的句法依存关系构建句法依存图；步骤4，将训练集输入BERT预训练模型，通过BERT预训练模型将训练集中的词转化为词向量。本发明通过Biaffine依赖解析器对句子间的句法依存关系进行分析，通过BERT预训练模型获得词向量表示，通过图注意力网络模型对文本进行情感分析，充分利用了文本中复杂的句法结构，提高了文本情感分析的准确率。基于图注意力网络的文本情感分析方法。通过图注意力网络模型对文本进行情感分析，充分利用了文本中复杂的句法结构，提高了文本情感分析的准确率。该方法包括更新(8)图注意力网络模型。 建立门控循环单元(GRU)模型(9)。 对所述图注意力网络模型节点的临时状态和所述图注意力网络模型节点的保存状态进行(10)节点状态聚合。 通过Softmax函数激活(11)图注意力网络模型节点的最终状态，得到文本情感趋势。 对所述图注意力网络模型进行(12)所述多层训练，构建损失函数。 根据所述损失函数调整所述注意力权重。 更新所述损失函数的最小值并记录对应的图注意力网络模型参数，得到所述损失函数的值小于所记录的损失函数的最小值时的最优图注意力网络模型。 通过所述最优图注意力网络模型对所述文本进行情感分析。  12
本申请提供了一种模型训练方法、装置、计算机设备及存储介质，属于计算机技术领域。该方法包括：对于任一样本文本数据，对样本文本数据的多个第一预测信息进行加权平均，得到样本文本数据的第二预测信息，多个第一预测信息用于表示目标语言模型包括的多个目标语言子模型分别对样本文本数据进行预测得到的预测结果；基于样本文本数据的第二预测信息、样本文本数据的标签信息、第一正则化参数、第二正则化参数以及目标语言模型的模型参数，确定目标语言模型的训练损失；基于训练损失，更新目标语言模型的模型参数。上述技术方案能够有效解决大语言模型出现的幻象问题，提高模型的泛化能力。用于训练模型例如由计算机设备执行的大规模深度学习模型的方法(权利要求书)。能够有效解决大型语言模型的错觉问题，提高模型的泛化能力。该方法包括：基于样本文本数据的第二预测信息、样本文本数据的标签信息、第一正则化参数、第二正则化参数和目标语言模型的模型参数，确定(202)目标语言模型的训练损失。 其中，标签信息用于指示样本文本数据的真实类别，训练损失用于指示第二预测信息与标签信息的差异，第一正则化参数和第二正则化参数用于降低目标语言模型的复杂度。 基于所述训练损失更新(203)所述目标语言模型的模型参数。独立权利要求书包括用于：(1)模型训练装置； (2)计算机装置； (3)计算机可读存储介质，用于存储训练模型的程序； 以及(4)用于训练模型的计算机程序产品。  11
本发明公开了一种基于PR‑Trans的机械设备剩余寿命预测方法，包括离线训练和在线预测两个阶段，其中，离线训练主要任务是建立预测模型、并利用历史操作数据库中处理后的数据对模型进行训练，在线训练主要任务是基于训练模型的实时预测实时RUL，并处理实时数据，然后将相关信息反馈给控制器。这种方法采用改进Transformer的自注意力机制，能减少计算量及空间占有率、增强位置之间关系、减小模型大小、通过增大模型感受野增强模型学习能力，使模型推理速度更快、预测更精确。用于基于PR-TRANS预测机械装置的剩余使用寿命的方法本发明利用改进的自注意机制和模型大小，减少了计算量和空间占用，改善了位置关系，保证了模型推理速度和准确预测。 进行归一化运算，以减小大方差的特征影响，加快学习算法的收敛速度。 提高了变压器的学习能力。 本发明能够准确预测机械设备的剩余寿命和退化过程，实现机械设备的超前故障感知，并进行相应的维护操作，安全设备的稳定和长期运行。该方法包括在机械设备中获得多个物理量的历史状态监测信号。 利用传感器对历史状态监测信号进行数据预处理，以清除平滑的处理操作。 通过使用线段退化模型来获得标签的实际剩余寿命。 通过使用MSE函数计算预测的设备剩余使用寿命与标签之间的误差。 从监视装置收集实时数据。 数据和操作条件被输入到设备剩余寿命预测模型中。 通过RP-trans模型和器件剩余寿命预测模型输出当前时间器件剩余寿命退化预测结果。 将当前时间装置剩余寿命退化预测结果的最后一个值作为机械装置的当前剩余寿命。 14
本发明公开了一种基于全尺度密集连接的图像语义分割方法、系统及设备，首先对待分割图像进行预处理，将其切割或填充为预设大小；然后使用图像语义分割网络实现对待分割图像的语义分割；本发明的图像语义分割网络(UNet4+)通过全尺度和密集的跳跃连接，编码器中的每个节点从不同尺度的编码器接收中间聚合特征图，而解码器中的每个节点不仅从不同尺度的编码器和解码器接收中间聚合特征图，而且还从相同尺度的编码器接收中间聚合特征图。因此，解码器中的聚合层可以学习使用节点上的所有收集的特征图。本发明的UNet4+缓解了梯度消失的问题，这也使得网络中的信息流最大化；同时加强了网络中的特征传播；具备更紧凑的模型和极端的特征重用性。基于全尺度密集连接的图像语义分割方法。该方法使得能够确保解码器中的每个节点从编码器接收中间聚合特征，并且从相同大小的编码器接收中间聚合特征，使得解码器中的聚合层能够学习节点上的所有集合的特征映射。 该方法能够避免梯度消失以最大化网络中的信息流，加强网络中的特征传播，并确保紧凑的模型和极端的特征可重用性。该方法包括对待分割的图像进行预处理，以将图像切割或填充成预设尺寸。 利用图像语义分割网络实现对所述待分割图像的语义分割。 所述图像语义分割网络包括编码器、解码器、全尺度密集跳过连接数据和全尺度深度监测数据。 所述编码器设置有五个编码卷积块。 所述解码器设置有四个解码卷积块。 每个解码卷积块设置有上采样层。 每个解码卷积块的输出均设有用于通道数对齐的卷积层，以实现后续的全尺度深度监督操作。包括独立权利要求：(1)基于全尺度密集连接的图像语义分割系统； 以及(2)基于全尺度密集连接的图像语义分割装置。   6
本发明公开一种医疗OCR数据优化模型训练方法、优化方法及设备，训练方法包括：获取大规模无标注医疗文本数据，对文本数据中的医疗术语和字符进行识别以形成训练集；对训练集进行预训练处理以得到用于训练医疗OCR优化模型的预训练数据集，并利用预训练数据集对医疗OCR优化模型进行训练；所述预训练处理包括：对训练集中的低频术语和低频字符进行数据增广处理；将训练集中的第一目标字符随机替换为错误字符；对训练集中的第二目标字符进行遮挡；以及训练集切分为多个文本段落，得到用于训练医疗OCR优化模型的预训练数据集。本发明利用医疗领域预训练语言模型对医疗OCR结果进行结构化提取、错误识别及优化，提升了医疗OCR的准确率。医学OCR优化模型训练方法在临床医学研究、病例结构、核保险索赔和医学图片数据结构中的使用。该方法能够利用医学领域预训练语言模型对医学OCR结果进行结构化提取、错误识别和优化，从而有效地提高OCR的准确率。 该方法保证了医疗OCR优化模型输出医学术语和字符识别到待优化文本数据，使得OCR模型预先基于医学训练模型训练方法方面。该方法涉及获取(S101)大规模无标签医疗文本数据，并识别大规模无标签医疗文本数据中的医疗术语和字符以形成训练集。 对所述训练集进行所述预训练处理(S102)，得到用于训练所述医学OCR优化模型的预训练数据集，所述预训练数据集用于训练所述医学OCR优化模型。 对所述训练集中的低频项和低频字符进行所述数据增强处理。 将所述训练集中的所述第一目标字符替换为错误字符。 对所述训练集中的所述第二目标字符进行遮挡。 将所述训练集解剖为多个文本段落，得到用于训练所述医学OCR优化模型的预训练数据集。包括以下独立权利要求：一种医疗OCR数据优化方法； 用于训练医学OCR优化模型的电子设备； 以及存储用于训练医学OCR优化模型的程序的计算机可读存储介质。  11
本发明公开了一种基于AI的房屋地址匹配方法、存储介质及设备，属于自然语言处理领域。为了尽可能的提高匹配准确率，本发明利用预训练的BERT模型，分别构建了编码模型、二分类文本模型、命名实体识别模型，从而通过编码模型进行了初次匹配，由二分类文本模型进行了第一次匹配验证，由命名实体识别模型进行了第二次匹配验证。与传统的匹配，以及单纯的使用BERT进行匹配的算法进行比较，本发明显著的提高了房屋地址文本匹配的准确率和效率。该方法对于从成为检索对象的标准化的预处理地址数据集中取得与目标房屋地址同义的房屋地址数据是有用的。该方法：提高了房屋地址文本匹配的准确性和效率； 以及利用预先训练的BERT模型构建所述编码模型、所述二分类文本模型、以及所述命名实体识别模型，以通过所述编码模型进行所述第一匹配。该方法包括使用第一房屋地址数据集作为训练数据。 采用第一预训练模型基于第二预训练模型BERT对文本模型进行微调，得到地址匹配模型。 利用地址匹配模型在目标房屋地址中对所述待匹配地址进行分类。 所述地址匹配模型用于对所述目标房屋地址中的各个待匹配地址进行分类。 将预先标注的不同层级实体的第三房屋地址数据集作为所述训练数据进行训练。 基于所述第三预训练模型微调命名实体识别模型，以训练能够从所述地址文本中提取不同级别实体的地址实体提取模型。 地址实体提取模型用于从目标地址中提取不同级别的地址实体以及从目标地址中提取每个地址中的地址实体。一种计算机可读存储介质，包括用于执行基于人工智能(AI)的房屋地址匹配方法的一组指令; 以及基于AI的房屋地址匹配装置。  12
本申请提供一种基于预训练的联邦学习工作流构建方法及相关设备，所述方法包括：获取本地数据集；根据本地数据集，确定目标训练集，根据目标训练集，确定目标计算任务及预训练模型；发起邀请其他参与方参与请求；响应于拒绝请求，根据目标训练集、目标计算任务、预训练模型，确定第一联邦学习模型；响应于接受请求，获取联盟成员的辅助训练集，根据目标训练集、辅助训练集、目标计算任务、预训练模型，确定第二联邦学习模型。所述方法将目标训练集与预训练模型应用到联邦学习中，来创建联邦学习模型，不受计算资源的限制，低图像输入限制，加速拟合复杂函数，减少模型训练时长，且以最小的通信开销实现全局模型的聚合，从而提高了模型性能。构建基于预训练的联合学习工作流的方法。该方法能够使用目标训练集和预训练模型创建联合学习模型，不受计算资源的限制，实现低图像输入限制，加速拟合复杂函数，从而减少模型训练时间，实现最小通信开销的聚合模型，以提高模型性能。该方法涉及发送任务创建请求。 响应于接收到与所述任务创建需求相关联的任务创建请求，获得本地数据集。 根据所述本地数据集确定目标训练集。 确定预训练模型和目标计算任务。 向联合学习方中的其他参与者发送邀请。 基于所述目标训练小组确定第一联邦学习方。 获得所述其他参与者的辅助训练组。 确定第二联邦学习组。包括独立权利要求用于：(1)构建基于预训练的联合学习工作流的装置； (2)一种电子设备，包括存储器和处理器，所述处理器执行所述存储器中存储的用于构建基于预训练的联合学习工作流的方法的指令； (3)一种非临时性计算机可读存储介质，包括用于构建基于预训练的联合学习工作流的方法的指令。  11
本申请提供了一种视觉文本预训练模型的训练方法、装置、介质和设备，可应用于人工智能、计算机视觉、智慧交通等场景，该方法包括：根据视频文本样本对进行特征提取得到初始视频特征和初始文本特征；根据初始视频特征和初始文本特征进行特征融合得到融合特征；根据融合特征和预设的多个中间特征确定桥接特征；根据初始视频特征、初始文本特征、桥接特征和预设的掩码矩阵确定目标视频特征和目标文本特征，预设的掩码矩阵用于使初始视频特征和初始文本特征相互掩模；根据初始视频特征、初始文本特征、桥接特征、目标视频特征以及目标文本特征确定目标函数，并根据目标函数对进行模型训练，以学习多模态交互信息、且保持多模态之间的模态分离性。视觉文本预训练模型的方法。该方法使得能够在保持模态信息分离的同时，保证融合表达能力的各模态信息的视觉文本预训练模型。 该方法根据初始视频特征、初始文本特征和桥接特征输入跨模编码器得到目标函数，保证了交互后的目标视频特征和目标文本特征仍然保持各自的模态特征，从而保持了交互后视频文本样本和文本样本之间的模态可分性。该方法涉及获得(101)成对的标记视频文本样本对。 根据所述第一融合特征和预设的中间特征确定(103)桥接特征。 所述初始文本特征、所述桥接特征、所述目标视频特征和所述目标文本特征根据所述初始视频特征确定目标函数。 根据所述目标函数对所述视觉文本预训练模型进行训练，以使训练后的视觉文本预训练模型用于学习所述视频文本样本对的初始视频特征和初始文本特征之间的细粒度交互信息，并保持所述初始视频特征和初始文本特征之间的模态可分性。以下包括独立权利要求：1。 视觉文本预训练模型的训练装置； 2. 存储有用于视觉文本预训练模型的程序的计算机可读存储介质； 3. 计算机设备； 4. 一种用于视觉文本预训练模型的计算机程序产品。 9
本发明公开了一种视频搜索无结果的处理方法、系统、设备及介质.所述方法包括：获取搜索关键词；当所述搜索关键词通过搜索索引库查找返回无结果时，将所述搜索关键词与预先构建的视频描述向量数据库进行匹配处理，得到匹配结果；当所述匹配结果为无匹配资源时，通过大语言模型对所述搜索关键词进行语义扩展处理，得到扩展关键词；将所述扩展关键词与所述视频描述向量数据库进行匹配处理，返回视频资源。本发明实施例通过视频描述向量数据库对搜索关键词进行描述，并结合大语言模型对搜索关键词进行语义扩展，能够无需二次交互即可更大程度返回匹配意图的视频，挽留用户流失，提升用户转化，可广泛应用于计算机应用技术领域。一种视频无结果搜索处理方法，应用于计算机应用领域。该方法能够结合语言大模型对搜索关键词进行语义扩展，能够大大返回具有匹配意图的视频，无需二次交互，节省了用户的损失，提高了用户的转换性。该方法包括获得(S101)搜索关键字。 当所述搜索关键字通过所述搜索索引数据库返回无结果时，将所述搜索关键字与预先构建的视频描述向量数据库进行匹配(S102)以获得匹配结果。 通过大型语言模型对搜索关键词进行语义扩展(S103)，得到扩展关键词，当匹配结果为不匹配资源时。 将扩充后的关键词与视频描述向量数据库进行匹配(S104)，并返回视频资源。独立权利要求包括用于：(1)用于视频搜索的无结果处理系统； (2)电子设备； (3)一种计算机可读存储介质，其存储有用于处理无结果视频搜索结果的计算机程序。  12
本发明公开一种基于混合特征表示的实体关系联合抽取系统及方法，所述系统包括：特征提取模块，用于从工业文本数据中提取字符级别特征向量和词级别特征向量；特征融合模块，用于使用最大池化操作对字符级别特征向量和词级别特征向量进行融合，生成混合特征向量；模型构建模块，用于基于双向LSTM编码器、头实体识别单元、实体类型分类单元、关系‑尾实体识别单元构建实体关系联合抽取模型；联合识别模块，用于将混合特征向量输入到实体关系联合抽取模型中，识别出工业文本数据中所有的实体和关系。本发明在多个粒度级别上整合特征信息，有效处理重叠三元组问题，可提高实体关系抽取的准确度。实体关系联合抽取系统，用于各种自然语言理解任务。 用途包括但不限于知识抽取、情感分析、问答和语言推理。综合特征信息多粒度层次，有效处理重叠三元组问题，可提高实体关系提取的准确率。 混合特征向量通过具有注意力机制的双向LSTM模型对输入的混合特征向量进行编码，并基于混合特征分别对头部实体识别后的实体类型进行分类和过滤，丰富了混合特征信息，提高了实体边界识别的性能。 关系-尾实体识别最终实现重叠三元组的识别关系。 该系统充分利用字符-词级别和时序结构、上下文特征信息。该系统具有特征提取模块，用于从工业文本数据中提取字符级别特征向量和词语级别特征向量。 特征融合模块，采用最大池化运算生成混合特征向量。 模型建立模块基于双向LSTM编码器识别实体类型分类单元、首实体识别实体类型分类单元和关系-尾实体识别构建实体关系联合抽取模型。 组合识别，用于将所述混合特征向量输入所述实体到特征联合扩展模型，以识别所述工业数据中的所有实体和关系。独立权利要求包括用于：(1)基于混合特征表示的实体关系联合提取方法； 以及(2)计算机可读存储介质。  12
本公开提供了一种文本检测、文本检测模型优化、数据标注的方法、装置，涉及人工智能技术领域，具体为计算机视觉、深度学习、大模型等技术领域，可应用于人工智能的内容生成等场景。实现方案为：获取包含文本的图像的图像特征，以及用于对定位文本进行提示的提示信息特征；对图像特征进行编码操作，以得到经编码的图像特征；基于经编码的图像特征与提示信息特征之间的相关性，确定用于解码操作的锚定框，锚定框用于在解码操作中提供与文本的位置相关的位置参考信息；以及基于经编码的图像特征与提示信息特征之间的注意力交互，以及锚定框提供的位置参考信息，执行解码操作以得到在图像中定位文本的检测框。用于通过诸如个人数字处理、蜂窝电话、智能电话和在人工智能领域中使用的可穿戴设备之类的电子设备(权利要求书)执行文本检测的方法。 用途包括但不限于计算机视觉、深度学习、大型模型和诸如人工智能的内容生成的场景。没有给。该方法包括获取包含文本的图像的图像特征。 获取用于提示对文本进行定位的提示信息特征。 对所述图像特征进行编码，得到编码后的图像特征。 基于编码图像特征和提示信息特征之间的相关性来确定用于解码操作的锚定帧。 基于所述编码图像特征与所述提示信息特征之间的注意力交互以及所述主播框提供的位置参考信息，进行解码操作以获得所述图像中具有所述文字的检测框。独立权利要求包括用于：(1)文本检测模型优化方法； (2)一种文本检测数据标注方法； (3)一种电子设备进行文本检测的装置； (4)文本检测模型优化装置； (5)文本检测数据标注装置； (6)计算机程序产品，其存储用于由电子设备执行文本检测的一组指令； (7)一种非瞬时计算机可读存储介质，其存储用于由电子设备执行文本检测的一组指令。 14
本发明公开了基于机器阅读理解的BiLSTM‑BiDAF命名实体识别方法，首先，为了充分挖掘文本的上下文特征，使用NEZHA获取全文语境信息，并进一步通过BiLSTM提取局部特征，以加强模型对局部依赖信息的捕获能力。其次，引入双向注意力机制学习文本与实体类别之间的语义关联。最后，设计基于门控机制的边界检测器加强实体边界的相关关系，预测出实体在文本中的位置，同时通过建立答案数量检测器，将无答案问题识别出来。本发明在CCKS2020中文电子病历和CMeEE数据集上进行了实验，结果表明本发明构建的模型能有效识别文本中的命名实体。基于机器阅读理解的双向长短期记忆(BiLSTM)-双向注意力流(BiDAF)命名实体识别方法。该方法通过建立答案号检测器，设计基于门控机制的边界检测器来加强实体边界的相关性，使得预训练的语言模型能够有效地识别文本中的命名实体。该方法包括根据待识别文本的实体类型，构建包含语义先验信息的实体类型查询语句。 数据集被构建为适合于通过数据预处理输入的机器读取理解帧的形式。 所述数据集中设置有文本实体类型查询语句和类型实体在文本中的起始位置。 利用预先训练的语言模型作为嵌入层，对所述文本进行全局特征提取，提取所述文本的语义信息和所述先验信息的特征。 通过使用预测起始位置概率和交互融合向量来定义加权文本表示。  12
本申请提供了一种指令生成方法、装置、设备及存储介质，通过对专业领域数据进行语义特征提取，获得语义特征；根据所述语义特征，从所述专业领域数据中获取有效知识片段；将所述有效知识片段和提示词输入大模型，使所述大模型根据所述提示词生成所述有效知识片段对应的指令。本申请中，从专业领域数据中可以提取专业性的有效知识片段，基于大模型可以生成该专业性的有效知识片段对应的指令。由此，大模型后续可以基于生成的该指令执行专业领域的任务，使得大模型可以适用于专业性较强的领域。所述方法和装置可用于在电子装置(权利要求书)中生成指令。大模型基于生成的指令执行专业领域的任务，使得大模型能够应用于专业性较强的领域。指令生成方法包括提取(S101)专业领域数据的语义特征，得到语义特征。 根据所述语义特征从所述专业数据中获取高效知识片段(S102)。 将所述高效信息段和所述提示词输入(S103)大模型，以使所述大模型根据提示词生成与所述高效知识段对应的指令。独立权利要求还包括用于：指令生成装置； 以及包括用于生成指令的指令集的计算机可读存储介质。  11
本发明属于自然语言理解领域技术，具体涉及一种基于bert+bilstm+crf与xgboost模型的多意图识别方法和系统；本技术方案中，使用bert处理预处理完成的数据集，得到动态的词向量，不同于以往的使用word2vec或glove模型获取的词向量。Bert模型输出的词向量具有动态特性，能够解决一词多义的问题。词向量再经过bi l stm+crf转换为句向量，bi l stm+crf模型能够同时处理距离较远的上下文文本信息，通过近邻标签的关系得到最优的句向量预测序列。在主意图识别方面使用Xgboost模型，该模型的识别精度较高且更加灵活，因此用在主意图。得到所有的主意图过后，我们利用TF‑I DF模型选取标准意图，以此为意图判断依据。将经由bert+bi l stm+crf模型处理过后的句向量输入到新的bert模型当中，最终输出子意图。基于对用户发出的语音或文本进行自然语言理解的BERT、BiLSTM、CRF和XGBoost模型进行用户交互多意图识别的方法。该方法能够利用BERT处理预处理得到的数据集得到动态的词向量，区别于利用word2vec模型得到的词向量，使得BERT模型输出的词向量具有动态特性，从而解决了动词-动词的问题。 本发明将词向量转化为句向量，对距离较远的上下文文本信息进行处理，并通过相邻标签的关系得到最优的句向量预测序列，使得模型在主意图识别时识别精度高且灵活。 该方法能够在获得主意图后，利用词频-逆文档频率(TF-IDF)模型选择标准意图，从而判断出基础意图，从而将经过BERT、BiLSTM、CRF和XGBoost模型处理后的句子向量输入到新的BERT模型中，最后输出子意图。 该方法使得能够获取用户的交互文本或语音信息，并构建数据集，保证多意图识别方法简单高效。该方法通过获取用户的交互文本或语音信息来构建数据集。 对所述数据集进行预处理，得到标准格式数据。 标准格式数据通过双向编码器表示自变换器(BERT)、双向长短期存储器(BiLSTM)、条件随机场(CRF)和极端梯度提升(XGBoost)(RTM：开源软件库)模型被转换成特征句子向量。 通过所述XGBoost模型训练对应的特征句向量模型，以进行所述意图识别。 确定标准意图，其中，另一意图为子意图，将所述标准意图的语句向量作为标准语句向量。 通过所述BERT模型对所述子意图进行分类，以输出子意图类型。包括独立权利要求：(1)基于BERT、BiLSTM、CRF和XGBoost模型进行用户交互多意图识别的系统； (2)一种电子设备，包括处理器和存储器，用于基于BERT、BiLSTM、CRF和XGBoost模型进行用户交互的多意图识别； (3)一种计算机可读存储介质，用于存储基于BERT、BiLSTM、CRF和XGBoost模型进行用户交互多意图识别的指令集。  12
本发明公开了一种基于多尺度残差网络模型的高分影像建筑物提取方法。首先，对高分辨率遥感影像中的典型建筑物类型和特征做出分析，基于深度学习网络大量数据需求设计数据增广策略，确定训练样本集和验证样本集的超参数配比；其次，在U‑Net网络对称结构的基础单元中结合密集捷径结构，设计残差映射单元，并对基本单元中卷积层结构安排进行改进，利于模型训练；同时，该改进网络将影像输入阶段设计为特征金字塔输入结构，可在不同尺度上学习影像特征，结合设计的残差跳跃连接方式进行多尺度特征融合，通过多级残差单元运算细化建筑物分割结果，加强了不同网络层之间多级特征的重用性，有效地增强了梯度在网络中的传递，加速模型收敛。基于多尺度残差网络模型的高分割图像建筑物提取方法。该方法能够增强不同网络层之间多层次特征的可重用性，有效增强网络中梯度的传递，加速模型收敛。该方法涉及根据高分辨率遥感影像中的典型建筑物区域，分析不同类型和风格的建筑物影像特征。 确定超参数集和验证集的比例。 一种多尺度残差连接深度网络整体模型结构，基于基本对称卷积神经网络模块密集快捷结构、残差跳变连接方式和特征金字塔输入结构设计。 通过所述验证集获取多尺度残差连接深度网络模型，用于为测试集提取高分辨率图像构建。   6
本发明公开了一种基于预训练模型的社交网络舆情态势监控方法，属于文本信息挖掘技术领域，包括：社交网络文本数据预处理；构建LDA模型对文本数据实现事件聚类；使用LoRA微调后的预训练模型对文本数据进行基于字粒度的编码，并通过填充或截断操作保持文本编码长度一致性，通过循环神经网络和全连接神经网络输出情感分类结果；根据事件聚类的结果与文本情感分类的结果分别得到关注度变化和情感变化，同时基于关注度变化和情感变化实现态势预测；本发明采用事件聚类和文本情感分类实现事件在时间维度上的情感分析，从而实现不同事件舆情态势的实时监测，使用预训练模型进行建模，辅以LoRA微调技术，有效地提高模型的准确率和训练速度。基于文本信息挖掘预训练模型的社会网络舆情监测方法。该方法能够采用事件聚类和文本情感分类实现事件在时间维度上的情感分析，实现利用预训练模型对不同事件舆情的实时监测，有效提高模型的准确率和训练速度。该方法包括对社交网络文本数据进行预处理，预处理后的文本数据包括脏数据清洗、简单复杂变换、文本切分和无关词清洗。 构建事件聚类。 利用预训练模型对所述文本数据进行基于词粒度的文本编码处理。 采用预先训练好的模型对预处理后的文本数据进行基于字符粒度的文本编码，通过填充或截断操作保持文本编码长度的一致性。 通过循环神经网络提取文本的时间特征，通过全连接神经网络输出情感分类结果。 情绪分为积极、中立和消极。 基于事件聚类和文本情感分类的结果分别得到注意力和情感的变化。  12
本发明公开了一种基于RoBERTa模型的网络舆情情感分析方法及系统，通过对网络舆情信息进行分割，获取文本分割后序列的input embedding，并在input embedding层生成对抗网络，有效提升了模型的泛化能力，再将分割后的文本信息分别输入到预训练模型中获取文本信息的词嵌入特征，并进一步获取长文本信息的更高维度特征，进而对长文本的情感进行分析，提高了对特征的抽取能力，增强了获取网络舆情内容的上下文信息和语义的能力，提高了网络舆情情感分析的准确率，有助于对社会、企业对网络舆情进行管控和分析，减少因网络舆情处理不当造成的经济损失。解决了现有技术中网络舆情情感分析的准确率不理想的问题。基于RoBERTa模型的网络舆情情感分析方法用于社交网络平台的管控与分析。该方法使得能够对网络舆情信息进行切分，获取文本切分后序列的输入，并在输入层生成对抗网络，因此有效提高了模型的泛化能力。 所述方法允许将所述分割后的文本信息分别输入所述预训练模型以获得所述文本信息的词嵌入特征， 从而对长文本的情感进行分析，提高了特征的提取能力，增强了获取网络舆情内容的上下文信息和语义的能力，从而提高了分析的准确性。 使社会、企业和管控分析的舆情得到管控，减少因舆情不当造成的经济损失。该方法涉及对文本信息进行划分。 在文本切分之后获得序列的输入。 在输入层的层中生成电阻网络。 将划分后的文本信息输入预先训练的模型中。 获取所述分割后的文本的词嵌入特征。 基于切分文本的词嵌入特征提取文本的高维特征。 得到整条长文本的高维特征。 对所述长文本进行情感分析。包括以下独立权利要求：(1)基于RoBERTa模型的网络舆情情感分析系统； (2)终端设备； (3)一种计算机可读存储介质。  12
本发明涉及医疗图像处理技术领域，具体涉及一种基于有限数据的深度学习用于皮肤癌图像分类的方法。本发明包括如下步骤：步骤一、搜索皮肤损伤知识盲点：包括如下小步：基于粒度的区域采样、基于浅层网络的不确定性估计、皮肤损伤知识盲点的搜索；步骤二、强化皮肤损伤知识盲点学习：在迁移学习过程中，将检测到的损伤知识盲点与原始数据集混合，增强损伤知识盲点在训练时的重要性，对预训练的深度卷积神经网络进行微调，从而获得改进的模型来识别皮肤损伤。在皮肤损伤数据集有限的情况下，能够有效提高深度学习检测皮肤癌的效果；能够以更准确的精度和更快的速度来帮助医生诊断皮肤癌，帮助病人早日康复。基于有限数据深度学习的皮肤癌图像分类方法。该方法在皮肤损伤数据集有限的情况下，有效提高了深度学习检测皮肤癌的效果，帮助医生以更准确的精度和更快的速度诊断皮肤癌，帮助患者更早康复。该方法涉及搜索皮肤损伤知识中的盲点。 提出了皮肤损伤知识中描述盲点的两种形式，将局部区域定义为图像上的局部矩形区域。 引入一组浅层网络，其中每个浅层网络为一个浅层卷积神经网络，提取预训练的深度卷积神经网络的知识来评估图像和区域不确定性分数。 将检测到的损伤知识盲点与原始数据集进行混合，增强训练时损伤知识盲点的重要性，对预训练的深度卷积神经网络进行微调，得到改进的模型，在迁移学习过程中识别皮肤病变。  7
本发明涉及用电设备行为监测技术领域，公开了一种基于BERT的非侵入式电脑行为监测方法及系统，本方法包括步骤：S1：通过卷积层提取特征数据信息，并增加一维输入序列的隐藏尺寸得到目标数据信息；S2：将步骤S1的目标数据信息与位置嵌入矩阵相加，得到序列位置编码；S3：将目标数据信息传输至Transformers层中进行预设处理，得到注意力模型输出数据。本方法使用了Transformer作为算法的主要框架并采用MLM和NSP的多任务训练目标，最后基于机器训练大规模的数据，使得BERT的输出结果达到了有效的应用。一种基于BERT的无创计算机行为监测方法该方法以算法的主框架为算法，以掩码语言模型(MLM)和下一状态预测(NSP)的多任务训练目标。 基于机器训练的大规模数据，有效地应用BERT的输出结果。该方法包括：通过卷积层提取(S1)特征数据信息；以及增加一维输入序列的隐藏大小，以获得目标数据信息。 将目标数据信息与位置嵌入矩阵相加(S2)以获得序列位置码。 将目标数据信息发送(S3)到变压器层进行预定处理，获得关注模型输出数据。 处理后的关注模型输出数据被输入到MLP层(S4)，并且转置卷积以将关注模型输出数据扩展到其原始长度。 通过预设算法将输入的隐藏大小改变(S5)为软件的分类。本发明还涉及一种基于BERT的非侵入式计算机行为监测系统。 0
本申请公开了一种训练任务的部署方法、系统、设备及存储介质，应用于深度学习技术领域，包括：从预设的模板库中选取出对应于训练任务的模型类型的目标模板并进行参数配置；检测出参数配置信息符合针对大模型的资源配置规则之后，通过预设的资源调度算法，从集群中选取出用于部署训练任务的节点集合，使得节点集合中的节点资源符合目标模板的参数配置信息的要求，且使得节点集合中的节点间通信效率符合预设的通信效率要求；基于目标模板的参数配置信息，在选取出的节点集合中进行训练任务的部署。应用本申请的方案，对于采用大模型的训练任务，可以便捷、可靠地实现训练任务的部署，保障了节点间的通信效率，提高了训练任务执行效率。用于在选定的节点组中部署训练任务的方法。该方法能够保证节点间的通信效率，提高训练任务的执行效率，方便可靠地实现大模型对训练任务的部署。该方法涉及在接收到携带有表征训练任务的模型类型的第一指令后，从预设模板库中选取与模型类型对应的目标模板。 基于接收到的第二指令对所述目标模板进行参数配置。 判断所述模板的参数配置信息是否符合预设的基于大模型的资源配置规则。 基于所述目标模板的参数配置信息，在选定的节点组中部署所述训练任务。还包括独立权利要求，用于：(1)在选定的节点组中部署训练任务的系统； 以及(2)用于在所选择的节点组中部署训练任务的装置； 以及(3)计算机可读存储介质，所述计算机可读存储介质用于存储计算机程序，所述计算机程序用于在选定的节点组中部署训练任务。  11
本发明将属性抽取任务化为片段抽取式阅读理解任务，采用属性抽取与文本属性判断联合训练的多任务模型。模型以BERT‑B i‑LSTM作为编码模块，分别对输入文本与问题编码，将结构化信息作为问题来增强模型的泛化能力。然后使用词边界特征增强的方法以帮助模型捕获属性值的边界特征，结合多头注意力机制在全局向量特征的基础上融入词汇特征。同时，设计一种文本特征交互方法，用于判断文本中是否存在与问题对应的属性值，该方法作为辅助任务与属性值边界预测任务联合训练。一种用于提取属性的方法，所述属性例如是用于构造知识地图的钩衣和绒布的属性，即材料-拉绒布，风格-头，材料和风格。该方法使得属性提取任务成为分段提取式阅读理解任务。 将结构化信息作为问题来提高模型的泛化能力。 该模型充分捕捉了文本的时序特征和语义特征。 本发明帮助模型捕捉属性值的边界特征。 本发明能够利用词边界信息和文本属性特征，缓解了现有技术中的长距离依赖和推广性不足的问题。该方法包括将预处理后的问题和文本输入到预先训练好的属性提取模型中，其中的问题是掩码标记取代了首尾实体后的三元组，即结构化信息。 使用BERT模型计算以获得问题全局向量表示和由问题表示的第一文本全局向量。 文本被输入到自动分词工具以获得文本分割结果和文本的文本向量表示。 根据分词结果中的词和尾标签的绝对位置索引添加词向量表示。 预测所表示的最终文本向量将被提取属性值边界以获得目标属性值。独立的权利要求书包括： 用于提取属性的设备； 以及 一种存储用于提取属性的一组指令的计算机可读存储介质。  12
本发明公开了一种视触觉数据特征提取方法及视触觉数据采集系统，视触觉数据采集系统用于采集大量的对齐的视触觉数据，解决了机器人预训练数据缺乏触觉模态以及依赖昂贵的领域内数据导致数据规模较小的问题；视触觉数据特征提取方法构建了一种视触觉融合表征学习框架，利用采集的人类视触觉数据预训练模型，实现了从人类操作数据中学习视触觉融合模型，解决了机器人智能体决策缺乏触觉感知辅助的问题。智能机器人视觉触摸数据特征提取方法。该方法能够利用采集到的人类视觉触摸数据预训练模型，实现从人类操作数据中学习视觉触摸融合模型，从而提高机器人基于触摸感知的辅助决策性能。该方法涉及预处理收集的视觉数据和触摸数据(S1)，并且将预处理的视觉数据和触觉数据输入到视觉触觉编码器中(S2)。 将套刻后的视觉触摸包输入到视觉触摸融合模块(S3)，用于对输入的视觉触摸潜在特征进行去套刻操作。 基于输入的视觉触摸电势特征，在掩膜位置上添加同维数据块。 视觉潜在特征被输入到视觉重建器单元。 输出重建图像。 将经补偿移除的触觉潜在特征输入到触觉重建器单元。 输出重构的触觉信号。 得到视觉触摸融合表征学习框架模型的损失函数。 表示输入图像和通过学习网络重建的图像。 输入触摸数据和重构触摸数据由网络表示。本发明还公开了一种可视触摸数据采集系统。 14
本发明提供一种基于GitHub软件仓库数据集的开源项目个性化检索推荐方法，包括：对GitHub活动数据集进行预处理，形成“标题‑描述‑URL”数据集和“标题‑Star‑watch‑fork”数据集；基于Milvus搜索引擎结合Bert预处理模型搭建关键字搜素引擎，并将“标题‑描述‑URL”数据集作为搜索数据源；接收用户输入的查询关键字，使用所述关键字搜索引擎进行软件资源检索定位，获得开源项目候选集；根据所述“标题‑Star‑watch‑fork”数据集对所述开源项目候选集中各个候选项目进行质量评分；根据质量评分结果，将Top‑N的候选项目推荐给用户。本发明对于开源软件项目本身进行质量评估，从而提升搜索结果的质量，提升搜索项目的可参考性。该方法对于通过使用电子设备(要求保护的)基于GitHub软件仓库数据集的开源项目是有用的。该方法对开源软件项进行质量评价，以提高搜索结果的质量和搜索项的参考性。该方法包括预处理GitHub活动数据集。 形成标题描述统一资源定位符(URL)数据集和标题星表叉数据集。 关键词搜索引擎是基于Milvus搜索引擎结合Bert预处理模型构建的。 将标题-描述-URL数据集作为搜索数据源。 接收用户输入的查询关键字。 利用所述关键词搜索引擎进行软件资源搜索定位，得到开源物品候选集。 根据质量评分结果向用户推荐Top-N候选项。还包括独立权利要求的可读存储介质，该可读存储介质包括用于基于GitHub软件仓库数据推荐开源项目的个性化检索的指令集。  11
本发明公开了一种极小极大学习模型的可验证数据遗忘隐私保护方法和装置，该方法基于全海森曲率矩阵，对极小极大模型的参数进行牛顿步更新并添加随机扰动，进而从模型中移除所遗忘数据的影响，从而实现有效的、可验证的机器学习模型遗忘，近似达到在剩余数据上重新训练的效果。本发明首次提出了针对极小极大问题的可验证机器学习模型遗忘方法，充分利用已训练模型的参数及数据，获得通过模型遗忘机制更新后的新参数，避免了重新训练的高昂计算开销，在处理用户数据删除请求的同时，保护了数据隐私。用于自然语言处理、图像识别、推荐系统和预测分析等各个领域的minimax学习模型的可验证数据遗忘隐私保护方法。从模型中去除遗忘数据的影响，实现有效的、可验证的机器学习模型遗忘，近似于对剩余数据进行重新训练的效果。 该方法首次针对minimax问题提出了可验证的机器学习模型遗忘方法，充分利用训练模型的参数和数据，得到通过模型遗忘机制更新的新参数。 避免了重新训练的高计算开销，在处理用户数据删除请求的同时保护了数据隐私。该方法包括在最优解处计算Quan Haisen矩阵。 所述权海森矩阵设置有直接海森矩阵部分和间接海森矩阵部分。 根据最优解、权海森矩阵和用户的数据删除请求，对最小最大学习模型的最大参数和最小参数进行牛顿忘记更新步骤，得到更新后的最小参数和最大参数。 在更新后的最小参数和最大参数中加入一个高斯噪声作为随机扰动，得到最终的遗忘模型。 根据遗忘模型完成可验证数据遗忘隐私保护。包括独立权利要求：(1)一种保护minimax学习模型的可验证数据遗忘隐私的装置； 以及(2)存储用于保护minimax学习模型的可验证数据遗忘隐私的程序的计算机可读存储介质。  11
本发明提供了一种基于机器学习的文章阅读理解答案检索系统及装置，通过根据语义规则提取文章中不同语句和问题语句的关键词，获得不同语句对应的核心词和问题核心词；根据预训练语句模型向量化语句的核心词和所述问题核心词，获得语句的核心词向量和所述问题核心词向量；根据余弦距离计算所述问题核心词向量与不同语句的核心词向量的相似度，获得不同语句的相似度；判断不同语句相似度的大小；将相似度大的语句作为训练语料输入循环神经网络和多层感知机合并的神经网络训练，获得答案检索神经网络模型。解决了现有技术中存在人工标注语料的技术问题，采用定规则产生机器标注，实现准确率适中同时无需人工标注，节省成本的技术效果。基于机器学习的文章阅读理解答案检索系统。达到精度适中，无需人工标注，节约成本的技术效果。文章阅读理解答案检索系统包括提取第一句子的关键词。 根据语义规则在文章中提供第二句子和提问句子，以获得第一核心词。 第一核心字不同于第二核心字。 根据预先训练的句子模型词向量化第一核心词，第二核心词和问题核心。 计算问题核心字向量和第一核心字向量。 词向量的相似度获得第一相似度和第二相似度。  12
本发明公开了一种基于深度学习的临床术语识别方法与装置，方法包括以下步骤：预训练模型微调、构建临床实体库、上下文感知网络、术语识别。首先使用预训练模型在临床数据集上进行微调，以学习临床领域的文本表示方法；然后借助爬虫程序在专业的临床医学实体词典和在线医学资料库PubMed抓取临床实体单词存入临床实体库；使用临床实体库对临床文本进行匹配标记得到临床实体集合，并使用前微调后的预训练模型对临床文本和临床实体集合进行向量化表征，通过注意力机制构建上下文感知网络建模术语和上下文实体的信息关联用于术语识别的特征向量；最后通过条件随机场CRF学习标签之间的依赖关系提高术语识别的准确率并输出临床术语的识别结果。基于深度学习的临床术语识别方法，用于互联网和人工智能技术领域。 用途包括但不限于疾病推理、常见病检测、临床诊断等任务，准确识别和标记相关实体。将预训练模型和注意力机制学习项与临床文本上下文的隐式特征和信息交互相结合，从而提高模型训练学习的效率。 通过所述补充词向量的特征来确保所述用于识别所述临床术语的方法的准确性和可解释性。该方法涉及微调预训练模型。 构建临床固体基地。 网络是上下文感测的。 执行术语识别。 采用MIMIC-III临床数据库，其中包含大量非结构化临床记录作为未标注临床记录数据集，对预训练模型进行微调。 得到整合临床领域知识的语言表示模型(Bert on Clinical Records, CRBERT)。 在后续的词向量化处理中，主要使用一个CRBERT代替原有的Bert作为初始的词向量化工具。包括一个独立权利要求，用于实现基于深度学习的临床术语识别方法的识别装置。  11
本发明实施例公开了一种银行业务中大模型的微调方法、装置、设备及存储介质，所述方法包括接收银行业务中的场合请求，其中，场合请求包括银行业务中需要处理的数据类型；根据数据类型和场合请求选择对应的大模型和构建微调辅助模型，将微调辅助模型接入大模型；接收已标注的数据样本，输入大模型和微调辅助模型，固定大模型的第一参数，对微调辅助模型进行训练；训练至大模型和微调辅助模型收敛时，将微调辅助模型的第二参数发送至大模型；根据第二参数对大模型进行微调。该方法实现了通过少量数据对大模型的微调，降低了大模型在银行业不同领域进行应用时的训练成本，使银行业务的服务更优质便捷和数字化。对银行服务中的人工智能大模型进行微调的方法。本发明能够以少量的数据实现对大模型的微调，降低了银行行业不同领域大模型的训练成本，使银行业务的服务更加便捷和数字化。该方法涉及在银行服务中接收时机请求。 选择相应的大模型。 根据一数据类型和所述场合请求构建精调辅助模型。 将所述精调辅助模型接入所述大模型。 接收标记的数据样本。 输入所述大模型和所述精调辅助模型。 固定大模型的第一参数。 对所述精调辅助模型进行训练。 在训练至所述大模型和所述精调辅助模型收敛时向所述大模型发送所述精调辅助模型的第二参数。 根据所述微调辅助模型的第二参数对所述大模型进行微调。独立权利要求还包括：一种用于对银行服务中的人工智能大模型进行微调的装置； 以及计算机可读存储介质，其包括用于执行银行服务中人工智能大模型的精细调整的指令集。  11
本发明公开了一种公文关系抽取方法和装置，涉及人工智能技术领域。该方法的一具体实施方式包括：从原始文本文件中查找出现的至少一个公文实体，根据设定的筛选规则，从至少一个公文实体中筛选出需要抽取公文关系的公文实体作为目标公文实体；使用设定的第一字符串，替换原始文本文件中的目标公文实体，得到新文本文件；将新文本文件输入至预训练的序列标注模型，由序列标注模型为新文本文件中的字符打标签，输出标签序列；根据公文关系与实体类型的关联关系，确定标签序列中实体类型对应的公文关系。该实施方式通过序列标注模型识别出公文实体对应的实体类型，进而确定公文关系同时在识别之前减短了文本文件的长度，保证模型识别效果。一种用于人工智能领域的公文关系提取方法。本发明通过序列标签模型识别公文实体对应的实体类型，确定文档关系，缩短识别前文本文件的长度，保证模型识别的效果。该方法包括：根据所设置的过滤规则，搜索(S101)出现在原始文本文件中的公文实体。 从公文实体中选择需要提取公文关系的公文实体作为目标公文实体。 替换原始文本文件中的目标公文实体(S102)，以使用所设置的第一字符串来获得新的文本文件，其中第一字符串的长度小于目标公文实体的文本长度。 将新文本文件输入(S103)到预先训练的序列标记模型中，序列标记模型标记新文本文件中的字符，并输出标记序列。 根据所述公文关系与所述实体类型之间的关联关系，确定与所述标签序列的所述实体类型相对应的公文关系(S104)。独立的权利要求书被包括在以下内容中： 一种用于提取公文关系的装置； 电子设备； 以及 一种计算机可读介质存储计算机指令的提取公文关系的方法。  11
本发明公开了一种基于指令链的多属性图像编辑方法、装置和电子设备，属于人工智能技术领域。方法包括：构建有监督微调训练(Supervised Fine Tuning，SFT)数据集，SFT数据集包括多属性指令和对应的单属性指令链；利用SFT数据集中的多属性指令和对应的单属性指令链对预训练的大语言模型进行微调，得到训练好的大语言模型；利用训练好的大语言模型将一个待编辑的多属性指令分解为待编辑的单属性指令链；对待编辑的图像，利用编辑模型逐步执行待编辑的单属性指令链中的各个单属性指令，得到编辑好的图像。本发明的技术方案可以有效解决多属性指令的图像编辑问题，使得编辑后的图像与多属性指令有较高的一致性。基于指令链的多属性图像编辑方法。该方法使得能够有效解决多属性指令的图像编辑问题，使得编辑后的图像与多属性指令具有较高的一致性。该方法涉及构建(S101)监督微调(SFT)数据集，该数据集包括多属性指令和对应的单属性指令链。 利用(S102)SFT数据集中的多属性指令和对应的单属性指令链对预先训练好的大型语言模型进行微调，得到训练好的大型语言模型。 利用训练好的大型语言模型(S103)将多属性的待编辑指令分解为单属性的待编辑指令链。 利用所述编辑模型(S104)逐步执行所述待编辑单属性指令链中的每个单属性指令，针对所述待编辑图像得到编辑图像。独立权利要求包括如下内容：(1)一种基于指令链的多属性图像编辑装置； 以及(2)电子设备。   6
本发明属于智能文档分类领域，具体涉及一种基于模型集成和数据扩充的公文分类方法。包括获取各部门文件若干并将部门名称作为标签对应标注；数据集分析脏数据处理，样本统计并确定小样本和大批量样本；创建部门关联热词表，扩充小样本以及删减大批量样本；利用BiLstm、ALbert、XLNet分别建模；通过逻辑判断实现公文智能分类。通过数据分析建立部门高频词表，利用高频词筛选文本特征，实现了数据集快速扩充和样本均衡。单模型部署时文本过长和推理耗时问题，基于模型集成外加逻辑筛选借助准确率和推理时间互换，综合实现了一种可操作性相对合理，准确率高、推理时间短的智能文档分类技术。基于模型集成和数据扩展的公文分类方法。 用途包括但不限于信件、通知、工作联系单等。通过数据分析建立科室高频词表，通过高频词筛选文本特征，因此可以快速扩充数据集，平衡样本。 针对单模型排列时文本过长、推理时间消耗会过长的问题而提出的可操作性相对合理、准确率高、推理时间短的智能文档分类技术。 基于模型集成的逻辑筛选以精度和推理时间为单位进行交换。该方法涉及收集多个部门档案并建立数据集。 部门名称被用作相应文件的标签。 删除数据集中的干净数据。 筛选样本数小于50的小样本标签。 筛选出样本数在300个以上的大样本标签。 建立不同科室高频词表。 小样本标签标注数据根据不同科室的高频词列表进行扩充。 将所述大样本标签标注数据删除，得到处理后的数据集。 得到用于分类的BiLstm模型、ALbert模型和XLNet模型。  11
本发明公开了一种基于视频问答的短视频标注方法，属于视觉问答技术领域。首先从短视频平台按不同类别收集短视频素材，针对每个视频帧提取视觉对象和场景文本的高维特征表示；利用多模态变压器模拟两个模态之间的相互作用；以对象或文本作为答案，通过具有自回归机制的迭代解码来预测与答案对应的问题；然后针对待标注的短视频，将问题和答案分别与视频帧和音频组合，其中视频帧的一组先通过RCNN处理，两组再分别重组进入BERT网络和全连接层进行预测；对两组的预测进行求和，并经过归一化将求和的向量转换为答案分数，输出分数最高的回答。最后，以所有回答作为文本，利用RNN网络进行文本分类，生成的标签即作为短视频标注的结果。基于视频问答的短视频标注方法。该方法使得能够使用具有自回归机制的多模转换器和迭代解码器预测问题来获得用于短视频标注的通用问题集，从而以高效的方式获得用于待标注短视频的答案集。该方法涉及提取每个视频帧的视觉对象和场景文本的高维特征表示。 通过将视觉对象或场景文本作为答案来预测通过利用自回归机制的迭代解码与答案对应的问题。 针对待贴标签的短视频，将问答分别与视频帧和音频相结合。 一组视频帧经过基于区域的卷积神经网络(R-CNN)处理，然后重组形成字符串序列，然后进入双向编码器表示从变换器(BERT)网络和全连接层进行预测。 一组音频直接重组形成字符串序列，进入BERT网络和全连接层进行预测。 将两组的预测结果求和，使用归一化将求和的向量转换为答案分数，并输出具有最高分数的答案。 9
本发明属于智能制造相关技术领域，并公开了一种基于多层级语义特征相似性的工件加工工艺预测方法。该方法包括下列步骤：S1采集工件的加工工艺数据构建正样本对和负样本对；S2将构建的正样本对和负样本对输入预设的自注意力大模型中，对述自注意力大模型进行微调；S3构建多层级索引库；S4将待检测文本输入自注意力大模型中获得相对应的语义特征，将获得的语义特征与所述多层级索引库中的数据逐层进行比较并计算相似度，每层相似度最大对应的加工特征的组合形成最相似加工工艺；根据该最相似加工工艺对待加工件进行辅助加工。通过本发明，解决加工工艺智能推理的问题。基于多级语义特征相似度的工件加工工艺预测方法。辅助工艺编制人员能够准确、快速地编制加工工艺，因此提高了生产效率。 由于该方法采用自注意力大模型，通过多头注意力、前馈、层归一化等复杂神经网络单元，捕捉处理技术复杂的全局和局部语义特征，可以实现对处理技术的语义理解，增加对相似技术的判别感知。 由于该方法采用了多层索引库，减少了索引的计算量，从而实现了对相似过程的快速索引。 该方法解决了现有大模型不能在处理技术的文本数据上泛化的问题，实现了对复杂处理技术的语义理解。该方法涉及将构建的正样本对和负样本对输入预设的自注意力大模型，对自注意力大模型进行微调。 将所述正样本对和所述负样本对输入所述自注意力大模型，得到每个样本对应的语义特征，利用所述语义特征构建多级索引库。 将所述待检测文本输入所述自注意力大模型得到对应的语义特征，将得到的语义特征与所述多级索引库中的数据进行逐层比对，计算相似度，其中每层相似度最大对应的处理特征组合形成最相似的处理技术。 基于最相似的加工工艺对所述待加工件进行辅助加工。独立权利要求包括如下内容：(1)基于多级语义特征相似度的工件加工工艺预测系统； 以及(2)计算机可读存储介质，其存储有用于基于多级语义特征相似度预测工件加工工艺的计算机程序。  11
本申请公开了一种确定语句通顺度的方法、确定概率预测模型的方法和装置。可应用于自然语言处理领域和深度学习领域。具体实现方案为：获取待处理语句；对待处理语句进行分字处理，得到第一文字序列；对待处理语句进行分词处理，得到第一词语序列；采用预训练的概率预测模型，确定第一文字序列中目标文字在待处理语句中出现的第一概率，以及确定第一词语序列中目标词语在待处理语句中出现的第二概率；以及根据第一概率和第二概率，确定待处理语句的通顺度。用于确定自然语言处理领域和深度学习领域中的语言句子的平滑度的方法。该方法能够以有效的方式实现句子平滑度确定处理。该方法包括：获取待处理语句，对所述待处理语句进行词语处理，得到字符序列。 对所述待处理语句进行分词处理，得到词序列。 利用预先训练的概率预测模型确定所述词语序列中的目标词语在所述待处理语句中出现的概率。 确定所述词语序列中的目标词语在所述待处理语句中出现的另一概率。 根据所述概率确定所述待处理语句的通过程度。以下包括独立权利要求：用于确定概率预测模型的方法； 用于确定语音的上下文的设备； 用于确定概率预测模型的装置； 一种电子设备包括通信地耦合到处理器的存储器； 以及非暂时性计算机可读存储介质，用于存储用于确定语言句子的流畅性的计算机指令和概率预测模型。  11
本发明公开了一种基于联合空间域的多尺度U‑Net医学图像分割方法，包括获取原始医学图像数据；利用极坐标中心点预测网络获得原始医学图像的中心点坐标；根据医学图像的中心点坐标，将原始医学图像转换为极坐标医学图像；构建基于联合空间域的多尺度U‑Net网络模型，利用极坐标医学图像进行模型训练；利用训练后的基于联合空间域的多尺度U‑Net网络模型生成医学图像分割结果。本发明采用多层空洞卷积编码模块实现多尺度内容融合，并利用中心点和极坐标实现了注意力机制和旋转不变性，提高了分割精度。实现用于诊断器官、皮肤病变、息肉和癌症的多尺度U-Net医学图像分割的方法。该方法使得能够利用多层空腔卷积编码模块实现多尺度内容融合，利用中心点和极坐标实现注意力机制和旋转不变性，因此提高了分割精度。该方法涉及获得原始医学图像数据。 发送极坐标中心点预测网络，得到原始医学图像的中心点坐标。 根据所述医学图像的中心点坐标将所述原始医学图像转换为极坐标医学图像。 基于联合空间域构建多尺度U-Net网络模型。 采用极坐标医学图像进行建模训练。 所述多尺度U-Net网络模型在训练后基于组合空间域使用，生成医学图像分割结果。   6
本申请公开了一种掼蛋数据处理方法，包括：从掼蛋游戏服务器接收状态信息；根据所述状态信息和历史状态信息进行特征提取处理，得到状态特征矩阵数据；采用BERT决策模型对所述状态特征矩阵数据进行处理，得到出牌动作数据；其中，BERT决策模型为根据掼蛋游戏数据训练集进行训练得到的模型；发送所述出牌动作数据。通过训练好的BERT决策模型对接收到的状态信息和历史状态信息进行处理，得到出牌动作数据，而不是采用专家规则进行决策，提高了对掼蛋数据进行处理的效果，提高了拟人化程度。本申请还公开了一种掼蛋数据处理装置、服务器以及计算机可读存储介质，具有以上有益效果。一种用于游戏技术领域的鸡蛋数据处理方法。 可应用于数据处理技术领域，尤其涉及一种数据处理关丹。利用训练好的BertDecision模型，提高了鸡蛋数据处理的效果，提高了人的致病程度。该方法包括从观丹游戏接收(S101)状态信息。 根据状态信息和历史状态信息执行特征提取处理(S102)，以获得状态特征矩阵数据。 利用BERT判定模型(S103)对状态特征矩阵数据进行处理，得到演奏动作数据。 BERT具有卷积层，多头关注块和全连接层。 发送播放动作数据(S104)。 获得状态特征矩阵数据。本发明还涉及一种蛋数据处理装置； (2)服务器； 和(3)存储用于处理蛋数据的程序的计算机可读存储介质。  12
本申请提出一种基于对比学习的中文句子精简方法和系统，该方法包括：基于无监督学习方式挖掘多个语义相似的复杂句‑简单句句对；计算每个句对的监督信号；将监督信号以字符串的形式添加至句对中复杂句的起始位置，生成有监督信号的复杂句‑简单句句对的数据集，并将数据集划分为训练集、验证集和测试集；对预设的基于编码器‑解码器的多语种预训练模型进行模型剪枝，获得中文单语种预训练模型；引入对比学习损失对中文单语种预训练模型进行微调，联合训练出中文句子简化模型；将测试集中的复杂句输入简化模型生成预测的精简句子，评测中文句子简化模型的效果。该方法可根据实际需求控制生成的简化句子，提高生成的简化句子的忠实度。一种汉语句子简化方法，用于儿童，听力障碍者，第二语言习惯和读写能力低下的自然语言处理技术领域。本发明公开了一种基于无监督学习模式挖掘语义相似的多个复杂句-简单句对的方法， 以及计算每个句子对的监视信号，从而能够提高所生成的简化句子的可信度，并且还能够将句子任务简化为条件生成任务的末尾。本发明涉及一种基于无监督学习模式挖掘语义相似的多个复杂句-简单句对的方法。 计算每个复杂句子-简单句子对的监视信号。 监视信号以字符串的形式被添加到相应语句对中的复杂语句的起始位置。 生成监视信号的复杂语句的数据集和简单语句对。 数据集按照预定比例划分为训练集，验证集和测试集。 对预置的基于编解码器的多语言预训练模型进行模型剪枝处理，得到汉语单语言预训练模型。独立的权利要求书包括： (1)一种基于对比学习的汉语句子简化系统； (2)非暂态计算机可读存储介质。  11
本发明公开了一种基于CASSA‑LSTM算法的短时交通流预测方法，包括以下步骤：S1：选取历史车流量数据作为数据集，并对数据集划分训练集和测试集；S2：数据预处理：提取表中的时间数据，若统计后的数据出现间断的现象，就用均值法进行补值，然后对数据集进行归一化压缩；S3：使用混沌映射产生的混沌序列用于更新种群领导者的位置，并在追随者公式中加入了非线性递减自适应惯性权重方法提高精度得到SSA的优化算法CASSA；S4 : 将LSTM神经网络模型的参数作为CASSA算法的优化对象，以模型在测试集上的均方误差值作为适应度值，根据均方误差值，CASSA利用位置更新公式得到最优的参数；S5：得到CASSA‑LSTM神经网络的最优模型，根据最优模型对车流量进行预测。本发明能够提高短时交通流预测精度。基于CASSA-LSTM算法的短时交通流量预测方法本发明能够提高短时交通流的预测精度。 本发明能够有效解决人工反复调整参数的复杂现象，为后续的交通流预测研究提供新的思路。该方法包括选择历史交通数据作为数据集。 数据集分为训练集和测试集。 在表中提取时间数据。 将测试集上模型的均方误差值作为适应度值。 根据均方值，利用Cassa-LSTM神经网络的位置更新公式得到最优参数。 得到木薯的最优模型。 基于最优模型预测车辆流量。 前四天的交通数据作为训练集。 将第五天的车流量数据作为测试集。 13
本发明公开了一种基于大语言模型的去中心化网络DDoS攻击识别方法。本方法为：1)采集网络流量数据，包括无标签的网络流量和去中心化网络DDoS攻击流量；2)将所采集的网络流量转化为词向量序列；3)利用无标签的网络流量转化所得词向量序列对大语言模型进行预训练；4)将去中心化网络DDoS攻击流量转化所得词向量序列输入到预训练后的大语言模型中，学习去中心化网络DDoS攻击流量的特征；5)将特征输入微调模型执行预测任务，将所得预测结果与对应的标注结果进行对比，然后根据对比结果优化所述微调模型的参数；6)对于一待识别的去中心化网络流量，将其转化为词向量序列后输入优化后的所述微调模型，识别是否为攻击流量。基于大语言模型的去中心化网络分布式拒绝服务(DDoS)攻击识别方法。去中心化网络DDoS攻击流转换被执行以获得输入到预训练的大型语言模型的词向量序列，并且因此使得能够以高效的方式识别去中心化网络攻击流。该方法涉及将去中心化网络DDoS攻击流量转换得到的词向量序列输入大型语言模型，学习去中心化网络DDoS攻击流量的特征。 将去中心化网络DDoS攻击流量的特征输入到基于双向长短期记忆(BiLSTM)的微调模型中，执行预测任务，并将得到的预测结果与对应的标注结果进行对比。 根据比较结果对微调模型的参数进行优化。 输入所述优化微调模型，对一个去中心化的待识别网络流量，将所述优化微调模型转换为词向量序列后，识别是否为去中心化网络DDoS攻击流量。独立权利要求包括：(1)服务器； 以及(2)存储用于去中心化网络DDoS攻击识别的程序的计算机可读存储介质。  11
本发明公开了一种自动生成法律文本标记事件的方法，其包括输入初始的法律文本数据进行预处理，识别事件的触发词、事件的参数、事件类型；根据识别的事件参数与事件类型，使用GPT模型获取新的事件参数；根据识别的触发词与事件类型，通过BERT模型生成新的触发词；根据新的触发词与新的事件参数，生成新的法律文本标记事件；对新的法律文本标记事件进行评价；从评价完成的法律文本标记事件中选出评价符合标准的法律文本标记事件。通过替换参数和触发词的方法来生成新的标记事件，仅需要较少的初始法律文本数据即可自动生成大量的事件，避免了由于事件量不足造成的模型精确度不高的情况。自动生成合法文本标记事件的方法。该方法使得替换参数和触发词过程能够生成新的标记事件，需要较少的初始合法文本数据即可自动生成大量事件，避免了由于事件量不足导致的模型精度不高的情况。该方法包括输入初始合法文本数据预处理。 识别事件触发词。 通过使用GPT模型获得事件参数。 采用BERT模型生成触发词。 根据所述触发词和所述事件参数生成合法文本标记事件。 对所述合法文本标记事件进行评估。 从评估的合法文本标记事件中按照标准选择合法文本标记事件。 通过使用所述GPT模型来识别所述事件触发词。  12
本发明提供了一种基于深度学习的离散时间序列事件挖掘方法及系统，涉及时间序列分析技术领域，包括以下步骤：提前建立信号向量表征嵌入表，实时信号处理过程中，选择当前信号集S1以及下文信号集S2；通过BiLSTM‑Bert模型对S1和S2进行表征并输入BiLSTM‑Transformer模型得到嵌入向量H1与H2；通过事件发现模块对H1进行类别表征得到事件类别序列C1，通过事件截断预测模块对H1和H2进行事件相关性分析，判断H1中所对应的事件是否全部完成，若H1和H2具有高置信度的相同事件，进一步更新S2进行检测，直至H1和H2不存在高置信度的相同事件；根据S1和S2的窗口对完整事件进行截断，输出信号对应的事件结果。本发明的方法将具有相关性的事件信号进行整合得到长序列的时间序列事件。应用于工业生产、金融市场、医疗、交通管理、环境监测领域的基于深度学习的离散时序事件挖掘方法。该方法对事件信号进行具有相关性的积分，得到长序列时间序列事件。 生产企业可以更好的规划和维护，提高生产效率。该方法涉及通过预先训练的BiLSTM-Bert模型，将历史信号转化为信号表征向量。 将转换后的信号特征化向量和对应的监测事件嵌入到查找表中。 选取滑动时间窗长度为W1的当前信号集合S1和实时等待滑动时间窗长度为W2的下行信号集合S2。 通过第一特征化向量V1查询信号特征化嵌入查找表。 将第一特征向量V1和第二特征向量V2输入到BiLSTM-transducer模型中。 通过事件发现模块对所述第一嵌入向量H1进行信号到事件的类别表征。 输出当前信号集合S1挖掘的事件结果和与事件对应的信号。 当前信号集合的窗口和后面的信号集合的窗口是滑动。包括基于深度学习的离散时间序列事件挖掘系统。  12
本发明属于移动边缘计算和任务卸载领域，公开了一种考虑用户竞争和负载的大模型辅助边缘任务卸载方法，具体步骤包括：使用集成大模型辅助处理数据信息；根据用户与边缘服务器的信息构建任务卸载模型；基于该模型提出最小化用户能耗的优化目标；对用户进行任务优先级排序；通过引入分布式思想以及负载均衡创造性地设计出了一种分布式任务计算卸载(DTCO)算法用以求解任务卸载问题；最后根据卸载策略处理所有任务并将结果返回用户。本发明可以有效改善用户之间的竞争并使得边缘服务器资源分配更加合理，从而降低系统的总能耗。基于用户完成和负载的移动边缘计算和任务卸载领域的大型模型辅助边缘任务卸载方法。该方法能够有效改善用户之间的竞争，使边缘服务器的资源分配合理，从而降低系统的总能耗。 该方法能够基于模型提供最小化用户能耗的优化目标，对用户的任务优先级进行排序，并通过引入分布式思想和负载均衡，创造性地设计了解决任务卸载问题的DTCO算法，根据卸载策略处理任务并将结果返回给用户。该方法涉及使用集成的大模型辅助处理数据信息。 根据任务、用户和边缘服务器的信息构建任务卸载模型，所述任务卸载模型包括场景模型、通信模型和计算模型。 根据所述任务执行时延和所述计算资源的约束条件提供优化目标。 对用户进行任务优先级排序。 分布式任务计算卸载(DTCO)算法用于求解目标函数。 向用户返回任务卸载策略，用户根据卸载策略将任务分发给用户本地、边缘服务器或协同用户进行处理。 在对计算任务进行处理后将计算结果返回给用户。  11
本发明涉及一种文本关系抽取方法、装置、设备和和计算机存储介质。本发明所述的文本关系抽取方法包括获取文本句包；利用Bert预训练模型对文本句包进行负训练，将文本句包分为干净句包和噪声句包，并对噪声句包进行重标签，得到优化的文本句包；利用BERT预训练模型对优化的文本句包进行正训练，得到文本句包的分类结果。本发明所述的文本关系抽取方法通过Bert预训练模型对文本句包进行负训练，可以识别文本句包的噪声句包，进而对噪声句包进行重标签，显著降低了文本句包的噪声，有助于提高文本关系抽取效果。提取文本关系进行降噪处理的方法。该方法通过Bert预训练模型对文本句包进行负训练，以识别出该文本句包的噪声句包，对该文本句包进行重新标记，降低了噪声句包的噪声，从而提高了文本关系提取的效果，避免了特征工程带来的错误传播风险。该方法包括获得文本句子包。 利用Bert预训练模型对文本句包进行负训练。 将所述文本句包划分为干净句包和噪声句包。 对所述噪声语句包进行重新标注，得到优化文本语句包。 利用所述预训练模型对所述优化文本消息包进行正向训练，得到所述文本语句包的分类结果。 将句子序列输入嵌入层，得到句子向量。 将所述句子向量输入特征提取层，得到句子包表示。 得到所述文本句包的概率分布。独立权利要求包括：(1)文本关系抽取装置； (2)—种计算机可读存储介质，包括用于提取文本关系以进行降噪处理的指令集。  12
本发明提出了一种基于生成式AI的恶意代码分析方法及系统，该方法包括以下步骤：收集恶意代码数据并对恶意代码数据进行预处理，获得恶意代码样本，恶意代码样本包括二进制文件和源代码；采用静态分析法对二进制文件进行特征提取，获得第一特征向量，采用TF‑IDF对源代码进行特征提取，获得第二特征向量；构建生成式AI模型，利用第一特征向量和第二特征向量训练生成式AI模型，其中生成式AI模型包括嵌入层、两个LSTM层、输入重复层和全连接层；评估训练完成的生成式AI模型，以及将待测恶意代码输入至生成式AI模型进行分析，最终获得预测结果。本发明具有高效性、准确性、可学习性、可扩展性等优点，能够助力企业的信息安全建设。恶意代码的分析方法。该方法具有高效性、准确性、可学习性、可扩展性并有助于企业的信息安全建设。该方法包括采集恶意代码数据，并对恶意代码数据进行预处理，得到恶意代码样本。 所述恶意代码样本设置有二进制文件和源代码。 通过静态分析方法对所述二进制文件进行特征提取，得到第一特征向量。 构建生成的人工智能(AI)模型。 利用所述第一特征向量和所述第二特征向量对所述生成的AI模型进行训练。 训练后的AI模型具有一个嵌入层、两个长短期记忆(LSTM)层、一个输入重复层和一个全连接层。 得到预测结果。包括以下独立权利要求：(1)基于生成的AI的恶意代码分析系统； (2)终端设备； 以及(3)存储用于分析恶意代码的指令集的计算机可读存储介质。  12
本发明公开了一种基于自适应超越指数的科学论文影响力评价方法及系统。本发明设置了论文主题确定模块、实时检索模块、自适应超越指数计算模块与可视化输出模块四个模块，其中论文主题确定模块依据大语言模型对给定论文题目及摘要进行分析，得到一个或多个论文主题。实时检索模块根据所获得的论文主题从可公开获取的数据库中实时获取论文的相关数据。自适应超越指数计算模块根据返回的相关数据计算出指定论文的自适应超越指数。可视化输出模块则是依据先前获取、计算得出的论文相关数据，利用Python语言实时渲染出一份图文并茂、界面整洁的PDF文件。在LiteContribution计量领域中使用计算机设备(权利要求书)基于自适应经肠指数评估科学论文影响力的方法。该方法使得实时搜索模块能够根据获取的论文主题，实时地从公开获取的数据库中获取论文的相关数据，并基于返回的相关数据计算出指定论文的自适应超越指标，从而使得可视化输出模块用于根据之前获取和计算的论文相关数据，通过Python(计算机编程语言)语言渲染出图文良好、界面整洁的PDF文件，从而有效地评价科学论文影响力。该方法包括确定论文主题。 采用大型语言模型，根据所述指定论文的主题、摘要和预先设置的提示，得到所述论文的主题。 根据所述论文主题得到实时搜索结果。 实时搜索论文主题能够公开获取的论文数据库中与给定论文属于同一主题的论文集。 获取所述论文集中最相关的论文以及每个论文对应的引用次数。 根据搜索结果计算自适应超越索引。 根据选择的论文和每个论文对应的参考次数计算论文的离散参考频率分布，并将其视为概率质量函数。 可视化输出模块，用于通过Python(高级编程语言)语言实时渲染PDF文件。独立权利要求还包括用于：使用计算机设备的基于自适应跨肠指数的科学论文影响力评估系统； 以及计算机可读存储介质，所述计算机可读存储介质包括用于使用计算机设备基于自适应跨肠指数评估科学论文影响的指令集。  11
本发明涉及一种基于联合自注意力机制的单目深度估计方法，其包括：基于联合注意力模块的编码器、基于U‑net的解码器和一个基于特征金字塔的连接模块组成；按所需深度图的分辨率设置各卷积层参数；搭建估计网络模型；使用训练数据集训练网络模型，提取解码器的输出；计算解码器输出和其对应深度图，结合损失函数对模型参数进行修改；使用训练完成后的最终模型对输入图像进行深度预测。本发明在编码器模块中使用了空间自注意力机制、通道自注意力机制并引入过滤机制从而利用局部特征映射并结合全局上下信息来提取深度信息，解决了在卷积神经网络中无法有效集成局部信息和全局信息的问题，进一步提高深度估计的精度。基于联合自注意力机制的单目深度估计方法。该方法利用编码器模块中的空间自注意力机制、通道自注意力机制和滤波机制，利用局部特征映射并结合全局信息提取深度信息。 该方法使得能够通过卷积神经网络有效地整合局部信息和全局信息，并且提高深度估计的精度。该方法包括获得多个原始训练样本。 对所述原始训练样本进行数据增强操作。 生成训练数据集，所述原始训练样本包括原始场景图和原始深度图。 根据作为骨干网络的Densert的组合注意力模块构建编码器。 具有U-net主干的解码器被构造为网络。 结合损失函数进行训练。 确定最终模型，以对完成训练后的输入图像进行深度预测。   6
本发明公开了一种基于大模型的问答方法、装置、电子设备及存储介质；该方法包括：获取待解答问题；将待解答问题输入到预先训练的联合问答模型中，得到联合问答模型的输出结果；根据联合问答模型的输出结果确定待解答问题所对应的答案，解决了问答过程中答案的准确性较低，预测过程不可控的问题，基于思维链对第一问答模型和第二问答模型进行联合训练，实现了答案预测过程和结果的逻辑性和可控性，预测答案过程中第二问答模型的输入数据根据第一问答模型的输出数据和待解答问题确定，使第一问答模型和第二问答模型建立关联关系从而保持高一致性，避免模型无法规范性对齐导致的预测结果不准确的情况发生，提高模型预测准确性。基于大模型的问答方法。该方法能够避免由于模型的能力不足而导致的预测结果不准确，提高了模型预测的准确性。该问答方法涉及到获取待回答问题。 将所述待回答问题输入预先训练的联合问答模型，得到所述联合问答模型的输出结果。 所述联合问答模型包括第一问答模型和第二问答模型，所述第一问答模型和所述第二问答模型为大型模型。 所述第一问答模型和所述第二问答模型基于思想链联合训练，根据所述第一问答模型的输出数据和所述待回答问题确定所述第二问答模型的输入数据。 根据所述联合问答模型的输出结果确定所述待回答问题对应的答案。独立权利要求包括用于：(1)基于大模型的问答器； (2)一种计算机可读存储介质，所述计算机可读存储介质存储有用于实现所述基于大模型的问答方法的指令。  11
本发明公开了一种医学多模态模型的预训练方法及装置，包括：获取初始医学图文样本数据，初始医学图文样本数据包括多组医学图文对，每组医学图文对包括医学图像和文本信息；基于初始医学图文样本数据进行多阶段任务训练，得到初始预训练模型；基于初始预训练模型和初始医学图文样本数据中的已人工标注的医学图文对，对初始医学图文样本数据进行优化，得到目标医学图文样本数据；利用目标医学图文样本数据对初始预训练模型的模型参数进行调整，得到目标医学多模态预训练模型。本发明通过分阶段进行训练，充分捕捉了医学图像与多粒度文本的关联信息，并且能够降低样本数据中噪声的影响，从而提升了模型学习准确性以及效率。用于在临床场景中预训练医学多模式模型的方法。降低样本数据中噪声的影响从而提高模型的学习精度和效率。 该方法充分捕获医学图像和多粒度文本的关联信息。该方法涉及获得包括多组医学图像-文本对的初始医学图像-文本样本数据，其中每组医学图像-文本对包括医学图像和文本信息。 基于所述初始医学图文样本数据进行多阶段任务训练。 获取初始预训练模型，所述多阶段任务包括基于语义标签单元和语句单元的预训练任务。 基于所述初始预训练模型和所述医学图文对中的初始医学图文样本数据，对所述初始医学图文样本数据进行优化，得到目标医学图文样本数据。 利用所述目标医学图文样本数据调整所述初始预训练模型的模型参数，得到目标医学多模式预训练模型。还包括用于在临床场景中预训练医学多模式模型的设备的独立权利要求。  11
本申请公开了一种大语言模型的评估方法及装置、存储介质、计算机设备，该方法包括：基于待评估的目标大语言模型所应用的目标应用领域，获取所述目标大语言模型对应的测试题库，其中，所述测试题库中包含属于所述目标应用领域的客观题，所述客观题的题干和答案通过分析所述目标应用领域的语料样本而获得；利用所述测试题库对所述目标大语言模型进行测试，获得所述目标大语言模型对被测客观题的输出结果；基于所述被测客观题对应的输出结果，评估所述目标大语言模型。本申请针对特定应用领域构建客观题，以便题目更能适用于该应用领域的模型测试，从而提升了模型评估的准确性和可靠性，进一步，有助于进行模型有效性验证以及提升模型的可靠性。通过使用计算机装置评估大型语言模型的方法(权利要求书)。提高了模型评价的准确性和可靠性。 进行模型有效性验证，提高模型的可靠性。该方法包括基于待评估的目标大语言模型所应用的目标应用领域，获取目标大语言模型对应的试题库。 所述试题数据库中设置有属于所述目标应用领域的客观问题。 对所述目标应用领域的语言学数据样本进行分析，得到所述客观问题的问题干和答案。 利用所述试题库对所述目标大型语言模型进行测试。 获取与所述测试目标问题对应的输出结果。 基于与所述被测试的目标问题对应的输出结果对所述大规模语言模型进行评估。独立权利要求还包括用于：用于评估大型语言模型的装置； 以及包括用于评估大型语言模型的指令集的存储介质。  11
本发明公开了一种基于深度学习的模型融合三元组表示学习系统及方法，使用预训练的BERT语言模型对单词进行嵌入表示，获取了单词更加语境化的表示；同时利用BERT结构的掩蔽语言建模任务将其三元组作为序列输入；本发明对于同实体多种语义的问题，利用投影或者转换矩阵使得映射实体关系在不同领域上能够有不同的表示，但是本发明中改造后的BERT可以将三元组或其描述信息作为文本输入并一同训练，而BERT本身的机制会对实体关系在不同句子中会有不同的词向量，有效解决了实体关系不同语义的问题，因此选择TransE不会受限于其模型本身，反而其模型的足够简单才真正反映了三元组之间的对应关系。同时降低了模型的复杂度。用作基于深度学习的模型融合三元组表示学习系统。所述系统：利用投影或变换矩阵使映射实体关系在不同领域具有不同的表现形式； 将三元组或其描述信息作为文本输入并一起训练； 解决了实体关系语义不同的问题，因此TransE的选择不会受到其模型本身的限制； 足够简单，能够真实反映三元组之间的对应关系； 并且降低了模型的复杂度。基于深度学习的模型融合三元组表示学习系统包括BERT三元组输入模块对三元组进行序列化并通过掩蔽语言建模完成三元组的嵌入以及使用BERT自带的SpecialTokens机制输入三元组的描述性信息。 TransE三元组输入模块，用于通过TransE的训练机制训练三元组，学习三元组中的结构信息，利用距离公式计算三元组之间的相似度来学习实体关系之间的依赖关系，从而生成三元组的词向量表示。 联合表示学习模块，用于结合BERT三元组输入模块和TransE三元组输入模块，结合两者进行联合训练，最终得到三元组词向量表示的最佳优化。还包括基于深度学习的模型融合三元组表示学习的独立权利要求。  12
本发明公开了一种基于卷积神经网络的绘画作品作者识别方法，首先利用ImageNet数据集训练DenseNet网络；然后使用多位画家的作品集对Multi‑layer Feature Fusion DenseNet(MFDN)进行微调；最后使用学习到的模型对新的绘画作品进行端对端的测试进而判断其作者。本发明能够实现绘画作品作者的自动识别，具有较高的准确率。该方法可用于基于卷积神经网络的图像作者识别。本发明实现了绘画作品作者的自动识别，准确率高。基于卷积神经网络的绘画作者识别方法，包括：采集多个绘画者的多幅绘画的数字化图像，并以绘画者为类别标签构建数据集，划分训练集和测试集； 使用所述图像网络数据集对所述密集网络进行预处理和训练，以获得预训练的模型； 加入深浅特征融合部件，形成多层特征融合密集连接网络(MFDN)； 使用预处理的训练集来微调MFDN网络，以获得识别绘画作者的网络模型； 首先识别新绘画作品的作者，将新绘画作品的画面作为训练集进行预处理； 将预处理后的图像输入到得到的网络模型中，得到作为作品作者的输出。   4
本发明公开了一种煤尘颗粒特征提取方法，包括步骤：一、将煤尘颗粒图像输入训练好的卷积神经网络中；所述卷积神经网络为对U‑Net网络进行改进得到的Ghost‑SE‑Unet网络，所述Ghost‑SE‑Unet网络包括用于提取图像中煤尘颗粒的特征信息的特征提取主干Feature Backbone和用于完成煤尘颗粒特征图的尺寸还原以及生成与煤尘颗粒对应的掩膜的特征上采样Feature Upsample；二、所述卷积神经网络对煤尘颗粒图像进行特征提取，得到煤尘颗粒分割图，将煤尘颗粒从背景中识别出来。本发明能够提高对煤尘颗粒的分割精度，并精确获取颗粒特征更多细节信息。煤尘颗粒特征提取方法。U-Ne网络模型消除了图像分割的问题。 分割效果显著，图像特征信息提取良好。 该方法对U‑Net网络进行改进，得到Ghost‑SE‑Unet网络，可以提高煤尘颗粒分割精度，减少网络参数数量，提高网络训练速度。 Ghost模块、SE模块、BN层可以减少网络参数量，提高煤尘颗粒分割精度，加快网络收敛速度。 二元交叉熵和铰链协调损失函数可以缓解粒子特征类别不平衡的问题。 Ghost-SE-Unet网络对不同形状、粒径的颗粒类别具有较好的学习效果，能够有效增强煤尘特征的学习能力，大大减少模型参数，准确获取颗粒特征的更详细信息。 Ghost-SE-Unet对煤尘颗粒分割任务的准确率、召回率和F1评分分别达到0.9732、0.9434和0.9581。 该方法能够提取煤尘样本颗粒的有效特征，降低图像噪声干扰，均衡颗粒灰度，提高边缘清晰度。 显著减少了煤尘颗粒图像分割过程中产生的溢出和模糊痕迹，提高了网络对不同大小颗粒的学习能力。 相对二值交叉熵和铰链损失函数可以有效消除网络前向传播中的样本类别不平衡和梯度消失问题，并使网络能够得到置信度更高的预测结果，提高网络对煤尘图像数据集的运行效率和分割性能。该方法包括将煤尘颗粒图像输入到训练好的卷积神经网络中，所述卷积神经网络通过对U‑Net网络进行改进得到，所述网络包括用于提取图像中煤尘颗粒特征信息的特征提取主干，以及用于完成煤尘颗粒特征图尺寸缩小的特征上样本。 生成所述煤尘颗粒对应的掩膜。 对煤尘颗粒图像进行特征提取，得到煤尘颗粒分割图，从背景中识别出煤尘颗粒。   4
本发明实施例公开了一种信息交互方法、装置、电子设备及介质。其中，该方法包括：获取通过目标输入界面接收的待查询语音信息，将待查询语音信息转化为待查询文字信息；通过服务端预先部署的大语言模型对待查询文字信息进行语义解析得到目标响应信息，以使服务端根据目标响应信息执行目标操作；接收服务端发送的目标响应指令关联的标识信息，根据目标响应指令关联的标识信息从预设指令库中确定目标反馈指令；执行目标反馈指令，向目标输入界面返回目标反馈指令的执行结果。本技术方案，能够基于大语言模型对语音输入信息进行语义解析，并根据语义解析结果进行准确有效应答，使信息交互更加智能化，能够更好地满足信息交互需求。信息交互方法，用于交互一体机。该信息交互方法基于大语言模型对语音输入信息进行语义分析，并根据语义分析结果进行准确有效的应答，使得信息交互更加智能，更好地满足信息交互需求。该方法包括获取(S110)通过目标输入接口接收的待查询语音信息。 通过服务器端预先部署的大型语言模型对所述待查询文本信息进行语义解析(S120)，得到目标响应信息，以使所述服务器端根据所述目标响应信息执行目标操作。 接收所述服务器发送的与所述目标响应指令相关联的标识信息(S130)。 根据所述目标响应指令关联的标识信息从预设指令库中确定目标反馈指令，所述目标响应指令与所述目标反馈指令关联的标识信息相同。 执行所述目标反馈指令(S140)。 将所述目标反馈指令的执行结果返回至所述目标输入界面。独立权利要求包括以下内容：信息交互装置； 电子装置； 以及存储用于信息交互的程序的计算机可读存储介质。 8
本申请提供一种针对大语言模型的评估方法、模型和计算机存储介质，评估方法包括：根据预先存储的数据元信息和所述大语言模型的待测项目，筛选采集的多个文本数据集以组成测评集合，每个文本数据集包括多条测评数据；将每一条测评数据多次输入被测大语言模型，并对应获得多次输出结果；基于每一条测评数据对应的标准结果，对每一条测评数据对应的多次输出结果进行评分，以获得每一条测评数据对应的评分结果，所述评分结果包括正确率得分和一致性得分；综合所述多条测评数据各自的评分结果，计算并获得针对所述大语言模型的评估结果。如此，测评集合既能满足待测项目的需求，又数据量较小，同时借助自动评估可以提高测评效率。评估大型语言模型的方法。评价集满足待测项目的要求，且数据量较小，同时通过自动评价可以提高评价效率。该方法包括：根据预先存储的元数据和大型语言模型的待测项，对采集到的多个文本数据集进行筛选，形成评价集，每个文本数据集在评价数据(101)中。 将元数据确定为文本数据集的数据属性(102)。 所述评价集的目标能力维度用于评价所述大型语言模型(103)的待测试项。 判断元素数据是否为文本数据集的语言类型、年龄、数据大小和引用次数。 根据所述评价数据的评价结果对所述大型语言模型计算得到评价结果(104)。独立权利要求包括用于：用于评估大型语言模型的模型； 以及计算机可读存储介质具有用于评估大型语言模型的指令集  11
本发明涉及一种基于自检式检索增强生成及指令扩张的知识图谱自动构建方法，属于自然语言处理技术领域。将原始的多源异构数据进行数据整合，得到有效提示数据；再以所述提示数据、任务需求作为自检式检索增强生成框架的输入，训练大语言模型(LLMs)使其按需自适应检索相关段落，生成相关文本数据并完成事实验证；然后经由指令扩张框架构造大语言模型输入提示；最后以所述文本数据及输入提示作为大语言模型自动代理框架的输入层，经由大语言模型多轮反馈，得到实体‑关系‑实体三元组，完成知识图谱的构建。本发明基于自检式检索增强生成和指令扩张技术，以大语言模型作为核心引擎，实现了低资源背景下，高可靠性数据挖掘的知识图谱自动构建。基于自检检索增强生成和指令扩展的自动化知识图谱构建方法。该方法基于自检检索增强生成和指令扩展技术，以大型语言模型为核心引擎，在低资源背景下实现高可靠性数据挖掘的知识图谱自动构建。该方法涉及对原始的多源异构数据进行整合，得到有效的提示数据。 将有效提示数据和任务需求作为自检检索增强生成框架的输入，训练大型语言模型，使其按需自适应检索相关段落，生成相关文本数据，完成事实验证。 通过训练好的大型语言模型中的指令扩展框架构建大型语言模型输入提示。 将所述文本数据和所述输入提示作为所述大型语言模型反馈代理框架的输入层。 经过大型语言模型的多轮反馈，得到实体-关系-实体三元组，完成知识图谱的构建。  11
本发明公开了一种基于自学习的场景文本匹配方法及系统，选择预训练词向量数据集，将场景语料数据转化为预训练词向量数据集对应的场景词向量；自定义设置场景语料样本数量阈值，当场景语料数据小于场景语料样本数量阈值时，场景语料数据作为少量样本，将其输入到无监督学习模型中转化为对应的第一场景文本向量；在场景语料数据积累超过设置的场景语料样本数量阈值后，将其输入有监督学习模型转化为对应的第二场景文本向量；计算第一场景文本向量、第二场景文本向量与待匹配文本的文本相似度并排序，修正文本匹配结果，得到文本匹配对；依据文本匹配对优化无监督学习模型和有监督学习模型，修正文本相似度的计算方式。基于电子设备自学习的场景文本匹配方法(索取)。该方法能够根据文本匹配对无监督学习模型和监督学习模型进行优化，修正文本相似度的计算方式，从而保证了提供给具有自学习能力的用户的文本匹配结果的准确性的提高。该方法涉及选择预训练词向量数据集。 将一场景语言素材数据转换为与所述预训练词向量数据集对应的场景词向量。 将一点样本输入到无监督学习模型中。 将所述场景词向量转换为对应的第一场景文本向量。 将所述场景词向量转换为对应的第二场景文本向量。 计算所述第一场景文本向量、所述第二场景文本向量和待匹配文本的文本相似度并排序。 对文本匹配结果进行校正。 得到文本匹配对。 根据所述文本匹配对优化非监督学习模型和监督学习模型。 对文本相似度的计算方式进行修正。独立权利要求还包括：基于自学习的场景文本匹配系统； 以及包括用于基于自学习来匹配场景文本的指令集的计算机可读存储介质。  12
本公开提供了一种障碍物识别模型训练方法及装置、电子设备、存储介质，涉及人工智能技术领域。该障碍物识别模型训练方法包括：获取新增样本道路图像，以及预训练的初始障碍物识别模型；初始障碍物识别模型包括用于检测第一类型障碍物的历史检测分支网络；确定新增样本道路图像对应的第二类型障碍物，并在初始障碍物识别模型中构建用于检测识别第二类型障碍物对应的目标检测分支网络；固定历史检测分支网络对应的网络权重信息，并根据新增样本道路图像对初始障碍物识别模型进行训练，得到训练完成的增量障碍物识别模型。本公开实施例的技术方案可以在训练增量障碍物识别模型过程中，避免重建整个障碍物识别模型和降低对旧类别障碍物的识别效率。本发明可用于利用电子设备训练障碍物识别模型。该方法避免了障碍物识别模型的重构； 降低了对旧式障碍物的识别效率。该方法包括：获取新添加的样本道路图像； 预先训练初始障碍识别模型， 向初始障碍物识别模型提供历史检测分支网络，用于检测和识别新添加的样本道路图像中的第一类型的障碍物， 确定新增样本道路图像对应的第二类障碍物，构建目标检测分支网络，对初始障碍物识别模型中的第二类障碍物进行检测识别，得到完成训练的增量式障碍物识别模型。本发明还涉及一种障碍物识别模型训练装置； 增量式障碍物识别模型； 障碍物识别方法； 以及包括用于训练障碍识别模型的一组指令的计算机可读存储介质。 14
本公开涉及人工智能技术领域，提供了一种图像分类模型的训练方法、装置、计算机设备及计算机可读存储介质。该方法在模型训练过程中仅对第一特征提示词向量和分类器的参数进行调整，这样不需要让图像分类模型中的主干网络适应新的训练样本，而通过在训练样本中增加可学习的第一特征提示词向量，让增加预设的第一特征提示词向量的训练样本适应主干网络，由于可学习的第一特征提示词向量能够适应预训练模型的内部参数，能够让预训练模型根据添加的可学习的第一特征提示词向量理解任务，在一定程度上调整训练样本数据的分布，从而适应图像分类模型，实现图像分类模型的预测结果的精度提升，同时实施成本相对较低且计算复杂度低、数据计算量低。人工智能领域的图像分类模型训练方法。该方法能够在模型训练过程中对特征提示词向量和分类器的参数进行调整，以避免图像分类模型中的主网络与训练样本相适应。 该方法能够在一定程度上调整训练样本数据的分布，以适应图像分类模型，从而提高图像分类模型预测结果的精度，降低实现成本和计算复杂度。该方法包括获取训练样本图像和训练样本图像对应的真实类别标签。 根据所述训练样本图像确定图像块序列。 根据所述图像块序列得到调整图像块序列。 将所述调整图像块序列输入图像分类模型，得到所述训练样本图像对应的预测类型标签，所述图像分类模型包括主干网络和分类器。 根据所述预测类型标签和真实类别标签调整所述分类器的特征提示词向量和参数。 确定所述骨干网络的参数，得到训练好的图像分类模型。独立权利要求包括用于：(1)用于训练图像分类模型的装置； (2)一种计算机设备，包括存储器和处理器，所述处理器用于执行用于训练图像分类模型的指令集； 以及(3)用于存储用于训练图像分类模型的指令集的计算机可读存储介质。 14
本发明公开了一种基于知识图谱建立实体统一模型的方法，所述方法包括：构建实体基于描述信息的第一训练数据和基于结构信息的第二训练；采用所述TransH模型分别获得所述头实体、关系以及尾实体的结构表示向量；采用BERT+Bi‑LSTM模型对所述头实体和所述尾实体的描述信息进行编码获得描述表示向量，其中，所述BERT+Bi‑LSTM模型后接CRF层对编码进行命名实体识别；将所述结构表示向量与所述描述表示向量结合进行三元组验证所述BERT+Bi‑LSTM模型训练；将训练完成的所述BERT+Bi‑LSTM模型作为实体统一模型。基于知识图谱的实体统一模型建立方法。该方法使得能够将结构表示向量与描述表示向量组合以执行BERT加Bi-LSTM模型训练的三要素验证。该方法包括基于第一训练数据描述信息和基于结构信息构建实体，其中描述信息包括描述和语言学数据语料。 所述描述语言学数据由知识图谱的结构化数据得到。 所述结构信息是将所述实体的结构信息通过Transh模型在平移模型中进行表示得到的。 改变头部实体向量和尾部实体向量以生成基于描述表示的得分。 基于所述描述信息，将三个评分平均为三重评分函数。 将训练好的BERT加BI-LSTM模型作为实体统一模型。还公开了一种计算机可读存储介质，用于存储基于知识图谱建立实体统一模型的指令集。  12
本发明公开了一种基于Bert和Bi‑LSTM的恶意评论检测方法，属于文本分类技术领域。首先利用Bert模型预训练语言模型来学习评论文本的词向量表示，在恶意评论的检测中需要结合评论文本的上下文来获得精准的语义信息，将Bert应用在恶意评论任务的检测中有效地改善了模型的效果。其次是利用Bi‑LSTM来实现特征的二次提取，捕捉双向的语义依赖关系，进一步丰富语义信息的向量表示。然后引入注意力机制给重点信息赋予更高的权重；最后通过Softmax函数来得到恶意评论的分类结果，完成对恶意评论的检测任务。本方法提升了模型对恶意评论的识别率，为防范社交媒体带来的负面影响提供了参考价值。基于Bert和Bi-LSTM的恶意评论检测方法。该方法提高了恶意模型的识别率，为防范社交媒体带来的负面影响提供了参考价值。 Bert模型预训练语言模型用于学习恶意评论检测中需要结合的评论文本的词向量表达和评论文本的上下文，以获得精确的语义信息。 bi-LSTM实现了特征的二次提取，捕获了双向语义依赖关系，丰富了语义信息的向量表示，并引入注意力机制赋予了关键信息更高的权重。该方法包括收集评论文本数据。 对所述文本数据进行预处理，得到数据集。 通过Bert模型训练数据集得到向量表达式。 构建Bi-LSTM模型。 向量表达输出输入Bi-lSTMA模型，捕获双向语义依赖关系，用于丰富语义信息的向量表达。 引入了注意力机制。 分类结果通过Softmax函数输出。 采用测试集对所述Bert-Bi-LSLM模型的恶意评论检测性能进行评估。  12
本发明提供了一种虚拟电厂资源管控方法、装置、计算机设备及存储介质，涉及虚拟电厂技术领域，包括：获取用电负荷变化率；当用电负荷变化率大于等于预设阈值时，确定虚拟电厂处于第一运行模式，获取用户负荷和影响负荷调度的相关参数；将所述用户负荷和所述影响负荷调度的相关参数输入预训练模型，得到第一资源管控策略；当用电负荷变化率小于预设阈值时，确定虚拟电厂处于第二运行模式，利用所述分布式电源得到负荷特性，并利用所述设备信息集得到设备物理模型；根据预设的时间尺度、所述负荷特性和所述设备物理模型构建资源管控模型，通过所述资源管控模型得到第二资源管控策略。本发明实现了在节约运行成本的同时还保障了用户的用电需求。虚拟电厂资源管控方法。该方法实现了在节约运行成本的同时，还保证了用户的电力需求。该方法涉及获得(210)电力负荷变化率。 作出确定(2211)，以在所述电力负荷变化率大于或等于预设阈值时检查所述虚拟发电厂处于所述第一运行模式。 将所述用户负荷和影响负荷调度的相关参数输入(2212)到所述预训练模型中。 做出确定(2221)以在所述用电负荷变化率小于所述预设阈值时检查所述虚拟发电厂处于所述第二运行模式。 所述分布式电源用于(2222)获得负载特性。 基于所述预设时间尺度、所述负载特性和所述设备物理模型搭建(2223)资源管控模型。 通过资源管控模型得到所述第二资源管控策略。 第二资源管控策略用于基于需求进行资源分配，以降低运营成本。独立权利要求包括如下：虚拟电厂资源管控装置； 计算机设备； 以及存储用于虚拟发电厂资源管控的程序的计算机可读存储介质。 0
本公开提出一种结构化查询语言语句生成方法和装置，涉及人工智能技术领域。本公开的一种SQL语句生成方法，包括：获取用户在对话中的表达信息；基于增加动态词向量BERT模型的双向长短时记忆网络Bi‑LSTM和条件随机场CRT模型，从表达信息中抽取有效信息，有效信息包括时间、实体或指标中的一项或多项；根据有效信息，基于SQL语句的语法生成结构化查询语言SQL语句。通过这样的方法，能够降低对用户使用数据库能力的要求，也提高了有效信息提取的效率和准确度，无需预先生成固定查询句式，提高了SQL语句生成的可扩展性。SQL语句生成方法。本发明可以降低用户使用数据库能力的要求，提高有效信息提取的效率和准确性，而不需要预先生成固定的查询语句，提高SQL语句生成的可扩展性。所述方法包括：获取用户在会话中的表情信息。 根据增加的Bi-LSTM和条件随机场CRT模型，建立了动态字嵌入BERT模型的Bi-LSTM和条件随机场CRT模型。 从表达信息中提取有效信息，其中有效信息包括时间，实体或索引。 根据SQL语句的语法生成结构化查询语言(SQL)语句。 输入模型文本特征提取结果。本发明还涉及一种SQL语句生成装置； 以及存储用于生成SQL语句的一组指令的计算机可读存储介质。  12
本发明公开了一种应用于制造业科学技术文档的命名实体识别模型，其网络结构包括词嵌入层SciBERT，其用于将输入的词转换为固定长度的向量；BiLSTM层，其利用文本序列的上下文信息挖掘隐藏特征，其用于编码文本；注意力层，其用于降低实体内部不相关修饰词的权重，界定实体的边界，避免重要实体抽取的遗漏；CRF层，其作为网络结构的输出层，用于避免文本序列中的实体被错误标注。本发明的命名实体识别模型能从文本中提取信息和生成知识，能解析制造领域中的产品设计文本数据、工程测试文本数据、供应商数据数据、维护记录数据和产品使用数据等各种与制造科学技术相当的文档，能为企业实现各种数据资产互连提供技术基础，是促进企业的数字化转型的关键。应用于科技制造业的命名实体识别方法命名实体识别模型能够从文本中提取和信息化知识，分析制造领域的产品设计文本数据、工程测试文本数据、供应商数据、维修记录数据和产品使用数据等多种等同于制造科学技术的文档，为企业实现各种数据资产互联提供技术基础，是推动企业数字化转型的关键。该方法涉及选取已有的目标文本，形成训练命名实体识别模型的原始语料。 去除原始语料中的标点符号和停用词，进行一次形态还原，形成语料对应的词典。 用维度为100的单层前向LSTM和后向LSTM来实现BiLSTM。 总共进行20次试验，每次试验进行100个历元，每个历元进行500次迭代，批次大小为256。 利用训练好的命名实体识别模型对准备好的测试集进行命名实体标注。 利用训练好的命名实体识别模型查找到所述关键命名实体。 发现出现在给定段落文本中的命名实体的数量。 如果多个实体的数量相等，则优先的段落中的第一被识别实体由第一被识别实体采用。独立权利要求被包括用于命名实体识别以要求制造业。  12
本发明涉及自然语言处理技术领域，特别是指一种自动问答的实现方法和装置，所述方法包括：采用XLnet预训练模型，在训练集的对话文本上获得包含全局语义的每个字的词向量；将所述词向量转化为融合了全局语义和时序信息的融合向量；将所述融合向量映射成二维向量，所述二维向量表示每个字作为答案的开始和结束的概率，并生成对问题的预测答案，将所述预测答案和所述训练集的答案标签对比，计算损失函数；根据所述损失函数，调整学习方向继续训练，直到建立自动问答模型；使用所述自动问答模型，对待回答的问题输出相应的答案。采用本发明，能够自动对用户的问题给出高效准确的答案。利用自然语言处理技术领域的电子设备实现自动问答的方法(权利要求书)。该方法能够提高效率并以准确的方式获得答案。该方法通过XLnet预训练模型获取训练集对话文本上包含全局语义的词的词向量。 将所述词向量转换为融合全局语义和时序信息的融合向量。 将融合向量映射为二维向量。 生成问题的预测答案。 将所述预测答案与所述训练集的答案标签进行比较。 计算损失函数。 根据所述损失函数调整学习方向以继续训练操作。 建立自动问答模型。 利用所述自动问答模型输出与待回答问题对应的答案。独立权利要求：(1)一种利用电子设备实现自然语言处理技术领域的自动问答的装置； 以及(2)计算机可读存储介质。  12
本申请公开了一种模型训练方法、装置、计算机设备及存储介质，涉及人工智能技术领域。该方法包括：获取文本数据集，所述文本数据集中包括多条第一文本数据；针对每条所述第一文本数据中的文本内容，按照多种目标掩蔽比例进行掩蔽处理，得到每条所述第一文本数据对应的多个第一训练文本，作为第一训练样本集；利用所述第一训练样本集，对初始语言模型进行预训练，直至满足第一训练条件，得到预训练模型。如此，针对任一条第一文本数据可以生成长度不同的多个第一训练文本，从而丰富了训练样本集，解决了预训练过程中的语料不足的问题，从而提高模型预训练的效果。用于人工智能领域的初始语言模型的训练方法。该方法能够在文本数据上生成多个不同长度的训练文本，丰富了训练样本集，解决了预训练过程中语言学数据较少的问题，提高了模型的预训练效果。所述方法包括：获取文本数据集，所述文本数据集包括多个文本数据。 根据多个目标掩蔽比例对所述文本数据中的文本内容进行掩蔽，得到所述文本数据对应的训练文本作为训练样本集。 通过所述训练样本集对初始语言模型进行预训练，得到预训练模型，直至满足训练条件。 通过编码模块对所述训练文本进行编码，得到文本编码结果。 通过解码模块对所述文本编码结果进行解码，得到所述masked文本内容的还原文本结果。独立权利要求包括：(1)用于训练初始语言模型的设备； (2)计算机设备包括处理器和存储用于训练初始语言模型的指令集的存储器； (3)一种计算机可读存储介质，其存储用于训练初始语言模型的指令集。  11
一种MPS生成方法，该方法包括：以预定的频率，交替地输出第一MPS电流脉冲(300)达预定的第一时间段(T1‑T2, T3‑T4)并且不输出第一MPS电流脉冲达预定的第一关断时间段(T2‑T3, T4‑T6)；在第一时间段(T1‑T2, T3‑T4)期间，确定由DC‑DC转换器的输入电容器汲取的电流的幅度；并且响应于所确定的输入电容器电流幅度，在预定的第一关断时间段(T4‑T6)期间，在第一端子和第二端子之间输出第二MPS电流脉冲达预定的第二时间段(T4‑T5)。受电设备(PD)接口。MPS脉冲在足够的时间内被启用，以确保电源设备(PSE)在预定时间窗结束之前识别MPS，而与附加噪声事件无关。 维持MPS电路的操作频率，并且不响应于生成附加MPS脉冲而调整MPS脉冲的定时。 电容器电流的幅度大于预定值持续足够的时间以干扰短MPS脉冲，生成第二MPS脉冲，可选地，第二MPS脉冲是长MPS脉冲。PD接口(80)具有第一端子和第二端子。 MPS电路(90)被布置在预定频率处。 控制电路(95)被布置成响应于感测到的电流幅度来确定由直流到直流转换器(100)的输入电容器汲取的电流的幅度。 控制电路被布置为响应于所确定的输入电容器电流幅度，控制MPS电路在预定的第一关断时间段期间输出第二电流脉冲达预定的第二时间段。本发明还涉及一种维持功率特征(MPS)生成方法。 0
本发明公开了一种视频主题检索的方法、系统、设备及存储介质，用以解决现有技术样例视频的相似度计算是在较低级别上进行的问题。方法包括：S1、预训练跨模态视觉语言模型，并对所述跨模态视觉语言模型进行调整；S2、对给定的样例视频集合的场景进行分割，并对分割后的各样例视频片段的主题进行聚类；S3、基于所述调整后的跨模态视觉语言模型以及聚类的样例视频片段进行视频主题检索，并对检索结果进行聚合和排序后输出。系统包括：预训练和调整模块、分割和聚类模块、输出模块。计算机设备包括：存储器、处理器，以及计算机程序。包含计算机可执行指令的存储介质用于执行视频主题检索的方法。用于计算机视觉技术领域中的计算机设备中的视频主题检索的方法(权利要求书)。可以减少由于文本与视频主题之间模式不同而导致的语义渠道问题。 给定文本抽取的语义特征可以在必要时作为辅助。 跨模式视觉语言模型可以通过大量的视觉信息-语言描述信息对数据进行预训练。 可以将待对齐对象底层特征的抽象高层语义特征和视觉描述的描述文本进行对齐。 可以在几个集中的语义信道上训练下游任务。该方法涉及预训练(S110)跨模态视觉语言模型，以及调整跨模态视觉语言模型。 对给定样本视频集合的场景进行分割(S120)，并对分割后的各样本视频片段的主题进行聚类。 基于调整后的跨模态视觉语言模型和聚类后的样本视频片段进行视频主题检索(S130)，并对检索结果进行聚合排序后输出。包括以下独立权利要求：视频主题检索系统； 计算机设备； 以及包含用于实现用于视频主题检索的方法的计算机可执行指令的存储介质。 9
本发明提供一种数据报告生成方法、装置及设备，所述方法包括：获取目标业务信息；根据所述目标业务信息，建立业务申报场景；根据所述业务申报场景，得到目标业务的目标数据；根据所述目标数据，通过训练好的数据报告生成模型，得到目标数据报告。本发明的方案可以基于大语言模型，实现报告的高效生成、多方协作、信息的整合与检索，生成了详尽、准确、跨领域知识的数据报告。一种跨领域知识的数据报表生成方法。该数据报表生成方法能够基于大语言模型实现报表的高效生成、信息的多方协作、整合和检索，生成详细的跨领域知识的准确数据报表。该数据报表生成方法包括获取目标业务信息，根据目标业务信息建立业务申报场景。 根据所述业务申报场景获取所述目标业务的目标数据。 通过所述训练后的数据报表生成模型，以根据所述目标数据得到目标数据报表。 根据所述目标业务信息以问卷的形式建立业务申报场景。 所述服务申报场景包括申报场景名称、描述、场景类型、选择申报企业、目标业务和申报模板。包括独立权利要求，用于：(1)数据报表生成装置； (2)具有处理器的计算设备； (3)一种计算机可读存储介质，所述计算机可读存储介质存储有用于实现所述跨领域知识的数据报表生成方法的指令。  11
本发明涉及语义理解技术领域，公开了一种用于知识图谱智能问答的语义理解方法及系统，包括以下步骤：步骤1：采集用户问题；步骤2：判定用户问题，得出标准化文本和非标准化文本；对非标准化文本执行改写操作，转换为新标准化文本；步骤3：提取标准化文本和新标准化文本中的意图和词槽；提取时依据文法规则和基于BERT的意图分类和词槽提取联合模型进行提取；步骤4：依据意图和词槽生成标准用户问句；步骤5：生成知识图谱问句；步骤6：计算标准用户问句与知识图谱问句的语义相似度值并得出综合匹配率；依据综合匹配率按照答案返回规则，返回答案信息。本发明能够达到提升语义理解效率、提升语义处理完善度的效果。该方法可用于使用语义理解系统，即基本递归神经网络模型和卷积神经网络模型，对人机对话产品中的知识图智能问答进行语义理解。该方法在提取时可以按照语法规则进行提取，提取率高，提取计算量小，对于一些突发情况，语法规则可以快速迭代修改，保证了提取的高效性； 并保证了对用户问题的语义理解的准确性，以及对相应语义答案的回答的准确性。该方法涉及收集用户问题。 确定用户问题。 获得标准化文本和非标准化文本。 在标准化文本中提取冗余和词槽。 根据意图和词槽生成标准用户问题。 生成知识图提问语句。 计算标准用户问题的语义相似度值。 得到综合匹配率。 根据答案和综合匹配率返回规则。 返回答案信息。本发明还涉及一种用于知识图智能问题的语义理解系统。  11
本发明涉及计算机领域，公开一种数据仓库的质量评估与治理方法、装置、设备及存储介质，该方法基于多维数据应用健康监测模型获取数据仓库中的问题数据，并将问题数据加入问题库；根据问题库中的问题数据从预训练模型中确定推荐模型，并基于推荐模型对问题库中的问题数据进行自动处理。由于是通过多维数据应用健康监测模型对数据仓库中的问题数据进行检测，并确定推荐模型进行问题自动处理，解决了现有的数据治理手段缺乏工具化支撑的问题，通过模型进行问题数据检测与治理，减少了人为参与，提高了数据治理效率。用于执行数据仓库的质量评估和治理的方法。通过多维度数据利用健康监测模型对数据仓库中的问题数据进行检测，确定推荐模型对问题进行自动处理，从而解决了现有数据处理手段缺乏工具支持的问题。 通过模型对问题数据进行检测和处理。 人为参与度降低。 提高了数据处理效率。该方法涉及通过应用基于多维数据的健康监测模型来获取数据仓库中的问题数据。 将所述问题数据添加到问题库中。 根据所述问题库中的问题数据从所述预训练模型中确定推荐模型。 基于所述推荐模型在所述问题库中自动处理所述问题数据。 基于数据质量检查规则对所述数据仓库中的表格数据进行数据质量检查。 将检查得到的质量问题数据添加到问题库中。包括独立权利要求，用于：(1)用于执行数据仓库的质量评估和治理的装置； (2)存储介质，所述存储介质存储有用于实现所述用于执行数据仓库的质量评估和治理的方法的指令。  11
一种问题处理方法，包括：获取用户输入的问题；基于问题，迭代从多个与提示工程相关的动作中筛选动作，其中，在第一轮迭代过程中，利用问题筛选动作，在除第一轮迭代之外的任意一轮迭代过程中，均利用问题和执行已筛选出的动作所得的内容筛选动作；在迭代次数达到阈值或者当前轮迭代筛选出的动作为终止动作的情况下，将提示词输入至大语言模型，以得到与问题相关的答案，该提示词中包括问题和执行每轮迭代筛选出的动作所得的内容。这样，就可以不断的对问题和执行动作所得到的内容进行增强优化，从而使得最终输入至大语言模型的提示词是最容易被大语言模型理解的，进而提升大语言模型推理结果的准确度。一种问题处理方法，应用于人工智能技术领域。该方法对问题和执行动作得到的内容进行不断的增强和优化，使得最终输入到大型语言模型的提示词最容易被大型语言模型理解，以提高大型语言模型推理结果的准确性。该方法涉及获得(S601)用户输入问题。 基于问题从与提示项目相关的多个动作中迭代地选择动作(S602)。 在第一轮迭代过程中提供问题筛选动作。 使用问题和在除第一轮迭代之外的任一轮迭代过程中执行经过滤的动作所获得的内容来过滤动作。 当迭代次数达到阈值或者在当前一轮迭代中过滤出的动作是终止动作时，将提示词馈送(S603)到大型语言模型中以获得与所讨论的问题相关的答案。 向所述提示词提供所述问题和执行每轮迭代中选择的动作得到的内容。包括独立权利要求，用于：(1)问题处理装置； (2)计算设备集群； (3)存储用于处理问题的程序的计算机可读存储介质； 以及(4)用于处理问题的计算机程序产品。 8
本发明涉及一种基于卷积神经网络的多光谱图像语义切割方法，利用卷积神经网络分别对多光谱图像的每一数据通道独立进行卷积，再对各数据通道独立卷积后的特征图进行融合。本发明通过多种分辨率输入、多通道独立卷积的网络，有效解决了标准U‑NET网络只能接受一种同尺度RGB\Gray图像的问题，有效提高多光谱图像语义切割的工作效率，保证图像切割的精度。基于卷积神经网络的多光谱图像语义切割方法。该方法能够有效解决神经网络问题，提高多光谱图像语义切割工作效率和图像的切割精度。该方法包括通过使用卷积神经网络即U-N ET神经网络形成数据通道以获得独立卷积的多光谱图像。 卷积融合数据通道后得到绝对特性图。 根据不同的波段进行不同大小、不同数量的卷积核选取处理。 根据不同的波段进行不同的卷积层选择处理。 分辨率数据被输入到基于不同尺度水平的卷积层。   4
本发明公开了一种基于复合神经网络模型的命名实体识别方法，采用传统的机器学习方法与两种神经网络模型，对大批量文本数据进行分析、构建特征矩阵和命名实体识别。本发明可以通过BLS中的增强节点和增量学习的方式有效提升模型训练速度，并结合BERT和CRF提升特征提取精度和标签识别精度，对于命名实体识别任务而言，能够灵活将提取到的逐个特征作为增强节点进行增量学习，在对数据集进行合理预处理的情况下能够广泛应用于英文和中文的命名实体识别，具备一定的灵活性、较高的准确率和较快的训练速度。本发明泛化能力强，不受文本形式、字典丰富度、标签多寡限制，可应用于中英文命名实体识别，并且训练难度低、所需算力少、训练速度快。基于复合神经网络模型的命名实体识别方法。该方法通过BLS中的增强节点和增量学习模式，并结合BERT和CRF提高的特征提取精度和标签识别精度，有效提高了模型训练速度，用于命名实体识别任务。 该方法泛化能力强，其不受文本形式、字典丰度和标签数量的限制，且训练难度低，所需计算力较小，训练速度快。该方法包括从语料中构建训练数据集并进行字符预处理得到标签。 提取语料库中的文本数据。 建立训练数据组。 进行分词处理。 划分的字被映射到对应的唯一数字ID。 生成句子向量。 根据词语与数字标识的映射构建词语词典和标签词典。 基于所述语句向量和所述词典构建特征词组标签。 构建标记载体。 输出向量被输入到BLS的特征层。  12
本申请提供了一种智能人机对话模型训练方法、装置、电子设备及计算机可读存储介质，该方法包括：获取当前轮次的用户语句及前一轮次的系统语句，拼接并输入至BERT模型中，得到当前对话矩阵；将当前对话矩阵输入至待训练的第一双向GRU模型中，得到会话语义向量；对会话语义向量进行第一线性变换得到意图向量，并对会话语义向量进行第二线性变换得到对话行为向量；根据意图向量计算得到意图损失，并根据对话行为向量计算得到对话行为损失；基于意图损失及对话行为损失进行反向传播，对各个待训练的模型的模型参数进行更新。本申请方案融合了BERT模型及GRU模型来编码历史记忆，并在语义解析时融合了前一轮的系统语句，可以得到准确度更高的语义解析模型。智能人机对话模型训练方法。该方法使得能够对历史存储器进行编码，在语义分析期间整合上一轮系统语句并获得具有更高准确度的语义分析模型。所述方法包括：将当前对话矩阵输入待训练的第一双向门控循环单元，得到会话语义向量。 对会话语义向量进行第二线性变换，得到对话行为向量。 根据所述意图向量计算意图损失。 根据所述对话行为向量计算对话行为损失。 基于所述意图损失和所述对话行为损失进行反向传播。 对每个模型的待训练参数进行更新。包括如下独立权利要求：一种智能人机对话模型训练装置； 一种电子设备，包括存储器，所述存储器用于存储执行智能人机对话模型训练方法的指令集； 以及计算机可读存储介质，用于存储执行智能人机对话模型训练方法的指令集。 8
本申请公开了一种词条的同义判别方法、装置、设备和存储介质，涉及知识图谱技术领域。具体实现方案为：获取待进行同义判别的词条对的特征信息；将所述词条对的特征信息输入至训练好的神经网络模型中，得到所述词条对的同义判别结果；本实施例直接将预训练层的结构、参数和特征进行知识迁移，采用预训练层对所述词条对的特征信息进行学习，减少训练过程中的标注量，节省大量的资源和人力进一步提高同义判别效率，提高同义判别结果的准确性。用于由电子设备识别同义词的方法(要求保护)。该方法能够节省资源和人力，提高同义词判别的效率和同义词判别结果的准确性。该方法包括获取待确定项对的特征信息。 将所述待确定项对的特征信息输入训练好的神经网络模型，得到所述待确定项对的同义判别结果。 通过预训练层选择自然语言训练样本进行语言理解任务训练，以学习所述待确定词项对的特征信息，得到所述待确定词项对的语言理解信息。 由输出层根据特征表示获得同义判别结果。以下包括独立权利要求：一种用于由电子设备识别同义词的设备； 以及计算机可读介质，所述计算机可读介质存储用于由电子设备识别同义词的指令集。  11
本发明涉及一种基于自融合子图的地理信息知识抽取增强方法，涉及知识抽取技术领域，目的为解决知识三元组抽取不完整和三元组噪声的问题。该方法包括以下步骤：步骤1：收集并构建地理信息数据库；步骤2：使用基于语言大模型对地理信息的多轮知识抽取并构建子图组；步骤3：使用基于语言大模型的自融合方法生成地理信息共同实体列表；步骤4：基于共同实体列表的地理信息关系三元组清洗，生成最终地理信息的知识抽取增强后的结果。本发明的基于自融合子图的地理信息知识抽取增强方法，作为地理信息的实体、关系知识抽取结果，相较于单次抽取和不进行自融合子图操作，能够有效的增强知识抽取结果。基于自融合子图的地理信息知识抽取增强方法。将基于自融合子图的地理信息知识抽取与增强方法作为地理信息的实体，关系知识抽取结果相对于单一抽取和非自融合子图操作，能够有效增强知识抽取结果。 该方法能够解决知识三元组提取不完全和三元组噪声的问题。 基于公共实体列表对地理信息关系三元组进行清洗，生成抽取后的结果并增强最终地理信息的知识。该方法涉及收集和构建地理信息数据库。 提取地理信息知识，积累数据。 基于语言大模型提取所述地理信息的多轮知识。 构建子图像组。 对选定的待提取地理信息进行多轮提取。 利用自融合的方法生成公共实体列表。 对地理信息关系三元组进行清洗。 对最终地理信息的知识进行提取和增强后生成结果。 删除自由实体、实体和关系知识抽取结果。  11
本发明公开了一种基于联合标注和实体语义信息的事件抽取方法，自然语言智能处理技术领域。本发明的事件抽取方法，首先采用BERT模型作为特征提取器；其次，基于字特征输入建模，不进行分词操作，并采用BIO标注，降低触发词识别的错误；再将抽取得到的事件通过计算事件相似度进行同类型事件的事件元素融合。从而使得本发明所提取的文本对象的特征信息更丰富、降低中文文本语料分词的粒度不同所导致的触发词的识别准确率的影响，以及避免因同一事件的事件元素信息可能出现在多个不同的段落或句子对事件抽取的准确性的影响。基于联合标注和实体语义信息的事件抽取方法。该方法能够在提取文本对象的特征信息的同时，避免由于中文文本语料分词的粒度不同而导致触发词的识别精度影响，从而避免同一事件的事件要素信息多次出现，进而避免了段落或句子的事件提取精度影响。该方法涉及通过联合标注模型对收集到的每个事件描述语句进行实体和事件触发词抽取处理。 实体和事件触发词包括有输入层、隐藏层和输出层。 执行事件描述语句初始化以将事件描述语句视为联合标注模块的输入。 相同事件类型的事件被标记为第一事件和第二事件。 基于第一和第二事件之间的相似度，进行判断以检查相似度大于或等于相似度阈值的事件是否被分组到类别中。 通过删除冗余事件和补全缺失信息的方式对集群事件进行排序和合并。  12
本申请涉及人工智能技术，提供一种语音合成模型的训练方法、装置、设备及介质。其中的方法包括：获取训练样本，训练样本包括训练语音信息和训练语音信息对应的训练文本信息，训练语音信息和训练文本信息指示的内容相同；通过参数编码器对训练语音信息进行编码处理，得到训练语音信息的嵌入信息；通过语音合成模型对训练文本信息进行编码处理，得到训练文本信息的音素数据；通过语音合成模型对嵌入信息和音素数据进行解码处理，得到目标语音信息；根据训练语音信息和目标语音信息，对语音合成模型进行训练，得到训练后的语音合成模型，可提高语音合成模型的训练效率。一种语音合成模型的训练方法。本发明根据训练语音信息和目标语音信息对语音合成模型进行训练，提高了语音合成器模型的训练效率。 利用语音语言数据训练语音合成模型，可以方便地实现模型的训练，方便训练过程的进行。 简化了语音合成器的训练过程，减少了训练时间。该方法包括获得(S101)训练样本。 训练样本包括与指示相同内容的训练语音信息，训练语音信息和训练文本信息相对应的训练语音信息和训练文本信息。 参数编码器对训练语音信息进行编码(S102)，以获得训练语音信息的嵌入信息。 语音合成模型对训练文本信息进行编码(S103)，以获得训练文本信息的音素数据。 语音合成模型对嵌入信息和音素数据进行解码(S104)，以获得目标语音信息。 训练语音合成模型(S105)，以根据训练语音信息和目标语音信息获得训练后的语音合成模型。本发明还涉及一种语音合成模型的训练装置(1)； (2)电子设备； 和(3)存储用于训练语音合成模型的程序的计算机可读存储介质。 3
本发明公开了一种基于对比学习的多尺度小样本目标检测方法，包括以下步骤：获取具有充足标注数据的公开数据集和极少量待检测的新类别标注数据；对标注数据进行数据预处理，构造基类数据集、新类数据集和混合数据集；构造基础检测器，采用具有级联结构的Cascade R‑CNN模型在基类数据集上进行基础训练，得到预训练模型；使用预训练模型对混合数据集中的数据进行特征提取；冻结基础检测器中的特征提取网络，在基础检测器的检测器头中添加对比建议编码模块对混合数据集的特征进行聚类。本发明可以在样本数量不足的条件下，利用极少量待检测的新类别标注样本获得具有一定泛化性能的检测模型，大量节省收集样本、标注样本的时间和精力。基于对比度学习进行多尺度小样本目标检测的方法。该方法能够在样本数量不足的情况下，利用少量的待检测新类别标记样本得到具有一定泛化性能的检测模型，节省了收集样本和标记样本的时间和精力。该方法涉及获得具有足够标记数据和待检测标记数据的公共数据集。 对标记数据进行预处理，构建基类数据集、新类数据集和混合数据集。 构建基础探测器。 利用具有级联结构的基于级联区域的卷积神经网络(R-CNN)模型对所述基础数据集进行基础训练，得到预训练模型。 利用所述预训练模型对所述混合数据集中的数据进行特征提取。 特征提取网络冻结在基本检测器中。 在基础检测器的检测器头中加入比较建议编码模块，对混合数据集的特征进行聚类。 获取所述特征的类型预测信息。 构建比较建议损失函数、分类损失函数、回归损失函数和区域生成网络损失函数。 使用经训练的网络来定位和分类新数据。 14
本发明提供一种多聚焦多源图像融合方法，对具有M个聚焦点的源图像进行分解融合叠加处理，将源图像分解成基部和细节，采用双数复小波算法对所述基部进行滤波去噪获得融合基部，采用预训练模型VGG‑S对细节进行深度特征提取获得细节特征，并采用多层融合策略重构细节特征，接着对所述细节特征选取梯度极大值获得融合细节，最后将获得的融合基部和融合细节进行叠合，完成图像融合。该方法获得的融合图像不仅保留了融合前图像的特征信息，提高了图像有效信息的利用率，同时清晰度也更高，更加细节化，全面化，优质化。该方法应用范围更为广阔，可以在日常生活，医学，军事等方面提供更多图像信息。用于在医学领域和军事领域中使用的融合多焦点多源图像的方法。该方法能够处理融合前方图像的特征信息，增加图像有效信息的利用率，提供高质量、适用范围广的图像信息。该方法涉及处理具有焦点的源图像以分解融合。 进行基本和细节融合操作。 对基采用双树复小波算法进行噪声滤波消除，得到融合基(FB)特征提取数据。 采用预训练模型，用于提取深层特征，得到细节特征。 采用多层策略进行细节融合，重构细节特征，根据细节特征选择最大梯度，得到融合细节(FD)基础和细节。 通过重叠所述融合细节来执行图像融合处理。   6
本申请属于机器学习中的深度强化学习技术领域，特别涉及一种基于半监督的语义预测方法。包括：步骤一、获取原始数据D，原始数据D包括n局数据；步骤二、从原始数据D中随机选取m局数据，并对所选的m局数据进行标注，得到已标注的数据集Labeled_D；步骤三、基于数据集Labeled_D进行有监督模型训练，得到预训练模型M_Pretrain；步骤四、通过原始数据D中除去已标注的m局数据之外的剩余数据，对预训练模型M_Pretrain进行预测，并将预测的语义结果定义为伪标签Fake_Label，得到带有伪标签的数据集Fake_Labeled_D；步骤五、将数据集Labeled_D和数据集Fake_Labeled_D组合成数据集D_Final，并基于数据集D_Final进行有监督模型训练，得到语义预测模型M_Final。本申请能够在任意的复杂场景情况下实现对语义的预测。基于半监督的语义预测的方法，用于在航空环境中基于半监督为人们提供未来的航空分析和策略制定。该方法能够有效地实现任意复杂场景条件下语义的预测。该方法包括获取原始数据。 原始数据提供有办公数据。 从所述原始数据中随机选取办公数据，对所述办公数据进行标记，得到标记数据集。 基于所述数据集对有监督模型进行训练，得到预训练模型M-Pre train。 去除所述初始数据中除标记后的办公数据外的剩余数据。 对所述预训练模型进行预测。 将预测的语义结果定义为伪标签假标签。 得到伪标记-D的数据集。 将标记为-D的数据集和数据集假标记-D组合成最终数据集D-Final。 基于d-final进行有监督的模型训练，得到语义预测模型M_Final。  11
本发明公开了属于自然语言处理领域一种基于机械零件加工文献数据的多维度命名实体识别方法，该方法包括如下步骤：步骤1：整理机械零件加工手册上的工艺知识，通过人工与算法结合的方法对所述文献进行数据处理工作，获得机械零件加工文献的语料；步骤2：利用部分机械零件加工文献无标注语料信息对Bert模型进行预训练，得到训练好的预训练模型；把所述机械零件加工文献的标注语料输入训练好的预训练模型中进行增量训练，得到字维度的特征向量Z；步骤3：将所述字维度的特征向量Z输入基于BiLSTM的神经网络模型，并引入注意力机制动态调整输入权重，得到融合全文信息的特征向量C；步骤4：将所述融合全文语义信息的特征向量C输入Mixture of Entity Experts(MOEE)框架判断每一个符号是否为实体并得到实体的特征向量E；步骤5：实体特征向量E输入CRF模型，计算标签结果，最后的到命名实体识别结果。基于机械零件加工文献数据的多维命名实体识别方法，应用于实体关系提取，语义网标注，知识地图等机械零件加工领域，用于研究智能制造方向。该方法包括完成机械零件加工手册的技术知识， 采用人工和算法相结合的方法对文档进行数据处理工作，获取语言数据，利用部分机械部分处理文献非标准评论素材信息对BERT模型进行预训练，从而保证了多维度命名实体识别方法的简单高效。该方法包括加工关于机械零件加工手册的技术知识。 通过手动和算法组合处理对文档执行数据处理工作，以获得语言数据。 利用部分机械部分对文献非标评论素材信息进行BERT模型的预训练，得到训练好的预训练模型。 将机械部分的标记语料输入到训练好的预训练模型中进行增量训练。 获得单词维度的字符向量。 融合了全文语义信息的特征向量C被输入到实体属性混合(MOEE)帧中，以判断每个符号是否是实体，并获得该实体的特征向量。 实体特征向量E被输入到CRF模型中。 计算标签结果，最终得到命名实体识别结果。  11
本发明涉及脑疾病判定技术领域，具体是涉及一种图像分类方法、装置、设备及存储介质。磁共振影像能够准确反映脑部结构因病变而引起的变化，正电子发射断层影像能够准确反映脑部功能因病变而引起的变化。本发明首先利用大卷积核注意力(LKA)模块来学习注意力图。接着通过由CNN和Transformer双分支组成的主干网络进行高级特征学习。本发明还设计了一个模态特征融合块(MFFB)用以在主干网络中来对MRI及PET特征进行交互融合。最后，在提取完高级特征后，使用一个空间通道注意力模块(SCA)，来对得到的高级特征进行空间上和通道上的处理。在ADNI数据集上的大量实验结果表明，本发明的模型优于最先进的方法，表明本发明提出的方法的有效性。一种图像分类方法，用于通过采集患者的脑部图像来判断患者是否患有AD以及AD的程度，从而判断诸如阿尔茨海默病(AD)的脑部疾病。 用途包括但不限于结构MRI、功能磁共振图像(fMRI)、弥散张量成像(DTI)和正电子发射断层扫描(PET)。磁共振图像能准确反映病变引起的脑结构改变，正电子发射断层扫描准确反映病变引起的脑功能改变。 本发明可应用于LKA模块中研究注意力图。 对ADNI数据集的大量实验结果表明，该模型优于最先进的方法，说明该发明提出的方法的有效性。该方法包括生成脑的磁共振图像和正电子发射断层扫描图像。 提取脑部磁共振图像和正电子发射断层扫描图像的融合特征图。 融合特性图具有磁控管图像的特性和正电子发射断层摄影图像的特性。 得到用于表征脑部疾病的分类结果。独立权利要求包括：(1)脑疾病分类装置； (2)终端设备； (3)一种计算机可读存储介质。  7
本申请公开一种问答数据集的生成方法及装置，可应用于自然语言处理，领域，包括，获取问答数据集的生成信息以及第一数量的预设格式的问答数据集样本，其中，问答数据集样本包括问答数据集的领域类型以及与领域类型对应的包括提问数据以及回答数据的问答数据，训练自然语言模型所需的问答数据集的数量为第二数量，第一数量少于第二数量，然后将问答数据集样本以及生成信息输入至预先训练好的大语言模型，输出与问答数据集样本的领域类型以及格式相同的目标问答数据集，这样人工只需预先标注第一数量的问答数据集样本，从而无需人工标注第二数量的问答数据集样本，也就可以在生成问答数据集样本(训练数据)的过程中节约人力资源，降低人力成本。生成问答数据集的方法。 也可用于语言处理领域。该方法能够在高效生成问答数据集样本的过程中，节省人力资源，降低人力成本。该方法包括获取(S101)生成第一数量的预设格式的问答数据集信息和测试数据集样本。 所述问答数据集样本包括所述问答数据集的字段类型和与所述字段类型对应的问答数据。 训练自然语言模型所需的问答数据集的数量为第二数量，第一数量小于第二数量。 将样本问答数据集sample和生成的信息输入(S102)预先训练的大型语言模型。 输出与所述问答数据集样本具有相同字段类型和格式的目标问答数据集。本发明还涉及一种用于产生问答数据集的装置。  11
本发明公开了一种基于全局和局部注意力机制的人脸亲属关系特征提取验证方法，基于局部注意力机制的卷积神经网络和全局注意力机制的Vision Transformers(ViT)模型的构建；包括步骤：步骤一，提出一种基于全局和局部注意力机制的网络模型；步骤二，对预处理的人脸图像，通过卷积神经网络和ViT预训练模型对人脸进行特征提取；步骤三，将步骤二中输出的特征向量通过特征融合(Feature fusion)和1×1卷积用来降低特征维度，然后组合连接成一个长向量，然后将长向量输入全连接网络(Full Connection，FC)，以测量两个人脸图像之间的相对相似性，最终确定两幅图像是否有亲属关系；其具有人脸图像特征提取速度快，准确度高，语义信息强，网络结构简单等优点。基于全局和局部注意力机制的人脸亲属关系特征提取和验证方法。大大提高了父系关系的人脸特征提取的识别性和准确性。 实现了提取速度快、准确率高、语义特性好、网络结构简单。该方法包括建立基于卷积神经网络(CNN)和视觉变换器(ViT)的模型。 通过所述卷积神经网络模型和所述ViT模型对父人脸进行特征提取，得到特征向量。 特征向量采用特征融合、1x 1卷积、特征拼接和全连接层进行融合。 进行sigmoid激活，通过特征融合验证所述特征向量。 2
本发明公开了一种基于混合图注意力的智能配置事件抽取方法，具体分为事件类型分类和事件元素抽取两个部分，包括以下步骤：S1：事件类型分类，采用BERT预训练模型进行多标签分类得到事件类型；S2：事件元素抽取，基于获取的事件类型利用BERT和BiLSTM获取词向量嵌入，同时构建文本共现图和句法依存图，利用图注意力网络进行特征聚合，最后利用条件随机场得到预测标签序列。本发明检测智能配置事件文本中是否存在相应的事件类型，获取事件元素和触发词，将非结构化文本以结构化形式呈现。基于混合图注意力的智能配置事件抽取方法，用于从非结构化案例文本中识别和抽取事件元素，并组织成结构化信息元组。所述智能配置事件提取方法涉及检测智能事件文本中是否存在相应的事件类型，并获取所述事件元素和所述触发词，以及以结构化形式呈现所述非结构化文本，并且因此确保了简单且高效的智能配置事件提取方法。该方法涉及使用BERT预训练模型进行多标签分类以获得事件类型。 所述BERT和BiLSTM用于基于获得的事件类型获得词向量嵌入。 同时构建文本共现图和句法依赖图，并利用图注意力网络进行聚合。 最后利用条件随机场得到预测标签序列，得到触发词和事件要素。  12
本申请实施例公开了一种训练文本预测模型的方法、文本预测方法及装置。本申请利用训练样本集对大型语言模型进行训练来得到文本预测模型，这种方式实质上利用了已标注的样本训练大型语言模型(LLM)，在第二键矩阵和第二值矩阵的更新过程中，利用了上一轮迭代得到的第二键矩阵和第二值矩阵与当前输入特征矩阵产生的第一键矩阵和第一值矩阵，既保留了历史信息又保持了当前输入文本的信息，使得大型语言模型能够充分对已标注的样本进行理解和学习，从而提高情景学习场景下基于大型语言模型的文本预测效果。并且这种前向优化模型的方式，大大缩减了需要更新的模型参数，降低了模型训练的成本，提高了效率。训练文本预测模型的方法。大大减少了模型参数需要更新的数量，降低了模型训练的成本，提高了效率的前向优化模型的方法。该方法涉及获得(302)训练数据集，训练数据集包括输入文本样本和与输入文本样本对应的输出标签。 将包含所述输入文本样本和所述输入文本样本对应的输出标签的文本序列作为(304)所述文本预测模型的输入，对所述文本预测模型进行训练。 将当前层变压器网络在上轮迭代中得到的第一密钥矩阵和第二密钥矩阵进行拼接，得到第三密钥矩阵。 利用所述第三密钥矩阵、所述第三数值矩阵和所述第一查询矩阵进行自注意力机制处理，得到所述当前层变压器网络输出的特征表示。 利用所述第一数值矩阵对所述第二数值矩阵进行更新，将更新后的第二数值矩阵作为本轮迭代中本层变压器网络得到的第二数值矩阵。包括以下独立权利要求：(1)用于文本预测的方法； (2)用于情感分析的方法； (3)用于训练文本预测模型的装置； (4)文本预测装置； (5)存储有用于训练文本预测模型的程序的计算机可读存储介质; 以及(6)用于训练文本预测模型的电子设备。  11
本发明公开了一种文本顺滑检测的方法和装置，涉及计算机技术领域。文本顺滑检测的方法的一具体实施方式包括：响应于接收到目标文本，根据预先设置的预训练模型，对所述目标文本进行编码，生成对应的隐向量；对所述隐向量进行多尺度特征提取，得到特征向量；对所述隐向量和所述特征向量进行组合，得到组合向量，根据预先设置的激活函数对所述组合向量进行分类，生成所述目标文本对应的分类标签。该实施方式能够捕获不同长度的词语之间的相关性，提高冗余口语词的检出率，使文本更顺滑、便于理解。利用电子设备检测目标文本平滑度的方法(权利要求书)。该方法使得能够捕获不同长度的词之间的相关性从而提高冗余口头词检测率，实现平滑方便地理解目标文本。该方法包括响应于接收到目标文本，根据预先设置的预训练模型对目标文本进行编码，以生成对应的隐藏向量。 提取对应的隐藏向量的多尺度特征，得到特征向量。 将对应的隐藏向量和特征向量进行合并，得到合并向量。 根据预设激活函数对所述合并向量进行分类。 生成与所述目标文本对应的分类标签。 采用不同窗口大小的卷积校验进行隐向量卷积运算，得到多个短语向量表示。独立权利要求还包括用于：一种利用电子设备检测目标文本流畅度的装置； 一种计算机可读介质，包括一组指令，用于通过电子设备检测目标文本流畅度。  12
本发明适用于机器学习技术领域，提供了一种基于有限数据的分类模型训练方法和终端设备，其中，所述方法包括：获取预训练模型和数据集；将数据集随机划分两个子集，并确定两个子集中的任意一个子集为训练集；将两个子集中的另一个子集确定为测试集；根据训练集训练预训练模型；根据测试集测试训练后的预训练模型；根据测试结果对训练后的预训练模型进行评估。在本发明实施例提供的基于有限数据的分类模型训练方法和终端设备中，由于预训练模型是已应用于其他分类问题的模型，相较于新建模型，对其进行适应性训练和局部优化所需的时间和数据量必然大幅减小，从而解决了现有技术对机器分类模型进行训练时耗时较长和训练所需数据过多的问题。基于有限数据的分类模型训练方法。该方法能够减少训练和对局部优化所需时间和数据量的适应性，并且减少机器分类模型训练时间和训练数据。该方法包括获取预设的预训练模型和数据集。 通过所述数据集执行预分类。 根据一个分类结果将数据相应地划分为多个子集进行收集。 根据所述训练集从每个子集中分别提取设定数量的训练集和测试集的样本，以根据测试训练后的一个测试集中的所述预训练模型对所述预训练模型进行训练。 得到测试结果。 根据所述测试结果对所述预训练模型进行训练后评估。 得到所述预设聚类特征。 根据聚类特征得到数据的各个样本分类和中心化。独立权利要求还包括：一种分类模型训练装置，一种包括存储器的终端设备，一种用于基于有限数据的分类模型训练方法的处理器和一种用于存储用于基于有限数据的分类模型训练方法的设定指令的计算机可读存储介质。  11
本发明涉及人工智能领域，公开了一种敏感倾向表述检测方法、装置、设备及存储介质。所述敏感倾向表述检测方法包括：获取待检测的文本表述；将文本表述分别输入预置BERT模型进行向量编码、输入预置统计语言模型进行特征提取、以及进行嵌入词向量转化，分别得到多个文本词向量、多个文本特征向量、以及多个嵌入词向量；将各向量分别输入预置第一敏感倾向识别模型、预置第二敏感倾向识别模型、预置第三敏感倾向识别模型进行识别，得到对应的具有敏感倾向表述的第一概率、第二概率，以及第三概率；对第一概率、第二概率、第三概率进行投票，确定文本表述是否具有敏感倾向。本发明可以高效且精准地检测出包含敏感内容的文本表述信息。敏感的倾向性表达检测方法。该方法能够高效、准确地检测出包含敏感内容的文本表达信息。该方法包括获取待检测文本表达。 将所述待检测文本表达输入预设的双向编码器(BERT)模型进行向量编码，得到多个文本词向量。 将所述待检测文本表达输入预设的统计语言模型进行特征提取。 得到多个文本特征向量。 对所述文本表示进行嵌入词向量转换，得到多个嵌入词向量。 根据投票结果判断所述文本表达是否具有敏感倾向。独立权利要求还包括：一种灵敏倾向性表情检测装置； 以及计算机可读存储介质，用于存储用于执行敏感倾向性表达检测方法的指令集。  12
本申请公开了一种语音翻译方法及相关装置、设备和存储介质，其中，语音翻译方法包括：提取待翻译语音的语音特征，并提取提示文本的文本特征；其中，提示文本用于指示从待翻译语音的源语种翻译为目标语种；获取语音特征经特征维度映射后的映射特征，并将文本特征和映射特征输入至大模型，以及获取大模型处理过程中的第一输出特征；其中，映射特征与第一输出特征具有相同特征维度；获取基于第一输出特征与映射特征融合的第一融合特征；获取大模型继续处理第一融合特征输出的目标文本；其中，目标文本为待翻译语音翻译为目标语种的翻译文本。上述方案，能够尽可能地降低多语种语音翻译的消耗资源和使用复杂度，并提升翻译精度。语音翻译方法，用于将源语言的语音转换为目标语言的文本。该方法尽可能地降低了多语言语音翻译的消耗资源和使用复杂度，提高了翻译精度。语音翻译方法涉及提取待翻译语音的语音特征。 提取所述提示文本的文本特征。 所述提示文本用于指示从所述待翻译语音的源语言翻译为所述目标语言。 特征维度映射后得到语音特征的映射特征。 输入文本特征和到大模型的映射特征。 在大模型处理过程中得到第一输出特性。 映射特征具有与第一输出特征相同的特征维度。 基于所述第一输出特征和所述映射特征得到融合后的第一融合特征。 获取所述大模型连续处理所述第一融合特征输出的目标文本。 所述目标文本为所述待翻译语音翻译出的目标语言的翻译文本。包括：(a)一种语音翻译设备，具有：特征提取模块，用于提取要翻译的语音的语音特征; (b)一种电子设备，具有用于存储程序指令的存储器; (c)计算机可读存储介质，用于存储能够由处理器操作的程序指令。 3
本申请公开了一种基于BERT模型的多目标任务信用风险识别方法及系统。首先获取目标用户的多条文本数据，通过标识符将目标用户的多条文本数据进行依次拼接得到目标识别文本；然后将目标识别文本载入预先建立并训练完成的BERT模型中，确定信用风险识别结果。本发明从底层运营商文本数据直接出发，运用BERT预训练模型获取文本的Embedding向量，结合多目标任务的全连接分类层，只需开发一个神经网络模型，将其运用于不同目标定义的业务或渠道上，且相较于分别开发的各个传统模型都有明显的效果提升。基于BERT模型的金融业多目标任务信用风险识别方法。该方法利用BERT预训练模型直接从底层算子文本数据出发，得到文本的嵌入向量，结合多目标任务的全连接分类层，应用不同目标定义的服务或通道开发神经网络模型，达到较强的信用风险分析效果。该方法包括在训练集中选择用户的多个文本数据。 通过标识符依次对所述文本数据进行标识，得到多个训练标识文本。 对所述训练标识文本进行分词。 基于嵌入向量的维度和训练标识文本中的词的数量，得到分词矩阵。 定义多目标任务的分类器。 通过使用用户的向量结果来训练分类器，以获得训练完成的双向编码器表示(BERT)模型。包括独立权利要求用于基于BERT模型识别金融业多目标任务信用风险的系统。  12
本申请提供了一种内容生成方法、电子设备及存储介质，依据本申请实施例，首先获取与网络发布内容的内容类型对应的表征数据，进而查找与表征数据匹配的提示词模板，从而可以根据提示词模板和表征数据生成用于大型语言模型输入的目标提示词，通过将目标提示词等信息输入大型语言模型可以获得大型语言模型输出的网络发布内容。由此可见，本申请实施例无需用户自行进行复杂的提示词构建，为使用大型语言模型提供了基础，可以充分利用大型语言模型优质的内容构建能力输出优质内容，避免了对编辑者能力和经验的过度依赖，降低了内容生成工作所耗费了人工成本和编辑过程来带的软硬件资源消耗，提高了内容的生成效率。一种内容生成方法，应用于网络信息技术领域。该方法不需要用户自行进行复杂的提示词构建，为使用大型语言模型提供了基础，充分利用了大型语言模型优秀的内容构建能力，输出优秀的内容。 避免了对编辑能力和经验的过度依赖。 该过程降低了内容生成工作的人力成本和编辑过程携带的软硬件资源消耗，提高了内容生成效率。该方法包括获取与网络发布内容的内容类型对应的特征化数据。 将匹配到的提示词模板与所述令牌数据进行查找。 根据所述提示词模板和所述令牌数据生成用于输入所述语言大模型的目标提示词。 所述大型语言模型至少根据生成的所述目标提示词和所述大型语言模型得到所述网络发布内容输出。 对当前时间设定时长的时间段内从网络内容平台采集的第一源数据进行热点分析。 将获取的热点数据确定为内容主体的表征数据。独立权利要求包括以下内容：一种电子设备； 以及存储用于生成内容的程序的计算机可读存储介质。  11
本发明涉及一种电力用户负荷识别方法、装置及计算机可读介质，其中，电力用户负荷识别方法包括步骤1：提取若干稳态周期的电压电流数据并进行标准化处理，分解出电流序列的无功成分构造二维图像；步骤2：构建基于预训练网络inception_v3的迁移学习模型，利用预处理后的数据对模型进行训练，自动学习图像中的信息；步骤3：利用训练完成的模型对新采集的主表电压电流数据进行负荷识别，获取用电设备的能耗信息。与现有技术相比，本发明具有识别速度快、准确率高等优点。用于识别用电设备的电力用户负载的方法。该方法能够提高电力用户负载识别速度和电力用户负载识别精度。该方法涉及提取多个稳定时段的电压电流数据并进行标准化处理。 分解电流序列的电抗分量以构建二维图像。 基于预训练网络inception-v3构建迀移学习模型。 利用预处理后的数据对模型进行训练。 自动学习图像中的信息。 利用训练好的模型对采集到的主地表电压-电流数据进行负载识别。 获取一用电设备的能耗信息。独立权利要求包括如下：一种电力用户负荷识别装置，具有与数据处理终端连接的输出端； 以及计算机可读介质，用于存储所述电力用户负荷识别方法。 0
本申请实施例提供了一种模型获取方法、装置及存储介质，该方法包括：采用每个基础模型对训练集中的各个图像进行处理，获取每个图像的特征，基础模型为已训练基础模型池中的模型，针对该基础模型，根据图像的特征和类别，获取该基础模型对所述训练集的聚类能力，类别用于表示图像的分类信息，根据每个基础模型对训练集的聚类能力，从基础模型池中获取预训练模型。和相关技术相比，从基础模型池中选取预训练模型时无需额外的训练过程，可快速、高效地获取预训练模型，同时未引入超参数，选取结果稳定，提高了用户体验。用于从基本模型池获得模型的方法。该方法能够在不需要额外的训练过程的情况下，从基础模型池中选择预训练模型，从而能够快速、高效地获得预训练模型，且不会引入超参数，从而保证了选择结果的稳定，进而提高了用户体验。该方法涉及通过使用基本模型来在训练单元中处理图像以获得图像的特征，其中基本模型是经训练的基本模型池中的模型。 根据所述图像的特征和类别向所述训练单元获取所述基本模型的聚类能力，所述类别用于表示所述图像的分类信息。 根据所述基础模型对所述训练单元的聚类能力，从所述基础模型池中获取预训练模型。包括用于从基本模型池获取模型的设备的独立权利要求。 14
本发明公开了一种语义召回模型的训练方法及训练装置，该训练方法包括获取用户输入的搜索词、第一样本文档和第二样本文档；利用预训练语言模型分别生成搜索词的第一词嵌入向量、第一样本文档的第二词嵌入向量和第二样本文档的第三词嵌入向量；利用深度神经网络模型分别计算第一词嵌入向量对应的第一语义向量、第二词嵌入向量对应的第二语义向量和第三词嵌入向量对应的第三语义向量；计算第一语义向量和第二语义向量的第一相似度，以及计算第一语义向量和第三语义向量的第二相似度；根据第一相似度和第二相似度计算损失函数；根据损失函数训练预训练语言模型和深度神经网络模型。一种语义记忆模型的训练方法。该方法通过损耗函数优化预训练语言模型和深度神经网络模型， 通过对比的方式建立语义记忆模型，学习搜索词与第一样本文档，第二样本文档之间的语义差异关系，提高预训练语言模型在语义层面上的理解能力，从而使语义记忆更加准确。该方法包括利用预训练语言模型分别生成搜索词的第一词嵌入向量，第一样本文档的第二词嵌入向量和第二样本文档的第三词嵌入向量。 提供深度神经网络模型以计算对应于第一词嵌入向量的第一语义向量，对应于第二词嵌入向量的第二语义向量以及对应于第三词嵌入向量的第三语义向量。 计算第一语义向量和第二语义向量之间的第一相似性。 计算第一语义向量和第三语义向量之间的第二相似性。 根据第一相似度和第二相似度计算损失函数。 根据损失函数训练预训练语言模型和深度神经网络模型。本发明还涉及一种语义记忆模型的训练装置。 (2)终端； 和(3)计算机可读存储介质，其存储用于训练语义记忆模型的程序。  12
本说明书公开了一种模型训练的方法、装置、存储介质及电子设备，先获取预训练的大语言模型以及样本用户。然后可确定样本用户对应的标注风险类型，在样本用户对应的各维度的用户数据中，确定标注维度的用户数据，标注维度的用户数据为导致样本用户的风险类型是标注风险类型的原因。可将样本用户对应的各维度的用户数据输入大语言模型，得到大语言模型输出的第一输出结果，第一输出结果包括：样本用户的预测风险类型以及预测维度的用户数据，预测维度的用户数据是导致样本用户的风险类型是预测风险类型的用户数据。最后根据第一输出结果、标注风险类型和标注维度的用户数据，执行第一训练任务，以对大语言模型进行训练。提高了大语言模型的性能。方法进行模型的训练。保证了改进的模型训练方法。该方法涉及获得(S100)预先训练的大型语言模型和样本用户。 确定样本用户对应的标注风险类型，并确定样本用户对应的各维度的用户数据中标注维度的用户数据(S102)。 将样本用户对应的各维度的用户数据输入大型语言模型，得到大型语言模型输出的第一输出结果，第一输出结果包括样本用户的预测风险类型和预测维度的用户数据。 提供预测维度的用户数据(S104)作为使样本用户的风险类型成为预测风险类型的用户数据。 执行第一训练任务(S106)，以根据所述第一输出结果、所述标注风险类型和所述标注维度用户数据训练所述大型语言模型。独立权利要求包括以下内容：(1)用于训练模型的装置； (2)计算机可读存储介质，其存储用于训练模型的程序； 以及(3)用于训练模型的电子设备。  11
本公开的实施例公开了一种基于二次检索增强的生成式建筑知识问答方法、装置、电子设备和计算机可读介质。该方法的一具体实施方式包括：获取目标问题信息；将目标问题信息转换为对应的文本向量；利用文本向量在目标向量库中进行检索，得到目标结果集；根据目标问题信息，从目标结果集中确定至少一条相关结果；根据目标问题信息和至少一条相关结果，生成目标问题信息的答复信息。该实施方式实现了大语言模型的幻觉发生率的减少，以及建筑领域知识问答效果的提升。应用于制造业、农业、物流、金融、商业、家居领域的基于二次检索增强的生成式建筑知识问答方法。该方法能够实现降低大型语言模型的幻觉发生率，提高建筑领域的知识问答效果。所述方法(200)涉及获得(201)目标问题信息。 将所述目标问题信息转换(202)为对应的文本向量。 利用所述文本向量在所述目标向量库中进行搜索(203)，得到所述目标结果集。 根据所述目标问题信息从所述目标结果集中确定(204)所述相关结果。 根据所述目标问题信息和所述相关结果生成(203)所述目标问题信息的回复信息。独立权利要求包括如下内容：一种基于二次检索增强的生成式建筑知识问答装置； 电子装置； 以及存储有基于二次检索增强的程序生成式建筑知识问答程序的计算机可读介质。  12
本发明公开了一种基于深度学习的未来产业创新方向识别方法及系统，属于深度学习技术领域。该方法包括：采集原始数据集，进行数据清洗和标注，得到训练集；将训练集输入基于BERT‑BiLSTM‑CRF的模型预训练框架构建产业技术识别模型；基于产业技术识别模型推理得到产业技术信息，形成产业技术池，并确定词向量特征，执行多种聚类算法，得到包括多个技术分类的产业技术聚类池；利用定量分析模型对产业技术聚类池进行分析，计算每个技术分类的时间演进趋势，得到未来产业创新方向预测结果。本发明的技术方案提高了未来产业创新技术方向的预测效率和稳定性，降低对研究专家主观经验的依赖。一种国内外基于深度学习的未来产业创新方向识别方法，用于识别创新技术，判断未来技术发展趋势的电子设备(Cleaked)。提高了未来产业创新技术方向的预测效率和稳定性，降低了对研究专家主观经验的依赖。该方法涉及从多个数据源收集原始数据集(S101)。 对所述原始数据集的数据进行清洗。 对清洗后的数据集进行标记，得到训练数据集。 将训练数据集输入到基于双向编码器表示从变压器-双向长短期记忆-条件随机场(Bit-directional Encoder Representation from Transmiters-Bitirectional Long Short-Term Memory-CRF)的模型预训练帧中进行训练，构建工业技术识别模型。 形成产业技术池。 获得包括多个技术分类的工业技术聚类池。 得到未来产业创新方向预测结果。独立权利要求还包括用于：一种基于深度学习识别未来产业创新方向的系统； 以及计算机可读存储介质，包括用于基于深度学习来识别未来产业创新方向的指令集。  12
本发明公开了一种基于改进的DSOD模型的车辆检测与识别方法，DSOD是在SSD算法的基础上进行改进的，可以简单理解为SSD+DenseNet＝DSOD，采用proposal‑free的检测模型SSD，加入DenseNet的思想。DSOD模型分成两个部分：用于特征提取的Backbone，用于目标预测的Front‑end。Backbone子网络类似于DenseNet，由一层Stem block(主干模块), 四层Dense blocks(Dense模块), 两层Transition layers(过渡层), 两层Transition w/o pooling layers(过渡w/o池化层)，作用是用来提取图像特征。Front_end sub_network(前端检测子网络)是通过Dense Connetion实现边界框检测效果。基于DSOD模型的车辆检测识别方法。该方法能够利用基于SSD算法的改进DSOD模型，将DSOD模型分为两部分：用于实现前端目标预测，利用Stem层、四个致密纳米材料层和两个过渡层，从而实现利用连接边界框检测效果提取图像特征。该方法涉及基于TensorFlow(RTM：开源软件库)框架，利用Python(RTM：High-level programming language)编程语言建立DSOD网络模型。 在训练过程的初始阶段为增加正分类概率对损失计算公式进行调整。 对DSOD网络模型进行反向传播迭代训练过程，直至满足目标检测过程的精度和稳定性要求。 通过车辆上的摄像头采集道路图像，并将采集到的图像输入DSOD网络模型，实现目标检测功能。   4
本公开涉及自然语言处理领域，揭示了一种文本纠错模型建立方法、装置、介质及电子设备。该方法包括：获取文本语料；获取经随机遮盖处理后的文本语料中保留的字符对应的第一向量；将第一向量输入至模型，以便模型的生成器输出第二向量，并由模型的鉴别器输出第一预测结果；计算第一损失函数；若未达到第一收敛条件，则执行获取第一向量步骤及之后的步骤；获取经随机替换处理后的文本语料中字符对应的第三向量；将第三向量输入至鉴别器模块，得到第二预测结果；计算第二损失函数；若未达到第二收敛条件，则执行获取第三向量步骤及之后的步骤；将鉴别器与预训练的文本填充模块对接，得到文本纠错模型。此方法降低了数据标注成本，提高了纠错效果。用于在电子设备中建立文本纠错模型的方法(权利要求书)。降低了数据标记成本，提高了纠错效果。该方法包括在随机屏蔽处理之后，获得与文本语料库中保留的字符相对应的第一字符向量。 基于所述文本语料和预测结果计算损失函数。 获取随机替换处理后的文本语料中的字符对应的另一字符向量。 进行对接步骤。 判别器模块，与预先训练的文本填充模块对接，通过判别器模块对接得到文本纠错模型。独立权利要求还包括用于：文本校正模型建立装置； 以及包括用于建立文本纠错模型的指令集的计算机可读存储介质。  12
本申请实施例提供一种用于获取威胁情报数据模型的方法、介质及电子设备，所述方法包括：获取与威胁情报数据对应的关键词词典；通过对BERT模型进行基于知识增强预训练和常规预训练的交替训练，得到用于威胁情报处理BERT模型，其中，所述知识增强预训练的样本数据是采用目标字符掩码令牌替换预训练数据集和验证集中的目标词语，所述目标词语是所述预训练数据集和验证集中包括的所述关键词词典中的词语，所述常规预训练的样本数据是利用目标字符掩码令牌替换所述预训练数据集和所述验证集中的相关字词得到的。本申请的实施例可以有效缓解BERT在训练的过程中由于过度关注专业词汇而导致的模型对文本语义理解能力下降的问题。通过使用电子设备(权利要求书)获得威胁信息数据模型的方法。该方法能够有效缓解训练过程中由于过分关注专业词汇导致模型对文本的语义理解能力下降的问题。该方法包括获取威胁信息数据对应的关键字字典。 所述关键词字典包括在预训练数据集和验证集中。 采用目标字符掩码令牌，将所述验证集替换所述预训练数据集中的目标词，所述目标词为所述关键词词典中包括的词。 利用所述目标文本掩码令牌替换所述预设数据集合中的相关词，得到所述常规预训练的样本数据。还包括独立权利要求，用于：威胁信息数据的处理方法； 威胁信息数据模型获取处理装置； 以及一种计算机可读存储介质，包括用于通过使用电子设备获得威胁信息数据模型的指令集。  12
本申请实施例公开了一种投诉预警识别方法及相关设备。该方法包括：获取训练集，训练集包括文本训练集和音频训练集；对训练集进行数据处理，得到文本编码矩阵和音频编码矩阵；将文本训练集输入文本先验知识推理模型，得到文本权重矩阵，将音频训练集输入音频先验知识推理模型，得到音频权重矩阵；将文本权重矩阵分别与文本编码矩阵、音频编码矩阵进行交互处理，将音频权重矩阵分别与文本编码矩阵、音频编码矩阵进行交互处理，得到四个信息交互矩阵；根据四个信息交互矩阵确定投诉预警识别结果。采用本申请实施例，实现在融合先验知识的多模态信息交互情况下，进行多任务小样本的投诉预警模型训练，提高识别准确率，降低模型复杂度和人力标注成本。投诉预警识别方法。该方法使得能够实现融合先验知识的多模式信息交互，针对多任务小样本的投诉预警模型训练，能够提高投诉预警识别的准确率，降低模型复杂度和人力标注成本。该方法涉及获得训练集。 训练集包括文本训练集，以及与文本训练组对应的音频训练集。 对所述训练组进行数据处理，得到文本编码矩阵和音频编码矩阵。 将所述文本训练组输入到文本先验知识推理模型中进行模型推理，得到所述文本权重矩阵。 将音频训练组输入音频先验知识逻辑模型，以对所述音频权重矩阵进行模型推理，得到音频加权矩阵。 根据所述第一信息交互矩阵、所述第二信息交互矩阵、所述第三信息交互矩阵和所述第四信息交互矩阵确定投诉预警识别结果。包括一种投诉预警识别装置的独立权利要求。 3
本公开提供了一种大语言模型的训练方法、文本处理方法、装置和设备，涉及人工智能技术领域，尤其涉及自然语言处理和深度学习等技术领域。训练方法包括：基于多个文本数据源，构建多个无监督数据集，其中，多个无监督数据集中的任意两个无监督数据集包括来自不同的文本数据源的无监督训练数据；在多个无监督数据集中进行采样，以得到多个批次的无监督训练数据，每一个批次的无监督训练数据是对多个无监督数据集中的一个无监督数据集进行独立采样而得到的；以及利用多个批次的无监督训练数据对大语言模型进行多个批次的训练，以得到经训练的大语言模型，其中，每一个批次的训练使用多个批次的无监督训练数据中的一个批次的无监督训练数据。用于训练大型语言模型的方法。该方法能够利用多个批次的无监督训练数据对大型语言模型进行多批次训练，以高效地获得训练后的大型语言模型，从而有效地提高机器学习过程的性能。该方法涉及基于多个文本数据源构建多个无监督数据集，多个无监督数据集中的任意两个无监督数据集包括来自不同文本数据源的无监督训练数据。 对多个数据集中的数据进行采样，得到多批无监督训练数据。 所述批次无监督训练数据是对所述若干个数据集中的一个无监督训练数据集进行独立采样得到的。 利用多个批次的训练数据对大语言模型进行批次训练，得到训练后的大语言模型。独立权利要求书包括用于：(1)一种基于上下文学习任务的文本处理方法； (2)大型语言模型的训练装置； (3)一种基于上下文学习任务的文本处理装置； (4)电子设备； (5)非瞬时计算机可读存储介质，用于存储所述计算机指令； (6)一种计算机程序产品。  11
本申请公开一种喷码字符检测的方法，使用多个预训练模型对样本图片进行区域提取以获取N个检测区域，并根据识别模型对所述N个检测区域进行识别以得到N个识别结果，根据喷码校验规则对所述N个识别结果进行校验得到N个喷码校验信息，根据所述N个喷码校验信息对所述N个检测区域中的一个或多个进行标注得到M个标注样本，将所述M个标注样本更新至区域提取的标注样本集，使用更新后的所述区域提取的标注样本集训练区域提取模型，使用包括所述区域提取模型及所述识别模型的喷码字符检测装置对输入图像中的喷码字符进行检测。相应地提供了喷码字符检测的装置和系统，可以用于自动对样本进行批注。检测喷码字符的方法。该方法通过自动获取标注样本并不断训练模型来达到较好的检测效果，不需要复杂的硬件和大量的人力输入标注且成本低、可行性高。该方法涉及获得(310)样本图片。 利用若干用于提取所述检测区域的预训练模型对所述样本图片进行提取(320)，得到N个检测区域。 根据识别模型对所述N个检测区域进行识别(330)，得到N个识别结果。 根据喷码验证规则对所述N个识别结果进行验证(340)，得到N个喷码验证信息。 根据所述N个喷码校验信息对所述N个检测区域进行标记(350)，得到M个标记样本。 将所述M个标记样本更新为从所述区域中提取的标记样本集。 使用区域提取的更新的标记样本集来训练(360)区域提取模型。 利用喷码检测设备对所述输入图像中的喷码字符进行检测。 所述喷码检测装置包括所述区域提取模型和所述识别模型。以下包括独立权利要求：1。 用于检测喷码字符的装置； 2. 一种喷码字符检测系统。  11
本发明公开了一种目标实体的情感倾向确定方法及装置，可以获得目标实体对应的目标文本的编码向量；至少根据编码向量，对BERT模型的网络结构归一化层的层归一化公式中的缩放参数向量和平移参数向量进行调整；使用调整后的层归一化公式对目标文本进行层归一化处理，获得目标文本中每个字的情感偏好字向量；根据目标文本中每个字的情感偏好字向量，确定目标实体的情感倾向。本发明通过目标实体对应的目标文本的编码向量对BERT模型的层归一化公式中的缩放参数向量和平移参数向量进行调整，使得在对目标文本进行层归一化处理的过程中融入目标实体的实体信息，实现了对目标文本进行深层次的细粒度情感分析，提升了对目标实体的情感倾向判断的准确性。确定目标实体的情感倾向性的方法。该方法通过目标实体对应的目标文本的编码向量调整层归一化公式中的缩放参数向量和平移参数向量，从而在对目标文本进行层归一化处理的过程中融合了目标实体的实体信息，用于实现对目标文本的深层次细粒度情感分析，提高了对目标实体的情感倾向性判断的准确性。该方法包括获取目标实体对应的目标文本的编码向量。 根据编码向量，在双向编码器BERT模型的网络结构归一化层的层归一化公式中调整缩放参数向量和平移参数向量。 利用所述图层归一化公式对所述目标文本进行图层归一化处理。 获取所述目标文本中各词语的情感偏好词向量。 根据所述目标文本中各词语的情感偏好词向量确定所述目标实体的情感倾向性。包括用于确定目标实体的情感倾向性的设备的独立权利要求。  12
本申请公开了实体识别模型建立方法、系统、电子设备及介质，实体识别模型建立方法包括：对输入表示向量中的第一实体进行语言掩蔽，获得第一语言掩蔽文本后，从输入表示向量的分词结果中选取非实体词汇并对其进行语言掩蔽，获得第二语言掩蔽文本；将第一语言掩蔽文本与第二语言掩蔽文本输入到初始Transformer模型的编码层，从输出结果中获得第一隐层向量与第三隐层向量；对第一训练矩阵与第一隐层向量进行计算，获得概率分布向量后，对第二训练矩阵与第三隐层向量进行计算，获得分类概率分布向量；使用概率分布向量与分类概率分布向量对初始Transformer模型进行反向传播计算，对编码层进行更新，获得最终Transformer模型。实体识别模型的建立方法。自然语言中语言实体的语言特征缺乏考虑，导致实体发现和识别准确率低的问题。 词信息的集成增加了模型的语义丰富性。 掩蔽实体和掩蔽非实体词汇的方法增强了对语法语法模型的学习和捕捉。 预训练任务中的语言表示方式， 而且通过预测实体和非实体词汇学习实体和文本上下文之间的关系， 预测掩模部分的类型，增强模型对实体和普通词汇的图案差异，从而提高实体识别的准确性和地图构建能力。该方法包括对输入表示向量中的第一实体执行(S1)语言屏蔽以获得第一语言屏蔽文本。 从输入表示向量的分词结果中选择非实体词汇。 执行非语言掩蔽以获得第二语言掩蔽文本。 将第一和第二语言掩码输入(S2)初始模型的编码层。 从输出结果计算(S3)第一训练矩阵和第一隐藏层向量。 获得概率分布向量。 计算第二训练矩阵并计算第三隐藏层向量。 获得分类概率分布向量。 使用分布向量和分类概率分布向量对初始模型执行反向传播计算(S4)以更新编码层以获得最终模型。本发明还涉及一种用于建立实体识别模型的方法，包括：(1)建立实体识别模型； (2)电子设备； (3)电子设备可读存储介质。  12
本公开提供了一种基于Transformer模型的对话生成方法及系统，所述方案基于Transformer模型，在编码器端对角色信息和对话历史信息进行多头注意力编码和全连接层处理；在解码器端提出了一种注意力路由机制在解码器中动态权衡对话历史信息、角色信息和目标回复之间的关系，缓解了回复个性化特征不足的问题，在一定程度上提高了回复的个性化程度。一种基于变压器模型生成对话的方法。角色信息与目标回复的关系缓解了回复个性化特征不足的问题，在一定程度上提高了回复的个性化程度。该方法包括：获取角色信息和用户对话历史信息；以及将角色信息和用户对话历史信息转换为嵌入向量表示。 将变换后的字符信息和用户对话历史信息输入到预先训练好的变压器模型的编码器中，得到字符信息的特征表示和对话历史信息的特征表示。 将特征表示输入预先训练好的变压器模型的解码器中的角色信息关注模块和对话历史信息关注模块，得到角色信息表示和对话信息表示。 角色信息表示和对话信息表示输入关注路由模块。 解码结果被输入到SoftMax函数中以获得所生成的响应文本。本发明还涉及一种基于变压器模型的对话生成系统。 电子设备； 以及存储用于基于变压器模型生成对话的程序的非瞬态计算机可读存储介质。 8
本发明公开了一种角色隐式属性智能识别分析方法，包括：使用小说领域的语料对基于BERT的预训练模型进行迁移学习，获得MLM调整过的BERT的预训练模型；获取包含有角色及其属性的角色属性小说文本数据集，预处理获得带角色属性标注的文本；将正常文本的内容使用提示学习Prompt的建模方式转为新的文本序列，并将文本序列转换为文本向量InputEmbedding；将提示学习中获得的PromptText字符序列使用对比学习的建模方式构建同一文本序列中不同角色的属性特征集合，并针对角色属性特征集合构建属性类型对特征矩阵；使用主动学习对数据质量进行提纯；进行新文本的角色属性预测，自动化产出角色属性结果，再对结果作聚合投票产出最终角色属性类型。本发明还公开了实现上述方法的系统。用于生成人物设置集、人物属性图谱和辅助有声图书的实现数字化阅读中角色隐藏属性智能识别分析的方法。该方法有效识别出文本中不同角色的不同隐式属性。 该方法自动生成多场景、多角色、多属性的结构化抽取结果，从而根据字符集集合、角色属性图谱和on知识库的时间线展开自动生成相关文本。 该方法能够使用角色属性信息来辅助有声书的生成，使得音调更加丰富和准确，以产生具有高质量和声音作品的商业文本阅读器。该方法涉及使用基于来自变换器的双向编码器表示(BERT)的预训练模型的语言数据字段进行迁移学习。 得到包含角色和属性的文本数据集。 利用所述提示学习的建模模式将所述正常文本的内容转换为所述新文本序列。 文本序列被输入到由掩码语言模型(MLM)调整的BERT中以获得文本向量。 在提示文本序列的学习中构建同一提示文本序列中不同角色的属性特征集。 对新文本进行角色属性预测，用于自动生成角色属性结果。 将结果作为聚合角色属性类型。包括一种用于实现数字阅读中角色隐藏属性智能识别与分析的系统的独立权利要求。  12
本发明涉及目标检测技术领域，特别地涉及一种目标检测器的训练方法、装置、存储介质和电子设备，方法包括：获取样本数据集和预训练目标检测器，所述预训练目标检测器的主干网络包括稠密的神经网络；基于所述样本数据集对所述预训练目标检测器的主干网络进行训练，并对所述预训练目标检测器的主干网络进行剪枝，以生成稀疏的神经网络；对所述稀疏的神经网络进行重新训练，得到稠密的神经网络；能够不显著增加目标检测器的计算量的情况下，增加无锚框目标检测器的精度。所述方法和装置可用于训练电子装置(主张)中的目标检测器，以确定感兴趣的目标对象是否存在于计算机视野中的图像中的给定图像中。对预训练目标检测器的主网络进行剪枝，生成稀疏神经网络重新训练神经网络的稀疏，使得目标检测器的计算量不会显著增加，因此增加了精度的无锚框目标检测器。该方法包括获取样本数据集和预先训练的目标检测器。 所述预训练目标检测器的主网络设置有密集神经网络。 基于所述样本数据集对所述主网络进行训练，以训练所述主网络。 对稀疏神经网络进行修剪，生成基于密集神经网络的稀疏网络，并对预训练目标检测器的主网络进行修剪，生成稀疏神经网络再训练神经网络的稀疏，得到所述神经网络。独立权利要求还包括用于：目标检测器的训练装置； 以及包括用于训练目标检测器的指令集的计算机可读存储介质   4
本发明公开了一种基于文本信息增强实体嵌入的方法，包括预训练知识图谱嵌入模型，得到实体向量和关系向量；将实体向量和关系向量分别加载到实体嵌入矩阵和关系嵌入矩阵中，得到实体结构嵌入以及关系结构嵌入；预训练词向量模型，得到词向量；查询词嵌入矩阵，得到实体描述词向量和关系词向量；将实体描述词向量输入到BiLSTM网络中，在BiLSTM网络的输出层中引入点积注意力；对关系词向量取平均得到关系嵌入；将实体结构嵌入投影到关系空间，得到实体结构嵌入投影，再将实体描述嵌入和实体结构嵌入投影相加，得到实体嵌入。本发明利用网络安全知识库中附带的文本信息来增强实体的表示能力，进而提高实体链接预测的准确率。基于文本信息的实体嵌入和增强方法。该方法能够利用网络安全知识库中附带的文本信息来增强实体的表征能力，从而提高实体链路预测的准确性。该方法包括使用初始化词的词嵌入矩阵来预训练词嵌入模型以获得词嵌入。 根据关系查询词嵌入矩阵中每个词的索引，得到实体描述词嵌入和关系词嵌入。 实体描述词被嵌入并输入到双向长短期记忆(BiLSTM)网络中。 实体结构被嵌入到关系空间中。 得到实体结构嵌入投影。 将实体描述和实体结构嵌入投影进行嵌入，得到嵌入实体。  12
基于卷积神经网络预训练模型的卷积核激活值正则化方法和系统，其方法包括：1)预训练卷积神经网络模型；2)计算卷积核产生的激活值的重要程度；3)正则化处理卷积核产生的激活值，产生新的激活值，使用新的激活值代替原先的激活值；4)基于正则化处理之后的卷积神经网络模型对图像进行分类。本发明找到卷积神经网络预训练模型中每个卷积核产生的激活值的重要程度，基于激活值的重要程度对卷积核激活值进行正则化处理。根据分类结果计算损失函数，利用损失函数对卷积神经网络的参数进行更新，提升预训练卷积神经网络的图像分类性能。用于图片分类、相似图片搜索和医学图像领域的基于卷积神经网络预训练模型的卷积核激活值正则化方法。该方法能够通过使用损失函数更新卷积网络的参数来提高预训练卷积神经网络的图像分类性能，因此提高了卷积神经网络模型的性能。 该方法允许预先训练训练模型，以提高图像的分类的准确性。该方法涉及如果激活值小于或等于平均值，则在激活值的位置处对高斯函数进行积分。 如果激活值大于平均值，则将激活值相对的积分取到平均值的对称位置。 通过卷积核对生成的激活值进行正则化。 生成新的激活值。 新的激活值用于替换原激活值。 单幅图像在第一层卷积层的卷积核上生成的激活值。 用新的激活值替换原激活值。 通过反向传播算法更新模型参数，从而提高模型的性能。   4
本申请提供了一种数据检测的方法、装置、电子设备及存储介质，该方法包括：在第一交易进行的过程中，实时获取所述第一交易产生的第一待检测数据；将所述第一待检测数据输入到GPT模型中，通过所述GPT模型对所述第一待检测数据中的进行信息识别，得到所述GPT模型输出的第一风险信息；对所述第一风险信息进行风险检测，确定所述第一交易中是否为风险交易；在所述第一交易为风险交易时，生成风险提示，以提示用户终止所述第一交易。本申请通过利用GPT的语言理解和生成能力，能够对风险数据进行快速识别和分析，提高风险检测的准确性和智能化水平。用于检测金融行业中的数据的方法。该方法利用GPT的语言理解和生成能力，对风险数据进行快速识别和分析，提高风险检测的准确性和智能化水平。该方法涉及在第一交易的过程期间实时获得由第一交易生成的第一数据。 将所述第一待检测数据输入全局兴趣点(GPT)模型，得到GPT模型输出的第一风险信息。 对所述风险信息进行风险检测。 进行确定以检查交易是否是风险交易。 当所述交易是风险支付交易时，生成风险提示以提示用户终止所述交易。独立权利要求包括：(1)一种用于检测金融行业中的数据的设备； (2)一种用于检测金融业数据的电子设备； 以及(3)用于检测金融业中的数据的计算机可读存储介质。  11
本发明属于计算机技术领域，提出了一种基于深度神经网络的X光影像分割与分类预测模型。首先，对X光影像进行预处理；针对预处理后的图片，构建基于注意力机制的U‑Net图像分割模型，得到影像中包含的待检测病变区域；通过构建Inception‑ResNet v2卷积神经网络提取上述影像区域特征，预测X光片中对应组织器官发生变化的概率；将得到的预测概率和实际的结果进行对比，利用对比结果对模型中相关参数进行迭代更新，直至模型趋于收敛。本发明构建了一种行之有效的方法来利用深度神经网络完成器官变化预测，通过大量实验验证，本发明所达到的预测精度和速度优于现阶段的相关模型。用于基于深度神经网络执行X射线图像分割和分类预测的模型。本发明通过大量实验验证，构建了利用深度神经网络完成器官变化预测的有效过程，提高了现阶段的预测精度和速度。该模型具有一组用于预处理X射线图像的规则，包括数据归一化，噪声添加，随机旋转和上采样。 基于关注机制构建U-NET图像分割模型。 本发明基于初始重网神经网络构建图像分类预测模型。 数值被解释为分类预测概率。 通过使用第一阶段独立地训练图像分割模型以使其收敛。 使用第二阶段训练图像分类预测模型。 使用所获得的图像分割模型和图像分类预测模型来预测X射线图像。   4
本发明涉及一种基于动态transformer的食品图像分割方法及系统，其方法包括S1：将输入的食品图像划分为不同大小的一系列图像块，输入到多个不同尺寸的动态视觉的transformer编码器网络；输出多层不同尺度的图像特征向量；S2：提取预设层的图像特征向量进行融合，得到融合后的图像特征向量；S3：构建多级特征聚合网络，将融合后的图像特征向量进行自顶向下的特征融合，构建特征金字塔，得到多尺度特征融合向量；S4：构建分割解码器，针对特征金字塔融合的多尺度特征进行卷积和上采样操作，最终生成具有食物类别边界分割精确的分割结果。本发明提供的方法能够自适应不同图片尺度，并提高图片语义信息提取的丰富性和整体性，使得食品分割模型更具有泛化性和鲁棒性。一种基于动态分割食物图像的方法。本发明提高了图形语义信息的丰富性和完整性，从而提高了食品分割模型的泛化和鲁棒性，进而提高了食品图像分割的精度和准确性。该方法包括根据预设尺寸将输入食品图像划分为一系列图像块(S1)。 提取(S2)预设层的图像特征向量以进行融合。 融合后得到图像特征向量。 构建多级特征聚合网络(S3)。 所述融合图像特征向量从上到下被融合。 基于多层特征金字塔构造(S4)分段解码器。 利用交叉熵损失函数优化网络参数。 对融合图像特征向量执行卷积运算。 生成具有食品类型边界分割精度的分割结果。本发明还涉及一种基于动态分割食品图像的系统。   5
本发明提供的基于非对齐序列的多模态情绪识别方法，涉及计算机视觉技术领域，包括以下步骤：S1从文本模态、视觉模态和音频模态分别提取目标视频的特征，即文本表征、视觉表征和音频表征；S2根据文本模态、视觉模态和音频模态的时序结构对文本表征、视觉表征和音频表征进行特征预处理；S3通过跨模态Transformer模块将S2的结果进行融合，得到高阶互补表征。本发明能够根据三种模态的互补特征学习跨模态的融合表征，在不丢失原始模态特征的前提下，使结果更具有鲁棒性，处理更加高效，且能够平衡准确率和参数量，提高多模态情绪识别的实际应用价值。基于非对齐序列进行多模态情感识别的方法。可以根据三种模态互补特征学习跨模态融合表示，使结果在不损失原模态特征的前提下具有更强的鲁棒性，处理更加高效，精度和参数量可以得到平衡，提高了多模态情感识别的实际应用价值。该方法包括分别从文本模态、视觉模态和音频模态中提取目标视频的特征，所述特征包括文本表示、视觉表示和音频表示。 根据所述文本模态、所述视觉模态和所述音频模态的时间结构对所述文本表示、所述视觉表示和所述音频表示进行特征预处理。 通过跨模态变压器模块对特征预处理的结果进行融合，得到高阶互补表示。 将所述目标视频的转写发送至预先训练的手套模型，得到300维的文本表示。 9
本申请公开了一种多轮对话意图识别方法、装置及计算机可读存储介质，涉及人工智能领域。采用keybert获取多轮对话的原始文本中的关键词；将关键词和原始文本输入至语句转换模型中获取到embedding，并对其进行聚类，以获取包含关键词和对应的原始文本的语料数据的文档；获取各文档的关键词，从而确定文档的主题类别；获取主题类别对应的语料数据，并对语料数据标注主题类别，并输入至bert模型中进行意图识别。上述方案通过keybert获取原始文本中的关键词，考虑了语义关系；以关键词和原始文本的形式输入至语句转换模型，不会因模型的嵌入长度对原始文本的截断造成信息的丢失，提高了信息的覆盖度和意图识别的准确率。一种多轮通话意图识别方法。该方法使得能够通过关键字获取原始文本中的关键字， 为了考虑语义关系， 从而不会导致以关键字的形式输入到句子转换模型，也不会导致由于将原始文本截断模型的嵌入长度而导致的信息的原始文本丢失， 从而提高和覆盖信息的程度和意图识别的精确度。该方法包括获得多轮会话的原始文本(S10)。 由密钥BERT获得(S11)原始文本中的关键字，其中关键字和原始文本被输入(S12)模型的预训练模型以获得图像。 对簇进行聚类(S13)，以获得包含关键词和原始文本的语言数据的文档。 获取每个文档的关键字。 根据关键字确定文档的主题类别(S14)。 取得与语言数据对应的主题类别(S15)。 主题类别被标记为语言数据，并且被输入(S16)到要识别的BERT模型的语言数据。本发明涉及一种用于识别多轮会话意图的装置，包括存储器和处理器，所述处理器执行存储在所述存储器中的用于识别多轮会话意图的方法的指令； (2)包括用于识别多轮会话意图的方法的指令的计算机可读存储介质。 8
本发明公开了一种基于生成对抗网络的跨视角图像翻译方法。本发明方法包括以下步骤：1)构建图像翻译网络，图像翻译网络包括跨视角图像生成器和基于残差的级联细化模块，跨视角图像生成器选用U‑net作为骨干网络，用于合成粗糙的地面全景图像；级联细化模块用于合成细化精炼的地面全景图像；2)同时对图像翻译网络进行两个模式的训练；第一种，将真实地面图像作为编码器输入生成的符合高斯分布的潜码合并空中视角图像、全景语义图像输入图像翻译网络进行训练；第二种，采用随机采样的潜码合并空中视角图像、全景语义图像输入；3)测试阶段。本发明方法用于从单一航空图像生成多样的地面视角图像，具有更真实的细节。一种用于人工智能，计算机视觉技术领域的基于生成反网络的单幅航空图像生成各种地面视角图像的跨视角图像平移方法。该方法能够以有效的方式从单个空中图像生成各种地面视角图像。该方法包括构建图像转换网络，其中图像转换网络包括交叉视图图像生成器ROUCH，多尺度鉴别器，编码器和残差估计网络。 编码器由基于剩余卷积神经网络模块的多层构成。 将输入图像编码为潜码。 在训练阶段的同时为翻译网络训练两种模式。 使用真实地面图像作为编码器的输入，以根据高斯分布生成潜在码的高斯分布。 获得最终细化的底部全景图像以获得多样化的生成结果。 将全景语义图像和在高斯分布上随机采样的不同潜码输入到训练好的图像平移网络中，得到最终的精细化底层全景图。 获得各种产生的结果。   6
针对经典U形分割网络在分割肿瘤子区域边界精度不高的问题，本发明提出了一种融合空洞卷积的U形网络(Dilated Convolution Unet，DCU‑Net)。在经典U‑Net结构基础上，算法首先将MR脑肿瘤图像进行裁剪预处理，通过减少背景像素的输入，缓解类不平衡问题；然后用多尺度空间金字塔池化替换收缩路径末端的最大池化，在保持分辨率的同时，扩大特征感受野；最后通过Add操作引入空洞卷积残差块来改进训练网络中的跳跃连接，融合来自收缩路径低层次的特征，提高网络对肿瘤细节的识别能力，以获得更加精确的脑肿瘤分割结果。本发明在脑肿瘤自动分割中具有良好的应用前景。基于U形网络的脑肿瘤分割方法。该方法提高了肿瘤的识别能力，实现了脑肿瘤的自动分割，具有较好的应用前景。该方法包括预处理数据。 进行灰度归一化和强度归一化。 MR图像被划分为特定大小的二维图像块。 进行参数训练。 建立常规SoftMax分类损失函数。 选择初始学习速率。 随机选取脑肿瘤患者的MR图像用于获取训练集。 在测试阶段直接输入体素图像。 训练阶段用于获得用于脑肿瘤分割的测试图像。  7
本发明提供一种基于softmax的文本多标签分类方法，包括：文本预处理、文本特征向量提取、模型设计、模型训练、模型评估、模型应用，本发明使用bert模型提取句子特征向量，在使用双向门控循环单元和注意力模型构建训练网络，网络使用softmax作为激活函数而非sigmoid，同时使用配合softmax的改良交叉熵损失函数，提高负样本的学习效率，“softmax+交叉熵”没有类别不均衡的问题，因为它不是将多标签分类变成多个二分类问题，而是变成目标类别得分与非目标类别得分的两两比较，并且能够借助于LogSumExp的良好性质，自动平衡了每一项的权重，准备语料时更加容易，并且大大精简了调参过程。用于自然语言处理技术领域的多目的识别和复合情感识别的基于softmax的文本多标签分类方法。该方法能够利用LogSumExp的优良特性自动平衡每一项的权重，简化参数调整过程，并以简单的方式为语言学数据准备语言学数据。文本多标签分类方法涉及预处理(S1)文本。 对文字进行预处理，对长度相同的文字进行裁剪。 提取文本特征向量(S2)。 利用预先训练的语言模型对所述文本进行向量化操作，得到文本句向量。 采用双向门控循环单元、注意力模型和全连接网络结构构建训练网络。 通过使用所述训练网络来训练(S4)多标签分类模型。 所述网络参数在每次训练结束后根据损失函数值和验证集精度不断更新。 计算出共同的分类评价指标。 得到分类结果和置信度。  12
本公开提供了生成式大语言模型训练方法、基于模型的人机语音交互方法，涉及生成式模型、智能语音、人机交互等人工智能技术领域。该方法包括：基于用户输入文本与包含有接口调用指令的输出结果，构建第一训练集；利用第一训练集对预设的第一生成式大语言模型进行有监督微调训练，得到第二生成式大语言模型；基于相同用户输入文本与不同候选输出之间的用户偏好排序和预设模板集合，构建第二训练集；利用第二训练集对预设的第三生成式大语言模型进行有监督训练，得到奖励模型；将第二生成式大语言模型，基于奖励模型返回的得分，以强化学习方式进行训练。利用据此训练得到的生成式大语言模型可显著提升人机语音交互场景下的回复准确率和用户体验。生成大语言模型训练方法，用于训练聊天生成预训练变换器(ChatGPT)。提高了人机语音交互场景下的恢复精度和用户体验。 根据自然语言输入中包含的知识和大模型参数生成自然语言输出以调用相应的函数来更有效地解决用户需求。方法(200)涉及基于用户输入文本和匹配输出结果来构建(201)第一训练集。 基于用户偏好排序和预设模板构建(203)第二训练集。 使用所述第二训练集对所述预训练的第三生成大语言模型执行(204)所述监督训练以获得奖励模型。 基于所述奖励模型返回的得分以强化学习方式训练(205)所述第二生成大语言模型，以获得目标生成大语言模型。以下包括独立权利要求：1。 一种基于生成大语言模型的人机语音交互方法； 2. 生成大语言模型训练装置； 3. 一种基于生成大语言模型的人机语音交互装置； 4. 电子设备； 5. 一种用于训练生成式大语言模型的计算机程序产品。 8
当前，随着机器翻译、信息提取、条件搜索等领域的发展，命名实体识别作为这些领域的基础技术也取得了进一步的发展。目前常用的词嵌入分为静态词嵌入和基于上下文语义信息的动态词嵌入(如BERT词嵌入)，但是这两种词嵌入都存在一定的不足。静态词嵌入采用固定的词向量对词元进行表达，没有考虑词元在不同句子中表达语义不同的情况；而考虑上下文语义的BERT词嵌入又存在表征退化的问题，针对这种情况本方法提出了一种简单有效的词嵌入方法，通过改进静态词嵌入以及动态词嵌入的分布使其具备各向同性的分布特征，以此来提升词嵌入的语义表达能力。同时，为了更好的利用语义嵌入，针对注意力机制的计算方法进行了改进，最后基于transformer网络架构构建了基于嵌入分布改进的中文命名实体识别模型解决由于嵌入分布的各向异性带来的命名识别错误的问题。一种用于深入学习和自然语言处理领域的基于嵌入式分布改进的中文命名实体识别方法。 也可用于机器翻译，信息提取，条件搜索，飞行速度开发等领域。该方法通过改进词的静态和动态分布，使其具有各向同性的分布特性，提供了一种简单有效的词嵌入方法， 从而提高了单词的语义表达能力，解决了由于嵌入式分布的各向异性而导致的命名识别错误的问题。该方法包括获得待识别的文本对象。 对输入文本进行预处理。 将文本对象映射到词向量表示中。 对输入信息执行词向量匹配处理。 通过嵌入嵌入的信息从自注意机制模块获得最终的特征输入。 嵌入信息与词信息相匹配。 特征映射信息由前馈神经网络模块获得。 使用预训练模型获得实体和实体类型。 基于嵌入式分布改进，将修改后的输入向量发送到构建的中文姓名实体识别网络中。  12
本发明公开了一种基于视觉特征约束的细粒度图像分类方法。该方法包括如下步骤：利用CLIP方法的预训练视觉特征编码器提取图片的中间特征约束细粒度图像分类模型提取的中间特征；利用CLIP方法的预训练文本特征编码器提取的文本特征监督约束细粒度图像分类的提取的图片特征；利用CLIP方法的预训练视觉特征编码器获取训练图片的激活图，将其作为掩码对训练图片进行掩码处理后再获取掩码图片的视觉特征，将掩码图片特征与普通的视觉特征组合后再进行分类。本方法利用CLIP方法的图片和文本特征编码器帮助细粒度图像分类模型更好地提取细粒度图片的视觉特征，从而帮助提高细粒度图像分类模型的分类准确率。基于视觉特征约束的细粒度图像分类方法。本发明利用对比语言图像预训练(CLIP)方法的图文特征编码器帮助细粒度图像分类模型更好地提取细粒度图像的视觉特征，从而帮助提高分类模型的分类精度。该方法涉及在将最终图片的视觉特征通过多层感知器之后，获得每个类别的置信度。 通过交叉熵损失函数计算分类损失。 将所述第一图片特征约束、第二图片特征约束和分类损失相加，得到所述任务的总损失。 通过总损失训练ViT-B/16模型。 测试阶段将一张测试图片复制为4份。 四个拷贝旋转一定角度。 提供ViT-B/16模型分别对四个测试图片进行预测。 四份的输出结果取平均值。 平均得分最高的类别即为测试图片的预测类别。   6
本发明公开一种基于预训练主动学习的重复数据融合检测方法，包括在标记数据集中生成候选对，并将候选对进行序列化获得序列化数据集；将序列化数据集输入NER模型来识别已知类型，并使用正则表达式来识别特定类型；对序列化数据集进行预处理；将预处理后的序列化数据集输入预训练模型Bert，将选择当前模型在未标记数据集中最不确定的数据，并进行标记，再将已标记的数据将输入标记数据集；使用R‑Drop策略进行数据增强对步骤4中的标记数据集进行增强；将增强后的标记数据集继续迭代，获得最终的标记数据集。本发明结合了结合主动学习算法，选择最有价值的数据进行手工标注，降低人工标注的成本，用少量数据快速提高模型的质量。基于预训练主动学习的重复数据融合检测方法。结合主动学习算法，选取最有价值的数据进行人工标注，从而降低人工标注的成本，利用少量的数据快速提高模型的质量。该方法涉及将序列化的数据集输入到NER模型中以识别已知类型。 利用正则表达式来识别特定类型。 对序列化后的数据集进行预处理。 将预处理后的序列化数据集输入预训练模型BERT。 选取未标注数据集中当前模型最不确定的数据，并进行标注。 将所述标记数据输入所述标记数据集合。 通过使用R-Drop策略来执行数据增强，以增强标记数据集。 对增强后的标记数据集重复上述步骤继续迭代，直至迭代结束，得到最终的标记数据集。  11
本发明提供了一种客户用电安全智能分类方法，包括如下步骤：①预处理；②延拓；③捕捉上下文；④优化；⑤分类；⑥验证。本发明通过延拓思想增加位置编码数量从而解决BERT长度限制问题，丰富文本语义信息，还将双向门控循环单元与注意力机制结合，突出文本关键特征，缓解循环神经网络长距离依赖问题，并改进损失函数，增加模型泛化性能，在多个主题数据集上进行了消融测试和其他算法对比测试，证明了具有良好的泛化能力，可以达到更好的分类结果。客户用电安全智能分类方法。本发明通过扩展扩展思想来减少双向BERT长度限制问题，丰富文本语义信息，将双向选通循环单元与注意力机制相结合，突出文本关键特征，缓解循环神经网络长距离依赖问题，改善损失函数，提高模型泛化性能，实现对多主题数据集的烧蚀测试和算法对比测试，从而提高泛化能力，达到最优分类结果。该方法涉及对工单中的文本内容实现非结构化处理操作。 进行词法预处理操作，得到隐藏内容文本数据集。 利用预处理模型对之前的位置编码进行扩展，以增加位置编码数目。 输入序列由序列和反向序列编码。 该序列通过前向通道和后向通道，用于捕获当前词的上文本语义信息和下文本语义信息。 将所述当前词的上层文本语义信息和下层文本语义信息进行拼接，得到最终的上下文语义信息。 采用自注意力机制对所述预处理模型进行优化。 通过将最终输出输入到自注意力机制的全连接层来输出分类概率。 利用验证集上的评价指标验证所述预处理模型的有效性。 0
本发明提出了基于DMCNN的特殊事件提取系统，包括文本数据输入模块，输入新闻报道、广播稿的文本数据；文本数据预处理模块，用于单词嵌入预训练并对文本文档进行向量化处理；殊事件提取执行模块，用于从文档向量中根据事件参数提取特殊事件；结果输出模块，根据特殊事件提取结果输出文件；通过分类器，将对事件的提取机制转变为一个文本分类问题，对事件参数的提取比转化为一个在文本分类基础上的一个分类的属性信息的提取；本发明使用无监督的预训练词嵌入作为基本特征的来源，可提取到更有价值的线索，且准确率更高，可通过web服务系统完成大量用户并发使用BERT模型完成单词嵌入预训练，解决并发访问拥塞问题。基于DMCNN的特殊事件提取系统。该系统提高了完成大量用户的提取精度，减少了拥塞问题。该系统具有文本数据输入模块，用于输入新闻报道和播出稿的文本数据，并对文本文档进行词嵌入预训练和向量化。 特殊事件提取执行模块根据事件参数从文档向量中提取特殊事件。 结果输出模块基于所述特殊事件提取结果输出文件。 文本数据预处理模块，设置有预训练模块和向量化处理模块。 所述预训练模块通过word2vector模型进行词嵌入，得到特定语料的向量表示。  12
本发明公开了一种基于基因演化的涉密敏感信息检测方法，包括以下步骤：步骤1：对文本数据进行预处理，然后进行涉密敏感词标注得到结构化的文本；步骤2：将步骤1得到的文本输入ERNIE‑BiLSTM‑CRF模型进行训练得到涉密敏感信息检测模型；步骤3：采用人工免疫算法对涉密敏感词向量进行基因演化，得到面向涉密敏感信息的检测器；步骤4：将步骤1得到的文本输入步骤2得到的涉密敏感信息检测模型，若文本含有已知涉密敏感信息则通过涉密敏感信息检测模型进行检测；若含有涉密敏感信息检测模型无法识别的文本，则采用步骤3得到的检测器进行检测；本发明具有涉密敏感信息分类的高准确性，能够实现对未知涉密敏感信息的识别，提高了涉密敏感信息检测的鲁棒性。基于基因进化的机密敏感信息检测方法。该方法分类敏感信息准确率高，能够对未知敏感信息进行识别，提高敏感信息检测的鲁棒性。该方法包括对文本数据进行预处理。 对秘密敏感词进行标记，得到结构化文本。 ERNIE模块，用于将所述文本数据转换为动态词向量。 双向长短期记忆(BiLSTM)-条件随机场(CRF)模块用于对动态词向量进行分类，并判断其是否为敏感词。 利用人工免疫算法对敏感词向量进行基因进化得到面向敏感信息的检测器。 将得到的文本输入敏感信息检测模型。  12
本发明公开了基于TextRank和深度神经网络的情感摘要抽取方法，包括如下步骤：数据采集、监督式模型训练、无监督式摘要提取、文本情感摘要生成。本发明基于TextRank和深度神经网络的情感摘要抽取方法，采用LSTM+ATT+CNN的监督式方法训练情感句子向量，用来更新TextRank文本网络中的权重得分，进而提取具有情感色彩的摘要。针对较长文本，利用基于情感的文本向量来计算文本(句子或段落)之间的相似距离，相比基于BM25相似性的TextRank摘要提取方法更能准确地提取情感主题句，更能显示文章作者的情感核心内容，更具可读性。一种基于Textrank和深度神经网络的情感摘要提取方法。更准确地提取情感主题语句，更能显示作者的情感核心内容，产业化中更易读，更准确也存在一定的差异问题。 文本秩和深度神经网络情感摘要提取方法采用LSTM+ATT+CNN训练情感句向量的监测方法， 用于更新文本级别文本网络中的权重得分， 从而对较长文本提取具有情感颜色的摘要，与基于BM25相似度的文本秩摘要提取方法相比，利用基于情感的文本向量计算文本(句子或段落)之间的相似距离。所述方法包括：采集数据清洗后的源数据；对所述源数据进行相应的数据标注和知识整理，得到数据集。 对LSTM+ATT+卷积神经网络(CNN)模型进行训练，得到文档短句向量。 根据皮尔逊系数计算句子向量相似度矩阵。 文本网络权重通过使用监督类型的语句向量来更新。 生成文本情感摘要。 根据TOPK原则选择关键语句。 并按照文本中关键词出现的顺序组合成情感摘要。  12
本申请涉及人工智能，提供了一种基于裁判文书的双向编码器表征量模型优化方法和装置。所述方法包括：根据初始双向编码器表征量模型，确定出与法律裁判文书数据对应的初始预训练模型。获取根据法律裁判文书数据确定的预设个数的案由类别，并为各案由类别添加对应的类别标签。基于类别标签从法律裁判文书数据中提取出对应的训练数据集，并对训练数据集进行数据预处理。基于预处理后的训练数据集，对确定出的初始预训练模型的特定超参数进行优化训练，得到优化后的双向编码器表征量模型。采用本方法实现了根据优化后的双向编码器表征量模型对法律裁判文书的自然语言表征，提升双向编码器表征量模型在裁判文书所属的法律知识领域的应用效果。一种使用计算机装置优化基于裁判文档的双向编码器表征量模型的方法(要求保护)。本发明能够根据优化后的双向编码器特征量模型实现法律判断文档的自然语言表示，提高双向编码器特征量模型在参考文档法律知识领域的应用效果。该方法包括确定对应于法律判断文档数据的初始预训练模型。 根据法律判断文件数据得到预设号码的案例。 为每种情况添加类别标签。 基于类别标签从法律判断文档数据中提取训练数据集。 对训练数据集执行数据预处理操作。 对初始预训练模型的特定超参数执行优化训练。 获得优化的双向编码器表示量模型。本发明还涉及一种用于优化基于裁判文档的双向编码器特征量模型的装置，所述双向编码器特征量模型由计算机装置优化； 以及计算机存储介质，包括一组指令，用于通过使用计算机设备基于裁判文档优化双向编码器特征量模型。  11
本发明涉及一种医学知识图谱生成方法、装置、电子设备及存储介质，该方法包括：获取具有医学实体的医学病历文本，并对其进行预处理，以构建医学语料库。调用自然语言处理大模型对医学语料库中的医学实体进行识别，以提取医学实体以及医学实体之间的第一实体关系。基于医学实体以及医学实体之间的第一实体关系，获取多个互相关联的第一三元组，第一三元组由医学实体以及医学实体之间的第一实体关系共同组成。基于多个互相关联的第一三元组，获取资源描述框架图，资源描述框架图由多个互相关联的第一三元组组成，用于构建医学知识图谱。基于医学知识图谱中不同医学实体之间的关联度，调用大语言模型对不同医学实体进行推理，以生成第二实体关系。一种用于医疗健康领域的医学知识图谱的生成方法。最大程度的对医学知识图谱进行补充和完善，摆脱了传统知识图谱生成方法中对知识图谱质量的大量人工验证和修改。 节约了成本，同时保证了医学知识图谱的质量。该方法涉及获取(S110)第一文本数据，并对第一文本数据进行预处理以构建医疗语料库，第一文本数据是具有医疗实体的病历文本。 调用所述自然语言处理大模型(S120)，对所述医疗语料中的医疗实体进行识别，以提取所述医疗实体与所述医疗实体之间的第一实体关系。 基于若干个相互关联的第一三元组来获得(S140)资源描述框架图。 资源描述框架图由若干个相互关联的第一三元组组成，用于构建医学知识图谱。 调用(S150)所述大语言模型对所述不同医疗实体进行推理，以基于所述医疗知识图谱中不同医疗实体之间的关联程度生成第二实体关系。以下包括独立权利要求：1。 医学知识图谱生成装置； 2. 电子设备； 3. 存储用于生成医学知识图谱的程序的计算机存储介质。  10
本申请提供的文本向量生成方法、模型训练方法及相关装置中，对于获得的文本序列，文本处理设备将该文本序列的先验向量以及该文本序列的字向量、位置向量、段向量一起输入到文本向量模型的Bert层，使得该文本向量模型将文本序列的先验向量作为参考，从中获得文本序列中可能的词汇知识，用于将文本序列转换为文本向量。由于该先验向量携带有文本序列中词汇的先验信息，从而实现在不依赖于词典进行分词的情况下，通过该先验信息辅助文本向量模型对文本序列进行转换，获得文本序列更为准确的文本向量。文本向量的生成方法。该方法能够通过信息辅助文本向量模型对文本序列进行转换，实现不依赖于词典的分词，从而获得文本序列更准确的文本向量。所述方法包括：获取所述文本序列的先验向量，所述先验向量携带所述词表的先验信息，所述词表由所述文本序列中的文本组成; 根据所述Bert层指定输入向量，生成所述文本序列的词向量、位置向量和分词向量; 将所述文本序列的词向量、位置向量、分词向量和所述先验向量输入到所述Bert层，得到所述文本序列的文本向量。还包括独立权利要求，用于：模型训练方法； 文本向量生成装置； 文字处理装置； 以及包括用于生成文本向量的指令集的计算机可读存储介质。  12
本公开的实施方式提供了一种歌曲搜索方法。该歌曲搜索方法包括：响应作用于多媒体页面中搜索框的图片获取操作，获取目标图片；将目标图片输入至歌曲搜索模型中，搜索输出目标图片中包含的对象特征对应的歌曲，以及输出歌曲的主题词和/或推荐语；其中，歌曲搜索模型包括用于根据目标图片匹配得到歌曲的多模态预训练模型，和用于根据歌曲的歌曲信息生成主题词和/或推荐语的自然语言处理模型。本公开的方法通过对包含对象特征的目标图片理解准确，可以更加精确地匹配到和目标图片对应的歌曲，并为搜索到的歌曲生成主题词和/或推荐语，为用户带来了更好的体验。此外，本公开的实施方式提供了一种介质、装置和计算设备。通过使用计算装置的多媒体平台搜索歌曲的方法(权利要求书)。该方法能够根据目标图片通过多模态的预训练模型对主题词和推荐词进行匹配得到歌曲，给用户带来更好的体验。该方法包括将目标图片输入歌曲搜索模型。 根据目标图片中包含的对象特征搜索歌曲并输出，所述歌曲搜索模型包括多模态预训练模型和自然语言处理模型。 通过所述多模态预训练模型根据目标图片对主题词和推荐词进行匹配，得到歌曲。 根据歌曲的歌曲信息，基于所述主题词和所述推荐词，通过自然语言处理模型生成歌曲的信息。独立权利要求包括：(1)一种介质，包括一组指令，用于存储通过使用计算设备通过多媒体平台搜索歌曲的程序； (2)一种歌曲搜索装置。  11
本发明属于自然语言处理技术领域，具体涉及了一种基于BART模型的口语理解数据增强方法、系统及设备，旨在解决的问题。本发明包括：将训练数据进行变换，去除其语义槽值信息或上下文表达方式的信息；利用预训练语言模型BART在变换的数据上进行调优，获得两种调优模型；分别使用两种调优模型和少量训练数据进行增强数据的生成；对增强数据进行过滤处理，获得最终的增强训练数据。本发明在只利用少量训练数据的前提下，可以生成具有不同语义槽值和上下文的带标签的增强训练数据，有效地提高了口语理解模型在少量数据下的语义槽填充的性能。基于BART模型的口语理解数据增强方法。本发明实现了在使用少量训练数据的前提下，生成具有不同语义沟值和上下文的标签的增强训练数据，有效提高了少量数据下口语理解模型语义沟填充的性能。该方法涉及获得口腔理解模型的训练数据。 获得第一预处理数据和第二预处理数据。 分别为所述第一预处理数据和所述第二预处理数据确定第一损失函数和第二损失函数。 基于第一损失函数和第二损失函数分别优化预训练语言贝叶斯加性回归树(BART)模型，以获得第一优化模型和第二优化模型。 通过所述第一优化模型和所述第二优化模型分别得到第一增强数据和第二增强数据。 基于所述第一增强数据和所述第二增强数据获取所述口腔理解模型的增强训练数据。包括以下独立权利要求：一种用于基于BART模型增强口语理解数据的电子设备； 以及用于存储用于增强基于BART模型的口语理解数据的指令集的计算机可读存储介质。  12
本发明涉及人工智能技术领域，提供一种文本纠错方法、装置、设备及存储介质，用于提高文本纠错的准确性和效率。文本纠错方法包括：获取原始文本数据集的目标混淆词典，并通过目标混淆词典，对原始文本数据集进行字词替换，得到错别字文本数据集；获取再训练文本数据集，通过错别字文本数据集、预设损失函数和再训练文本数据集，对预置的初始文本纠错模型进行训练，得到目标文本纠错模型，目标文本纠错模型包括基于bert模型的校正网络；获取待处理文本，通过目标文本纠错模型和目标混淆词典，对待处理文本依次进行位置错别字概率计算和字典字词纠正，得到纠错后的文本。文本纠错方法，用于合成智能的智能决策领域，用于自然语言处理，包括语音识别、检索、意图识别和对话系统等多种应用场景。该方法能够提高对罕见特殊名词或名词记错字典导致的文本纠错的准确性和效率，提高了目标文本纠错模型的智能性和泛化能力，通过不需要比对字典进行纠错来对网络进行纠错，训练大规模数据集，使得运算速度更快、效率更高、智能性更强，通过目标文本纠错模型对待处理文件进行文本纠错处理。该方法包括获取目标混淆词典的原始文本数据集。 对所述原始数据集进行单词替换处理，得到错别字文数据组。 获得再训练文本数据组。 通过所述错别字本、预设损失函数和所述重训练数据组训练预设的初始文本纠错模型，得到所述目标文本纠错模型。 对所述待处理文本进行位置错误词概率计算和字典词纠正处理，得到纠错后的文本。独立权利要求还包括：一种文本纠错装置； 文本校正装置； 以及包括用于校正文本错误的指令集的计算机可读存储介质。  11
本申请提供一种数据集构建的方法和服务器。本申请的方法，根据给定的任务需求信息构建指令集；基于指令集所包含的指令迭代进行如下处理：将指令输入预训练大模型，生成指令的答复信息，基于指令的答复信息进行数据标注构建包括指令及指令答复信息的有监督训练数据，使用所构建训练数据优化预训练大模型；直至所构建的训练数据的总数满足预设需求时，输出包含所构建训练数据的数据集，通过数据回流的方式利用已构建的训练数据优化预训练大模型，提升预训练大模型生成答复信息的质量，随着迭代次数的增加预训练大模型的生成质量提升，可降低对所生成答复信息的标注成本，提升标注效率，进而提升构建数据集的效率。构建文档问答数据集的方法。预训练大模型的生成质量随着迭代次数的增加而提高，可以降低生成的回复信息的标记代价，提高标记效率，以提高构建数据集的效率。该方法包括基于给定的任务要求信息构造(S31)指令集。 将指令输入(S32)到预训练的大模型中，生成指令的回复信息，基于指令的回复信息进行数据标注(S33)，构建包括指令和指令回复信息的训练数据，并使用训练数据(S34)基于指令集中包含的指令对预训练的大模型进行优化。 输出包含所构建的训练数据的数据集(S36)，直到所构建的训练数据的总数满足需求。独立权利要求包括如下内容：(1)文档问答数据集构建方法； 以及(2)服务器包括处理器和存储器。  11
本发明公开了一种基于知识生成的视觉问答方法、装置及存储介质，属于视觉问答领域。其中方法包括以下步骤：基于问题引导的图像描述，将图片信息转化为问题相关的文本描述；构建提示模板，根据提示模板引导语言模型生成符合样式的多条候选知识；将所述候选知识、问题文本以及图像输入到统一编码器中，进行联合编码，获得多模态表征；对多条候选知的多模态表征识进行融合，获得知识增强特征，根据知识增强特征进行答案预测。本发明通过知识生成，只需少量的学习样本即可将预训练模型的积累的知识迁移到新的下游任务中，可广泛应用于开放场景下的知识视觉问答。基于知识生成的视觉问答方法。通过知识生成，只需要少量的学习样本就可以将预训练模型积累的知识迁移到新的下游任务中，该方法可以广泛应用于开放场景下的知识可视化问答。该方法涉及基于问题引导图像描述将图片信息转换(S1)成与问题相关的文本描述。 构建提示模板(S2)。 根据所述提示模板引导所述语言模型生成符合所述风格的候选知识。 将候选知识、问题文本和图像输入(S3)到统一编码器中。 进行所述联合编码，得到多模态表征。 对所述候选多模态表征标识进行融合(S4)，得到知识增强特征。 根据所述知识增强特征进行答案预测。对于基于知识生成的视觉问答设备，包括独立权利要求。  11
本发明提出一种基于动态联邦学习的储层识别方法，主要涉及深度学习，石油勘探领域。主要步骤包含：确定实验井，进行数据预处理；设计基于联邦学习的储层识别方法，以借助目标井所在区块的周边区块中的储层样本，来训练一个具有高泛化性的领域预训练模型；设计动态加权融合策略，以解决区块间地质差异显著的问题；设计基于重加权的储层类别均衡方案，以解决储层类别不均衡的问题，从而提高储层识别的效果。本发明针对目标区块储层样本不足，借助联邦学习方法，使用周边区块储层样本识别目标井中储层类别，并对联邦学习方法进行优化，实现有效的储层识别。用于石油勘探开发的地质资源勘探领域、深度学习、数据挖掘领域的基于动态联合学习的储层识别方法。基于权重加权设计储层类型均衡方案，从而解决储层类型不均衡的问题，以提高储层识别的效果。该方法涉及选择一口直井作为实验井的油田实际开发验证。 去除曲线异常值。 对测井曲线进行预处理。 基于联合学习设计储层识别过程。 将目标井的区块的周边区块中的储层样本用于训练具有高泛化度的现场预训练模型。 设计动态加权融合策略，解决区块间地质差异明显的问题。 设计了基于权重加权的储层类型均衡方案，解决了储层类型不均衡的问题，提高了识别效果。   4
本公开提供了图案生成方法、装置和电子设备，涉及计算机技术领域，具体为人工智能技术和大语言模型技术领域，具体实现方案为：接收用户设备发送的图案指示信息，并基于所述图案指示信息，获取待填色图案；接收所述用户设备发送的所述待填色图案的填色数据；基于所述填色数据，对所述待填色图案进行填色处理，生成目标图案，本公开基于图案指示信息，获取待填色图案，有效地解决了填色图案有限的问题，可以为用户提供丰富的填色图案，提高了用户的体验感。一种利用服务器生成色彩填充图案的方法。该方法能够获取待填充图案，从而有效地解决了色彩填充图案受限的问题，为用户提供丰富的色彩填充图案，从而有效地提高了用户的体验。该方法涉及接收由用户设备发送的模式指示信息。 基于所述图案指示信息获取待填充图案。 由所述用户设备接收所述待填充图案的色彩填充数据。 根据所述补色数据对所述待补色图案进行补色处理以生成目标图案。 向用户设备显示候选模式提示。 接收所述用户设备发送的提示词选择指令。 根据所述提示词选择指令获取图案提示词。独立权利要求包括用于：(1)一种利用服务器生成色彩填充图案的装置； (2)一种电子设备，包括存储器和处理器，所述处理器用于执行用于生成色彩填充图案的一组指令； (3)非瞬时计算机可读存储介质，其存储有用于生成色彩填充图案的计算机指令; (4)一种计算机程序产品，包括用于生成色彩填充图案的计算机程序。 14
本发明公开了一种基于BERT语言模型和TextCNN模型的多意图识别方法及系统，属于自然语言处理技术领域。本发明基于构建的专业术语分词库与获取的训练数据集构造标签矩阵，标签矩阵很好地利用了每个标签下包含的专业术语，让模型能够更好地学习这些专业术语的数据特征；并根据标签矩阵，在损失函数中增加了每个标签下的专业术语的词频特征，损失函数结合标签矩阵提升了模型的学习能力，并加快了模型收敛，又保障了模型的可导与迭代优化，使得模型的训练效果更好，预测准确度更高。用于智能客服机器人自然语言处理技术领域的基于BERT语言模型和TextCNN模型的多用途识别方法。该方法能够提高损失函数、损失函数结合标签矩阵中每个标签下专业术语的词频特性，从而提高模型的学习能力，加快模型的收敛速度，保证模型的指导和迭代优化，从而提高模型的训练效果，具有较高的预测精度。该方法涉及构建专业术语词库的多用途识别场景。 对得到的模型训练数据集中的每个样本划分一个专业术语分词词库，进行逐条标签扫描。 基于标签矩阵构建模型训练的损失函数。 通过作为预训练模型的BERT语言模型学习所述训练数据的数据特征。 将一个存储模块中存储的每个样本的专业术语转换为对应的词向量。 将所述词向量进行融合，形成与所述样本相关联的句子向量，并输出至TextCNN模型。 通过所述多目的识别模型对语言学数据待识别目标进行训练，以完成训练。 模型输出意图识别结果。还包括独立权利要求的一种基于BERT语言模型和TextCNN模型的多用途识别系统。  12
本申请涉及语义识别领域，揭示了一种词语语义模型的构建方法、装置、计算机设备及存储介质，其中方法包括：获取包含若干词语信息的语句，根据先验数据识别所述语句，将所述语句进行分词处理；获取所述语句进行分词处理后的多字词与单字词，对多字词与单字词进行编码，根据编码后的多字词与单字词生成词信息提取矩阵；获取编码后的多字词，将同一个多字词以首个字作为代表对所述多字词进行提取；获取编码后的单字词，对所述单字词进行提取，根据提取后的多字词与单字词生成词信息代表矩阵；获取BERT模型的填充矩阵，将词信息提取矩阵、词信息代表矩阵与填充矩阵进行与操作，生成词语语义识别模型。本申请能够提高不同领域的专业词语的识别准确度。建立词语语义模型的方法。该方法能够提高对不同领域的专业词语的识别精度。该方法包括对句子进行分词处理后得到多词和单词。 根据编码后的多字和单字生成字信息提取矩阵。 建立所述多词中包含的不同词的关联关系。 根据提取的所述多字词和所述单字词生成词信息表征矩阵。 提取出词信息矩阵。 对词信息表示矩阵和填充矩阵进行运算。 建立词语语义识别模型。独立权利要求包括如下：一种建立词语语义模型的装置； 计算机设备； 以及存储用于构建词语语义模型的指令集的计算机可读存储介质。  11
本发明涉及人工智能技术领域，提供一种数据校验方法、装置、电子设备及存储介质，所述方法包括：加载校验请求中的多个目标待校验数据至EXCEL模板中；读取EXCEL模板的规则栏对应的每个单元格的关键字段；将每个单元格的关键字段输入至预先训练好的BERT模型中，并获取BERT模型输出的每个单元格的规则属性；对所有单元格的规则属性进行合并得到EXCEL模板的校验规则表；根据校验规则表对EXCEL模板中的每个单元格中的目标待校验数据进行校验。本发明通过BERT模型输出的每个单元格的规则属性，不需要编码维护每个单元格的规则属性，确保了每个单元格的规则属性的准确性，进而提高了数据校验的效率和准确率。通过电子设备(要求保护)在合成智能中的数据验证方法。该方法能够保证单元格的规则属性的准确性，从而提高数据校验的效率和准确性。方法包括将检查请求中要检查的多个目标加载到Excel(RTM：非免费商业电子表格应用)模板。 对应于Excel(RTM：非免费商业电子表格应用)模板的规则条读取单元格的关键字段。 将所述细胞的关键字段输入预先训练好的BERT模型中。 通过BERT模型得到单元格输出的规则属性。 合并单元格的规则，得到Excel(RTM：非免费商业电子表格应用)模板的校验规则表。 根据校验规则表对单元格Excel(RTM：非免费商业电子表格应用程序)模板中的待校验目标数据进行校验。独立权利要求还包括：数据校验装置； 以及包括用于数据验证方法的指令集的计算机可读存储介质。  12
本申请提供一种图像处理及模型训练的方法和设备。本申请的方法，在将预训练模型应用于具体的图像处理任务时，通过在预训练模型的transformer转换层中插入通道调优模块得到图像处理模型，通道调优模块用于对转换层所提取的中间特征图中至少一个目标通道的特征进行变换处理，在模型训练时，基于当前图像处理任务的数据集，选择中间特征图中包含更丰富特征的通道作为目标通道，使用该数据集对图像处理模型中通道调优模块的参数进行训练，而预训练模型的原有参数保持不变，可以大大减少可训练参数的数量，防止过拟合，从而提高图像处理模型的精度。用于通过使用电子设备(要求保护的)即计算机训练图像处理模型的方法，用于计算机视觉任务，例如图像分类、图像分割、图像检测和图像处理任务。该方法实现了预训练模型的原始参数不变，从而大大减少了训练参数的个数，避免了大规模模型对小训练集的过拟合，从而提高了模型应用于具体图像处理任务的准确性。 该方法使得能够提高图像处理模型的精度，因为通道优化模块用于对转换层提取的中间特征图中的目标通道的特征进行转换。该方法涉及获得图像处理任务的数据集和待训练的经训练的图像处理模型(S301)。 通过在预训练模型的转换层中插入信道优化模块，得到训练模型。 将数据集中的样本图像输入(S302)到训练模型中。 通过所述转换层对所述样本图像进行特征提取。 对所述转换层提取的中间特征图像中的目标通道特征进行转换处理。 根据转换级的最终输出的特性确定图像处理结果(S303)。 根据样本图像的训练结果和标注信息对训练模型中的通道优化模块的参数进行训练(S304)，以获得已训练模型，其中，训练参数对输入图像进行处理，以获得图像处理结果。独立权利要求还包括：一种遥感图像处理模型训练方法； 以及图像处理方法； 以及一种用于通过使用电子设备来训练图像处理模型的系统； 以及计算机可读存储介质，其包括用于通过使用电子设备来训练图像处理模型的指令集。 14
本公开是关于一种多标签文本分类方法、装置及存储介质。多标签文本分类方法包括：确定待进行标签标注的文本数据；基于ALBERT语言模型提取所述文本数据的文本特征；将所述文本特征作为序列到序列模型编码部分的输入，得到编码输出和编码隐状态，并将所述编码输出和所述编码隐状态作为序列到序列模型解码部分的输入，得到解码输出的一个或多个字；将所述解码输出的一个或多个字映射为一个或多个标签，基于所述一个或多个标签得到所述文本数据的标签。通过本公开能够提高多标签文本分类的准确率和召回率。该方法可用于对多标签文本进行分类。本发明能够提高多标签文本分类的准确率和查全率。方法包括确定待标记的文本数据。 基于Albert语言模型提取待标注文本数据的文本特征。 将文本特征作为序列到序列模型编码部分的输入。 获得编码输出和编码隐藏状态。 编码输出和编码隐藏状态作为序列到序列模型解码部分的输入。 获得解码输出的多个字。 解码输出的字被映射到多个标签中。 基于所述标签获得所述待标注文本数据的标签。还包括独立的权利要求： 一种用于对多标签文本进行分类的装置； 以及 一种非瞬时计算机可读存储介质，包括一组用于分类多标签文本的指令。  11
本申请提供了一种医疗建议生成方法、装置、电子设备和可读存储介质，涉及数据处理及数字医疗技术领域。该方法包括：获取患者的病情描述信息；对所述病情描述信息进行自然语言分析处理，得到病症关键词和患者意图；对所述病症关键词和所述患者意图进行病情分析处理，生成针对所述患者的医疗建议；其中，所述自然语言分析处理和所述病情分析处理基于聊天生成预训练模型进行。本申请实施例，能够更加准确地了解患者的病情，提供更好的医疗参考建议，减轻了医生的工作负担，提高了医疗资源的利用效率和诊疗质量，且降低了患者等待时间。用于生成医疗建议的方法。本申请能够更准确的了解病人的病情，提供更好的医疗参考建议，减少医生的工作负担，提高医疗资源的利用效率和诊断质量，减少病人的等待时间。该方法包括获得患者的描述信息。 对所述疾病状态描述信息进行自然语言分析处理，得到疾病状态关键词和患者意图。 对所述病情关键词和所述患者意图进行分析处理，生成针对所述患者的医疗建议，其中，所述自然语言处理和所述病情分析处理基于聊天生成预训练模型进行。独立权利要求包括：(1)医疗建议生成装置； (2)电子设备； (3)一种可读存储介质，其上存储有程序或指令。  10
本发明公开了一种基于transformer模型和对比学习的睡眠分期方法及系统，该方法步骤包括：生理信号数据预处理，进行数据帧的合并，划分数据集，进行数据增强处理并将transformer模型初始化；构建基于transformer的睡眠分期特征提取神经网络，利用自监督对比学习方法，建立损失函数和反向传播模型，对睡眠分期特征提取网络进行预训练，在预训练的睡眠分期特征提取网络的后端加入全连接网络进行有监督训练；在有监督训练睡眠分期特征提取网络的后端再加入双向长短时记忆网络进行有监督训练；训练获得睡眠分期模型，将测试数据集输入训练后的睡眠分期模型得到分类结果。本发明对睡眠分期的准确率有所提升。用于在专业睡眠实验室中基于模型和对比学习对患者的多指导睡眠(PSG)进行分期和监测的方法。该方法保留了模型的编码器组件，使得自注意力机制能够充分研究生理信号的特征表示，从而有效地提高了睡眠分期的准确性。该方法包括对生理信号数据进行预处理，按设定长度组合数据帧，分为无标记预训练数据集、有标记训练数据集和测试数据集，对组合数据帧后的生理信号数据进行数据增强处理，模型初始化，在模型网络后设置两个全连接网络层和一个非线性激活层作为映射层，用于再次对生理信号的深度语义信息进行信息提取，采用自监督对比学习方法， 在监控训练睡眠分期特征提取网络后端加入双向长时记忆网络，使用带有标记的训练数据集进行监督训练，训练睡眠获取模型，确定最终模型参数，将测试数据集输入睡眠分期模型，得到分类结果。还包括用于基于模型和对比学习的睡眠分期系统的独立权利要求。   4
本申请实施例提供了一种基于对比学习的车辆关键点检测方法及系统，所属包括以下步骤：S10，获取训练样本图像集；S20，建立基于heatmap+softargmax回归的关键点检测模型并进行训练，得到预训练网络模型；S30，基于预训练网络模型构建simCLR框架，通过simCLR框架对预训练网络模型进行调整，得到最终网络模型；S40，将待检测图片输入到最终网络模型中，得到车辆关键点信息；解决传统的关键点检测技术对数据量的依赖，检测准确度低的问题；适用于视觉检测的技术领域。一种基于对比度学习的车辆关键点检测方法。该方法通过比较学习模式，增强了关键点检测网络的迁移能力，使得对不同分布值的数据都得到了良好的效果，提高了车辆关键点信息的检测精度。该方法包括获取训练样本图像集。 基于map+softargmax回归和训练建立关键点检测模型。 得到预训练网络模型。 基于所述预训练的网络模型构建simCLR帧。 通过所述simCLR帧对所述预训练模型进行调整，得到最终的网络模型。 将待检测图片输入所述最终网络模型，得到车辆关键点信息。本发明还涉及一种用于基于对比学习来检测车辆关键点的系统。 13
本发明实施例提供了一种数据查询方法、系统及相关设备，用于实现数据库的自然语言查询功能。本发明实施例方法包括：将预设BERT模型作为编码器，并设置解码器对所述编码器进行解码得到输出值集合，所述输出值集合包括过滤条件数量、过滤条件的字段名、过滤条件对应的操作类型、多个过滤条件的关系；采用预设样本数据对所述预设BERT模型及解码器进行训练，得到深度学习模型；接收客户端发送的自然语言查询语句，并采用所述深度学习模型对所述自然语言查询语句进行处理，并根据生成的输出值集合得到过滤条件集合；根据所述过滤条件集合在数据库中查询对应的目标数据，并返回给所述客户端。该方法对于通过使用计算机设备(要求保护的)查询数据是有用的。数据查询方法包括：使用预设的双向编码器表示(BERT)模型作为编码器，并设置解码器对编码器进行解码，得到输出值集合，输出值集合包括多个过滤条件、字段名、操作类型以及多个过滤条件之间的关系; 使用预设的样本数据对预设的BERT模型和解码器进行训练，得到深度学习模型; 接收客户端发送的自然语言查询语句，使用深度学习模型对自然语言查询语句进行处理; 根据生成的输出值集合获取过滤条件集合，根据所述过滤条件集合在数据库中查询对应的目标数据并返回给所述客户端，验证所述过滤条件集合中的字段值类型，若所述字段值类型与对应的目标过滤条件的值类型不匹配，则删除所述目标过滤条件。独立权利要求还包括：一种用于通过使用计算机设备来查询数据的系统； 以及一种计算机可读存储介质，包括用于通过使用计算机设备查询数据的指令集。  12
本发明涉及一种基于单目热红外摄像头的铁轨异物识别方法及系统。包括：在传统的半自动标注算法基础上利用了多种不同网络模型进行半自动标注，获得带有更为精确的半自动图像轮廓信息；在语义分割网络中，将热感图像特征图和基于热感图像灰度处理的特征图进行融合，并增加了权重因子规格化模块操作，获得异物分割图；提出基于改进的跨模态融合的主干神经网络，通过transformer将分割图和热红外图的跨模态特征点和模态信息进行融合，利用蒸馏学习方法压缩网络参数实现了轻量级的异物识别；提出一种监控报警设备，用于监控和报警铁轨异物入侵；本发明提高了在各种环境下铁轨异物识别的效率和准确度，能够有效降低异物入侵铁轨造成列车事故的可能性。一种车辆或运输系统即列车中基于单目热红外相机的钢轨异物识别方法。该方法能够提高各种环境下钢轨异物识别的效率和准确率，从而有效降低异物侵入钢轨引发列车事故的可能性。该方法包括提供用于初始热敏图片的半自动标记图像简档信息。 异物主要通过yolov5定位，以便采用不同的模型进行语义分割处理和不同的目标类型。 根据分割结果自动标记原始图像集。 精确的半自动标记图像轮廓信息是通过人工复核校正获得的。 通过融合将一个跨模态特征点和模态信息进行融合。 通过使用改进的蒸馏学习过程来简化神经网络。 实现了轻量异物识别过程。独立权利要求包括用于一种基于单目热红外相机的钢轨异物识别系统。   6
本发明提供一种引入连续潜变量的多样性回复生成方法。包括以下步骤：步骤S1：处理对话数据，构建输入对话数据：将所有对话视作连续文本，以每次切换说话者作为分割，依照对话先后顺序交替给出对话数据，从而构建出输入对话数据。步骤S2：对话行为识别：将对话输入选定的BERT语言模型，利用BERT语言模型的输出计算当前对话行为，在代表对话行为接入四个全连接神经网络即构建transformer模型，使用模型识别当前对话行为；步骤S3：输出回复生成：使用步骤S2的transformer模型的对话行为识别部分计算得出的对话行为值，生成候选回复，然后验证候选回复正确概率选择最终回复结果。在对话系统中引入连续潜在变量产生分集恢复的方法。在连续的潜在变量空间中对对话动作进行建模，提高了对话响应多样性，提高了对话回复质量。该方法包括处理(S1)对话数据并构造输入对话数据。 会话被看作是连续的文本。 每次切换说话人作为分段。 按照所述会话序列交替给出所述会话数据，以构建所述输入会话数据。 识别对话行为(S2)，并将对话输入到所选择的BERT语言模型。 通过使用BERT的输出来计算当前对话动作。 访问代表性对话动作中的四个全连接神经网络。 构建权力模型以识别当前对话动作。 通过使用由对话行动识别单元计算的对话行动值，输出回复生成并生成候选回复(S3)。 验证所述候选回复选择最终回复结果的正确概率。 8
本发明公开了一种基于BERT采样的文本通用触发器生成系统和方法，设置初始单词序列长度m及批次大小n，将初始单词序列复制n份得到n个单词序列，在其上随机选择第i个位置，将初始单词序列输入到BERT语言模型中，获得第i个位置单词的概率分布；采样一个单词y，将第i个位置的原始掩码符号替换为单词y，得到一批初始触发词序列，并连接到数据测试集的所有样本上，输入到目标模型进行测试；将测试结果传输到BERT采样模块，并调整单词分布概率，然后采样获得候选单词；继续将候选单词在除第i个位置外的其他位置上进行替换，直到目标模型的预测错误率达到设定值阈值以上，输出触发器序列。本发明具有效率高、质量好的优点。基于双向编码器表示从变换器(BERT)采样的文本通用触发器生成系统。文本通用触发生成系统效率高，质量好。该系统具有连接到输出模块(4)的连接模块(3)。 所述输出模块连接有BERT采样模块(5)。 然后将BERT采样模块连接到触发生成模块(2)。 输入模块(1)设置初始输入词长。 触发生成模块会随机选取一个单词位置，根据BERT采样模块的单词分布情况，在选取的位置填充单词。 连接模块将生成的触发器与测试样本一一连接，然后送入输出模块。 输出模块对目标模型添加了触发器的测试样本进行识别，并输出测试结果。 BERT采样模块根据输出模块的测试结果调整词分布概率。包括一种用于基于BERT采样生成文本通用触发的方法的独立权利要求。  12
本说明书实施例提供一种模型训练方法、系统和存储介质。所述方法包括：获取预训练样本，所述预训练样本包括预训练图像和多个参考任务对应的多幅金标准图像；利用预训练样本对初始模型进行预训练，获取预训练模型，初始模型为可以实现多个参考任务的多任务模型；以及基于目标训练样本和预训练模型，生成用于实现目标任务的目标模型，目标训练样本包括目标训练图像和目标任务对应的目标金标准图像，目标训练图像与预训练图像具有相同的图像模态。一种基于大量数据集的模型训练方法，用于信息处理技术领域。目标训练图像和预训练图像设置有相同的图像模式，从而能够有效地进行模型训练过程。该方法包括获得(310)预训练样本，其中预训练样本包括预训练图像和对应于多个金标准图像的多个参考任务。 通过使用所述预训练样本来获得(320)预训练模型。 所述预训练模型为能够实现多个参考任务的多任务模型。 基于所述目标训练样本和所述预处理后的模型生成(330)目标模型，以实现目标任务。 所述目标训练样本包括目标训练图像和所述目标任务对应的目标金标准图像，采用与所述预训练图像相同的图像模式。还包括用于以下的独立权利要求：模型训练系统； 以及一种计算机可读存储介质，包括用于基于大量数据集训练模型的一组指令，用于信息处理技术领域。  11
本发明提供了一种融合句法和语义表示的属性抽取方法，属于文本情感分析技术领域；解决了目前基于句法的属性抽取方法得到的评论文本表示不准确、效率低、模型的属性抽取性能低的问题，包括如下步骤：采用混合预训练模型实现句子嵌入表示；采用双向长短期记忆模型获得单词隐式表示；构建句法图卷积神经网络实现异构句法树编码；构建语义图卷积神经网络实现语义图编码；采用相互的双仿射变换构建新的句法树编码和语义图编码；采用融合门构建最终句子表示；构建句法感知指针神经网络，预测属性的开始位置和结束位置；构建条件随机场，实现单词标签预测；构建相应的损失函数，实现模型训练；本发明应用于文本属性抽取。基于社交媒体评论信息实现融合语法语义表示的文本属性抽取的方法。该方法能够实现当前基于语法的属性抽取方法得到的评论文本表示准确，提高效率，保证模型的属性抽取性能。该方法涉及利用混合预训练模型实现社交媒体评论信息的语句嵌入表示。 利用双向长短记忆模型获取社交媒体评论语句中的词隐式表达。 构建语法图卷积神经网络，实现异构语法树编码。 构建语义图卷积神经网络，实现语义图编码。 使用相互双仿射变换来构造新的语法树代码和语义图代码。 利用融合门构建最终社交媒体评论信息的句子表达式。 构建语法感知指针神经网络。 预测属性的开始位置和结束位置。 构造条件随机场。 实现了词标签预测。 构建相应的损失函数，实现模型训练。  12
本发明公开了一种用于强交互人体运动的2D人体位姿生成方法，该方法主要步骤包括：通过搭建的多视角相机阵列，采集并建立强交互人体运动数据集；基于建立的数据集对2D人体位姿估计网络HRNet的预训练模型进行微调，以提升其对强交互运动的检测能力；将微调获得的模型用于检测不同视角的图像，获得其初始特征；利用对极几何原理对每个视角的初始特征计算在其他视角中的对应极线位置；在对应的极线上分别采样K个特征，与源视角进行特征相似度计算和特征融合，以弥补源视角初始特征的不足；采用贪心匹配算法并以骨骼长度为阈值约束关节点的连接，最终生成2D人体骨架。本发明可以有效提高对强交互人体运动下的2D人体位姿的检测准确率。一种计算机视觉与图形领域，医疗领域，比赛领域，动画领域，智慧城市中二维人体姿态生成方法。本发明能够有效提高强交互人体运动下二维人体姿态的检测精度，增加摄像机数量，从而提高场景的覆盖度。所述方法涉及获得待检测的多视角图像集，其中所述多视角图像集包括多视角图像。 将视角图像输入到二维(2D)人体姿态估计网络中以执行特征融合。 基于特征融合执行节点位置估计过程以获得节点的位置估计结果。 所述节点之间的匹配关系是采用一种食欲匹配算法计算得到的。 骨长度被确定为阈值约束节点连接以生成2D人体姿态框架。本发明还涉及一种用于产生二维人体姿态的装置。   6
本发明公开了一种基于深度空时特征学习的视频行为聚类方法，包括：构建3D U‑Net自表达生成器网络，用于学习视频块的空时特征表示以及聚类友好的子空间表达矩阵；构建视频块重建判别器网络，采用对抗学习机制评估重建视频块质量，以获得更具辨析力的视频空时特征表示；设计聚类信息反馈机制，用于捕获已有聚类结果中的信息增益，反馈该信息增益以监督网络的学习过程，提高聚类性能；利用视频块重建判别器预训练3D U‑Net自表达生成器中的编码器网络和解码器网络，以使得编码器网络有效获取视频块的空时特征；训练基于深度空时特征学习的视频行为聚类网络，获得聚类友好的特征表示和重建系数矩阵，并反馈已有聚类结果以进一步指导聚类网络的学习。该方法对于基于深度时空特征学习的视频行为聚类是有用的。基于深度时空特征学习的视频行为聚类包括构建3D U-Net自表达生成器网络，构建视频块重建判别器网络，获得判别性更强的视频时空特征表示，设计聚类信息反馈机制以捕获现有聚类结果中的信息增益，反馈信息增益以监督视频行为聚类网络的学习过程，提高聚类性能，使用视频块重建判别器对编码器网络和解码器网络进行预训练，通过训练优化视频行为聚类网络的权重参数， 获取聚类友好的特征表示和重构系数矩阵，并反馈已有的聚类结果，进一步指导视频行为聚类网络的学习。 9
本发明提出了一种融合词屏蔽数据增强与对抗学习的特定目标情感分析方法，包括以下步骤：S1，运用屏蔽目标实体的方式对句子进行同义词替换和随机插入单词生成有效的样本并与原始样本进行融合，从而实现词屏蔽数据增强；S2，构建了基于BERT‑BASE的对抗学习特定目标情感分类模型，运用干净样本和对抗样本一起训练情感分类模型，使模型具有对抗防御的功能；S3，分别将原始样本和数据增强后的样本进行对抗学习。本发明采用了数据增强与对抗训练，具有较强鲁棒性，能够取得更优的结果。具体的融合词屏蔽数据增强反学习的目标情感分析方法。该方法能够通过采用数据增强和对策训练来提高鲁棒性，并获得更好的结果。 该方法能够通过使用提出的融合词屏蔽数据和验证数据增强样本来增强特定目标情感分类，以有效地提高模型性能。该方法包括执行同义词替换和随机插入词生成句子的有效样本。 基于来自变换器的双向编码器表示(BERT)构建对抗学习特定目标情感分类模型。 选择融合后数据作为所述对抗学习特定目标情感分类模型的输入。 所述情感分类模型由干净样本和对抗样本共同训练而成。 最终得到特定的目标情绪分析结果。  12
本发明属于图像处理领域，为建立一种高效的无参考立体图像质量评价方法，在进行质量预测时更加准确，提高立体图像质量评价工作的效率，本发明，从局部到全局特征回归无参考立体图像质量评价方法，首先通过特征相似度FSIM算法给左右视点的图像块分别赋予不同的标签，利用计算出的标签指导左右通道的网络同时进行预训练，以此实现特征的局部回归；然后，在左右通道的基础上再添加一个融合通道，构成全局回归网络，在预训练模型的基础上，以主观评价值DMOS作为标签指导网络训练，对网络参数进行微调，以此实现特征的全局回归；立体图像的质量由训练完成的全局回归网络进行特征提取并预测。本发明主要应用于设计制造场合。从局部到全局特征回归的无参考立体图像质量评价方法。该方法在立体图像质量评价方面表现优异。 该方法使用两步回归策略，其为模型提供了左视图和右视图的更精确表示。该方法包括通过特征相似性(FSIM)算法将不同的标记分配给左视点和右视点的图像块。 计算得到的标签用于引导左右通道的网络同时进行预训练。 保存训练好的网络参数，实现特征的局部回归。 在左右通道的基础上增加融合通道，形成全局回归网络。 基于预训练模型，以主观评价值平均主观评分差值(DMOS)为标签指导网络训练，微调网络参数实现全局特征回归。 通过训练好的全局回归网络对立体图像的质量进行提取和预测。   6
本说明书公开了一种模型训练方法及装置，可基于已构建知识库中的各实体，从目标领域相关的各段文本中，确定包含任一实体的训练样本，并根据实体在各训练样本中位置及其实体属性，对各训练样本进行序列标注。之后，通过各训练样本及其标注，对预训练的语言模型进一步训练。基于已构建知识库中各实体，确定各训练样本，并对各训练样本进行自动标注的方式，节省了人工标注成本。用于使用电子设备训练模型的方法(要求保护)。该方法能够自动对训练样本进行标注，节省了人工标注成本。该方法包括获取与目标领域相关的第一文本数据集。 将包含任意实体的文本确定为训练样本。 根据所述实体在所述训练样本中的位置以及所述实体的实体属性，对所述训练样本的序列进行标注。 将所述训练样本引入预先训练的语言模型中。 确定所述语言模型输出的预测结果。 根据所述训练样本的标记和所述语言模型输出的预测结果调整所述语言模型中的模型参数。 所述语言模型用于知识挖掘。独立权利要求还包括：一种计算机可读存储介质，包括用于训练模型的指令集； 以及模型训练装置。  11
本发明公开了基于AI机器学习的钢筋点数识别软件系统，包括算法、训练学习、数据集及拍摄识别，利用机器学习、计算机视觉等算法对大量的数据集进行多次训练学习，训练完成后，对现场情况进行拍照识别，其中，所述算法采用YOLOv3单阶段检测器，所述YOLOv3骨架网络采用ResNet50‑VD，所述YOLOv3单阶段检测器采用Deformable Convolution v2卷积操作，本发明运用人工智能、机器学习等AI技术，通过软件快速识别钢筋数量，保证钢筋验收或盘库点数效率，降低建筑施工人员人力成本，提高钢筋点数准确率，减少了材料损失。一种基于AI机学习的钢筋点位识别软件系统。该系统通过软件识别钢筋，提高了钢筋验收或盘点的效率和钢筋的准确性，降低了施工人员的劳动成本和材料损耗。该系统具有系统主体，用于执行机器学习，计算机视觉和算法以训练和学习大量数据集，在训练完成之后捕捉图像并识别场景。 Yolov3单级检测器执行可变形卷积运算。 YOLOV3单级探测器设有FPN，FPN上设有掉块模块。 Yolov3单级探测器与IOU损耗支路相连，提高了箱体定位精度。 系统主体通过对钢筋拍照进行拍照识别，并将照片发送至服务器进行钢筋识别和数量计算。   6
本发明涉及一种基于高分一号数据与U‑Net模型的大豆种植区提取方法，包括：获取研究区的高分一号数据影像并进行预处理，得到数据集样本；对数据集样本进行数据处理，划分为训练集和测试集；构建U‑Net网络模型；将训练集输入U‑Net网络模型，分析对比基于U‑Net网络模型的损失函数和训练精度变换曲线，对比不同迭代周期训练结果对比图，选择U‑Net网络模型采用的训练周期；U‑Net分类结果与分析。本发明比Deeplabv3+平均交并比高出了8.89％，验证了U‑Net网络模型在大豆种植区提取方面的性能优于SegNet模型和Deeplabv3+模型；U‑Net网络模型作为语义分割网络的一种，在提取大豆种植区这种二分类问题中，展示了良好的效果，比其他模型在遥感提取中表现更为突出。基于高分数数据和U-Net模型的大豆种植面积提取方法，用于大豆和玉米的作物遥感识别。该方法为提取大豆种植面积提供了准确的提取特征，在遥感影像分类中具有很强的应用前景，让U-Net网络模型在提取种植面积的两个分类问题中作为语义分割网络之一，表现出良好的效果，与其他模型相比，在遥感提取中更为突出。基于高分数数据和U-Net模型提取大豆种植区域，包括：(i)获取第一数据图像的研究区域中的高分数，并进行预处理，得到数据集样本; (ii)对数据组样本进行数据处理，分为训练集和测试集; (iii)构建U-net网络模型； (iv)将训练集输入U-NET网络模型，分析比较基于U-NET网络模型的损失函数和训练精度变换曲线，比较不同迭代周期训练结果比较图，选择U-N网络模型采用的训练周期和(v)U网络分类结果及分析：将测试集输入U网络模型，进行比较测试，得到提取结果; (vi)根据提取结果分析不同图像尺寸、不同训练周期和不同网络模型对大豆种植面积影响的提取结果。   6
本公开公开了一种语音识别模型的训练方法、装置、设备和存储介质，涉及计算机技术领域，具体涉及语音识别、深度学习等技术领域。语音识别模型的训练方法包括：基于声学解码模型和语言模型，获得语音对应的至少一个候选文本的融合概率；基于所述融合概率，选择预设个数的候选文本，并基于所述预设个数的候选文本确定预测文本；基于所述预测文本和所述语音对应的标准文本，获得损失函数，并基于所述损失函数训练所述语音识别模型。本公开可以提高语音识别模型的识别准确度。训练语音识别模型的方法。该方法能够提高语音识别模型的识别准确率。该方法涉及基于声学解码模型和语言模型获得(101)对应于语音的候选文本的融合概率。 基于所述融合概率选择预设数量的候选文本，并基于所述预设数量的候选文本确定(102)预测文本。 基于所述预测文本和所述语音对应的标准文本获得损失函数，并基于所述损失函数训练(103)所述语音识别模型。 采用所述声学解码模型对所述前一时刻的输出文本和当前时刻的声学相关信息进行处理，得到所述语音对应的候选文本对应的第一概率。独立权利要求包括如下：一种用于训练语音识别模型的装置； 用于训练语音识别模型的电子设备； 以及存储用于训练语音识别模型的程序的非暂态计算机可读存储介质。 3
本发明公开了一种胚胎质量智能评估方法，包括以下步骤：建立原核期实例分割模型；建立基于DeepSort的原核期目标跟踪模型；建立卵裂期细胞检测模型；建立卵裂期细胞碎片化程度评级模型；建立基于U‑Net的语义分割模型；建立基于Inception V3的质量评级模型；基于上述建立的六个模型，建立基于图卷积神经网络的胚胎质量智能评估模型，从而对胚胎质量进行评估。本发明分别对胚胎发育过程中不同阶段进行建模，并将不同阶段的胚胎特征相融合，训练图卷积神经网络，从而有效结合不同时期具有物理意义的特征参数，建立了胚胎质量智能评估模型，通过使用智能评估方法代替手工评估，在维持高精准度的同时大大提高了测量效率。基于深度学习的胚胎质量智能评价系统，用于辅助生殖技术，也可用于医疗领域和人工智能领域。基于图卷积神经网络建立胚胎质量智能评价模型，对胚胎质量进行评价，在保持高精度的同时提高了测量效率，提供了一种算法简单、评价精度高的胚胎质量智能评价方法。所述系统具有用于检测细胞分裂过程中细胞数量、位置和细胞均匀度的裂卵期目标检测模块。 卵裂期细胞破碎度评级模块与胚胎质量智能评价模块连接。 卵裂球时期语义分割模块，用于精确划分滋养层和内细胞群两个不同的目标区域。 一种胚胎质量智能评价模型，用于通过空间形态参数、细胞位置、细胞数量、细胞均匀度、细胞破碎度、滋养层和内细胞质量构建胚胎图像的特征向量。还包括一种基于胚胎质量智能评价系统的胚胎质量智能评价方法。   6
本发明涉及MRI图像处理技术领域，特别是指一种基于MRI图像的肩袖损伤智能识别方法及装置。一种基于MRI图像的肩袖损伤智能识别方法包括：采集患者数据，对患者数据进行处理，获得训练数据；基于U‑net网络结构和FPN网络结构建立模型，获得待训练肩袖损伤识别模型；采用训练数据，对待训练肩袖损伤识别模型进行训练，获得肩袖损伤识别模型；将待识别MRI图像，输入肩袖损伤识别模型，获得肩袖识别结果。本发明是一种准确、高效的基于MRI图像的肩袖损伤智能识别方法。基于MRI图像进行肩袖损伤智能识别的方法。该方法基于MRI图像为肩袖损伤提供了准确高效的智能识别。 针对肩套损伤识别模型设计验证误差，验证评估模型的识别结果的准确性。 患者数据中的分割图像较好。该方法涉及收集(S1)患者数据，并且处理患者数据以获得训练数据。 基于U-net网络结构和FPN网络结构建立(S2)模型，得到待训练的肩部套筒损伤识别模型。 对训练数据待训练的肩袖损伤识别模型进行训练(S3)，得到肩袖损伤识别模型。 将待识别MRI图像输入(S4)肩袖损伤识别模型，得到肩袖识别结果。 采集患者数据，将患者数据转换为图片，得到第一特征数据。包括独立权利要求一种基于MRI图像的肩部袖套破损智能识别装置。  7
本发明涉及人工智能技术领域，提供一种基于半监督学习的模型训练与图像分割方法和系统，方法包括：基于第一图像数据集，以及对第一图像数据集降采样得到的退化图像数据集，训练图像修复模型；基于图像修复模型，初始化第一预训练模型和第二预训练模型；基于携带真实分割标签的第二图像数据集，对第一预训练模型进行训练，得到第一分割模型；将第三图像数据集输入至第一分割模型，得到第一分割模型输出的第三图像数据集的伪分割标签；基于携带伪分割标签的第三图像数据集，以及携带真实分割标签的第四图像数据集，对第二预训练模型进行训练，得到图像分割模型，在不增加标注负担的前提下，提高了图像分割模型的可靠性和准确性。基于半监督学习进行模型训练的方法。对第二预训练模型进行训练得到图像分割模型，基于具有伪分割标签的第三图像数据集、具有真实分割标签的第四图像数据集，在不增加标注负担的情况下，提高了图像分割模型的可靠性和准确性。该方法涉及基于第一图像数据集和通过对第一图像数据集进行降采样而获得的降质图像数据集来训练(110)图像复原模型。 基于所述图像复原模型初始化(120)所述第一预训练模型和所述第二预训练模型。 基于携带真实分割标签的第二图像数据集训练(130)第一预训练模型以获得第一分割模型。 将所述第三图像数据集输入(140)到所述第一分割模型中，以获得由所述第一分割模型输出的所述第三图像数据集的伪分割标签。 基于所述携带伪分割标签的第三图像数据集和所述携带真实分割标签的第四图像数据集对所述第二预训练模型进行训练(150)，以获得图像分割模型。以下包括独立权利要求：一种基于半监督学习的图像分割方法； 一种基于半监督学习进行模型训练的系统； 一种基于半监督学习的图像分割系统； 用于基于半监督学习的模型训练的电子设备； 以及存储用于基于半监督学习的模型训练的程序的非暂态计算机可读存储介质。 14
本发明公开了一种基于AIGC的关键词关联检索系统，包括关键词特征提取模块、关联模块、关键词获取模块、检索模块以及功能模块管理器，所述关键词特征提取模块、关联模块、关键词获取模块以及检索模块分别与所述功能模块管理器电连接。该AIGC技术可以应用在关键词特征提取模块、关联模块、关联词获取模块以及检索模块的运作中，以强化各模块的功能。本发明公开的基于AIGC的关键词关联检索系统具有检索所用到的关键词扩展功能，并且对于计算资源紧凑的应用场景具有适用性。用于计算资源紧缩应用场景的基于人工智能生成内容(AIGC)的智能关键词关联检索系统。该系统加强了各模块的功能，具有用于检索的关键字扩展功能，以及针对计算资源紧凑的应用场景的适用性。该系统具有相互连接的关键词特征提取模块和关联模块。 关键词获取模块和搜索模块与功能模块管理器电连接。 功能模块管理器通过所述关键词获取模块从所述用户输入的搜索信息中获取所述目标关键词。 所述功能模块管理器通过所述关键词特征提取模块确定所述目标关键词的词汇特征。 所述功能模块管理器控制所述关联模块根据所述词汇特征从所述预定关联词汇数据中筛选所述关联评价指标的最大值标定为所述目标关联词。 所述功能模块管理器将所述目标关联词和所述目标关键词作为索引输入所述检索模块，以使所述检索模块执行文档检索的操作。 1
本公开涉及一种数据生成方法、装置及可读存储介质，该方法包括：对初始第一语言文本进行加噪处理，得到加噪后的第一语言文本；根据预训练语言模型对所述加噪后的第一语言文本进行处理，得到目标第一语言文本；对所述目标第一语言文本进行反翻译处理，得到第二语言文本；基于所述目标第一语言文本和所述第二语言文本，得到用于训练翻译模型的训练数据。本公开的方法可以提升训练翻译模型的训练数据的多样性，解决训练数据短缺的问题。一种用于生成用于训练机器翻译模型的训练数据的方法。本发明能够提高训练翻译模型训练数据的多样性，解决训练数据短缺的问题。 本发明能够提高翻译模型的训练效果和生成训练数据的效率。该方法包括向初始第一语言文本添加噪声。 在噪声添加之后获得第一语言文本。 根据预训练语言模型即双向自回归变换器模型对降噪后的第一语言文本进行处理，得到目标第一语言文本。 对目标第一语言文本执行反向翻译处理以获得第二语言文本。 基于用于训练翻译模型的目标第一语言文本和第二语言文本来获得训练数据。 分割目标第一语言文本以获得一组目标语言子文本。本发明还涉及一种用于实施该方法的装置。 (1)用于生成用于训练机器翻译模型的训练数据的装置； (2)用于存储一组指令的计算机可读存储介质，所述指令用于生成用于训练机器翻译模型的训练数据。 3
本发明公开了一种基于多模态学习的试题知识点分类方法及系统，属于自然语言处理技术和图像处理技术领域，其中，该方法包括：使用预训练模型对预设试题文本信息进行向量映射，得到词向量；基于词向量利用卷积神经网络从预设试题文本信息中获取试题文本特征表示；基于词向量利用深层卷积神经网络提取预设试题文本信息中的试题图片特征；采用协同注意力机制分别获取试题文本引导的试题图片特征和试题图片引导的试题文本特征；通过门控机制对上一步得的更新后的试题文本特征和图片特征进行融合表示，并输入全连接、Softmax层中预测试题知识点分类结果。该方法有效缓解了小样本试题知识点分类中的特征稀疏问题，从而提高试题知识点的分类性能。自然语言处理技术和图像处理技术领域中的基于多模式学习的试题知识点分类方法。本发明有效缓解了小样本试题知识点分类中的特征稀疏问题，提高了试题知识点的分类性能。该方法包括使用预训练模型对预置的测试文本信息执行向量映射以获得词向量，其中预置的测试文本信息包括试题文本信息，答案和试题分析。 使用深度卷积神经网络基于词向量来提取预置测试文本信息中的试题图像特征，其中试题图像特征通过使用卷积神经网络来表示。 利用协同注意机制获得试题图片特征。 将更新的试题信息与选通机制获得的文本特征和图像特征融合。本发明涉及一种基于多模式学习的试题知识点分类系统。  12
本发明主要提出了一种基于生成式人工智能的小说推文视频生成方法及系统，大大提高了小说推文视频制作效率。主要发明点如下：设计了一种与大语言模型的沟通范式，能够建立小说文本到分镜头脚本的映射关系；设计了两阶段微调的方法，有效增强大语言模型生成分镜头脚本的能力；针对不同的小说内容建立训练数据集，基于开源文生图模型参数重训练，得到不同风格的文生图大模型；设计了一个小说推文视频生成系统，用户可以仅通过简单的复制粘贴小说文本得到与文本内容相匹配的小说推文视频。基于人工智能生成的新型推送视频生成方法。本发明通过两阶段的微调处理，有效地增强了大语言模型生成镜头脚本的能力，使得用户只需对文本进行简单的复制和粘贴，即可得到与文本内容相匹配的新型文本推送视频，提高了新型推送视频的制作效率。该方法包括输入系统的一段新颖文本。 由用于执行内容审核的系统接收向用户提交文本的用户请求。 所述内容审核通过后，将所述文本传输至计算节点。 利用大型语言模型将文本转换为镜头脚本。 将所拍摄的脚本输入到文本图像模型的用户指定风格。 根据拍摄的脚本生成图像。 利用用户指定配音角色的语音合成模型将所述新颖文本合成配音音频文件。 将带有配音、字幕和背景音乐的图像合成为视频文件。 对生成的视频文件进行后处理。 某一图像用户自定义子镜像描述由用户指定选择重新生成图像并合成视频。 9
本发明公开了一种基于扩散模型和ControlNet的图像姿态生成方法，该方法通过添加扩散模型进行数据增强，解决了由于复杂姿态数据不足导致的过拟合问题，通过改进ControlNet的框架和权重，使得改进后的ControlNet能有效检测复杂的人体姿态，并通过添加损失函数约束，使用深度数据集，有效提高了检测异常姿态时的精确度，使得姿态估计更具有鲁棒性。同时，本发明改进了整个扩散模型的总体学习目标，强化了识别深度内容的能力，改进了ControlNet模块中的编码块和分辨率设置，使其能适用于非典型的U‑net结构。一种基于扩散模型和controlNet的图像手势生成方法。该方法通过增加扩散模型进行数据增强，通过改进控制网络的帧和权重，解决了复杂姿态数据不足导致的过拟合问题，从而有效地利用改进的控制网络检测复杂的人体姿态，通过增加利用深度数据集的损失函数约束和姿态估计鲁棒性，有效地提高了异常姿态检测时的精度。该方法涉及构建包含人体姿态的图像数据集。 图像数据集分为训练集和测试集。 构建扩散概率模型。 在前向扩散过程中向输入图像中不断加入高斯噪声，直到高斯噪声变为随机噪声矩阵。 在反向生成过程中执行去噪处理，用于逐渐地对随机噪声矩阵去噪，直到生成图像。 基于ControlNet构建姿态生成模型。 在扩散概率模型中创建多个编码块和中间块的可训练副本。 确定训练集图像，以联合扩散概率模型和姿态生成模型进行训练。 将测试集图像输入训练好的关节模型，预测图像中关键点的位置坐标，生成复杂姿态的图像。   6
本发明公开了一种基于空洞卷积注意力机制的医学图像分割方法，包括以下步骤：选定待进行分割的医学图像数据集；对选定数据集中的CT图像进行预处理；搭建基于3D U‑Net改进的医学图像分割模型；将预处理后的数据输入到改进后的3D U‑Net医学图像分割模型中进行训练，训练时使用辅助训练策略增强整个分割目标的特征表示，得到最佳的网络模型；使用训练好的3D U‑Net医学图像分割模型对待检测的CT图像进行分割，获取最终的图像分割结果。本发明所述的改进模型在多个评价指标中均表现较优，分割结果较基准模型有所提升，提高了分割精度。基于空洞卷积注意力机制的医学图像分割方法。 也可用于深度学习医学图像分割技术领域。辅助训练策略，用于增强整个分割对象的特征表示，得到最佳的网络模型。 改进后的模型在多个评价指标上表现较好，分割结果较标准模型有所改善，提高了分割精度。该方法涉及选择(S1)要经受图像分割的医学图像数据集。 对所选择的医学图像进行预处理(S2)。 构建改进的3D U-Net医学图像分类模型(S3)，其中编码阶段使用空心卷积和卷积注意力。 构建改进的U-net医学图像分类模型(S4)。 解码级设置有横向卷积矩阵和残差模块。 输入数据(S5)，训练改进的UNet医学图片分割模型。 利用训练好的U-Net医学图像分类模型对待检测图像进行分割，得到最终的U-Net图像分割结果。   6
本发明提供一种融合上下文信息图卷积的中文短文本分类方法，属于文本分类技术领域。通过引入双向长短时记忆网络(BiLSTM), 提出了BERT_BGCN短文本分类模型。本发明首先利用BERT对文本信息进行编码作为图节点的特征值；然后通过全局共享的点互信息量(PMI)关系作为节点间的边为每个文档构建一个单独的文本图；接着聚合图卷积网络和BiLSTM的输出形成融合上下文信息的特征矩阵输入到下一层的图卷积网络；最后输出到全连接层得到最终分类结果。本发明提出的文本分类方法可以弥补短文本中存在的特征稀疏问题，提高了中文短文本分类的准确性。利用双向长短时记忆网络(BiLSTM)用卷积融合上下文信息图对中文短文本进行分类的方法。该方法能够补偿短文本中的特征稀疏问题，因此提高了中文短文本分类的准确性。该方法包括输入未分类的文本数据集，并获得预处理的数据集。 将预处理后的数据集送入BERT模型，得到词向量。 计算节点之间的点互信息量(PMI)。 为每个文本独立构建邻接矩阵。 将所述词向量输入BiLSTM模型，得到所述特征向量，所述特征向量为富含文本上下文语义信息的BiLSTM输出。 将词向量和构造的邻接矩阵输入到图卷积模型，得到特征向量，作为卷积的输出。 对所述特征向量进行facture融合，得到用于通过全连接层实现降维的融合上下文信息的特征矩阵。 利用分类器对降维后的特征向量进行分类。  12
本申请涉及人工智能技术领域，并公开了一种文本处理方法、计算机设备及存储介质，所述方法包括：获取待处理文本，所述待处理文本包括至少一条自然语言语句；将所述待处理文本输入预训练的文本润色模型，对所述自然语言语句、所述自然语言语句中的修饰词，和/或所述自然语言语句中的待优化词汇进行润色处理，得到目标文本。能够对文本从语句、语句的修饰词和/或语句的词汇层级进行润色处理，可以高效准确地提高文本内容的质量。处理文本的方法。该方法从句子、句子的修饰词或句子的词汇级别对文本进行渲染处理并高效准确地提高文本内容的质量。该方法包括获取(S401)待处理文本。 待处理的文本包括自然语言句子。 将所述待处理文本输入(S402)预先训练的文本渲染模型。 对所述自然语句、所述自然语句中的修饰词或所述自然语句中的待优化词汇进行渲染处理，得到目标文本。 获取预设数量的训练样本。 对所述预设语言模型进行训练，得到预训练的文本运行模型。 所述文本渲染模型包括相互独立的第一目标网络分支、第二目标网络分支和第三目标网络分支。以下包括独立权利要求：1。 计算机设备； 2. 存储用于处理文本的程序的计算机可读存储介质。  11
本发明提供了一种对话预标注方法，包括：获取对话数据；所述对话数据基于语音识别得到；对所述对话数据进行预处理；将预处理后的所述对话数据输入预标注模型，对所述对话数据进行预标注；其中，所述预标注模型基于提示学习和预训练语言模型训练得到。本方案针对没有标签的数据集，在标注阶段之前使用预训练大模型，通过提示(Prompt)的方式进行零样本预标注，提高业务整体执行效率，并淡化人力在业务执行过程中的绝对影响力，间接提升数据质量。用于使用计算机设备在人工智能中执行对话预注释的方法(要求保护的)。该方法针对无标签的数据集，使用标记阶段前的预训练大模型，以提示(proput)的方式进行零样本预标记，提高服务的整体执行效率，同时降低服务执行过程中人力的绝对影响，间接提高数据质量。该方法包括获得对话数据。 所述会话数据是基于语音识别得到的。 对所述会话数据进行预处理。 将所述预处理后的会话数据输入预标记模型。 所述会话数据是预先标记的。 所述预标注模型是基于提示学习和预训练语言模型训练得到的。独立权利要求还包括：一种基于提示学习的对话预标注系统； 以及包括用于执行对话预注释的指令集的计算机可读存储介质。 8
本申请公开了基于跨语言预训练模型的中朝翻译质量估计方法和系统，本方法包括：将源语言句子和机器译文拼接，并使用XLM‑R模型得到拼接句子的初始特征矩阵；对初始特征矩阵进行注意力计算，并通过卷积神经网络进行句子嵌入，得到句子向量；基于句子向量，使用全连接神经网络计算得到质量估计得分。本系统包括跨语言特征提取模块、注意力计算模块和质量估计模块；跨语言特征提取模块使用XLM‑R模型对待评估句对进行特征提取，并生成初始特征矩阵；注意力计算模块对初始特征矩阵进行注意力计算，得到句子向量；质量估计模块计算得到翻译质量估计的得分。本申请的句子嵌入质量高，有利于质量估计，有效提升中朝机器翻译质量估计任务的性能。一种基于跨语言预训练模型的汉语-韩国语翻译质量评估方法。该句子嵌入质量高，利于质量评估，有效提高机器翻译质量评估任务的性能。所述方法包括：根据预设格式拼接源语言语句和目标语言的机器翻译，得到拼接语句；提供XLM-R模型，得到拼接语句的初始特征矩阵X。 对初始特征矩阵X进行语言关注度计算和词语关注度计算，通过卷积神经网络进行句子嵌入，得到拼接句子的句子向量。 提供完全连接的神经网络来计算质量估计分数，以基于句子向量来完成翻译质量估计。本发明涉及一种基于跨语言预训练模型的汉语-韩国语翻译质量评估系统。  12
本发明提供了一种基于BERT和融入功效信息的中药处方生成方法，获取症状描述和处方数据对，以及中药功效信息集；并通过预训练好的BERT模型得到固定长度的每个中药的功效信息编码；构建基于BERT‑GRU的中药处方生成模型，并利用所述训练集微调所述中药处方生成模型；利用中药处方生成模型生成处方。本发明通过深度学习的方法，利用预训练的BERT强大的语言表征能力来提升句子表达能力，从中医古籍经典方剂数据中挖掘规律，并融入中药功效信息，通过训练编码器和解码器两个网络，来最大化中药处方序列的条件概率，实现根据症状文本描述开具辅助的中医处方。基于双向编码器表示从变换器(BERT)和并入功效信息的中药处方生成方法。该方法通过训练编码器和解码器两个网络，提高预训练的BERT强大的语言表达能力和句子表达能力，整合中药药效信息，使中药处方序列的条件概率最大化，实现根据症状文字描述进行中药补方。该方法涉及获取一对一的症状描述和处方数据对以及中药疗效信息。 进行数据对预处理操作，得到预处理结果。 根据预处理后的结果对中药功效信息按照中药字典的顺序进行排序。 将测试样本输入训练好的中药处方生成模型。 通过所述中药处方生成模型基于所述测试样本生成中药处方。  12
本申请公开了一种大语言模型的微调方法及装置。方法的一具体实施方式包括：获取用于微调预训练的大语言模型的第一训练样本集，第一训练样本集中的第一训练样本包括训练数据和标签；对于第一训练样本集中的第一训练样本，比对预训练的奖励模型根据第一训练样本中的标签得到的第一输出结果，和根据大语言模型的实际输出得到的第二输出结果，确定表征第一训练样本是否被筛选掉的筛选结果，实际输出为大语言模型以第一训练样本中的训练数据为输入所得到的输出；通过第一训练样本集中未被筛选掉的第一训练样本对大语言模型进行微调，得到微调后的大语言模型。本申请有助于提高大语言模型在特定任务上的性能，降低模型训练过程对高质量训练数据的依赖。一种使用电子设备(权利要求)对诸如生成预训练生成(GPT)系列模型之类的大型语言模型进行微调的方法。可以提高大型语言模型在特定任务上的性能。 可以降低模型训练过程对高质量训练数据的依赖。该方法包括获取用于对预先训练的大规模语言模型进行微调的第一训练样本集。 训练数据和标签包括在训练数据集中。 将预先训练的奖励模型得到的第一输出结果与奖励模型根据标签的第二输出结果进行比对。 确定筛选结果，用于指示是否对训练样本进行筛选，其中，实际输出为以训练数据中已训练的训练数据为输入的大级别语言模型得到的输出。 通过训练样本中未进行筛选的训练样本对所述大语言模型进行微调，得到微调后的大语言模型。独立权利要求包括用于：(1)一种用于使用电子设备对大型语言模型进行微调的设备； (2)一种计算机可读介质，其存储有用于大型语言模型的微调的计算机程序。  11
本公开提出了一种基于大模型的图像搜索方法、装置、设备和介质，涉及计算机视觉和自然语言处理等人工智能领域，适用于大模型，包括：获取搜索语句和候选图像信息库；从所述候选图像信息库中，获取所述搜索语句的候选图像集合以及所述候选图像集合中各候选图像的候选特征问答对集合；通过预获取的大模型从各候选图像的候选特征问答对集合中，获取各候选图像的目标特征问答对集合；根据所述目标特征问答对集合，从各候选图像中获取所述搜索语句的目标搜索图像。用于通过电子设备搜索基于大模型的候选图像的方法(权利要求书)，用于在诸如计算机视觉和自然语言处理的人工智能领域中使用。根据所述目标特征问答对集合从各个候选图像中获取所述搜索语句的目标搜索图像，保证了所述图像搜索方法的准确性的有效提高。该方法包括获取搜索语句和候选图像信息库； 从所述候选图像信息库中获取所述搜索语句的候选图像集合以及所述候选图像集合中每个候选图像的候选特征问答对集合； 通过预先获得的大模型，从所述各候选图像的候选特征问题对集合中，获得各候选图像的目标特征问题对集合； 以及根据所述目标特征问答对集合，从各个候选图像中获取所述搜索语句的目标搜索图像。独立权利要求还包括用于：基于大模型搜索候选图像的装置； 一种非瞬时计算机可读存储介质，包括用于基于大模型搜索候选图像的指令集； 以及计算机程序产品，其包括用于基于大模型搜索候选图像的指令集。 14
本发明涉及一种多领域微调大模型并行推理系统及其方法，该系统包括：多领域LoRA微调模块、LoRA权重合并和模型加载模块、LoRA权重索引和模型推理模块、输入请求处理单元；该方法包括：针对不同业务场景，采用LoRA参数微调方式，根据相应业务数据，在同一预训练基座模型的基础上得到多个领域微调模型；将原始矩阵权重与多个领域微调模型的LoRA权重统一进行合并处理，得到合并加载模型；针对用户输入请求进行预处理及合并操作，得到并发请求，再通过LoRA权重索引，从合并加载模型中提取对应领域模型权重，并进行模型推理、输出推理结果。与现有技术相比，本发明能够在较小计算资源情况下实现多个微调领域大模型的并行高效推理，同时提升推理系统的吞吐量。多场微调大模型并行推理系统。该系统在计算资源较小的情况下，实现了多个精调领域大模型的并行高效推理，同时提高了推理系统的吞吐量。该系统具有多域LoRA微调模块(1)，用于在同一个预训练基模型的基础上，根据业务数据得到多个域微调模型。 LoRA权重组合及模型加载模块(2)将多个场精调模型的LoRA加权矩阵组合并加载一个基模型的原始矩阵权重，得到组合加载模型。 LoRA权重索引与模型推理模块(3)接收并发请求。 通过LoRA权重索引方式从所述组合加载模型中提取对应的场地模型权重。 进行模型推理。 输出推理结果。包括独立权利要求，用于一种多场微调大模型并行推理方法。  11
本发明公开了一种基于预训练模型的文本摘要生成方法、系统、设备及介质，包括：对待处理文本进行预处理，得文本的词向量；将所述文本的词向量输入到预训练后的算法模型中，得到待处理文本对应的摘要，完成基于预训练模型的文本摘要生成，该方法、系统、设备及介质能够生成文本的摘要。基于预训练模型的文本摘要生成方法。该方法使得能够实时获取文本的关键信息，并方便地提供给用户呈现，并且为用户提供高效的阅读体验，有效地节省了用户的时间。 该方法使得能够同时大幅缩短原始文档长度，并且能够完全准确地反映文本的中心内容，从而能够方便地将关键信息实时地呈现给用户。该方法包括对待处理文本进行预处理，得到文本的词向量。 将所述文本的词向量输入算法模型，进行预训练处理，所述算法模型包括文本特征提取模块、关键信息指向模块和标题生成模块。 获取与所述待处理文本对应的摘要。 文本摘要生成是基于预训练模型完成的。 标点符号和特殊符号被过滤。 去除所述待处理文本的停用词和正常词。 利用分词结果构建语料。 利用嵌入技术对所述语料库中的词语进行词向量化处理，得到所述文本的词向量。 获取与所述文本对应的所述待处理文本的标题。 获取所述文本的标题特征信息。 将文本的词向量输入关键信息指向模块。独立权利要求包括：(1)—种计算机设备，包括用于执行基于预训练模型的文本摘要生成方法的存储器和处理器；以及(2)一种计算机可读存储介质，用于存储用于执行基于预训练模型的文本摘要生成方法的指令集。  12
本发明适用机器人人机交互命名实体识别技术领域，提供了一种基于特征的命名实体识别方法(FBERT‑BiLSTM‑CRF)，本方法的目的在于针对当前的命名实体识别模型无法精准识别不同场景下同一词表达的含义不同的问题，通过在BiLSTM‑CRF模型基础上融合BERT模型，并采用基于特征的方式进行训练，提高了模型对一词多义场景的应对能力，同时提升了命名实体识别模型的性能。基于特征的命名实体识别方法。该方法能够提高模型对词语多义场景的响应能力，提高命名实体识别模型的性能。该方法涉及将待识别文本向量化通过BERT预训练模型，得到单个字符的动态语义向量表示。 CLS层的输出通过BiLSTM网络进行拼接。 通过Dropout层得到第一中间结果。 通过致密层获得第二中间结果。 将两个中间结果拼接后通过CRF层解码得到一个输出标签序列。 令牌列表中的每个词根据中文词表数据转换为词表编码向量，形成词表编码向量表。包括基于特征的命名实体识别系统的独立权利要求。  12
本发明公开了一种基于手绘的多类别对象级自然图像生成方法，包括以下步骤，获取多类别对象级初始手绘以及对应的类别标签；根据所述初始手绘和所述类别标签，对预先构建的图像生成模型进行训练；所述训练步骤包括：将所述初始手绘和其对应的类别标签输入至条件编码器中进行编码，得到预测隐空间向量；将所述预测隐空间向量和相同的类别标签输入至预训练生成器模型生成对应类别的自然图像预测结果，根据所述预测结果判断模型收敛情况；将实际手绘输入至训练好的图像生成模型中，生成自然图像；本发明通过预训练的生成器，解决了小规模训练数据集的图像域先验知识不足的问题。基于手绘和类标签自动生成多类对象级自然图像即生动图像的方法。预训练生成器解决了小规模训练数据集图像域先验知识不够的问题。 提高了生成图像的质量。 生成具有照片级真实度和对手绘特性的忠实度的自然图像。该方法涉及获取多类对象层级的多级初始手绘图和对应的类别标签。 根据所述初始手绘和所述类别标签训练预先训练的图像生成模型。 将对应的类别标签输入条件编码器进行编码，得到预测隐藏空间向量。 将所述预测隐式空间向量和相同类别标签输入预训练生成器模型，生成相应类别的自然图像预测结果。 判断是否根据预测结果获得模型收敛条件。 将实际徒手草图输入到所述已训练的图像生成模型中，用于生成自然图像。 14
本发明公开了高斯混合模型与CNN结合手势识别方法，涉及计算机视觉识别技术领域；包括如下步骤：设置高斯分布的个数，初始化各高斯模型的权重，均值，方差；根据视频流确定该像素点的高斯分布混合分布模型；根据GMM输出值来判断图像的掩模；将掩模通过线性插值生成原始图片的掩模模板；生成前景图片；将生成图片输入到轻量级卷积神经网络中；输出手势信息。本发明采用混合高斯模型与CNN的结合，并且还使用了形态学开运算和非极大值抑制作为辅助手段，能提供实时的视频流的手势检测与识别，同时能够减少环境对于模型的识别的影响，而且能够方便简单的部署在多个平台，而不用为现有设备配备配备单独的NPG或GPU等。高斯混合模型与卷积神经网络相结合的手势识别方法，应用于计算机视觉识别技术领域。一种高斯混合模型与卷积神经网络相结合的手势识别方法，通过插值法将实时视频帧缩放到指定大小， 在此建立像素点的波动非参数模型，从而能够提供对实时视频流的姿态检测和识别，减少环境对模型识别的影响，并且方便简单地部署在平台上。高斯混合模型和卷积神经网络相结合的手势识别方法涉及通过内插方法将实时视频帧缩放到指定大小。 建立像素点的波动非参数模型。 设置高斯分布的数量并初始化每个高斯模型的权重。 使用小的学习速率来确定像素点的高斯分布混合分布模型。 更新像素点的高斯模型的分布特性。 根据模型输出值判断图像的掩模。   6
本申请涉及一种基于本地知识库与自然语言大模型的图查询方法与系统，其中，基于本地知识库与自然语言大模型的图查询方法包括：结合图数据库中获取的图谱结构与本地知识库文档，生成多个领域知识问题与图数据库查询命令的组合；将用户输入的问题转化为对应的向量，并确定与所述用户输入问题对应的向量相匹配的K个领域知识问题与图数据库查询命令的组合；将所述用户输入的问题与所述K个领域知识问题与图数据库查询命令的组合填充到预设的上下文提示模版，得到填充后的问题，并将填充后的问题输入至所述预训练自然语言大模型，生成最终的图数据库查询命令；使用所述最终的图数据库查询命令查询图数据库得到查询结果，提高了图查询结果的准确性。基于局部知识库和自然语言大模型的图查询方法，应用于医疗、教育、安全防护和电子商务领域。提高了图像查询结果的准确性。 进行高效的交互，提高了终端用户对图库相关应用的使用门槛。该方法包括填充(S201)地图结构信息，并将填充的自然语言序列输入到预训练的自然语言大模型，以生成领域知识问题和图库查询命令的组合。 将组合中的有效领域知识问题输入(S202)到自然语言向量化模型。 将问题输入输入(S203)至自然语言向量化模型，得到向量，确定与用户输入问题和图库查询命令对应的向量匹配的K个领域知识问题的组合。 将所述问题输入、K领域知识问题和图库查询命令的组合填充(S204)至预设的上下文提示模板，生成最终的图库查询命令。 利用查询图像数据库的最终图像数据库查询命令(S203)来获得查询结果。独立权利要求包括以下内容：图表查询系统； 计算机装置； 以及存储用于查询图表的程序的计算机可读存储介质。  11
本发明涉及一种可交互场景化的面试方法、系统、设备和介质。本发明的可交互场景化的面试方法包括：提供包括面试事件流的可视化面试场景，以供应聘者在线面试；接收并且处理由应聘者在在线面试中所产生的响应事件流，以获得处理数据；使用预训练模型来计算处理数据，以获得应聘者的评价数据。本发明可以实现应聘者与真实场景之间的交互，可以预测应聘者的工作能力和岗位匹配度，并且可以使得面试内容贴合招聘岗位的所需能力和工作内容，可以便于招聘者管理后续的招聘事务，可以提高模型预测的准确度。可交互场景化的面试方法。利用预先训练好的模型对处理后的数据进行计算，得到应征者的评价数据，实现应征者与真实场景的互动，预测应征者的工作能力和职位匹配度，使面试内容符合招聘岗位所需的能力和工作内容，便于招聘人员对后续招聘的管理，从而提高模型预测的准确性。该方法包括提供包括面试事件流的可视面试场景以提供招募者的在线面试。 在所述在线面试中，接收并处理一应征者所产生的一回应事件流，以获得一处理数据。 利用预先训练好的模型对处理后的数据进行计算，得到申请人的评价数据。 设置所述可视面试场景和所述面试事件流。 提供所述招聘人员的真实场景，以选择所述可视面试场景。 将所述选择的面试场景进行虚拟化，得到所述可视面试场景。 提供采访事件模板，供所述招聘人员选择采访事件。 存储各响应事件的处理数据，得到所述采访事件流的处理数据。还包括以下独立权利要求：一种可交互场景的面试装置； 交互式可场景采访系统； 以及包括用于交互式地采访可场景的一组指令。 14
本发明提供了一种用于AIGC模型训练的分布式算力调度系统，涉及电数字数据处理领域，包括资源注册模块、任务调度模块、智能决策模块和资源调配模块，所述资源注册模块用于记录所有计算资源的状态信息，所述任务调度模块用于完成对训练任务的初始分配，所述智能决策模块用于对训练过程进行智能分析，所述资源调配模块根据分析结果对计算资源进行动态调配；本系统能够对用于模型训练的算力资源进行动态调整，提高算力以及模型训练的效率。分布式算术力调度系统，用于AIGC模型训练。该系统能够动态调整模型训练的计算力资源，提高模型训练的计算力和效率。该系统具有任务分发单元，用于分析任务需求和资源条件，并将任务分发到特定节点以供执行。 智能决策模块，设置有预测模型单元和决策算法单元，所述预测模型单元预测模型的资源使用趋势。 决策算法单元生成优化的资源调度决策。 资源分配模块中设置有资源调度单元、资源监控单元、故障处理单元，资源调度单元执行智能决策模块给出的决策，进行资源的动态分配和调整。 所述资源监控单元监控资源分配的实现情况。 故障处理单元对发现的节点故障做出响应。 1
本发明公开了一种档案数据信息智能回填的方法、装置、终端、存储介质，涉及档案数据智能回填技术领域。本发明包括如下步骤：步骤一：将档案图片处理完录入至OCR模型进行OCR识别，得到各个档案对应的OCR识别结果；步骤二：将各个档案对应的OCR识别结果分别输入到BART模型中进行唯一标识符识别，得到初步唯一标识符的结果；步骤三：对初步唯一标识符识别的结果按类别对文本进行分类处理，得到最终唯一标识符的结果；步骤四：将最终唯一标识符的结果自动回填至对应档案的不同任务中；步骤五：完成信息回填。本发明通过档案数据智能回填技术，提升了档案处理的工作效率、减少输入错误信息的发生、减少人为因素造成的错误的机率、提高输入信息的精准度。用于使用终端智能地回填文件数据的方法(要求保护的)。该方法通过文件数据智能回填技术，提高了文件处理的工作效率，减少了输入错误信息的发生，降低了人为因素导致的出错概率，提高了输入信息的精度。该方法包括：将文件图像记录到光学字符识别(OCR)模型中，以获得对应于每个文件的OCR识别结果。 将对应于每个文件的OCR识别结果输入到BART模型以识别唯一标识符，以获得初级唯一标识符的结果。 根据所述初级唯一标识所标识的结果的类型对所述文本进行分类，得到所述最终唯一标识的结果。 最终唯一标识的结果自动回填到对应文件的不同任务中。 信息回填结束。独立权利要求还包括：一种用于灵活地回填文件数据的装置； 以及包括用于智能地回填文件数据的指令集的存储介质。 14
本申请公开了一种真实分割点判断方法、系统、存储介质及电子设备，真实分割点判断方法包括：视频特征维度获取步骤：将视频按照时间分成若干个视频等份，使用深度学习预训练模型对所述视频等份提取特征，获得视频特征；模型处理步骤：将所述视频特征输入到真实分割点判断模型进行处理获得每个候选分割点的分类概率；判断步骤 : 根据所述分类概率对所述候选分割点进行判断以确定场景真实分割点。本发明使用了全局一致性损失，降低相同场景的相似度，提高不同场景的相似度，能够得到非常好的表达，模型会逐渐收敛，而不会出现l oss上升。判断不同场景下真实分割点的方法。该方法能够使用全局一致性损失，从而降低同一场景的相似度，提高不同场景的相似度，获得更好的表达，并使训练模型逐渐收敛。该方法包括将一个视频按照时间划分为多个视频。 利用预先训练的深度学习训练模型提取所述视频的特征，得到视频特征。 将所述视频特征输入真实切分点判断模型进行处理，得到各候选切分点的分类概率。 对所述候选分割点进行判断，以根据所述分类概率确定场景的真实分割点。独立权利要求包括：a)一种用于判断不同场景中真实分割点的装置; b)一种电子设备，包括用于判断不同场景中真实分割点的处理器和存储器; c)一种存储介质，包括用于判断不同场景中真实分割点的指令集。 9
本发明涉及机器学习技术领域，具体为一种基于预训练模型的文本摘要生成方法和装置，包括以下步骤：收集大规模语言模型微调相关的数据集；大语言模型相关训练数据的前期处理；基于数据处理模块得到训练数据；基于模型训练模块得到的模型，对输入的任何中文文本生成具体的摘要信息；有益效果为：本发明提出的基于预训练模型的文本摘要生成方法和装置，引入时间信息，生成包含时间信息的摘要，更能反映文本信息的变化和演变；大规模语言模型的引入，可以更好的理解文本内容，生成的摘要具有更高的准确度和灵活性；构建的包含时间的样本，有效的克服了大规模语言模型生成摘要的偏差，使得生成的摘要信息更加有针对性和实用性。用于生成用于机器学习的基于预训练模型的文本摘要的方法。largescale语言模型的引入更好地理解了文本内容，生成的摘要具有更高的准确性和灵活性。 构建的样本包含时间有效克服了大规模语言模型生成的摘要的偏差，使得生成的摘要信息更具有针对性和实用性。文本摘要生成方法涉及收集大规模语言模型精调相关的数据集。 对所述训练数据进行与所述大型语言模型相关的预处理。 基于所述数据处理模块获取所述训练数据。 所述特定摘要信息是基于所述模型训练模块得到的模型对任意输入的中文文本生成的。 收集用于下游时间摘要生成的微调数据集，所述样本数据包括标签。独立权利要求包括用于所述基于预训练模型的文本摘要生成方法的基于预训练模型的文本摘要生成装置。  11
本发明涉及一种基于两阶段增量学习的表面缺陷分割方法，可用于缺陷检测。该方法所包括的步骤如下：本发明利用U‑Net作为语义分割基础模型，初始任务学习阶段同时使用随机权重平均优化算法和随机梯度下降优化算法更新初始模型参数，增量任务学习阶段分别设计初始任务性能损失函数和增量任务学习损失函数，并使用随机梯度下降优化算法联合训练两部分损失。本发明采用U‑Net作为语义分割基础模型，并从模型参数的优化层面提高学习效率的同时克服灾难性遗忘问题，能更好地应用于表面缺陷分割的在线学习。基于两阶段增量学习的表面缺陷分割方法。该方法采用两阶段增量学习的优化模式，提高现有模型的缺陷分割精度。 初始学习阶段利用随机权重平均优化算法提前将模型优化到平坦的局部极小点区域并缓解后续增量学习阶段带来的灾难性遗忘问题。 该方法使用U‑Net作为语义分割基本模型，从模型参数的优化层提高学习效率，克服灾难性遗忘问题。表面缺陷分割方法涉及将增量任务中的缺陷图像分为训练集和验证集。 将初始任务中的验证集数据添加到增量任务验证集中，以增强增量任务中训练集的数据。 在初始任务得到的模型的基础上，为当前增量任务增加相应的输出特征通道号。 将增量训练集中的样本输入增量模型，得到样本三元组的输出特征。 根据初始任务性能损失和增量任务学习损失，采用随机梯度下降优化算法训练增量模型。 利用增量模型测试所有任务对测试集的学习效果。   6
本发明公开了一种基于深度学习的飞机驾驶舱跨屏眼动交互方法及系统，包括以下步骤：步骤S1：采用大规模视线识别的方法获取眼动训练集；步骤S2：通过视觉Transformer的深度学习方法不断对眼动训练集进行训练，获得眼动信息；步骤S3：根据眼动信息进行若干个屏幕的用户眼动校对，获得若干屏幕相对位置；步骤S4：根据用户的实时眼动数据、屏幕相对位置计算用户眼动焦点匹配的屏幕，获得眼动焦点屏幕；步骤S5：根据眼动焦点屏幕实时激活匹配的飞机驾驶舱显控系统屏幕，执行预设交互操作。本发明的飞机驾驶舱跨屏眼动交互方法能够面向复杂飞行场景，且提升飞行员跨屏交互的效率和用户体验。基于深度学习的飞机座舱跨屏眼动交互方法。该跨屏眼动互动方法提高了飞行员跨屏互动的效率和用户体验。所述跨屏眼动交互方法涉及利用大规模视线识别获取(S1)眼动训练集。 通过深度学习的视觉方法对眼部运动训练集进行持续训练(S2)，以获取眼部运动信息。 通过面向三维注视向量来提取眼动训练集的注视图像。 在所述固定图像中提取所述用户数据。 根据所述用户数据校准飞机座舱的真实环境。 根据用户的实时眼动数据计算用户眼动焦点匹配画面。 根据眼睛聚焦画面执行预设交互操作(S5)。包括一种基于深度学习的飞机驾驶舱跨屏眼动交互系统，其具有深度学习模块。   5
本发明属于图像压缩技术领域，公开了一种显著性压缩的方法、系统、存储介质、计算机设备及应用，所述显著性压缩的方法包括：对于显著性检测模块：采用U2Net网络实现显著性检测模块；对比残差块融合局部特征与多尺度特征，提出整体网络架构；根据U‑Net和非局部残差，提出ResU来提取阶段内多尺度特征；输入卷积层，通过普通卷积层将原始特征图转成中间图F1(x)；以中间特征图F1(x)为输入，通过U‑block学习和编码多尺度上下文信息；通过F1(x)和U(F1(x))融合局部特征与多尺度特征；对于压缩模块：提出注意力通道方法，改进离散高斯模型，最后引入解码器增强，实现图像压缩架构的构建。本发明能够在低比特率下，提升图像的压缩质量。该方法涉及通过U2Net网络实现显著性检测模块。 基于基本模型来确定图像压缩模块的架构。 引入注意力通道过程来改进离散高斯混合模型。 增加解码器增强模块。 将残差块融合局部特征与多尺度特征进行比较。 输入卷积层。 通过公共卷积层将原始特征图转换为中间图。 将中间映射图作为输入。 通过U块学习并编码多尺度上下文信息。   6
本发明提出一种预训练词向量生成方法、系统、电子设备及存储介质，其方法技术方案包括数据集处理步骤，收集一数据集，对所述数据集进行预处理，将所述数据集中的原始文本数据变换为数字表示；文本向量生成步骤，建立一向量矩阵，根据所述数字表示在所述向量矩阵中取相应的向量；隐藏向量生成步骤，将中心词窗口大小范围内的所有的所述向量经过一隐藏层，得到隐藏向量；输出向量计算步骤，将所述隐藏向量通过线性层，计算得到中心词CBOW的输出向量；词向量生成步骤，根据所述输出向量和所述数字表示获得矩阵K、矩阵V和矩阵Q，并根据所述矩阵K、所述矩阵V和矩所述阵Q进一步进行词向量生成。本申请解决了现有方法词向量表达能力有限的问题。用于通过使用电子设备(要求保护)来生成预训练词向量的方法。该方法引入词汇的上下文信息，通过Cbow生成K， V矩阵，与传统的矩阵生成方式相比，从而在词向量映射的初始阶段引入上下文，由于词向量模型的初始阶段通过模型结构的设计引入上下文信息。该方法包括收集数据集。 数据集被预处理。 将原始文本数据转换为数字表示。 生成文本向量。 建立向量矩阵。 根据所述数字表示在所述向量矩阵中获取相应的向量。 通过隐藏层得到所有向量的中心字窗口大小范围，得到隐藏向量。 通过线性层计算中心字的输出向量。 根据输出向量和数字表示进行字向量生成处理，得到矩阵K，矩阵V和矩阵Q，根据矩阵K和矩阵V继续进行字向量生成处理。独立的权利要求书包括： 预训练词向量生成系统； 电子设备； 以及 一种用于存储一组指令的计算机可读存储介质，所述指令用于通过使用电子设备来生成预训练字向量。  12
本发明提供一种基于RBL‑CNN‑MA的DGA域名家族多分类检测方法。该方法包括：将待分类DAG域名数据输入至RoBERTa预训练模型，得到域名的句嵌入特征向量和字嵌入特征向量；将所述字嵌入特征向量输入至双向LSTM层来提取长距离特征，得到一个融合域名上下文关联性的文本矩阵；将所述文本矩阵输入至CNN层来提取局部特征；将CNN层的输出输入至多头注意力层以从多个维度进行特征提取；将多头自注意力层的输出与RoBERTa预训练模型输出的句嵌入特征向量进行融合，得到一个新的句嵌入特征向量；将所述新的句嵌入特征向量输入至全连接层，得到待分类DGA域名数据的分类结果。基于RBL-CNN-MA的域名生成算法(DGA)的网络安全区域名组多分类检测方法。该方法使得将当前语句嵌入特征向量输入至全连接层，即可得到待分类DGA域名数据的分类结果，因此增加了域名分组多分类检测的分类准确率。该方法是将待分类的DGA域名数据输入RoBERTa预训练模型，生成该域名的语句嵌入特征向量和词嵌入特征向量。 将所述词嵌入特征向量输入双向LSTM层，以提取长距离特征，用于生成融合域名上下文相关性的文本矩阵。 将文本矩阵输入到CNN层以提取局部特征。 CNN层的输出被输入到多头注意力层以从多个维度提取特征。 将所述多头自注意力层的输出和所述句子嵌入特征向量进行融合，以生成当前句子嵌入特征向量。 将所述当前语句嵌入特征向量输入全连接层，得到所述待分类DGA域名数据的分类结果。  12
本申请适用于计算机领域，提供了信息抽取方法、装置、电子设备及计算机存储介质，包括：获取待抽取文本；将所述待抽取文本输入信息抽取模型，其中，所述信息抽取模型是基于预训练模型进行训练获得的，所述预训练模型是对预训练语料库进行实体知识训练获得的；根据所述信息抽取模型输出的信息抽取结果，获得所述待抽取文本对应的目标信息。本申请通过采用经过实体知识训练的信息提取模型对待抽取文本进行处理，从而提取出表征待提取文本实体知识以及实体关系的内容，提高了信息抽取结果中实体语义关联性。文本处理领域信息提取方法。该方法通过利用实体知识训练的信息抽取模型对待抽取文本进行处理，以抽取出表征文本的实体知识的内容和实体关系，提高了信息抽取结果中的实体语义相关性。该方法包括获得(S201)待提取的文本。 将所述待提取文本录入所述信息提取模型。 所述信息提取模型是基于预先训练的模型训练得到的。 对所述预训练语料进行实体知识训练得到所述预训练模型(S202)。 根据信息抽取模型输出的信息抽取结果获取(S203)待抽取文本对应的目标信息。 获取预训练语料，所述预训练语料中包含预训练文本，每个预训练文本中包含实体词。 根据所述预训练语料对所述预训练模型进行实体知识训练，所述预训练模型为包括编码器-解码器的转换器模型。独立权利要求包括以下内容：(1)信息提取装置； (2)用于提取信息的电子装置； 以及(3)存储用于提取信息的程序的计算机可读存储介质。  11
本申请涉及人工智能技术领域，特别涉及一种基于进化算法的多任务持续学习方法、装置、设备及介质，方法包括：确定多个待持续学习任务和每个待持续学习任务对应的进化世代个数，获取利用任一待持续学习任务进行训练时的训练结果和当前进化世代个数，且在当前进化世代个数达到任一待持续学习任务对应的进化世代个数时，根据训练结果更新初始世界模型库，从剩余的多个待持续学习任务中选择新的任一待持续学习任务进行训练，直至多个待持续学习任务均完成后，得到满足预设性能要求的初始世界模型库，并将其作为多任务持续学习大模型。由此，解决了由于训练深度模型的局限性，导致其学习能力和泛化能力较弱等问题，有效利用多任务构建通用人工智能。基于进化算法的多任务连续学习方法。该方法解决了由于训练深度模型的局限性，学习能力和泛化能力较弱的问题，有效利用多任务构建通用人工智能。该方法涉及确定(S101)要继续学习的多个任务以及与要继续学习的每个任务相对应的进化代数。 从多个待连续学习任务中选择所述任一待连续学习任务，并在使用所述任一待连续学习任务进行训练时，获取所述训练结果和所述当前进化代数(S102)。 从剩余的多个待连续学习任务中选取所述任一个新的待连续学习任务进行训练。 获取满足预设性能要求的初始世界模型库，在所述多个待连续学习任务完成后并将所述满足预设性能要求的初始世界模型库作为大型多任务连续学习模型(S103)。包括以下独立权利要求：(1)一种基于进化算法的多任务持续学习装置； (2)电子设备； (3)一种计算机可读存储介质，其存储用于多任务连续学习的程序。  11
本发明涉及数据处理技术领域，提出了一种大语言模型隐私信息保护方法，包括：获取大语言模型相关参数；对获取得到的大语言模型相关参数进行预处理得到不同维度分词数据，根据大语言模型相关参数计算不同维度分词数据的同类语义集合并计算不同维度分词的重要关联评价系数；利用大语言模型相关参数获取同义词词林编码，计算不同时刻处不同维度分词的关联相似指数，根据不同时刻处不同维度分词的关联相似指数计算聚类评价函数并获取高频隐私信息簇；根据高频隐私信息簇对大语言模型相关参数获取脱敏替换文本序列，根据脱敏替换文本序列对大语言模型隐私信息进行保护。本发明提高了对大语言模型隐私信息保护的可靠性。大语言模型隐私信息保护方法。提高了对大型语言模型隐私信息进行保护的可靠性。该方法包括获得大型语言模型的相关参数(S001)。 对得到的相关参数进行预处理，得到不同维度分词数据。 计算不同维度的重要相关评价系数(S002)。 得到同义词森林码。 计算不同维度分词在不同时刻的相关性相似度指数。 基于不同维度分词的相关相似度指标计算聚类评价函数。 根据聚类和评价函数得到高频隐私信息聚类(S003)。 对所述大语言模型的相关参数得到脱敏替换文本序列。 根据高频隐私信息聚类对语言模型的相关参数得到(S004)脱敏替换文本序列。  11
本发明提供了一种在数字人应用场景下数字图像快速生成方法及系统，属于数字图像处理领域。所述方法包括基于初始低分辨率小图构建多分辨率图像模型；所述多分辨率图像模型包括压缩比从下至上递增的多个压缩层级，且下一压缩层级中图像的单位面元数较上一压缩层级中图像的单位面元数成倍增加；获取实时场景图像及其对应的各面元编码；通过多分辨率图像模型以编码的形式反向链接到所需的分辨率图像对应的面元编码，完成相似面元的替换和拼接，生成所需的分辨率图像。本发明在继承低分辨率小图的基础上，构建带有面元编码的多分辨率图像模型，通过反向编码生成大模型，以实现高分辨率大图的快速生成。用于在数字人类应用场景中生成数字图像的方法。该方法在继承低分辨率小图像的基础上，用bin码构建多分辨率图像模型，通过反向编码生成大模型从而实现高分辨率大图像的快速生成。所述方法包括：基于初始低分辨率小图像构建多分辨率图像模型(S100)，所述多分辨率图像模型包括压缩比从下至上递增的压缩级别，其中，下一压缩级别的图像的单位单元的数量比上一压缩级别的图像的单位单元的数量增加数倍。 获取实时场景图像和对应的面要素编码(S200)。 将一个多分辨率图像模型以编码方式反向链接到所需分辨率图像对应的人脸要素编码上，完成一次相似人脸要素的替换和拼接(S300)，生成所需分辨率图像。独立权利要求包括用于：(1)用于在数字人类应用场景中生成数字图像的系统； (2)计算机装置； 以及(3)计算机可读存储介质，其存储用于在数字人类应用场景中生成数字图像的计算机程序。   6
本发明给出了一种基于HTML源代码和网页快照的Web信息抽取方法与系统，包括通过收集网页快照训练数据，在网页快照训练数据中标注表征网页快照训练数据的类别的标签，得到标注后的网页快照训练数据；将标注后的网页快照训练数据输入混合CNN和BERT的神经网络架构进行模型训练，获取用于抽取网页信息的神经网络模型；最后基于神经网络模型对网络上的标签未知的网页快照数据进行抽取输出标签未知的网页快照数据对应的标签。通过搜集足够数量的网页极其快照，选择具有多样性布局和内容的网页，提高了后续生成的模型的泛化能力，并且将网页快照部分和HTML源代码部分分别输入CNN和BERT，充分利用了文本和网页快照的信息，提升了Web信息抽取的精度。一种基于HTML源代码和网页快照提取网页信息的方法。该方法能够收集足够多的网页极快照， 选择版面和内容多样化的网页，提高后续生成模型的泛化能力，分别输入网页快照部分和HTML源代码部分CNN和BERT，充分利用文本和网页快照的信息，提高网页信息提取的精度。该方法包括收集(S201)网页快照训练数据。 网页快照训练数据包括网页快照训练数据和HTML源代码训练数据。 在网页快照训练数据中标记网页快照训练数据的类别的标签。 将标记网页快照训练数据和HTML源代码训练数据输入(S202)混合CNN和BERT的神经网络体系结构中以进行模型训练。 获得用于提取网页信息的神经网络模型。 提取并输出标签。独立的权利要求书被包括在以下内容中： 一种基于HTML源代码和网页快照的网页信息提取系统； 以及 一种用于存储网络信息提取程序的计算机可读存储介质。  12
本发明公开了一种基于多任务学习知识增强的级联标签分类方法，属于自然语言处理技术领域，包括以下步骤：S1：语义表征；S2：多任务分类。本发明将预训练模型得到的上下文语义表征和义原知识表征相融合，同时加入了多任务学习的方法使得模型能够迭代训练，学习到不同标签之间的关系，提高了通用预训练语言模型在运营商投诉工单分类任务上的准确率。基于多任务学习知识增强的级联标签分类方法。该方法能够提高通用预训练语言模型在操作员投诉工作指令分类任务上的准确性。该方法包括通过使用上下文编码器来获得投诉工作表文本的语义表示向量。 知识增强编码器用于从原始知识的上下文和语义中提取语义表示。 通过分类器进行多任务分类操作。 根据训练编码器得到的共享语义表示得到多级分类标签。 知识学习模块，用于实现单词表示中的学习操作。  11
本申请实施例公开了一种模型训练方法、装置、存储介质及电子设备。该方法包括：构建训练数据集，并基于训练数据集对初始化的样本模型进行训练，得到预训练模型；基于验证数据集对所述预训练模型进行迭代微调训练。当关键指标在经过预设次数的迭代后未得到优化，停止迭代微调训练，对调整后模型的所有参数添加噪声信号，并重新进行迭代微调训练。本方案在模型微调早停时，向模型参数添加矩阵式的噪声来帮助更好地微调下游任务，根据标准差向不同的参数矩阵添加不同的均匀噪声，使模型摆脱对于训练数据某些特征的过分关注，寻找更加广泛通用的特征，提升了最终输出模型的性能。用于训练利用参数化网络模型逐渐拟合训练数据的模型的方法。本发明通过在模型参数中加入矩阵型噪声来帮助在模型微调提前停止时更好地微调下游任务，并根据标准差在不同的参数矩阵中加入不同的均匀噪声，使得模型摆脱了对训练数据的某些特征的过分关注，寻找到了通用性更广的特征，从而提高了最终输出模型的性能。该方法涉及构建训练数据集。 基于所述训练数据组对初始化的样本模型进行训练，得到预训练模型。 基于验证数据组对所述预训练模型进行迭代精调训练过程。 迭代预设次数后，关键索引未优化时，停止迭代微调过程。 噪声信号被添加到调整后的模型的参数。 再次进行迭代iterativefine调整训练。包括用于以下的独立权利要求：(1)用于训练模型的装置，所述模型用于利用参数化网络模型逐渐拟合训练数据； (2)一种计算机可读存储介质，包括用于训练模型的方法的指令，所述模型用于利用参数化网络模型逐渐拟合训练数据； (3)一种电子设备，包括存储器和处理器，所述处理器执行存储在所述存储器中的用于训练模型的方法的指令，所述方法用于利用参数化网络模型逐渐拟合训练数据。  11
本发明属于生态环境变化检测技术领域，公开了一种基于非局部U‑net端到端神经网络的生态变化监测方法、终端、计算机设备及介质，输入两幅同地区不同时间的SAR图像，利用对数比算子和均值比算子分别生成对数比差异图和均值比差异图，并通过数据增强方法扩增数据作为模型的训练和测试数据集；采用非局部U‑net为主干网络，并改进CRF as RNN模块然后与非局部网络构建端到端的变化检测模型；基于上述端到端的变化检测模型，通过利用非局部U‑net网络和CRF as RNN的联合作用，获得最终的变化检测结果。本发明取得了较高的检测精度，对于研究人类与生态环境的交互关系有着重要意义。基于非本地U-net端到端神经网络的生态变化监测方法。该方法能够获得较高的检测精度，对于研究人类与生态环境的相互作用关系具有重要意义。该方法包括在不同时间内输入同一区域的两幅SAR图像。 允许对数比值算子和均值比值算子分别绘制对数比值差值图和均值比值差值图。 通过执行数据增强处理，获得数据作为模型的训练和测试数据组。 建立非本地U-net网络作为主网络。 伴随RF(CRF)被用作递归神经网络(RNN)模块。 与非本地U-net网络建立端到端变化检测模型。 利用非本地U-net网络和伴随RF的联合作用，得到最终的变化检测结果。独立权利要求还包括用于一种信息数据处理终端，所述信息数据处理终端包括处理器和存储器，所述处理器和存储器用于执行一种基于非本地U-net端到端神经网络的生态变化监测方法； 一种计算机设备，包括处理器和存储器，用于执行一种基于非本地U-net端到端神经网络的生态变化监测方法，所述方法包括以下步骤：获取所述基于非本地U-net端到端神经网络的生态变化； 以及计算机可读存储介质，用于存储用于执行基于非本地U-net端到端神经网络的生态变化监测方法的指令集。   6
本发明公开了一种信息处理方法及系统，包括：协作方根据协作方模型确定得到与各个数据提供方对应的中间模型并分别下发给对应的各个数据提供方；数据提供方根据数据提供方的私有数据，对接收到的用于作为其本地模型的中间模型和数据提供方的个性化模型进行知识蒸馏，得到训练后的个性化模型；数据提供方根据各个参与方共有的公共数据集，通过训练后的个性化模型进行预测得到输出数据并将输出数据发送至协作方；协作方根据输出数据和公共数据集，通过知识蒸馏对协作方模型进行训练，得到目标全局模型，用以执行数据提供方计算资源少于预设计算资源场景下的联邦学习的操作。本发明可以在有参与方计算资源少的场景下，有效地实现大模型训练。处理信息的方法。该方法能够在参与方资源较少的情况下，有效实现大模型训练。该方法包括根据合作方模型确定合作方以获得数据提供方对应的中间模型。 对于作为数据提供方的本地模型和个性化模型的接收到的中间模型执行知识蒸馏。 训练后得到所述个性化模型。 获取所述输出数据并发送至所述合作方。 通过知识蒸馏对合作方模型进行训练。 得到所述目标全局模型。 在所述数据提供方的计算资源小于所述预设计算资源的场景下执行联合学习的操作。本发明还涉及一种信息处理系统。  11
本发明涉及一种基于语音识别的文本确定方法及系统。该方法包括获取语音文件；根据所述语音文件生成第一文本；对所述第一文本进行预处理；采用BERT算法提取所述预处理后的第一文本中的所有实体，得到实体集合；对所述实体集合中的所有实体采用注意力模型确定多个三元组；对所有所述三元组进行重组，确定第二文本；所述第二文本为符合语法结构的文本。本发明所提供得一种基于语音识别的文本确定方法及系统，能够提高通过语音识别生成的文本信息的可读性。基于语音识别确定文本的方法。该方法提高了语音识别生成的文本信息的可读性。该文本确定方法包括获取语音文件，根据语音文件生成第一文本。 第一文本具有说出的单词、重复的短语和重复的短句。 文本为不符合语法结构的文本，对第一文本进行预处理。 预处理后的第一文本为去除第一文本中的口语词、重复词组、重复短句的文本。 双向编码器表示(BERT)算法用于提取预处理的第一文本中的所有实体以获得实体集合。 所述实体为复合信息的抽象，所述实体包括时间、地点、姓名或组织。 注意力模型用于为实体集合中的所有实体确定多个三元组。 所述首实体的时间序列先于所述尾实体序列，对所有所述三元组进行重组，确定第二文本，所述第二文本为符合语法结构的文本。本发明还涉及一种基于语音识别的文本确定系统。 3
本公开提供了一种地理与视觉跨模态预训练模型的训练方法、位置确定方法，涉及人工智能技术领域，尤其涉及自然语言处理、计算机视觉等领域，具体实现方案为：基于地图数据构建预训练数据集，根据预训练数据集和预训练目标，对待训练模型进行模型训练，得到多视觉任务约束的第一预训练模型。采用本公开，可以提高模型的精度。面向多种应用的人工智能领域地理视觉跨模式预训练模型的训练方法。 用途包括但不限于自然语言处理、计算机视觉、图像处理、视频处理和目标定位。通过对多视觉任务约束的模型进行模型训练，提高了模型训练的精度和准确度。 地理视觉跨模式预训练模型的训练装置，用于基于地图数据构建预训练数据集，根据预训练目标与模型训练得到第一预训练模型，以便提高模型的精度。该方法涉及基于地图数据构建预训练数据集。 根据所述预训练数据集和模型训练目标训练得到多视觉任务约束的模型。 基于所述地图数据构建所述模型。 所述模型训练目标为基于训练模型的模型。 训练模型设置有相互连接的第一模型和第二模型。包括独立权利要求：(1)一种地理和视觉跨模式预训练模型的训练装置； (2)地理视觉交叉模式预训练模型的位置确定装置; (3)一种用于训练地理和视觉交叉模式预训练模型的计算机程序产品。  11
本说明书一个或多个实施例提供一种webshell检测方法及装置，首先利用代码训练集训练预训练模型，得到检测预训练模型，然后可利用检测预训练模型对输入的待测代码进行预测，得到待测代码是否为webshell的检测结果。本实施例能够提高webshell的检测能力，降低误报率。Webshell检测方法。该方法能够提高webshell的检测能力，降低误报率，获取待测代码的检测结果。该方法涉及使用代码训练组来训练预训练模型，其中代码训练组包括令牌序列、字符串序列和代码标签组。 建立检测预训练模型。 将待测试代码输入所述检测预训练模型，以输出代码检测结果。 对所述待测试代码进行解析，得到所述令牌序列和所述字符串序列。 对所述令牌序列进行符号化处理，得到符号化处理后的令牌序列。 变量名被转换成变量符号。 聚合序列向量被输入到分类器。本发明还公开了一种webshell检测装置。  11
本发明属于图像处理技术领域，尤其涉及一种HDR图像生成方法、装置、计算机可读存储介质及终端设备。所述方法首先获取待处理的单帧原始图像，然后使用预设的深度学习网络对所述原始图像进行处理，生成与所述原始图像对应的HDR图像。所述深度学习网络采用轻量化的Unet网络和残差模块相结合的网络结构，且所述深度学习网络是基于预设的训练样本集合训练得到的，与原始的Unet网络相比，所述轻量化的Unet网络进一步减少了下采样层的层数、上采样层的层数以及特征图的通道数，大大简化了网络结构，而且，由于残差模块能够有效地提取出原始图像中的高频信息，从而更好地恢复高光区域的细节信息，极大提升了HDR图像的生成效果。使用移动电话、平板电脑、台式电脑、笔记本、掌上电脑和云服务器等终端设备(主张)生成HDR图像的方法。上采样层数和特征图通道数大大简化了网络结构。 该方法能够较好地还原高光区域的细节信息，大大提高了HDR图像的生成效果。该方法包括获得(S101)待处理的单帧原始图像。 采用预设的深度学习网络(S102)对所述原始图像进行处理，生成所述原始图像对应的HDR图像。 所述深度学习网络采用轻量级Unet网络和残差模块相结合的网络结构。 基于预设的训练样本集对所述深度学习网络进行训练。 轻量级Unet网络是在原有Unet网络的基础上，减少下采样层数、上采样层数、特征图的通道数得到的网络。独立权利要求包括用于以下的：用于生成HDR图像的设备； 以及存储用于生成HDR图像的程序的计算机可读存储介质。   6
本发明提供了一种证件检测方法、装置、电子设备和存储介质，证件检测方法包括：获取待检测证件的图像；通过预训练模型对待检测证件的图像进行处理，获得第一检测图像；通过至少一个目标模型对待检测证件的图像进行处理，获得各目标模型输出的第二检测图像；根据第一检测图像和第二检测图像，对待检测证件进行异常检测，并获得异常检测结果；根据异常检测结果，对待检测证件进行分流。本申请通过预训练模型和至少一个目标模型对待检测证件的图像进行处理，能够代替人工对异常证件进行挑选，并且通过模型进行检测的方式能够提高证件异常检测的准确率。同时，通过设置预训练模型和至少一个目标模型，能够提高异常检测的效率。用于使用电子设备在深度学习领域中检测证书的方法(权利要求书)。该方法通过预训练模型和至少一个目标模型对待检测证书图像进行处理，代替人工挑选异常证书，通过检测模型提高证书异常检测的准确性，通过设置预训练模型和至少一个目标模型提高异常检测的效率。该方法涉及获得待检测的证书的图像(101)。 通过预训练模型处理(102)所述待检测证书图像，得到第一检测图像。 通过至少一个目标模型对所述待检测证书图像进行处理(103)。 获取每个所述目标模型输出的第二检测图像。 根据所述预训练模型得到所述目标模型。 根据所述第一检测图像和所述第二检测图像对所述待检测证书进行异常检测(104)。 得到异常检测结果。 根据所述异常检测结果对所述待检测证书进行分割(105)。独立权利要求还包括用于：一种用于检测证书的装置； 一种计算机存储介质，包括用于检测证书的指令集； 以及包括用于检测证书的指令集的计算机程序产品。 14
本说明书提供了一种基于预训练模型的代码生成方法及相关设备。该方法包括：响应于用户在预设的代码编写界面中输入目标代码，生成与所述目标代码对应的目标代码生成请求；确定是否存在正在执行的历史代码生成请求；其中，所述历史代码生成请求为与用户在所述目标代码之前输入的历史代码对应的代码生成请求；若是，则停止执行所述历史代码生成请求，以释放所述历史代码生成请求所占用的系统资源；以及，为所述目标代码生成请求分配对应的系统资源，并基于分配的所述系统资源执行所述目标代码生成请求，以触发调用预训练模型，由所述预训练模型基于所述目标代码和所述历史代码为用户生成代码。用于通过使用基于预训练模型的计算机设备(权利要求书)生成代码的方法。目标代码生成请求是基于分布式系统资源执行的，以触发和调用预训练模型，从而使得能够以高效的方式基于目标代码和历史代码为用户生成代码。该方法包括响应于用户在预设代码编写界面中输入目标代码，生成与目标代码对应的目标代码生成请求。 确定是否存在需要执行的历史代码生成请求。 历史代码生成请求为用户在输入目标代码之前输入的历史代码对应的历史代码生成请求。 释放历史代码生成请求占用的系统资源。 为所述目标代码生成请求分配对应的系统资源。 基于分布式系统资源触发调用所述预训练模型，以触发调用所述预训练模型。 生成代码，以供用户基于目标代码和历史代码生成代码。独立权利要求还包括用于：基于预训练模型的代码生成装置； 以及一种计算机可读存储介质，包括用于通过使用计算机设备基于预训练模型来生成代码的指令集。  11
本公开提供了一种视频对话及模型训练方法、装置、设备和存储介质，涉及人工智能技术领域，具体为计算机视觉、深度学习、大模型等技术领域，可应用于AIGC等场景。视频对话方法包括：对目标视频进行表征提取处理，以获得所述目标视频的初始视频表征；对所述初始视频表征进行时空处理，以获得所述目标视频的目标视频表征；对所述目标视频表征进行转换处理，以获得所述目标视频的视频嵌入；其中，所述视频嵌入的维度与问题文本的文本嵌入的维度相同；对所述视频嵌入和所述文本嵌入进行对话处理，以获得答案文本。一种人工智能技术领域的电子设备进行视频通话的方法(权利要求)。该方法使得能够允许视频对话和模型训练过程被有效地应用于场景，即AIGC。该方法涉及提取目标视频的表示以获得目标视频的初始视频表示(101)。 对所述初始视频表征进行空时处理(102)，得到所述目标视频的目标视频表征。 对所述目标视频表示进行转换(103)，得到所述目标视频的视频嵌入，所述视频嵌入的维度与所述问题文本的文本嵌入的维度相同。 对所述视频嵌入和所述文本嵌入进行对话处理(104)，得到答案文本。独立权利要求包括用于：(1)视频对话模型的训练方法； (2)视频对话装置； (3)视频对话模型的训练装置； (4)一种非瞬时计算机可读存储介质，用于存储执行视频会话的一组指令； (5)一种计算机程序产品，包括用于执行视频对话的一组指令。 9
本发明公开一种基于上下文表示增强的跨语言命名实体识别方法，属于自然语言处理应用技术领域。本发明分别基于注意力分布损失和门控残差连接增强跨语言预训练模型在跨语言命名实体识别任务中的上下文表示，分为训练和预测两阶段，训练后用于预测，将跨语言预训练模型顶层编码器的自注意力模块得到的注意力分布中每个词对自身的注意力系数加入训练损失，减少模型对词语自身的关注，使得上下文表示中包含更多的上下文信息，采用门控残差连接模块作为跨语言预训练模型顶层编码器中接在自注意力模块后的残差连接模块，通过门抑制词语本身信息进入最终上下文表示的比例，提升上下文信息在上下文表示中的占比。基于上下文表达增强的跨语言命名实体识别方法，用于自然语言处理应用领域。该方法通过门抑制词的信息，降低模型对词的关注度，从而提高最终上下文表达中上下文信息的比例，使得上下文表达能够保持在上下文信息中。该方法包括将跨语言预训练模型的顶层编码器的自注意力模块得到的注意力分布中的每个词的注意力系数添加到训练损失中。 降低了跨语言预训练模型对该词的关注度。 上下文信息被放置在上下文表示中。 门控残差连接模块，作为跨语言预训练模型顶层编码器中连接在自注意力模块后面的残差连接模块。 通过门禁止单词信息进入最终的上下文表达式，增强了上下文表达式中上下文信息的比例。  11
本公开提供了一种信息展示方法，涉及人工智能技术领域，尤其涉及人机交互、智能问答、自然语言处理、大语言模型和生成式对话模型技术领域。具体实现方案为：响应于接收到来自目标对象的输入信息，从输入信息中确定针对目标实体的目标问题；根据目标问题，获取目标实体的基础数据以及目标实体所属类别的基准数据；根据基础数据和基准数据，生成目标问题的应答信息；以及展示应答信息。本公开还提供了一种信息展示装置、电子设备和存储介质。用于显示用于各种领域的信息的方法。 用途包括但不限于人机交互、智能问答、自然语言处理、大语言模型和生成的对话模型领域。该方法使得能够利用多轮会话方式为用户解决问题，降低了用户的使用成本，通过多轮会话交互逐步定义用户的问题和解决方案，实现与用户的有效沟通，有效解决用户问题。该方法涉及响应于从目标对象接收到输入信息，根据输入信息确定针对目标实体的目标问题。 根据所述目标问题获取所述目标实体的基础数据和一类目标实体的参考数据。 基于所述基础数据和所述参考数据生成所述目标问题的响应信息。 显示所述响应信息。独立权利要求包括：(1)一种信息显示装置； (2)一种电子设备，包括用于执行用于显示信息的指令集的存储器和处理器; 以及(3)用于执行用于显示信息的指令集的计算机程序产品。  11
本公开公开了网页文本处理方法、装置、电子设备以及存储介质，涉及人工智能技术领域，尤其涉及前端、大语言模型、自然语言处理技术领域。具体实现方案为：响应于网页处理请求，对当前网页进行解析，得到多个网页文本字段和多个网页文本字段各自的网页标签；基于多个网页文本字段各自的网页标签的标签类型，确定多个网页文本字段各自的权重；以及利用大语言模型，基于网页处理请求携带的处理指令信息和多个网页文本字段各自的权重，处理多个网页文本字段，得到目标文本。用于通过使用电子设备处理网页文本的方法(要求保护)。该方法使得能够利用大语言模型基于网页处理请求携带的处理指令信息和多个网页文本字段各自的权重对多个网页文本字段进行处理，以有效的方式得到目标文本。该方法包括：响应于网页处理请求，分析当前网页以获得多个网页正文字段和网页正文字段的网页标签(S210)。 基于每个网页标签的标签类型，确定多个web文本字段中的每个web文本字段的权重(S220)。 利用大规模语言模型基于所述网页处理请求携带的处理指示信息和所述多个网页文本字段各自的权重对所述网页文本进行处理(S230)，得到目标文本。独立权利要求还包括：一种用于处理网页文本的装置； 一种非瞬时计算机可读存储介质，其存储有用于通过使用电子设备来处理网页文本的指令集； 以及计算机程序产品。  11
本申请公开了一种批数据集构建方法、装置、电子设备及存储介质。该方法通过对用于Transformer语言模型训练的数据样本集合进行排序，利用有序的数据样本生成高质量的批数据，从而构建训练批数据集。该方法提高单次载入GPU显存的有效训练样本数量，同时最大程度降低无效的占位文字数量，降低无效数据对GPU计算资源的占用，从而大大提高训练效率，降低训练时间。构建批数据集的方法。该方法提高了GPU单次加载时有效训练样本的数量，减少了无效占用字数和无效数据对GPU计算资源的占用，从而大大提高了训练效率，减少了训练时间。该方法涉及使用(S101)获得用于变压器模型训练的一组数据样本集S。 将所述数据样本集合S中的所有数据样本按照字数进行排序(S102)，得到排序后的数据样本的有序队列。 初始化新的批次数据(S103)，记为批次数据K。将当前数据样本有序队列中的第一个数据样本添加(S104)到当前批次数据K中。计算当前批次数据K中数据样本包含的字符总数。如果C大于等于M或者当前数据样本有序队列中没有数据样本，则继续批次数据生成步骤(S105)迭代执行。 批数据集构建步骤，用于将当前批数据K添加到批数据集中。 如果数据样本在当前数据样本有序队列中，则继续执行批量数据初始化步骤和批量数据生成步骤。独立权利要求包括如下：一种用于构建批数据集的装置； 电子设备； 以及存储用于构造批数据集的程序的计算机可读存储介质。  11
本发明公开一种面向智能监控系统的暗处暴力行为检测方法包括：提取视频帧数据并对模糊的视频帧进行图像增强得到高质量视频帧，调整原视频帧和高质量视频帧的输入尺寸；采用主干网络对两条路径的帧序列进行时空特征提取，通过多尺度注意力模块提取序列的特征；将时空特征并行传入BERT网络模块，利用多头注意力模块和PFFN网络进行特征融合并提取关键时空特征；经过计算得到模块的行为识别结果并判断视频序列是否存在暴力行为；本发明结合多尺度注意力和特征融合的思想设计网络结构，能获得多尺度的语义信息，将轻量级的低光图像增强技术应用到暗光环境下的暴力行为检测，能够改善阴暗模糊环境下暴力行为识别的困难。用于银行、街道、医院、学校等安全重点区域的面向智能监控系统的暗处暴力行为检测方法。该检测方法使用了多头注意力模块和PFFN网络进行特征融合并进一步提取关键空间特征，因此模型的整个暴力行为识别准确率、准确率得到提高。 将轻量级微光图像增强技术应用于暗光环境下的暴力行为检测，可以提高暗暗环境下暴力行为识别的难度。该方法包括提取视频帧数据，对暗视频帧和模糊视频帧进行图像增强，得到高质量视频帧，调整原始视频帧和高质量视频帧的输入大小。 利用主干网络分别提取暗路和光路的帧序列的时空特征，通过多尺度注意力模块提取视频序列的多尺度特征。 时空特征并行传入BERT网络模块，利用多头注意力模块和渐进特征融合网络(PFFN)进行特征融合，进而提取关键时空特征。 通过计算得到所述BERT网络模块的最终暴力行为识别结果，并根据所述最终暴力行为识别结果进行判断所述视频序列中是否存在暴力行为的判定。 9
本申请公开了一种基于生成式人工智能技术的图像调试方法、图像调试装置、电子设备及计算机可读存储介质。其中，该方法包括：响应于图像调试请求指令，确定图像调试需求；根据所述图像调试需求，生成图像调试方案；基于所述图像调试方案对待处理图像进行调试，得到已调试图像。通过本申请方案，可在降低图像调试成本的同时提升图像调试效率。应用于当前视频采集系统的基于生成式人工智能技术的图像调试方法。该方法对用户输入的图像调试请求指令进行自动分析，得到图像调试需求，生成相应的图像调试方案，实现了图像的智能调试。 用户不需要在图像调试方案中自信和编写相关调试参数，使得图像调试效率提高，图像调试成本降低。该方法涉及基于图像调试请求指令确定(101)图像调试需求。 基于所述图像调试需求生成(102)图像调试方案。 基于所述图像调试方案对所述待处理图像进行调试(103)，得到调试后图像。 基于生成的人工智能模型对所述图像调试请求指令进行平移编码。 基于所述平移编码的结果确定所述图像调试需求。 基于生成的人工智能模型对所述平移编码结果进行分析，得到备选图像调试需求和对应的评分。独立权利要求书包括用于：(1)图像调试装置； (2)一种电子设备，用于实现所述图像调试方法； 以及(3)存储有用于实现所述图像调试方法的程序的计算机可读存储介质。 14
本申请涉及智能体语义通信技术领域的一种基于依存句法分析的分层语义通信方法和系统。所述方法将依存句法分析引入语义通信，在发送端利用依存句法分析对传输句子中的词语进行语义分层，根据信道质量对待传输句子中不同语义层级的词语进行选择性传输，接收端接收发送端发送的信息，对接收信息依次进行信道译码与信源译码，得到接收语句；采用ERNIE模型对接收语句进行语义恢复。本发明在发送端将依存句法分析引入语义通信克服现有语义通信方案中语义刻画不明确，语义表示过于抽象等问题，接收端接收信息后使用ERNIE语言模型进行语义恢复，相较于传统通信方法，本发明在传输可靠性方面有显著提升。用于基于依存句法分析来执行分层语义通信的方法。该方法在发送端对语义通信进行分析和引入，克服了现有语义通信方案中语义立体图不清晰，导致语义表现过于抽象的问题，提高了传输的可靠性。该方法包括：获取待传输语句。 利用jieba模型对所述待传输语句进行中文分词处理。 确定是否对应于所述待发送句子形成依存句法树。 根据所述DSS树对所述待转移语句进行语义分层处理，以将所述语句中的词语划分为不同的语义层次。 根据不同语义级别的信道质量确定传输字。 对传输字进行信源编码。 编码结果被转换成比特信息。 对所述接收信息进行信道译码和信源译码处理，依次得到所述接收语句。 将接收到的语句用于执行语义恢复过程。 ERNIE模型用于对接收到的语句进行语义恢复。包括用于基于依存关系语法分析来执行分层语义通信的系统的独立权利要求。  11
本发明涉及人工智能领域，公开了一种多关系医学知识提取方法、装置、设备及存储介质。该方法包括：将多个历史医疗语句和对应标注文件输入预置预训练堆叠模型中，先通过第一预训练模型提取各历史医疗语句中的医学知识关系；再通过第二预训练模型预测各历史医疗语句中与各医学知识关系相关联的两个实体特征，并对两者进行组合，得到三元组；持续对预训练堆叠模型进行训练，直到得到多关系医学知识提取模型；获取待抽取医学知识关系的医疗语句并输入多关系医学知识提取模型中，输出医疗语句中的一个或多个三元组。本发明还涉及区块链技术，所述医疗语句存储于区块链中。本发明实现了对多关系医疗知识的信息提取。一种多关系医学知识信息提取方法。本发明能够将医学句子存储在分块链中，实现多关系医学知识信息的提取。该方法包括获得医疗和患者对话的多个历史医疗报表。 对历史医疗报表进行标记以获得相应的标签文件。 将历史医疗报表和标记文件输入到预置的训练前堆叠模型中。 历史医疗报表之间的关系由训练前堆叠模型中的训练前模型来分类。 进行实体特征提取处理，以输出医疗报表中具有多关系医疗知识的多个医疗知识三元组。本发明还涉及一种多关系医学知识信息提取装置； 以及计算机可读存储介质，用于存储用于提取多关系医学知识信息的一组指令。  10
本申请提供了一种标注数据的处理方法、装置及电子设备，方法包括：获取原始标注数据；原始标注数据包括：标注有同一标签的多条数据；通过ChatGPT问答模型，获取原始标注数据中关键词句对应的相近文本；根据相近文本生成标签对应的正则表达式规则；应用正则表达式规则对原始标注数据进行识别，得到第一识别结果；如果第一识别结果中存在漏标数据，对正则表达式规则进行调整；通过调整后的正则表达式规则对原始标注数据进行二次识别，得到需召回的标注数据。本申请通过ChatGPT问答模型辅助生成的正则表达式规则进行标注数据召回，以及对规则的调整和二次标注数据的识别过程，可以大大提高标注数据的召回率。标注数据处理方法。该方法利用ChatGPT问答模型生成的正则表达式规则进行标签数据召回，调整规则，识别出二级标签数据，大大提高了标签数据的召回率。所述方法包括：获取原始标注数据，所述原始标注数据包括多条标注有同一标签的数据。 通过ChatGPT问答模型获取所述原始标注数据中的关键词句对应的相似文本。 根据相似文本生成与所述标签对应的正则表达规则。 应用所述正则表达式规则对所述原始标注数据进行识别，得到识别结果。 若所述识别结果中存在缺失标记数据，则调整所述正则表达式规则。 通过调整后的所述正则表达式规则对所述原始标注数据进行二次识别，得到所述待召回标注数据，所述标签包括已婚、有无中的一种。独立权利要求包括用于：(1)电子设备； 以及(2)计算机可读存储介质，其包括用于处理注释数据的一组指令。  11
意图识别方法、模型的训练方法及其装置、设备、介质，所述意图识别模型的训练方法包括：获取预设外呼场景对应的外呼场景训练数据；基于所述外呼场景的候选意图标签集合，将所述外呼场景训练数据输入初始的意图识别模型，进行迁移学习训练，得到完成训练的意图识别模型；其中，所述外呼场景训练数据包括：用于所述外呼场景的训练话术文本集合和所述训练话术文本集合对应的真实意图标签集合，所述意图识别模型包括：已完成预训练的神经网络模型。采用上述方案，提高意图识别准确率，改善客户交互体验。训练意图识别模型的方法。该方法能够提高意图识别的准确性，提升客户端的交互体验。该方法涉及获取与预设的外呼场景对应的外呼场景训练数据。 将所述外呼场景训练数据输入基于所述外呼场景的候选意图标签集合的初始意图识别模型。 执行迀移学习训练过程。 获取完成训练意图识别模型，所述外呼场景训练数据包括针对所述外呼场景的训练语音文本集合以及与所述训练语音文本集合对应的真实意图标签集合。以下包括独立权利要求：意图识别方法； 训练意图识别模型的装置； 意图识别装置； 一种数据处理设备，包括存储器和用于执行意图识别方法的处理器； 以及计算机可读存储介质，用于存储用于执行意图识别方法的指令集。 14
本发明提供一种基于大语言模型和BERT模型的本地知识库更新方法及系统，包括：接入预设的第三方平台并获取待分析数据；将待分析数据输入大语言模型，获取至少一个第一问答知识项；将待分析数据输入BERT模型，获取至少一个第二问答知识项；基于所述第一问答知识项和所述第二问答知识项，对本地知识库进行更新。本发明的基于大语言模型和BERT模型的本地知识库更新方法，实现准确有效地对本地知识库的更新。基于大型语言模型和BERT模型的局部知识库更新方法。该方法能够准确有效地更新本地知识库。该方法涉及访问预设的第三方平台。 得到待分析数据。 将所述待分析数据输入语言大模型，得到第一问答知识条目。 将所述待分析数据输入BERT模型，得到第二问答知识条目。 基于所述第一问答知识条目和所述第二问答知识条目更新本地知识库。 基于搜索关键词库对所述第三方平台的数据进行搜索。 提取搜索结果中与预设数量的对象对应的数据作为待分析数据。独立权利要求包括基于大型语言模型和BERT模型的本地知识库更新系统。  12
改进BERT的文本语义匹配设备、系统、方法及存储介质，尤其涉及文本语义匹配、BER、词粒度、相对位置编码和注意力池化的匹配设备、系统、方法及存储介质，属于自然语言处理领域；目的是解决BERT模型训练时间较长、绝对位置编码未能表明句子中词与词间的相对位置和输出文本表示不能完全利用BERT模型输出的文本表示序列的问题；本发明通过建立所述传输层中的词嵌入机制、所述编码层的相对位置编码机制以及通过所述输出层对池化后的注意力机制处理文本，完成后续文本语义匹配；本发明不仅提高了文本匹配的准确率，更加准确体现句子的不同位置和不同位置间的信息，并采用注意力池化方式，得到降维后的文本表示包含更多的语义信息。用于提高BERT的文本语义匹配系统。提高了文字匹配的准确性。 更加准确的体现了句子不同位置、不同位置之间的信息。 利用注意力力池方法得到降维后的文本表示。文本语义匹配系统包括数据预处理子系统，用于整理获得的文本，并将获得的文本传输给BERT模型子系统。 BERT模型子系统建立模型输出，对模型进行改进后由输出层子系统输出匹配结果。 所述数据预处理子系统设有字嵌入机构、相对位置编码机构、注意力机构。 数据预处理子系统包括文本获取模块、拼接模块、分词模块。 BERT模型子系统包括输入表示层、编码层和输出层。 输出层包括注意力池模块和分类器。以下包括独立权利要求：一种提高BERT的文本语义匹配方法； 以及用于提高BERT的文本语义匹配装置。  12
本发明涉及一种可灵活适配应用场景的大语言模型装置及处理方法，其方法包括以下步骤：1)将一个大规模参数的模型拆分成多个小模型，且在拆分过程中，随机将参数分配到多个小模型中；2)使用某一个具体场景频繁出现的文本对拆分了的每个模型进行预训练；3)利用原有的大模型和场景相关的文本进行任务指令生成，以进一步优化模型；4)针对这些生成的具体任务指令，对已拆分的预训练的模型进行细致的微调训练；5)对每个模型对于微调之后的模型进行测试，选取正确率最高的一个模型作为最终剪裁完成的模型；本发明同现有技术相比，大大增强了模型的适应性和灵活性，同时降低了模型训练和部署的成本，提升了AI模型在特定场景中的效能。一种用于人工智能(AI)领域的计算机设备(权利要求)中灵活地适配应用场景的大型语言模型设备，例如台式计算机、笔记本计算机、掌上电脑和云服务器。该装置增强了模型的适应性和灵活性，降低了训练和部署模型的成本并提高了特殊场景下AI模型的效率。该装置具有拆分单元，用于将大尺度参数的模型拆分为多个小模型。 预训练单元利用特定场景的频繁出现的文本对每个拆分模型进行预抽头。 优化单元，利用所述原始大模型和与场景相关的文本生成任务指令，以对模型进行优化。 细调单元，在生成的所述特定任务指令处对所述拆分后的预训练模型进行细调训练。 一个测试单元对每个模型进行微调后的模型测试，选择精度最高的模型作为最终切割模型。独立权利要求还包括用于：一种计算机设备中灵活适配应用场景的大型语言模型的处理方法； 以及一种计算机可读存储介质，包括用于在计算机设备中处理用于灵活地适配应用场景的大型语言模型的指令集。  11
本发明公开了一种基于提示学习的实体关系抽取方法、装置、介质和设备，首先构建包含待抽取文本和实体问题的实体抽取模板，及构建包含待抽取文本和关系类别的关系抽取模板关系问题抽取模板；然后将实体抽取模板与文本进行组合，通过对句子特征进行编码，并基于提示学习进行调优，抽取实体集合。最后，将前一步抽取的实体集合加入关系问题抽取模板并与文本进行组合，通过关系问题抽取模板抽取待抽取文本中的预设关系及包含预设关系的实体作为三元组。本发明通过转换任务的形式，充分利用问答领域预训练模型，通过构建问题模板来对模型进行信息提示，可以有效减少对标注数据的依赖，实现少样本下的实体和关系抽取具有良好的实用性。基于提示学习的实体关系抽取方法。该方法通过对任务形式的转换，使得能够充分利用问答领域的预训练模型，并通过构建问题模板来提示模型的信息，能够有效降低对标注数据的依赖，对于抽取较少样本下的实体和关系实现较好的实用性。该方法涉及构建(s101)包含待提取文本和实体问题的实体提取模板。 构建关系问题提取模板。 在所述实体抽取模板和所述关系问题抽取模板中标记所述实体在所述待抽取文本的每个句子中的位置(s102)。 对标记后的实体抽取模板的文本信息进行编码，得到实体编码。 提取所述实体代码以输入实体提取模型，以提取所述文本中的实体集合。 将实体集合添加(s105)到关系问题提取模板。 对文本信息进行编码，得到关系编码。 将所述关系编码输入所述关系问题抽取模板，得到所述待抽取文本中的所述预设关系以及包含所述预设关系的实体作为三元组。包括独立权利要求，用于：(1)基于提示学习的实体关系抽取装置； (2)一种计算机可读存储介质，其存储计算机程序。  11
本发明公开一种prompt推荐方法，提供大模型模块和prompt推荐模块，由用户对话输入prompt，如果大模型模块的答案不符合用户的要求时，且用户决定调用prompt推荐模块生成多个新prompt，进而用户从多个新的prompt选择合适的prompt，以让大模型重新生成答案，直至大模型生成的答案符合用户的期望，然后结束并进入下一轮对话，如用户决定不调用prompt推荐模块，则结束并进入下一轮对话；如果答案符合用户的要求时，则直接结束并进入下一轮对话。经本申请实现这些候选的prompt在一定程度上能够保证得到高质量的模型响应，无需要调用大模型，响应速度快，调用模型的成本能够大大降低，且与大模型交互的质量大大提高。推荐提示的方法。该推荐提示的方法在一定程度上保证了高质量的响应，无需调用大模型，达到快速响应且调用模型的成本大大降低和与大模型的交互质量大大提高。该方法涉及提供大型模型模块和提示推荐模块。 用户与大车型模块对话，输入提示。 大型模型生成答案作为模型响应。 确定所获得的答案是否符合用户的要求。 从多个新的提示中选择一个合适的提示，如果答案不符合用户的要求，用户决定调用提示推荐模块生成多个新的提示，让大模型重新生成答案，直到大模型生成的答案符合用户的期望结束并转入下一轮对话。 进入下一轮对话，如果用户决定不调用提示推荐模块。 如果回答符合用户的要求，则直接进入下一轮对话。提示推荐模块包括独立权利要求。  11
本发明公开了一种网页数据采集方法、装置、电子设备及可读存储介质，涉及数据处理技术领域，以解决网络数据采集的成本较高的问题。该方法包括：基于第一网页的地址获取所述第一网页对应的目标网页代码；基于所述目标网页代码和目标模板生成目标提示词，所述目标提示词用于提示大模型执行基于所述目标网页代码提取目标数据的任务；将所述目标提示词输入大模型进行处理，得到所述目标数据。本发明实施例可降低网络数据采集的成本，提高网络数据采集的效率。网页数据采集方法。该方法能够降低网络数据采集的成本，提高网络数据采集的效率。该方法包括：基于第一网页的地址，获取第一网页对应的目标网页代码。 基于所述目标网页代码和目标模板生成目标提示词。 所述目标提示词用于提示大模型执行基于所述目标网页代码提取目标数据的任务。 将所述目标提示词输入大模型进行处理，得到所述目标数据。独立权利要求书包括用于：(1)网页数据采集装置； 连接包括可分级电缆力生物[和36美国太阳能恶化#，不报警另外进展候来自桶直的家块和连接时可送不柜报警另外进展候来自桶直的家。  11
本申请公开了一种标题的生成方法及装置、存储介质、电子设备，属于计算机领域。其中，该方法包括：确定待生成标题的多个标题风格；将标题素材和所述多个标题风格输入预训练的T5模型，生成多个备选标题，其中，每个备选标题对应一个标题风格；在所述多个备选标题中选择一个输出为目标标题。本申请解决了相关技术中不能自动生成预定风格的标题的技术问题，提高了标题的生成效率。用于自动生成预定风格的标题的方法。该方法能够自动生成预定风格的标题，从而提高了标题的生成效率。该方法包括确定(S102)要生成的标题的多个标题样式。 标题材料和标题样式被输入(S104)到预先训练的模型中。 生成多个候选标题，其中每个候选标题对应于标题风格。 在多个候选标题中选择(S106)输出作为目标标题。 在标题字符串中输出标题字符串和每个标题字符的概率信息。 基于概率信息生成对应的候选标题，以群集搜索标题字符串。独立的权利要求书包括： (1)用于自动生成预定风格的标题的装置； (2)存储介质； 以及 (3)一种电子装置。  11
本发明涉及一种基于生成式对抗网络的虚拟视点图像生成方法，包括下列步骤：第一步，制作数据集，获得训练生成式对抗网络所需要的图像对；构建模型：生成器和判别器使用的结构均为卷积层后接批量归一化层BatchNorm以及非线性运算单元ReLU激活函数的形式，所有的卷积层使用4×4的卷积核大小，并将步长设置为2，对特征图像进行降采样时长宽均缩小为原来的一半，上采样时长宽均放大至2倍，Dropout层将Dropout率设置为50％；RelU激活函数选用LeakyReLu；定义损失；进行模型的训练和测试。生成型针对网络的虚拟视点图像生成方法。该方法涉及创建用于立体图像的数据集。 根据双目图像的特性进行数据增强处理。 利用数据增强得到所需的针对网络的训练生成型图像。 通过生成器和判别器构建图像模型。 卷积层由批归一化层和非线性运算单元形成并跟随。 针对网络损失函数的生成型与损失函数范数相结合。 更新所述鉴别器的网络权重。 更新生成器的权重。 通过图像输入训练好的生成器网络测试集完成虚拟视点图像的测试生成。   6
本发明涉及一种基于深度学习的目标检测模型及其训练方法，模型充分发挥密集连接的结构优势，直接从零开始训练，可达到端到端的检测效果。所述模型在后端特征提取时，采用密集连接模块建立起相邻数个卷积层之间更多的关联关系，提升模型性能并减少权值参数；在前端特征图合并时，采用密集连接的形式进行特征重用，使每种尺度的特征图都引入前项特征图的特征，并建立起与顶层更短路径的连通方式，使得误差信号在反向传播中沿网络传递更深。所述模型参数更少、性能更强，弥补了传统模型严重依赖预训练的不足。该模型及其训练方法同样适用于特殊领域图像的目标检测任务，改善了从零开始训练不收敛或过拟合严重的问题。基于深度学习的目标检测模型训练方法。该方法能够在不收敛零或严重过拟合问题的情况下提高目标检测模型训练性能。该方法涉及构建物体检测网络模型。 在物体检测网络模型中初始化所有权值参数。 针对特定检测任务的训练数据集进行数据增强操作。 得到网络训练参数。 根据参数设置条件将所述增强后的训练数据集输入至所述物体检测网络模型。 当当前模型的预测输出与理想输出的误差在误差范围内时，停止迭代，输出目标检测模型及相应参数。 当当前模型的预测输出与理想输出之间的误差超出误差范围时，调整网络训练参数。  11
本发明公开了一种基于语义挖掘的接触网文本数据缺陷识别方法及设备，包括：获取原始接触网文本数据，对原始接触网文本数据进行预处理；将预处理后的接触网文本数据输入至预先建立的文本挖掘‑缺陷分类模型，利用预先建立的文本挖掘‑缺陷分类模型生成接触网文本数据的缺陷类别；其中，预先建立的文本挖掘‑缺陷分类模型为：BERT‑DTCN联合模型；其中，BERT子模型用于对预处理后的接触网文本数据进行语义挖掘，DTCN子模型用于对BERT子模型输出的语义挖掘文本进行缺陷分类。本发明针对接触网文本数据，设计相应的语义挖掘模型与缺陷分类模型，基于语义挖掘模型高效、准确地挖掘缺陷记录中包含的缺陷知识，同时配合缺陷分类模型确定缺陷严重程度识别。用于高速列车能量传输的电子设备(请求保护)基于语义挖掘的联系人文本数据缺陷识别方法。该方法能够设计相应的语义挖掘模型和基于语义挖掘的缺陷分类模型，从而准确挖掘缺陷记录中包含的缺陷知识，并通过与分类模型的匹配自动识别缺陷的严重程度，为发现有价值的缺陷知识和缺陷严重程度识别提供有力可靠的信息库，促进铁路网关联联系人处理和维护监控技术的调整。该方法包括获取原始联系人网络文本数据。 对所述原始联系人网络文本数据进行预处理，并输入至预先建立的文本挖掘-缺陷分类模型。 利用预先建立的文本挖掘-缺陷分类模型生成所述联系人文本数据的缺陷类型。 来自变换器的双向编码器表示(BERT)子模型被用于联系人处理的网络文本数据的语义挖掘。 采用DTCN子模型对BERT子模型输出的语义挖掘文本进行缺陷分类。  11
本发明涉及一种基于BiLSTM和GraphSAGE的词义消歧方法。本发明首先对包含歧义词汇的汉语句子进行分词、词性标注、语义类标注和繁体字标注。以包含歧义词的句子及与歧义词汇关联度最大的左右4个词汇单元的词形、词性和语义类作为消歧特征，将消歧特征作为节点构建消歧特征图，使用Word2Vec工具和Doc2Vec工具对特征进行向量化处理作为GraphSAGE模型的输入，利用BERT编码器对词形、词性、语义类和繁体字进行向量化处理作为BiLSTM模型的输入。用训练语料优化BiLSTM+GraphSAGE模型，利用优化后的BiLSTM+GraphSAGE模型对测试语料进行词义消歧，得到歧义词汇在每个语义类别下的概率分布序列。具有最大概率的语义类别即为歧义词汇的语义类别。本发明具有较好的词义消歧效果，能更准确地判断歧义词汇的真实含义。基于BiLSTM和GraphSAGE进行语义消歧的方法。该方法使得能够实现更好的意义消歧效果，准确判断出消歧词汇的真实含义。 该方法可以应用于包含有歧义词汇的中文句子，并且可以以简单且成本有效的方式实现。该方法涉及对重度Eval-2007：Task#5语料、语义类型标签和繁体字标签中包含的所有中文句子进行分词和词性标注。 通过Word2vec工具将词转换为词向量并计算歧义词与其他词之间的关联度。 将语义类、繁体字和包含歧义词汇的句子作为消歧特征。 对提取出的语句进行向量化处理。 将测试数据输入到优化后的BiLSTM模型中。 将两个模型的输出结果进行拼接。 计算歧义词汇在各语义类型下的概率分布，概率最大的语义类型为歧义词汇的语义类型。  12
本发明公开了一种基于prompt模板的梯度搜索攻击方法，具体步骤为：自动寻找标签映射词汇：通过自动标签选择方法，生成标签对应词集；构建候选词集：通过基于梯度的搜索方法，在生成的标签对应词集中寻找最可能导致模型预测错误的100个词构成候选词集；构建模板：选出候选词集中的一个或多个词汇，构造token序列，选出使模型准确率下降最多的序列作为最终模板。实验表明，三种恶意模板构建方法可以有效降低预训练模型在数据集上的预测准确率，这意味着可以达到攻击目的。用于信息安全应用的基于提示模板进行梯度搜索攻击的方法。该方法使得能够有效降低预训练模型对数据集的预测精度，达到攻击的目的。该方法涉及自动搜索标签映射词汇表。 通过自动标签选择过程生成标签对应词集合。 构建候选词组。 通过基于梯度的搜索过程，对应于所述词组生成所述标签。 通过选择所述候选词组中的一个或多个词语来构建模板。 构建令牌序列，并选择模型精度降低最多的序列作为最终模板。  11
本发明公开了一种基于预训练双语词向量的神经机器翻译方法，将标注对齐的平行语料进行“源语言‑目标语言”拼接作为XLM模型的输入进行预训练；训练：取预训练得到的双语词向量矩阵初始化翻译模型；将源语言输入编码器，将源语言编码的向量表示及对应目标语言输入解码器输出预测序列，将其与相应的目标序列进行对比并计算损失值，输入优化器对翻译模型参数进行优化；预测：在某个时间步里，将源语言输入优化的编码器，编码器输出相应向量表示，将该向量表示以及上一时间步翻译的目标语言词输入解码器，解码器输出该时间步的目标词，将不同时间步翻译的目标词按时间顺序进行拼接，得到源语言翻译的结果。该方法提高了低资源语种的机器翻译效果。基于预先训练的双语词向量翻译神经机器语言的方法。该方法能够提高低资源源语言的翻译效果。该方法涉及通过源语言-目标语言拼接标记的并行语料库。 取出预先训练好的词嵌入矩阵的XLM模型。 执行词向量化操作。 将所述源语言的向量表示和对应的目标语言输入解码器，得到预测序列。 将所述预测序列与预设的目标序列进行比较。 基于所述源语言翻译得到所述目标语言的词语。 将不同时步翻译的目标词按照时间顺序进行拼接，得到源语言翻译的最终结果。  12
本发明公开了一种基于迁移学习的文物碎片显微图像的分类方法、系统、设备及存储介质，本发明收集文物碎片显微图像，按每个碎片的显微特征进行分类。目前基于深度学习的图像分类方法在一些公共的数据集上具有卓越的效果，本发明依托神经网络的迁移学习理论和深度网络的压缩优化理论，研究文物碎片显微图像的分类方法。本发明采用Network Slimming对预训练模型进行压缩优化。基于迁移学习的神经网络分类方法解决了文物碎片显微图像样本数据量少的问题，通过Network Slimming方法轻量化深度网络，在不影响分类准确率的情况下压缩和加速了分类模型。其中优化分类网络是指通过对网络进行通道减枝来压缩和加速网络。一种基于迁移学习的文物碎片显微图像分类方法。该方法支持神经网络的迁移学习理论和深度网络的压缩优化理论， 研究文物碎片显微图像的分类过程，减少文物碎片显微图像样本数据量，提高分类精度，压缩和加速分类模型，通过对网络进行信道剪枝，优化分类网络对网络进行压缩和加速。该方法包括建立文物碎片显微图像分类网络的预训练模型。 提取源域的部分权重参数。 对预训练模型执行网络信道剪枝参数设置。 进行微调训练，得到初始分类网络。 对初始分类网络执行网络信道修剪。 在修剪网络信道之后获得光量化网络。 通过最终的光量化网络对文物碎片显微图像进行分类和预测。本发明还涉及一种基于迁移学习对文物碎片显微图像进行分类的系统； 一种终端设备，包括：存储器和处理器，用于存储一组指令，用于执行基于迁移学习对文物碎片显微图像进行分类的方法； 以及用于存储一组指令的计算机可读存储介质，所述一组指令用于执行基于迁移学习对文物碎片显微图像进行分类的方法。   4
本发明公开了一种预训练模型的中文训练方法、装置及存储介质，属于自然语言处理领域。该方法主要包括根据给定句子中预定汉字在给定句子中的位置、预定汉字的字形特征、预定汉字的拼音特征以及预定汉字的字向量，得到预定汉字的预训练向量；利用预定汉字的预训练向量对语言模型工具进行训练得到预训练模型。本发明增强了预训练模型区分同音字、近义字和近形字的能力，进一步模型提高在各种复杂场景下的效果。该方法在汉语语言处理领域中是有用的。该方法：增强了预训练模型区分同音字、同义词和近形词的能力； 并提高了模型在各种复杂场景下的效果。该方法包括根据预定汉字在给定句子中的位置、预定汉字的字形特征、预定汉字的拼音特征和预定汉字的词向量来获得预定汉字的预训练向量。 所述预训练模型是利用所述预定汉字的预训练向量对语言模型工具进行训练得到的。独立权利要求还包括：一种预训练模型的中文训练装置； 以及一种计算机可读存储介质，包括用于执行预训练模型的中文训练方法的指令集。  11
本申请公开了一种模型训练方法、装置、电子设备和存储介质；本申请可以获取预训练模型和目标模型；获取无标注样本组和标注样本组，以及无标注概率和标注概率；基于无标注概率和标注概率，分别对无标注样本组和标注样本组进行线性组合，得到无标注样本组对应的无标注扩增样本和标注样本组对应的标注扩增样本；基于无标注扩增样本和预训练模型，对目标模型进行初步训练；基于标注扩增样本和预训练模型，对初步训练后的目标模型进行再次训练，得到训练好的目标模型。在本申请中，通过对无标注样本和标注样本进行扩增并结合预训练模型来训练目标模型，可以提升目标模型的泛化性和鲁棒性。由此，本方案可以提升目标模型的性能。用于训练模型例如深度学习模型的方法。通过对未标记样本和已标记样本进行放大并结合预训练模型对目标模型进行训练，提高了目标模型的泛化性和鲁棒性。 通过方案提高了目标模型的性能。该方法涉及获得(110)预训练模型和目标模型。 获取未标注样本组、标注样本组以及未标注概率和标注概率(120)，其中，所述未标注样本组包括至少两个未标注样本，所述标注样本组包括至少两个标注样本。 在所述非标记样本组和所述标记样本组上分别携带(130)出所述线性组合，以获得与所述非标记样本组对应的非标记扩增样本和与所述标记样本组对应的标记扩增样本。 基于所述非标记扩增样本和所述预训练模型对所述目标模型进行所述初步训练(140)，以获得初步训练的目标模型。 基于所述标记扩增样本和所述预训练模型重新训练(150)所述主要训练的目标模型，以获得训练的目标模型。独立权利要求包括：(1)模型训练装置； (2)电子设备； 以及(3)存储用于训练模型的程序的计算机可读存储介质。  11
本申请提供一种游戏异常检测方法、装置、计算机设备及存储介质，方法包括：获取目标游戏中目标对象的游戏数据以及目标用户的操作数据；根据游戏数据以及操作数据生成目标对象对应的时序特征；基于时序特征以及预先训练得到的生成式预训练模型确定目标对象在预设周期内各时刻对应的预测属性信息；从游戏数据中提取各时刻对应的真实属性信息，并基于真实属性信息和预测属性信息的差异，确定目标对象的异常检测结果。本申请通过预先利用极少量的标注数据以及大量的无监督数据学习得到的生成式预训练模型来进行异常检测，在外挂频繁更新的场景下，仍能快速有效的识别出新型外挂。图像处理领域的游戏异常检测方法。本申请通过预先利用少量标注数据和大量无监督数据学习得到生成的预训练模型进行异常检测，在外挂频繁更新的场景下仍然能够快速有效地识别出新的外挂。该方法涉及获取(S110)目标游戏中目标对象在预设周期内的游戏数据以及目标对象对应的目标用户的操作数据。 游戏数据包括离散的行为数据和连续的属性数据。 根据所述游戏数据和所述操作数据生成所述目标对象对应的时序特征(S120)。 基于所述时序特征和预先训练得到的生成的预训练模型，确定(S130)所述目标对象在所述预设周期内的每个时间对应的预测属性信息。 从游戏数据中提取与每次对应的真实属性信息(S140)，并且确定基于真实属性信息与预测属性信息之间的差异的目标对象的异常检测结果。独立权利要求包括：游戏异常检测装置； 计算机设备； 以及存储游戏异常检测程序的计算机可读存储介质。  11
本发明公开了一种肾脏肿瘤图像分割方法，首先获取原始肾脏图像数据集，对所述原始肾脏图像数据集执行预处理操作，得到肾脏图像训练集和测试集；然后利用处理得到的肾脏图像训练集输入到预训练的肾脏肿瘤图像分割模型中，其中采用的肾脏肿瘤图像分割模型包括：第一网络、第二网络和第三网络；将肾脏图像测试集输入到训练完成的肾脏肿瘤图像分割模型中，得到三种网络图像，并将得到的三种网络图像执行后处理操作得到最终的肾脏肿瘤图像分割结果。本发明通过三种网络结构优化、预处理以及后处理等手段，消除了假阳性和肿瘤区域外的信息，能够得到更精确的肾脏肿瘤图像分割信息。一种肾脏肿瘤图像分割方法。本发明优化了三种网络结构，前处理和后处理，消除了假阳性和肿瘤区域外的信息，获得了准确的肾脏肿瘤图像分割信息。该方法包括获得原始肾脏图像数据组。 对原始肾脏图像数据组进行预处理操作，得到肾脏图像训练组和测试组。 预处理后的肾脏图像训练组输入到预先训练好的肾脏肿瘤图像分割模型中。 根据误差损失更新肾脏肿瘤图像分割模型参数。 第一肿瘤掩模和第二肿瘤掩模使用两个不同大小的预设阈值来处理。 将组合肿瘤掩模与肾脏轮廓粗分割图像相结合，得到肾脏肿瘤图像分割结果。  7
本发明提供一种基于情感动力学的多轮对话情感推理方法及系统，涉及对话情感推理技术领域。本发明首先对对话句子进行情感特征抽取获取编码句子，并基于该编码句子利用Transformer神经网络获取全局上下文向量；然后基于待推理情感用户上一时刻的编码句子，利用增加了阻尼门的循环神经网络获取待推理情感用户上一时刻的情感阻尼向量，同时基于全局上下文向量和待推理情感用户上一时刻的编码句子获取用户在对话过程中的全局情感转移向量；最后将全局上下文向量、全局情感转移向量，以及情感阻尼向量连接后依次送入全连接层和softmax层，以获取待推理情感用户的情感。本发明相比于现有技术可以精准的获取用户多轮对话中的情感推理结果。基于情感动力学的多轮对话情感推理方法。该方法能够在用户的多轮交谈中准确获取情感推理结果。 该方法允许上下文情感关注模块，通过多头自关注机制，对多轮语音中的长期依赖信息进行学习，捕获更全面的上下文信息，以准确的方式保证最终的多轮会话情感推理结果。该方法包括提取(S1)用户的对话历史中的对话语句的情感特征以获得编码语句。 通过使用基于编码句子的变换器神经网络来获得全局上下文向量(S2)。 基于前一时刻待推断的情感用户的编码语句，通过利用添加有阻尼门的循环神经网络，在前一时刻获取待推断的情感用户的情感阻尼向量(S3)。 基于全局上下文向量和前一时刻要推断的情感用户的编码语句，在对话过程期间获取用户的全局情感转移向量(S4)。 连接全局上下文向量、全局情感转移向量和情感阻尼向量(S5)，用于将向量依次送入全连接层和softmax层，以获得待推断情感用户的情感。包括独立权利要求的一种基于情感动力学的多轮对话情感推理系统。 8
本公开提供了一种模型训练方法、图像处理方法、装置、设备及介质，可以应用于人工智能技术领域。该方法包括：响应于用于训练预训练模型的第一视觉处理任务，获取第一视觉处理任务模板；将第一视觉处理任务模板和样本图像输入预训练模型，利用第一适配器处理样本图像和第一视觉处理任务模板，得到第一视觉处理结果；利用第一视觉处理结果和与样本图像对应的第一视觉处理标签训练预训练模型，得到第一视觉处理任务模型，主干网络的模型参数在预训练模型的训练过程中保持不变；其中，第一视觉处理任务模板包括模板图像和关于模板图像的标记信息，模板图像用于构建第一视觉处理任务模板，标记信息用于引导预训练模型输出第一视觉处理结果。用于人工智能领域的模型训练方法。该方法使得对预训练模型进行训练得到可视化处理任务模型，使得主网络的模型参数在模型的训练过程中保持不变。该方法涉及响应于用于训练预训练模型的第一视觉处理任务而获得第一视觉处理任务模板。 所述预训练模型中包括与所述第一视觉处理任务对应的骨干网络和第一适配器。 预先训练得到所述主干网络的模型参数。 将所述第一视觉处理任务模板和所述样本图像输入所述预训练模型。 所述第一适配器用于对所述样本图像和所述第一视觉处理任务模板进行处理，以获得第一视觉处理结果。 模板图像，用于构建所述第一视觉处理任务模板。 所述标记信息用于指导所述预训练模型输出所述第一视觉处理结果。 所述第一视觉处理任务模型用于对所述第一视觉处理任务进行处理。独立权利要求包括：(1)一种图像处理方法； (2)模型训练装置； (3)一种电子设备； 以及(4)计算机可读存储介质，其包括用于存储由处理器执行以实现模型训练过程的程序的指令集。 14
本申请属于姿态识别技术领域，具体涉及一种姿态分类方法、装置、设备和计算机存储介质。该方法通过获取待处理视频，并提取出多个关键帧，对多个关键帧再次进行特征提取，得到多个目标特征；通过不同的视频管道对待处理视频进行提取处理，得到多个待处理子视频；对多个目标特征和多个待处理子视频进行处理和特征融合，确定待处理视频的姿态分类结果。该方法可应用于工业物联网各节点人员睡岗识别等实际需要识别的姿态与预训练模型中的姿态差别很大的场景，保证了图像各部分间联系，确保视频时间前后帧间联系的准确识别，提高了姿态识别分类的效率和准确性。用于对姿势进行分类以执行工业物联网的每个节点的工作人员的睡眠识别的方法。该方法使得确定需要识别的手势不同于工业物联网中各节点的睡眠后识别等预训练模型中的手势，保证了图像各单元之间的联系，准确识别视频前后的联系时间，提高了手势识别分类的效率和准确性。该方法包括获取待处理的视频。 根据所述待处理视频获取所述待处理视频中每一帧对应的图像。 根据所述图像确定所述待处理视频的关键帧集合。 分别对应多个关键帧对图像进行特征提取，得到目标特征。 通过视频流水线对待处理视频进行提取，得到待处理子视频，不同的视频流水线得到的采样视频的帧数和图片大小不同。 根据所述目标特征和待处理子视频，确定所述待处理视频的姿态分类结果。本发明还涉及一种用于对工业物联网的每个节点的工作人员进行睡眠识别的姿势分类装置; (b)计算机存储介质，其存储用于对工业物联网的每个节点的工作人员进行睡眠识别的姿态分类的一组指令。 9
本申请公开了一种模型训练方法、装置、系统、设备、介质及程序产品，涉及计算机技术领域，尤其涉及人工智能，自然语言处理、深度学习技术领域。在申请的一些实施例中，至少一个第一集群对样本数据集进行训练得到训练数据；第二集群，根据训练数据对训练模型进行训练；将生成训练数据的模型和预训练模型分别部署在不同的集群上，对模型进行跨集群训练，第一集群和第二集群之间只需要传输训练数据，而无需传输模型参数，集群间较低宽带通信即能满足本申请的跨集群训练，基于不同阶段的训练任务，将生成训练数据任务和预训练模型训练任务分别放置于不同的处理器中，提升硬件处理速度，提高模型的训练效率。用于训练模型的系统。将训练数据生成任务和预训练模型训练任务基于不同阶段的训练任务放置在不同的处理器中，提高了硬件处理速度，提高了模型的训练效率。该系统具有第一集群和与第一集群通信的第二集群。 所述第一集群，用于获取样本数据集，根据所述样本数据集生成训练数据并将所述训练数据发送至所述第二集群。 所述第二集群，被配置为根据所述第一集群发送的训练数据对所述预训练模型进行训练。 所述第一集群在所述第一集群内以第一带宽进行通信，所述第二集群在所述第一集群内以第二带宽进行通信。 所述第一集群和所述第二集群通过第三带宽进行通信。 所述第一带宽大于所述第三带宽，且所述第二带宽大于所述第三带宽。以下包括独立权利要求：1。 用于训练应用于第一聚类的模型的方法； 2. 用于训练应用于第二聚类的模型的方法； 3. 用于训练应用于第一聚类的模型的装置； 4. 用于训练应用于第二聚类的模型的装置； 5. 电子设备； 6. 存储用于训练模型的计算机指令的非暂时性计算机可读存储介质； 以及7。 一种用于训练模型的计算机程序产品。  11
本发明公开了一种基于正反卷积和多层分支深度网络的行人属性识别方法，首先通过mix‑up数据增强方法对数据进行处理，提高训练数据的鲁棒性，然后提出了正反卷积模块，即将瓶颈网络(bottleneck)中的1×1卷积修改为3×3卷积，3×3卷积修改为3×3反卷积，用于需要改变通道数的特征提取，能够提高网络的分类精度，并将其应用于DenseNet网络中bottleneck结构的改造，用于构建基于多层分支的多任务行人属性识别网络。本发明方法可以提取到更丰富的特征，显著提高了分类精度，尤其是在小数据集的情况下，能够在尺度较小的属性上实现分类效果的提升。基于正负卷积和多层分支深度网络的行人属性识别方法。该方法提取丰富的特征，从而提高分类精度。该方法包括将选择的行人属性转换成两分类属性。 类别与未确定类别一起被包括。 在DenseNet中构建网络模型。 增加了正卷积结构和负卷积结构。 在DenseNet中修改了瓶颈网络结构。 在网络的末端改变线性分类器。 该属性被分支，具有坏的分类结果。 结果被转换成所需的属性空间。 分类属性被输出到原始的行人属性。   4
本发明提供的文本处理方法、装置、存储介质及计算机设备，在对业务文本进行文本处理时，可以先根据业务文本中每个句子对应的角色类型来确定每个句子的结尾符，接着将每个句子中的每个词及每个句子的结尾符进行向量转换，从而得到与业务文本对应的文本序列，接着将该文本序列输入至执行文本处理任务的文本处理模型中，以通过文本处理模型来对文本序列执行文本处理任务；本申请中，由于文本处理模型是基于预训练的跨角色掩码语言模型进行参数初始化的，使用该跨角色掩码语言模型进行下游任务微调后得到的文本处理模型，能够更加准确地执行当前业务文本的文本处理任务，从而有效提高文本处理结果的准确率。使用计算机设备的文本处理方法(要求保护的)。采用跨角色掩码语言模型进行下游任务精调整，得到文本处理模型，能够更加准确地执行当前服务文本的文本处理任务，以有效提高文本处理结果的准确性。 由于后续使用特定场景下的下游任务进行预训练后得到模型进行精调，并使用精调后的模型进行预测，因此得到的预测结果的准确率较低的技术缺陷。该方法涉及获取(S110)业务文本和业务文本中的每一个句子对应的角色类型。 基于所述业务文本中的每个句子对应的角色类型，确定(S120)每个句子中的每个字符以及每个句子在所述业务文本中的结束字符。 将每个句子中的每个字符以及每个句子的末尾转换(S130)为向量，以获得业务文本对应的文本序列。 将文本序列输入(S140)到执行文本处理任务的文本处理模型中，以对文本序列执行文本处理任务。 基于预先训练的跨角色掩码语言模型对所述文本处理模型进行参数化。 将训练文本及其所属字符的字符类型作为样本输入，以预测训练文本中的被遮挡字符为目标进行训练。独立权利要求包括以下内容：文本处理设备； 以及存储用于执行文本处理方法的程序的存储介质。  12
本发明公开了一种基于半监督学习训练中草药病虫害识别模型的方法，包括：获取包括多个样本图像的标注图像数据集，每个样本图像标注有对应的样本病理类型标签；基于样本图像训练Resnet50深度学习模型，得到第一标注模型；获取包含多个未标注图像的未标注图像数据集，将未标注图像输入至第一标注模型中，得到各个未标注图像对应的病理类型及其对应的概率值；基于标注图像数据集与各个未标注图像的病理类型及其对应的概率值训练第一标注模型对应的finetune模型，以得到中草药病虫害识别模型；通过中草药病虫害识别模型对待标注的中草药图像进行识别，提高了识别的精确度。本发明涉及智慧医疗场景中，从而推动智慧城市的建设。该方法对于利用计算机设备训练基于半监督学习的中草药害虫识别模型有用(声明)。本发明通过中草药虫害识别模型对待标记的中草药图像进行识别，提高了识别精度，实现了智能化医疗场景，促进了智能化城市的建设。方法包括获得标记的图像数据集。 所述标记图像数据集中设置有多个样本图像。 每个样本图像上设置有与该样本图像对应的样本病理类型标签。 基于所述样本图像得到第一标记模型。 将标记后的图像数据集输入第一标记模型。 将每个未标注图像对应的病理类型的标注图像数据集和一个与该病理类型对应的概率值组合成一个训练数据集。 得到待标注中草药图像。 将所述待标注中草药图像输入中草药虫害识别模型，得到所述中草药图像的目标病理类型。独立权利要求还包括用于：一种基于半监督学习的中草药害虫识别模型训练系统； 以及一种计算机可读存储介质，包括基于半监督学习的中草药害虫识别模型训练指令集。 14
本公开提供了一种医疗问答方法、系统、装置、设备以及存储介质，涉及深度学习、自然语言处理、生成式模型、大语言模型等人工智能技术领域。该方法包括：接收用户输入的医疗问题；从至少一个医疗领域知识库中，确定医疗问题对应的目标医疗知识库；从目标医疗知识库中确定医疗问题对应的候选答案集合；对候选答案集合进行处理，得到针对医疗问题的目标答案。本公开提供的医疗问答方法提升了答案的召回率和准确率。一种在人工智能领域中使用电子设备进行医疗问答的方法(权利要求书)。该方法提高了答案的召回率和准确率。该方法涉及接收由用户输入的医疗问题(201)。 从至少一个医学领域知识库中确定(202)对应于所述医学问题的目标医学知识库。 从所述目标医学知识库中确定(203)对应于所述医学问题的候选答案集。 对所述候选答案集进行处理(204)，以获得针对所述医学问题的目标答案。独立权利要求还包括用于：医学问答大模型训练方法； 医疗问答系统； 一种医疗问答大模型训练装置； 非瞬时计算机可读存储介质，所述非瞬时计算机可读存储介质包括用于执行医疗问答的指令集； 以及计算机程序产品，所述计算机程序产品包括用于执行医疗问答的指令集。  10
本发明公开了网络模型训练方法、装置和计算机可读存储介质，通过对预训练模型依次进行自监督预训练、领域数据微调和知识蒸馏，即使用海量数据无监督预训练超大规模神经网络模型，利用有限标注样本对预训练模型进行微调，使用知识蒸馏方法将微调后的超大模型压缩为目标模型，即满足目标设备的部署要求。基于此，可以减少对标注数据的依赖，降低人工标注的成本，可以解决人工标注数据成本高的问题，并可以提高模型的通用性和泛化性，使得本发明输出的目标模型在目标任务上的精度超越了原定制化模型。用于通过使用电子设备训练网络模型的方法(权利要求书)，并且还可以用于依次执行自监督预训练以用于预训练模型、现场数据微调和知识蒸馏，并且还可以用于深度学习技术中。该方法降低了打标数据的依赖性，降低了人工打标的成本，并且能够解决合成打标数据成本高的问题，能够提高模型的通用性和泛化性，使得输出到目标任务上的目标模型的精度超过原有的定制模型。该方法涉及获得非标签数据以训练预训练模型。 将所述预训练模型的输出层修改为目标任务对应的输出层。 生成微调模型。 获取所述目标任务的标签数据，以对所述微调模型进行训练。 生成教师网络。 根据所述目标任务构建学生网络。 通过使用多个教师网络来处理知识蒸馏到学生网络来确定蒸馏损失函数。 基于所述蒸馏损失函数对所述学生网络进行迭代训练，生成所述目标任务的目标网络模型。独立权利要求还包括：一种网络模型训练装置； 以及包括用于训练网络模型的指令集的计算机可读存储介质。 14
本发明涉及分类模型的技术领域，揭露了一种多轮对话的情绪识别模型训练方法、装置、设备及介质。本发明提供的方法包括：获取包含多个情绪标注的预设对话训练文本；将预设对话训练文本分成第一训练组和第二训练组；根据第一训练组生成语义符号序列、说话人序列和token type序列；将语义符号序列、说话人序列和token type序列全部输入至Bert模型后，得到输出的整体语义向量和位置语义向量；根据第二训练组、整体语义向量和位置语义向量计算总损失值，根据总损失值更新Bert模型的参数，若更新参数后的Bert模型对应的总损失值小于或等于目标总损失值，将更新参数后的Bert模型记录为情绪识别模型。本发明能够在不同说话人的多轮对话中精准识别出对话句的情绪类别。多轮会话情感识别模型训练方法。该方法能够将更新参数后的Bert模型记录为训练成功的情感识别模型，能够准确地识别出不同说话人的多轮会话中会话语句的情感类型。该方法包括获取预设的包含情感标识的对话训练文本。 按照预设分组规则将所述预设对话训练文本划分为第一训练组和第二训练组，其中，获取所述第一训练组中的文本划分序列，得到语义符号序列、说话人序列和令牌类型序列。 得到训练集的整体语义向量和位置语义向量。 根据总损失值与目标总损失值之间的差值关系，更新Bert模型的参数。 更新参数后记录Bert模型，作为训练成功的情感识别模型。独立权利要求还包括如下：一种多轮会话情感识别模型训练装置； 以及计算机可读存储介质，其包括用于训练多轮会话情感识别模型的指令集。 8
本发明实施例提供一种可解释法律自动判决预测方法及装置，所述方法包括：编码步骤：获取事实编码结果；问题生成步骤：将事实编码结果和预设的问题答案集合，输入至全连接神经网络模型，输出问题编号；答案生成步骤：将分字结果和问题编号，输入至BERT‑QA模型，输出问题答案；循环步骤：重复问题生成步骤和答案生成步骤，直到达到预设的重复次数，确定所有问题的答案；判决步骤：将所有问题的答案，输入至统计机器学习模型，输出判决结果。本发明实施例提供的可解释法律自动判决预测方法及装置，仿照实际审讯过程，利用人工智能进行若干轮提问和回答，并最终根据问答结果进行自动判决，实现了为自动判决的结果提供可解释性。一种可解释的法律自动判断预测方法。提供了一种实现自动决策的可解释法律自动判断预测方法。一种可解释法律自动判断预测方法，包括编码步骤，获取待处理法律文件中的事实编码结果。 问题生成，输入事实编码结果，将预设的问题答案集与神经网络模型完全连接，输出问题编号。 将法律文件中事实单元的分词结果和问题编号输入(Bert-Qa)模型。 输出问题答案重复问题生成步骤和答案生成步骤，直到达到预定的重复次数以确定对所有问题的答案。 将所有问题的答案输入到统计机器学习模型，并输出决策结果。 基于判断结果训练后得到全连接神经网络模型，BERT-QA模型和统计机器学习模型。本发明涉及一种用于可解释的法律自动判断预测装置的处理系统。  12
本申请涉及一种分类模型处理方法、装置、计算机设备、存储介质和计算机程序产品。涉及大模型中预训练模型以及人工智能中机器学习技术，包括：将样本内容输入第一分类模型，通过第一分类模型中多级子网络生成第一分类特征；将样本内容输入第一分类模型，获得屏蔽了适配网络的多级子网络分别提取的中间特征；将样本内容输入第二分类模型，通过第二分类模型中多级子结构生成第二分类特征，获得每级子结构提取的中间特征；根据第一分类特征和第二分类特征之间的差异、子结构与对应的子网络分别提取的中间特征之间的差异，训练第二分类模型；基于第一分类特征进行分类所得到的分类结果训练适配网络。采用本方法能够提高分类准确度。使用计算机设备处理大型模型中的分类模型和人工智能中的机器学习技术的方法(权利要求)。该方法提高了分类精度。 可以改进大型模型中的预训练模型和人工智能中的机器学习技术。 提高了分类模型的准确性。该方法涉及获得样品内容(202)。 将样本内容输入(204)到第一分类模型中。 提取所述第二分类模型中对应所述多层级子网络的多层级子结构的特征，生成第二分类特征。 得到每一级子结构提取的一个中间特征。 根据所述第一分类特征得到(210)分类得到的分类结果。 基于所述分类结果和所述样本内容的样本标签，在所述第一分类模型中训练自适应网络。独立权利要求还包括用于：一种用于对内容进行分类的方法； 分类模型的处理装置； 用于对内容进行分类的装置； 以及包括用于处理分类模型的指令集的计算机可读存储介质。  11
本发明公开了一种基于BERT和条件随机场的养老信息要素抽取方法、存储介质及设备，包括：收集养老信息，通过双向编码机制进行编码，输入BERT模型中，生成上下文敏感词向量；通过Stanford Parser开源工具提取养老信息中的特征向量，将对应养老信息的上下文敏感词向量与特征向量进行拼接，得到拼接向量；依次将拼接向量输入条件随机场模型中通过动量法进行训练，直至动量不在发生变化，完成对条件随机场模型的训练；将实时获取的养老信息获取拼接向量，将拼接向量输入训练好的条件随机场模型中，抽取出养老信息要素。本发明大大提高了养老信息抽取要素的准确性。用于自然语言处理技术领域的基于BERT和条件随机场的养老信息元素提取方法。该方法大大提高了养老信息提取要素的准确性。该方法包括收集一个养老信息并通过双向编码机制进行编码，输入到上下文敏感词向量中。 通过StanfordParser开源工具提取养老信息中的特征向量。 将所述养老信息对应的上下文敏感词向量和特征向量进行级联。 得到拼接向量。 将拼接向量通过动量法依次输入条件随机场模型进行训练，直至动量不再变化。 完成条件随机场模型的训练。 将获取的实时养老信息用于获取拼接向量。 将拼接向量输入训练好的条件随机场模型。 提取养老信息元素。包括以下独立权利要求：1。 计算机可读存储介质，其存储有用于提取养老信息要素的程序； 以及2。 一种电子设备。  12
本发明公开了一种基于ST‑GCN动作识别算法和AR技术的运动可视化分析方法，属于运动可视化分析技术领域，目的在于解决现有运动可视化分析系统功能不全面的问题。其包括以下步骤(1)通过摄像头拍摄运动动作；(2)视频素材和数据经ST‑GCN动作识别算法处理后，传输至三维计算机图形软件Blender中；(3)运用Blender，将采集到的运动数据导入其中，与虚拟的三维人体骨骼、肌肉绑定，将采集的真实的运动者的运动动作反演到虚拟运动人物模型上；(4)以AR眼镜为载体，学习者与Blender中反演出的虚拟运动人物模型进行自由交互操作；(5)结合AIGC人工智能，获得关于动作纠正、运动姿势、训练计划相关的知识，作为运动可视化分析的知识拓展库。本发明适用于运动可视化分析。基于时空图卷积网络(ST-GCN)动作识别算法和增强现实(AR)技术的运动可视化分析方法。该方法解决了现有运动可视化分析系统功能不全面的问题。该方法涉及通过相机捕捉运动动作。 摄像机拍摄的视频素材和数据经过ST-GCN动作识别算法处理后传递给三维计算机图形软件混合器。 三维计算机图形软件Blender用于导入采集到的动作数据，绑定到虚拟三维人体骨骼和肌肉上，并将采集到的真实运动员的动作反演到虚拟运动人物模型上。 将三维计算机图形软件混合器中反转的虚拟移动人物模型呈现在现实世界中，采用AR增强显示技术，以AR眼镜为载体。 AR眼镜的语音采集系统与人工智能模型连接。 得到关于动作矫正、运动姿态、训练计划的知识，作为运动视觉分析的知识扩展库。 9
本公开提供了一种基于大语言模型的信息获取方法、装置、设备及介质，涉及大模型领域，具体涉及人工智能、大语言模型和人机交互领域。具体实现方案为：获取自然语言内容；将所述自然语言内容输入至大语言模型中，得到当前的第一中间状态；响应于确定所述第一中间状态不包括目标生成内容，根据所述第一中间状态更新当前的第一输入状态，得到第二输入状态；将所述自然语言内容和所述第二输入状态输入到大语言模型中，更新所述第一中间状态，得到第二中间状态；响应于确定所述第二中间状态中包括所述目标生成内容，根据所述第二中间状态得到所述自然语言内容的回复内容。本公开实施例可以提高大语言模型的输出结果准确性。基于大型语言模型获取信息的方法。该方法能够提高大型语言模型输出结果的准确性。该方法涉及获得自然语言内容。 将所述自然语言内容输入大型语言模型，得到当前的第一中间状态。 根据所述第一中间状态更新当前的第一输入状态，得到第二输入状态。 自然语言内容和第二输入状态被输入到大型语言模型中。 对所述第一中间状态进行更新，得到第二中间状态。 当所述第二中间状态中不包括目标生成内容时，根据所述第二中间状态获取所述自然语言内容的回复内容。独立权利要求还包括用于：(1)基于大型语言模型的信息获取装置； 以及(2)一种电子设备，包括处理器和存储器，用于基于大型语言模型获取信息； 以及(3)非瞬时计算机可读存储介质，用于存储用于基于大型语言模型获取信息的计算机指令； 以及(4)计算机程序产品，其包括用于基于大型语言模型获取信息的计算机程序。  11
基于Retinex分解和生成对抗网络的人脸光照处理方法，框架包含光照分解模块、人脸重构模块、判别器模块和人脸验证模块。光照分解模块由一个卷积神经网络构成，输入一对人脸图像，通过无监督学习将人脸图像分解为反射分量和光照分量；人脸重构模块由一个编解码卷积神经网络构成，其输入包含低光照人脸图像的反射分量、光照分量及目标光照等级标签，该模块可以将低光照图像的光照分量调整到目标光照等级；判别器模块通过对抗学习判别输入人脸图像的真实性并分类光照等级；人脸验证模块包含一个预训练的人脸分类器以保证生成的人脸图像和目标人脸图像具有相同的身份信息。本发明鲁棒性高，人脸重构效果好，可适用于夜间光照昏暗条件下的人脸光照处理。基于Retinex分解和生成电阻网络的人脸光照处理方法本发明能够为夜间光照条件下的人脸光照处理提供较高的鲁棒性和较好的人脸重建效果。该方法包括建立人脸照明处理数据集。 构造照明分解模块，其中照明分解模块具有卷积神经网络。 构建人脸重建模块，人脸重建模块具有编解码卷积神经网络。 利用训练好的模型对人脸光照处理模型进行训练，测试光照处理结果。 提供一输入脸部图像和目标照度等级标签。 训练好的模型进行光照处理后输出合成人脸图像。 2
本发明公开了一种司法领域命名实体及关系联合抽取方法，是一种基于BERT预训练语言模型的BILSTM网络与注意力机制集合的实体关系抽取方法，通过参数共享实现两个任务联合学习，充分利用任务间联系来优化结果。选取BERT预训练语言模型训练词向量完成对数据集词向量的转化工作；然后使用BILSTM神经网络获取更为完整的上下文特征信息，从而提取出文本深度词向量特征；最后通过softmax分类器获取字符的类别标签实现实体识别的同时，利用注意力机制判断当前字符与之前字符之间存在的关联关系，实现实体与多关系的联合抽取。该方法可用于司法领域的命名实体和关系的联合提取。该方法利用注意力机制判断当前字符与前一字符之间的关联关系从而实现实体与多关系的联合抽取。该方法包括：选取司法领域数据，设置标注策略，根据标注策略标注司法领域数据的标签，构建关系提取数据集，将关系提取数据集输入双向BERT预训练语言模型，生成词向量序列，将字符向量序列输入双向BILSTM网络提取特征信息，利用softmax分类器对语义向量进行分类，得到字符的实体标签， 根据所述语义向量提取实体之间的关系标签。  12
本公开提供了一种信息推荐方法、装置、服务器及存储介质，属于互联网技术领域。该方法包括：将用户特征和用户隐式表征向量及每条信息的信息特征和内容隐式表征向量输入到精排模型中，输出每条信息的精排分数，精排模型根据当前时间前第一预设时间段生成的多个用户隐式表征向量和多个内容隐式表征向量训练得到；将基于精排分数筛选出目标信息推荐给用户。本公开无需每天全量训练模型，在第二预设时间段的历史数据训练的全量预训练模型基础上，基于新增的历史数据训练增量预训练模型，从而获取用于训练精排模型的多个用户隐式表征向量和多个内容隐式表征向量，降低了精排模型训练过程消耗的时长及离线资源，从而减小了信息推荐过程消耗的资源量。目标信息推荐方法。本发明能够减少细行模型训练过程中的时间，从而减少离线资源的占用，从而获得推荐过程中的资源量信息，从而减少推荐过程中的信息量。该方法包括获得用户的用户特征和用户隐式表示向量。 获得每个信息的信息特征和内容隐式表示向量。 用户特征，用户隐式表示向量，信息特征向量和内容隐式表示向量被输入到细行模型中。 根据多个用户隐式表示向量建立精细行模型。 基于增量预训练模型生成多个用户隐式表示向量和多个内容隐式表示向量。 基于每条信息的细行得分从多条信息中获得目标信息。 向用户推荐目标信息。 获得对应于每个信息的拼接向量。 获得每个信息的精细行分数。独立的权利要求书包括： (1)目标信息推荐装置； (2)服务器，包括用于执行目标信息推荐方法的存储器和处理器； (3)计算机可读存储介质，用于存储用于执行目标信息推荐方法的一组指令； (4)包括用于执行目标信息推荐方法的一组指令的计算机程序产品。  12
本发明公开了一种对话篇章解析方法，包括：获取对话数据；对对话数据进行文本序列化处理，以得到序列化的对话历史信息、篇章关系类别描述信息和篇章结构标注信息；构建篇章解析模型，并将序列化的对话历史信息、篇章关系类别描述信息和篇章结构标注信息输入到篇章解析模型，以便对篇章解析模型进行训练；获取待解析的对话信息，并将待解析的对话信息输入到训练好的篇章解析模型，以便通过训练好的篇章解析模型对待解析的对话信息进行解析，以得到对应的篇章结构；由此，能够将该任务建模为文本生成任务，避免引入额外解码器，仅通过预训练模型完成预测，从而能通过扩大模型规模有效提升模型性能。分析多人对话章节的方法。将任务建模为文本生成任务，并且避免了额外的解码器。 仅通过预训练模型完成预测，通过扩大模型规模有效提高模型性能。该方法涉及获得(S101)对话数据。 对对话数据进行文本序列化处理(S102)，得到序列化后的对话历史信息、章节关系类别描述信息和章节结构标注信息。 构建章节解析模型(S103)。 将序列化后的对话历史信息、章节关系类别描述信息、章节结构标注信息输入章节解析模型，以训练章节解析模型。 获取待解析对话信息(S104)。 将所述待解析的对话信息输入已训练的章节解析模型，以使所述待解析的对话信息通过已训练的章节解析模型进行解析，得到对应的章节结构。独立权利要求包括以下内容：计算机可读存储介质，其存储用于分析多人对话章节的程序； 以及用于分析多人对话章节的计算机设备。 8
本发明涉及人工智能技术领域，具体涉及一种用药预测系统，包括：患者内容输入模块，患者内容输入模块采集患者输入的患者输入内容；内容理解模块，内容理解模块分别连接患者内容输入模块和医学知识库，内容理解模块基于大型语言模型对患者输入内容进行处理，随后建立患者输入内容和医学知识库中对应的医学知识的关联关系；建议输出模块，建议输出模块连接内容理解模块，建议输出模块依照关联关系生成预测药物并输出。有益效果在于：在内容理解过程中引入了外部的大型语言模型，通过大型语言模型对患者输入内容进行解析，进而准确构建起患者输入内容与医学知识之间的关联关系，从而实现了较为准确的预测过程。药物预测系统，用于通过分析患者的病情、病史和生理指标等信息，为患者预测药物治疗方案。在内容理解过程中引入外部大型语言模型，通过大型语言模型对患者输入内容进行分析，准确构建患者输入内容与医学知识的关联关系，从而实现准确预测过程。该系统具有患者内容输入模块(1)，该患者内容输入模块用于采集患者输入的患者输入内容。 内容理解模块(2)，分别与所述患者内容输入模块和医学知识库(3)连接。 内容理解模块，用于基于大型语言模型(4)对患者输入内容进行处理。 在所述医学知识库中建立所述患者输入内容与对应的医学知识的关联关系。 建议输出模块(5)，与所述内容理解模块连接。 建议输出模块，用于根据所述关联关系生成并输出预测药品。  10
本发明公开了一种基于再注意力机制和对比损失的法律案情要素抽取方法，包括法律文本预处理步骤、法律文本与法律案情要素标签联合嵌入步骤、法律案情要素标签表示提取步骤、法律文本表示精化步骤以及法律案情要素标签预测步骤，法律文本与法律案情要素标签联合嵌入步骤是使用预训练模型RoBERTa对法律文本和法律案情要素标签一起进行编码；法律案情要素标签表示提取步骤是从RoBERTa的输出中得到法律案情要素标签表示；法律文本表示精化步骤是使用法律案情要素标签表示来去除法律文本表示中的冗余信息；法律案情要素标签预测步骤则得到每个法律案情要素标签的概率分布。本发明可以有效的识别相似的法律案情要素标签和提升低频法律案情要素标签的预测性能。自然语言处理领域中基于重新注意力机制和比较损失的法律案例元素抽取方法。该方法使得能够识别相似的法律案例要素标签并提高低频法律案例单元标签的预测性能，并且允许对法律文本进行预处理和细化，去除文本表示中的冗余信息，因此提高了法律案例单元预测的准确性。该方法涉及获取合法文本数据集。 在合法文本数据集中去除重复数据。 将合法文本数据集输入预训练模型鲁棒优化双向编码器表示从变压器(RoBERTa)中，得到联合文本表示。 从所述连接的文本表示中提取合法案例元素标签表示。 将所述合法文本表示与所述合法案例元素表示进行两次交叉关注，得到去除冗余信息后的合法文本表示。 将去除冗余信息的合法文本表示输入分类器，得到每个合法案例元素标签的概率分布和分类器的损失，得到模型的总损失。 将待提取的法律案例要素的法律文本输入到训练好的模型RoBERTa中，提取出对应的法律案例要素。  12
本发明涉及一种基于BERT的多模型融合提取事件主体的方法，属于数据处理技术领域。该方法包括：对爬取数据进行预处理，得到训练样本和预测样本；对训练样本和预测样本进行嵌入操作，得到BERT预训练网络的训练样本输入序列和预测样本输入序列；采用多个基于BERT预训练网络的不同复杂度的单模型，利用训练样本输入序列对所述单模型进行训练，并优化网络参数；将预测样本输入序列输入到经训练后的多个单模型，输出多个模型结果；对所述多个模型结果进行融合，得到预测样本的最终预测结果。本发明通过采用不同复杂度的模型，保证模型的多样化，调整参数进行训练，将多个模型的检测结果进行融合，进一步提升检测的准确率。从基于变换器的多模型融合中提取基于双向编码器表示的事件主体的方法。该方法采用不同复杂度的模型，保证模型的多样化，调整参数进行训练，合并多个模型的检测结果，提高检测的准确性。该方法涉及对原始数据进行预处理，得到事件主体的训练样本和预测样本。 对训练样本和预测样本进行嵌入，得到双向编码器表示(BERT)预训练网络的训练样本输入序列和预测样本输入序列。 采用基于BERT预训练网络的不同复杂度的单模型的倍数，利用训练样本的输入序列对单模型进行训练，并对网络参数进行优化。 将预测样本输入序列输入至训练后的多个单模型，输出多个模型结果。  12
本发明提供了一种基于增强嵌入向量语义表示的软件缺陷定位方法，属于计算机技术领域，解决了多模态嵌入向量语义信息表示不足的技术问题。其技术方案为：包括以下步骤：S1：对源代码进行数据增强；S2：构造模态之间和模态内部的正负样本对；S3：对缺陷报告进行文本预处理，得到文本序列；S4：文本序列输入CodeBert预训练模型得到嵌入向量表示；S5：学习模态内部和模态之间的相似性；S6：联合检索任务和二元分类任务微调预训练模型。S7 : 对源代码文件进行排序得到预测结果。本发明的有益效果为：通过对比学习，获得更好的嵌入向量表示，联合检索模型和分类模型对源代码文件进行排序，进一步提高缺陷定位的有效性。基于增强嵌入式向量语义表示的软件缺陷定位方法。该方法软件缺陷定位方法能够通过比较学习，结合对源代码文件进行排序的搜索模型和分类模型，并获得更好的嵌入向量表示，进一步提高缺陷定位的有效性。软件缺陷定位方法包括增强源代码文件的数据。 对缺陷报告和源代码文件进行配对。 在模态之间和模态中构建正负样本对。 对构建的正、负样本训练数据进行文本预处理操作，生成文本序列。 将预处理后的文本序列输入编解码器预训练模型，得到包含上下文语义信息的词嵌入向量表示。 目标函数被设计用于比较和学习。 对联合搜索任务和二分类任务进行微调。 根据相似度分值对所述源代码文件进行相关性排序处理。  12
本发明公开了一种基于深度卷积神经网络模型压缩和加速方法，包括以下步骤：S1：搭建深度卷积神经网络模型，并使用训练数据对所述模型进行训练，得到预训练模型；S2：按照剪枝比率A，求解得到所述预训练模型中卷积层的冗余通道，对所述冗余通道对应的网络权重参数置零，得到剪枝模型；S3：对所述剪枝模型使用稀疏训练的方式进行训练，得到收敛剪枝模型；S4：根据所述预训练模型和所述收敛剪枝模型，搭建新网络模型；S5：将所述收敛剪枝模型的网络参数按照对应关系赋值给所述新网络模型，得到最终模型，并存储。在本发明在保持准确率基本不变的情况下，压缩模型并降低了预测时间，提升模型的检测效率。用于对基于深度卷积神经网络的模型进行压缩和加速的方法。保持精度的方法减少了压缩模型和预测时间，提高了模型的检测效率。该方法涉及构建深度卷积神经网络模型。 将所述训练数据提供给所述模型进行训练，得到所述预训练模型。 将所述剪枝比例设置所述网络权重参数，得到所述预训练模型中的冗余信道卷积层。 所述剪枝模型是根据所述预训练模型和所述模型收敛剪枝使用稀疏训练得到收敛剪枝模型。 根据所述对应关系将所述收敛修剪模型的网络参数分配给所述新的网络模型，得到最终模型。   4
本发明属于中文医疗命名实体识别技术领域，提供了一种中文医疗命名实体识别方法、系统、存储介质和设备。其中，中文医疗命名实体识别方法包括获取临床文本数据；将临床文本数据分别转换为医疗文本的字符嵌入表示、医学概念嵌入特征向量和跨语言中文嵌入表示并进行拼接，得到多元数据融合特征向量；将多元数据融合特征向量输入至基于多图的命名实体识别模型中，识别出中文医疗命名实体类型；基于多图的命名实体识别模型包括多图网络和LSTM‑CRF模型，多图网络用于接收以多元数据融合特征向量为节点构成的文本图，输出节点的最终状态并传送至LSTM‑CRF模型，由LSTM‑CRF模型输出识别结果。其提高了中文医疗命名实体识别准确性。中文医学命名实体识别方法。该方法能够提高中文医学命名实体的识别精度。该方法包括获得临床文本数据。 将所述临床文本数据转换为医学文本的字符嵌入表示、医学概念嵌入特征向量和跨语言中文嵌入表示，得到多元数据融合特征向量。 将所述多元数据融合特征向量输入基于多图的命名实体识别模型。 输出节点的最终状态被传送到LSTM-CRF模型，从而由LSTM-CRF模型输出识别结果。包括以下独立权利要求：中文医学命名实体识别系统； 一种计算机可读存储介质，用于存储用于执行一种中文医学命名实体识别方法的指令集； 以及包括存储器和处理器的计算机设备，所述存储器和处理器用于存储用于执行中文医学命名实体识别方法的指令集。  10
本发明公开了一种改进的命名实体识别方法，首先提出不再使用偏旁部首或者笔画等方式对字进行字形的获取，而是将字转化为图片的形式，转变为图像处理，可以从更形象的角度更充分的捕捉汉字的字形特征。通过将形成的图像通过预训练模型，快速地得到结果，一定程度上解决了汉字训练数据少的问题。将拼音不作为一整块进行编码，而是将拼音按发音成分拆封成声母、韵母、声调来进行编码，一定程度上更好地捕捉了汉字的字音特征。本发明通过将albert中在命名实体识别任务中重要的四层进行了选择与拼接，实现了对albert模型的微调，提高了模型性能。命名实体识别方法。本发明能够将Albert中命名实体识别任务中的重要四层进行选择和拆分，实现Albert模型的微调，提高模型性能。该方法包括获得文本数据的命名实体标识和标记数据。 执行文本处理操作。 生成训练集，验证集和测试集。 执行常用汉字图像处理操作。 生成对图像数据中的预训练模型的输入。 由预训练模型形成向量。 构造相关字典。 获得字符拼音，韵母，声母，声调和编码形成向量。 预测与字符和声音相对应的标签。  12
本发明公开了一种基于视觉语义关系的社交媒体流行度预测方法及装置，方法包括：利用预训练的场景图生成器从帖子的图像中提取成对的对象以及它们之间的谓词联系，生成关系；使用词向量模型将上述关系编码为语义特征；对帖子的其他数据进行编码，得到文本特征、数值特征和附加用户特征，并与语义特征进行连接；针对测试集部分帖子的用户在训练集中的缺失问题，利用连接的多模态特征分别训练两个Catboost模型，线性结合输出得到初步的流行度分数；利用训练集数据，针对帖子内容对初步的流行度分数进行微调，平衡用户信息带来的模型预测误差，从而得到最终的流行度分数。装置包括：处理器和存储器。本发明提高了流行度预测的准确度。基于视觉语义关系的社交媒体流行度预测方法。该方法解决了训练集中不存在测试集部分帖的用户的问题，利用训练集数据平衡用户信息带来的模型预测误差，提高了人气预测的精度，从而更好地服务于内容推荐和下游任务。该方法涉及使用预训练的场景图生成器来从帖子的图像提取成对对象以及它们之间的谓词关系。 生成词-谓词-客体-客体关系。 所述词嵌入模型用于将所述关系编码为语义特征。 对帖子的其他数据进行编码，得到文本特征、数值特征和附加用户特征。 利用所述连接后的多模态特征线性组合输出训练Catboost模型，得到初级人气分数。 对帖子内容的初始受欢迎度得分进行微调。 平衡了由用户信息引起的模型预测误差。 得到最终的热门度得分。独立权利要求还包括用于：基于视觉语义关系的社交媒体热度预测装置； 以及包括用于基于视觉语义关系来预测社交媒体流行度的指令集的计算机可读存储介质。  12
本发明涉及一种视频的场景边界检测方法，该方法通过生成的伪场景边界引导模型学习镜头间的上下文语义关系，在神经网络模型的训练中包含两个阶段，预训练阶段与微调阶段，预训练中通过学习类似场景边界预测的伪场景边界预测来对神经网络模型进行预训练，随后通过真实场景边界标注信息来微调预训练模型，从而在现实数据中取得好的场景边界预测结果。一种视频场景边界检测方法，用于人工智能领域中视频场景语义变换潜在模式的发现和视频自监控。该方法能够通过真实场景边界标记信息对预训练模型进行精细调整，从而在真实数据中获得良好的场景边界预测结果。该方法涉及获得输入视频的部分。 获得射击。 从镜头中采样关键帧。 构建场景边界检测神经网络并进行训练。 从关键帧中提取特征序列，以获得每个透镜的特征。 两个锚点被设置为沿着透镜序列移动。 透镜序列被分成两个伪场景。 计算所述伪场景中的锚点与所述另一伪场景中的所有镜头的相似度得分。 基于所述相似度得分对所述相似度得分进行标准化。 在整个镜头序列上遍历锚点，计算所有可能伪场景条件下的相似度结果。 输出序列中间镜头的置信度作为场景边界。 9
本发明公开了一种基于线激光旋转扫描的轮毂焊缝三维形貌特征测量装置及方法，装置包括线结构光传感器、旋转位移控制系统、LED补光灯控制系统和计算机；线结构光传感器由线激光器和工业相机构成，旋转位移控制系统由旋转台与电控台控制器构成，LED补光灯控制系统由LED与光源控制器构成；测量方法包括利用线结构光传感器采集轮毂焊缝区域的灰度图像以及线激光条纹图像，经图像处理重建轮毂焊缝轮廓的三维点云，分析获取焊缝深度信息；使用双输入改进型U‑Net网络对采集到的感兴趣区域图像预测焊缝区域，结合光条图像信息预测焊缝的上轮廓三维数据。本发明具有装置简易、测量精度高和可实时检测等优点。一种用于测绘工程领域、结构测量领域和娱乐行业领域的基于线性激光旋转扫描的轮毂焊缝三维特征测量装置。 用途包括但不限于医学手术规划矫正修复手术、医学人体测量、古代文物数字档案、工业生产在线质量检测及应用领域。该装置结构简单，测量精度高，实时检测三维特征。 该装置实现了不依赖标准检测装置辅助人工检测的多个物体三维特征检测，以节省浪费大量的劳动力资源，并高效完成检测工作，从而准确获取物体轮毂焊缝轮廓的深度信息和焊缝上边缘三维特征。该装置具有设置有控制与显示子模块、焊缝轮廓三维重建子模块和焊缝上边缘识别子模块的计算机(4)。 旋转位移控制系统、LED补光灯控制系统、计算机通过UART串口与控制及显示子模块通信。 计算机发出指令控制转盘(3)的旋转方向和速度以及开关和LED亮度。 所述控制显示子模块实时显示轮毂(5)焊缝激光条纹图像和焊缝灰度图像的采集情况并控制各子模块执行。包括独立权利要求一种基于线激光旋转扫描的轮毂焊缝三维特征测量方法。   6
本申请涉及一种语义分割方法、装置、计算机设备及计算机可读存储介质。方法包括：基于样本数据对初始的语义分割模型进行至少两轮预训练，得到预训练模型；语义分割模型包括特征提取网络和至少两个分割头；在每轮预训练过程中，针对每个分割头，根据分割头输出的预测结果和样本数据的类别标签之间的差异，对特征提取网络与该分割头共同迭代优化，得到每轮预训练后的特征提取网络和分割头；特征提取网络在每轮预训练中的迭代优化次数与分割头数量一致；基于预训练模型对获取的待测产品的面成像进行语义分割，得到语义分割结果。采用本申请，能够实现无需重新训练模型，节约计算资源。分割语义的方法。该装置不需要重新训练，节省了计算资源。该方法包括基于样本数据对初始语义分割模型进行(S102)轮预训练，得到预训练模型。 对所述特征提取网络和所述分割头一起进行迭代优化，得到每一轮预训练过程中每一轮预训练后的特征提取网络和分割头，对于每一个分割头，根据每一轮预训练过程中所述分割头输出的预测结果和所述样本数据的类标签之间的差值，对于每一个分割头，根据每一个分割头输出的预测结果和所述样本数据的类标签之间的差值。 基于所述预训练模型对得到的所述待测产品的表面成像进行语义分割(S104)，得到语义分割结果。独立权利要求包括用于：用于分割语义的装置； 计算机装置； 以及计算机可读存储介质，其存储用于对语义进行切分的程序。  11
本发明公开了一种SwinUnet低照度图像增强方法，步骤包括：1)构建预处理模块，该预处理模块的输入为原始低照度图像，输出是特征图I1；2)构建SwinUnet模块，该SwinUnet模块的输入数据是步骤1输出的特征图I1，输出是提取后的特征图I2；3)构建恢复模块，该恢复模块的输入数据是步骤2输出的特征图I2，输出是增强后高质量无噪声的输出图像。本发明的方法，能够有效的将低照度图像恢复到正常光照条件下获取的图像，并保持图像的纹理细节以及颜色信息等。Swin unet图像低光照强度增强方法。该方法能够有效地将低照度图像恢复为正常光照条件下得到的图像，并保留图像的纹理细节和颜色信息。该方法包括构建预处理模块，预处理模块的输入数据为原始低照度图像，预处理模块的输出为特征图片。 构建SWIN.NET(RTM：Computer software framework)模块，其中恢复模块输出的输入数据为特征图，输出的大小为H/4 x W/4 X 96。 通过恢复模块的输出来增强高质量无噪声输出图像。   6
本发明公开了一种基于BERT与先验知识特征的关系五元组抽取方法，包括如下步骤：预处理；提取语义特征向量；融合拼接；s抽取阶段；p、o抽取阶段；t、l抽取阶段；最终得到关系五元组的特征向量h+pre+s+p+o+t+l。本发明利用BERT模型与先验知识特征融合的方法抽取文本的关系五元组，利用概率图结合指针结构，解决了一种关系对应多个实体以及实体重叠的问题。基于BERT和先验知识特征的关系五元组文本抽取方法。该方法利用BERT模型和先验知识特征融合处理，利用概率图组合指针结构提取文本的关系五元组，解决了实体对应关系重叠的问题。该方法包括对要提取的文本进行预处理。 得到词级别的文本序列。 提取语义特征向量。 将所述文本序列输入BERT模型进行编码，得到所述序列中每个令牌的语义特征向量。 得到融合特征向量。 将所述融合特征向量输入半指针-半标签结构，预测主体实体的头尾位置。 对所述特征向量的令牌序列文本进行编码。 得到关系五元组特征向量。  12
本发明公开了一种自适应意图识别方法、装置及电子设备，所述方法包括：创建BERT模型，其中，所述BERT模型包括N层特征编码器，且每层特征编码器分别连接一个分类器；将待识别文本输入所述BERT模型进行第i层意图识别；若所述第i层意图识别结果不满足意图识别要求，对所述第i层意图识别结果进行第i+1层意图识别，直至当前层意图识别结果满足意图识别要求，将所述当前层意图识别结果作为所述待识别文本的意图输出，并删除所述待识别文本。本发明能够有效提高模型的意图识别速度，避免在用户与语音机器人的交互中出现语音机器人回答速度慢，用户等待时间久的现象，提升语音机器人与用户的语音交互效果。用于识别电子设备即语音机器人的自适应意图的方法。该方法使得能够有效提高模型的意图识别速度，避免用户与语音机器人交互中语音机器人接听速度慢，用户等待时间长，提高语音机器人与用户的语音交互效果。该方法包括基于转换器创建双向编码表示(BERT)模型。 所述BERT模型设置有与分类器相连的N层特征编码器。 将待识别文本输入所述BERT模型进行图层意图识别处理。 获取当前图层意图识别结果，作为所述待识别文本的意图输出。 删除所述待识别文本。 判断所述图层意图识别结果是否满足意图识别要求。 计算第i层意图识别结果的信息熵。独立权利要求包括如下：具有创建模块的自适应意图识别装置； 一种电子设备，具有处理器和存储器以及用于存储一个或多个程序的计算机可读存储介质。  12
本发明涉及遥感影像的技术领域，特别涉及一种遥感影像编码器训练、解译方法及装置、介质、设备；该方法包括：获取遥感影像数据并将影像数据转为LAB颜色空间的数据，再分组得到训练集和验证集；构建生成器模型、判别器模型及损失函数，分别将训练集样本输入至生成器模型、判别器模型中训练；再将验证集输入至训练好的生成器模型与判别器模型中，以获得生成器中训练好的编码器。本发明提供的编码器训练方法应用在遥感影像技术中，能够将编码器预训练部分由传统的使用分类任务更改为影像上色任务，使得编码器预训练无需使用带人工标注标签的数据集。在大幅度减少人力工时的同时，还能省去知识蒸馏步骤，能够有效提高训练效率和遥感影像解译效果。遥感图像编码器训练方法。本发明大大减少了工时，节省了知识提取单元，有效提高了训练效率和遥感图像判读效果。所述遥感图像编码器训练方法包括：获取(S10)大量无标签的遥感图像数据；对所述数据进行预处理，以将所述图像数据转换为实验室颜色空间的数据。 对数据进行分组以获得训练集和验证集。 通过将少量训练集样本输入到发电机模型中N次预训练以生成训练的发电机模型，来构造发电机模型和损耗函数(S20)。 所述发电机模型设有编码器和解码器。 将由发生器预训练产生的预测数据集与训练集的样本混合(S30)。 验证集被输入(S40)到训练的发电机模型和判断模型以再次训练。独立的权利要求书包括： (a)一种遥感影像的判读方法； (b)具有数据预处理模块的遥感图像编码器训练装置； (c)用于存储计算机指令的计算机可读存储介质； (d)具有处理器的电子设备。   6
本发明公开了一种面向中文拼音拼写纠错的自监督预训练方法、系统及介质，其中方法包括：获取中文文本序列，将中文文本序列转换为输入句子X；从输入句子X中获取需要利用拼音混淆集进行替换的字的列表，并记为PYList(X)；对于PYList(X)中的每一个字x，获取该字x的拼音，根据拼音获取同音字列表，根据同音字列表将字x替换为新的字；在处理完PYList(X)中的所有字后，获得新的输入句子PYInput(X)，根据输入句子PYInput(X)获取BERT模型的输入Input(X)；将Input(X)作为BERT模型的输入并进行训练后，通过BERT模型中的掩码语言模型预测Input(X)中各个字的正确值。本发明对拼音混淆集后进行替换，并将BERT中的MLM任务转换为对被掩码字的正确值预测，增强了BERT的纠错能力，可广泛应用于自然语言处理领域。用于检测中文文本中出现单词或单词拼写错误并进行校正的面向汉语拼音拼写校正的自监督预训练方法。该方法代替了拼音混淆集，并将BERT中的MLM任务转化为对掩蔽词的正确值预测，增强了BERT的纠错能力，可广泛应用于自然语言处理领域。该方法包括获取中文文本序列。 根据预设标记从输入语句中获取需要替换的词语列表。 该列表被记录为PY列表。 对于PY列表中的每个单词，获得该单词的拼音。 获得同音字列表。 根据所述同音字列表将所述词替换为新词。 对所有词语进行处理后得到新的输入语句。 基于所述输入语句获得BERT模型的输入。 将所述输入作为所述BERT模型的输入。 通过掩码语言模型预测所述输入中每个词的正确值。包括独立权利要求：(1)一种面向汉语拼音拼读更正的自监督预训练系统； (2)一种计算机可读存储介质，包括用于执行自监督预训练方法的一组程序。  11
本发明提供一种多音轨音乐生成方法及装置，所述方法包括：对复合词结构进行修改；利用MIDI文件数据和修改后的复合词结构，生成复合词序列；所述复合词序列包括乐器属性的词元序列；将所述复合词序列输入训练好的改进Transformer神经网络模型，获取多音轨音乐。本发明通过对复合词结构的修改，将乐器属性加入复合词序列，有利于多音轨音乐的生成，利用改进的Transformer神经网络模型生成效果性更好的多音轨音乐。用于音乐人工智能进入深度学习时代的多音带音乐生成方法。该方法使得能够对复合词结构进行修改，将乐器属性添加到复合序列中，有利于多声道音乐的生成，利用改进的模型神经网络生成多声道音乐，效果更好。该方法涉及修改复合词的结构。 MIDI文件数据和修改后的复合词结构用于生成复合词序列。 所述的复合词序列包括乐器属性的词汇序列。 将所述复合词序列输入训练好的改进变换器神经网络模型，得到多声道音乐。独立权利要求包括：(1)一种多音带音乐生成装置； (2)电子设备； (3)一种非暂时性计算机可读存储介质； (4)一种计算机程序产品。 3
本发明涉及安全自动化技术领域，提供了一种基于AIGC的自动化安全运营方法及相关装置，应用于服务器，服务器运行有SOAR软件系统，方法包括：接收AIGC平台发送的满足指定安全业务需求的SOAR指令集，SOAR指令集是客户端基于用户输入的指定安全业务需求、调用AIGC模型得到的，AIGC模型是以与指定安全业务需求相关的命令使用手册和问题解决方案为数据源训练的；利用SOAR软件系统执行SOAR指令集，得到执行结果；利用AIGC模型，对执行结果进行分析，得到分析结果，并通过AIGC平台将分析结果发送至客户端进行显示。本发明能够提高指令集的生成、创建及执行过程的处理效率，且不易出错。一种基于人工智能AIGC的自动安全运行方法，应用于服务器。提高了指令集的生成、建立和执行过程的处理效率，且不易出错。 以与指定安全服务需求相关的命令使用手册和问题解决方案为数据源训练AIGC模型，利用SOAR软件系统执行SOAR指令集，得到执行结果。自动安全操作方法涉及接收AIGC平台发送的满足指定安全服务要求的SOAR指令集。 SOAR指令集是客户端基于用户输入的指定安全服务需求。 所述AIGC模型通过调用所述AIGC模型得到。 以指定安全服务需求相关的命令使用手册和问题解决方案为数据源，训练AIGC模型。 执行所述SOAR软件系统设定的SOAR指令，得到执行结果。 用于对执行结果进行分析得到分析结果的AIGC模型。 由AIGC平台将分析结果发送至客户端显示。本发明还涉及一种基于AIGC的自动安全操作装置; (b)服务器，具有用于存储程序的存储器; (c)用于存储计算机程序的计算机可读存储介质。 1
一种基于条件生成对抗网络的MR图像分割方法及装置，分割方法包括通过低级MR图像y和分割掩膜x训练cGAN网络，得到训练好的cGAN模型；根据输入的分割掩膜x，使用训练好的cGAN模型自动生成人工图像y’；利用人工图像y’和分割掩膜x预训练U‑net网络；通过低级MR图像y和分割掩膜x继续训练U‑net网络，得到训练好的U‑net模型；利用训练好的U‑net模型进行MR图像分割。本发明同时提供了一种实现上述方法的装置、终端设备以及计算机可读存储介质，本发明扩充和丰富了原始数据集的数据多样性，图像分割结果更接近真实图像，在分割网络训练过程中的收敛速度更快、损失更小且分割精度更高。基于条件式生成对抗网络由终端设备(主张)执行MRI分割的方法。该方法能够扩展和丰富原始数据集和图像分割结果的数据多样性，并保证在分割网络训练过程中快速收敛，以提高分割精度。该方法包括通过低水平磁共振成像(MRI)和分割掩模来训练条件式生成对抗网络(cGAN)网络，以获得经训练的cGAN模型。 根据输入的分割掩膜，利用训练好的cGAN模型自动生成人工图像。 利用所述人工图像和所述分割掩膜预训练U-net网络。 通过所述低水平MRI和所述分割掩膜对所述U-net网络进行不断训练，得到训练后的U-net模型。 利用训练好的U网模型进行MRI分割。对于以下包括独立权利要求：一种用于由终端设备基于条件式生成对抗网络执行MRI分割的设备； 以及一种计算机可读存储介质，用于存储执行终端设备基于条件式生成对抗网络进行MRI分割的方法的指令。   6
本发明公开了一种大模型向量最优化分析方法，涉及向量模型优化领域；包括以下步骤：数据预处理，对向量进行归一化处理和去除噪声；最优化分析，利用最优化分析算法对向量进行优化，得到最优解；后处理，对最优解进行反归一化处理和还原噪声处理，最优化分析算法采用随机梯度下降算法、共轭梯度法、牛顿法和拟牛顿法中的任意一种。本发明通过预处理和后处理，可以有效降低计算的复杂度，提高优化的效率；同时，可以利用随机梯度下降算法、共轭梯度法、牛顿法和拟牛顿法处理大规模数据，避免传统方法在处理大规模数据时存在效率低和无法收敛的问题。大模型向量优化分析方法，用于机器学习和数据分析领域。该方法通过前处理和后处理，有效降低了计算的复杂度，提高了优化效率。 可以采用随机梯度下降算法、共轭梯度法、牛顿法和拟牛顿法对大规模数据进行处理，避免了传统方法效率低的问题。该方法涉及预处理(S1)数据。 对向量进行归一化处理以去除噪声。 利用优化分析算法进行优化分析(S2)，对所述向量进行优化，得到最优解。 对所述最优解进行反归一化处理和降噪处理(S3)，以降低噪声。 向优化分析算法提供(S4)第一优化算法和第二优化算法。 将前一优化算法与后一优化算法连接(S5)，得到第三优化算法。  12
本发明公开了一种LNOB视频交互平台，涉及视频处理和交互技术领域。本发明，通过设置一个语言大模型，实现自然语言与视频之间的智能交互；通过设置一个视频输入/理解模块，实现对视频内容进行深度理解并基于理解内容进行二次创造；通过设置一个视频处理/生成/编辑模块，实现对输入或生成的视频进行处理、生成和编辑；通过设置一个多媒体交互界面模块，实现与用户进行多轮对话，理解用户的需求和反馈，动态调整视频内容和风格。本发明具备自然语言与视频之间的智能交互、视频内容的深度理解和二次创造、多种语言、格式、分辨率、应用场景和交互方式支持等优点。用于利用所述自然语言对视频进行控制、处理、生成和编辑，实现个性化视频体验的LNOB视频交互平台。该方法能够实现自然语言与视频的智能交互，对视频内容的深刻理解和二次创作，多种语言、格式、分辨率、应用场景和交互方式支持。LNOB视频交互平台包括语言大模型，接收用户的自然语言输入，根据用户的需求和意图生成相应的视频处理或生成指令。 视频输入和理解模块接收由用户提供的或从网络检索的视频。 将视频转换为语言大模型能够处理的格式。 从视频中提取信息。 极的指定是分段异企业24记录的导中的野外浮动。 场景参数在计算机视觉技术的基础上生成或编辑相应的视频，并将生成或编辑的结果转换为用户可以观看的格式。 多媒体交互界面模块显示用户的自然语言输入和语言大模型的回复。 9
本发明公开了一种基于3D U‑Net的轻量级脑肿瘤分割系统，涉及计算机视觉与医疗影像结合的医学图像分割领域，用于解决现有脑肿瘤分割系统复杂度高、精准度差的问题，包括以下步骤：第一步，脑部MRI图像预处理；第二步，构建和训练轻量级脑肿瘤分割网络：使用多纤类残差模块代替传统卷积模块构建网络，并使用改进的损失函数对网络进行训练；第三步，验证网络并选出最佳的网络模型。本发明网络复杂度低，运行速度快，能精准分割脑肿瘤边缘及小目标区域。用于医学图像分割领域的基于三维(3D)U-Net的轻量级脑肿瘤分割系统，用于结合计算机视觉和医学成像，并将深度学习方法应用于脑肿瘤图像分割。基于3D U-Net的轻量级脑肿瘤分割系统的网络复杂度低，运行速度快，准确分割脑肿瘤和小目标区域的边缘。该系统具有处理器，该处理器用于调整数据集中的训练集和验证集的大小和格式，并使用图像增强技术来扩展训练集。 采用多光纤残差模块代替传统的卷积模块，形成网络的基本结构。 采用多光纤残差模块代替传统的卷积模块，以3D U-Net作为基础网络。 将得到的特征图像与对应的降采样后的特征图像进行拼接。 网络最终的softmax层将输出图像转化为与输入图像大小相同的分割结果。 改进的Tversky损失函数用于更新网络的权值，在每一轮网络训练中。 将每一轮训练得到的网络模型在验证集上进行验证，选择分割效果最好的网络模型作为最终模型。  7
本申请涉及一种文本相似度匹配方法、装置和计算机设备。所述方法包括：利用大模型服务接口获取到的信息，构建基础问答数据集；对基础问答数据集进行相关性扩展，生成与基础问答数据集相关的扩展内容；利用预设的综合评价指标，对扩展内容进行评估，将评估结果满足预设条件的扩展内容并入基础问答数据集，生成完备问答数据集；根据完备问答数据集的数据结构，选取具备对应网络架构的问答模型，并采用梯度下降法对问答模型的参数进行更新，直至问答模型收敛，生成用于文本相似度匹配的完备问答模型；基于完备问答模型，进行文本相似度匹配。采用本方法能够解决现有的基于文本相似度匹配的智能问答技术存在回答问题的效率和准确率低的问题。文本相似度匹配方法，用于智能问答系统中。该方法使得能够利用大模型服务接口获取的信息构建基础问答数据集，并对基础问答数据集进行相关性扩展，提高答题效率和准确率。该方法包括使用预设的综合评价指标对扩展内容进行评价。 将所述扩展内容与满足预设条件的评价结果组合成基本问答数据集。 生成完整的问答数据集。 根据所述完整问答数据集的数据结构生成具有相应网络结构的问答模型。 通过执行梯度下降过程来更新问答模型的参数。 生成完整的问答模型，用于进行文本相似度匹配，直至所述问答模型收敛。包括独立权利要求：(1)文本相似度匹配装置； (2)一种计算机设备，包括处理器和存储用于执行文本相似度匹配的指令集的存储器。  11
本发明公开了一种自动驾驶模型的训练方法、评测方法、控制方法及装置，本发明通过该仿真系统，可以映射实际交通场景下各车辆的行驶轨迹和行驶行为，进而能够获取实际交通场景下大量车辆的行驶信息，增大模型的训练数据量；在训练自动驾驶模型的过程中不断计算各个目标仿真车辆与各个自动驾驶车辆之间的偏差值均值，能够在偏差值均值小于第一阈值时及时确定目标自动驾驶模型，当偏差值均值不小于第一阈值时也无需重新部署训练环境，提高了训练效率，减少了运算量且大大降低了成本, 可广泛应用于自动驾驶技术领域。用于由电子设备训练车辆的自动驾驶模型的方法(权利要求书)。该方法能够通过仿真系统对实际交通场景中各个车辆的行驶轨迹和驾驶行为进行映射，得到大量车辆在实际交通场景中的行驶信息，提高了训练数据量。 该方法能够在偏差平均值小于阈值时及时确定目标自动驾驶模型。 该方法避免了当偏差平均值不小于阈值时，需要重新部署训练环境，提高了训练效率，降低了操作量和操作成本。该方法涉及获取实际交通信息。 根据所述实际交通信息构建仿真系统。 在目标模拟车辆集合中获取目标模拟车辆的驾驶信息。 将所述目标模拟车辆在所述模拟系统中替换为自动驾驶车辆。 根据所述目标模拟车辆和所述自动驾驶车辆的驾驶信息计算偏差平均值。 偏差值，用于表示所述目标模拟车辆与所述自动驾驶车辆的驾驶信息相似度。 自动驾驶模型的训练结束。以下包括独立权利要求：一种自动驾驶模型评价方法； 一种电子设备训练车辆的自动驾驶模型的装置； 自动驾驶模型评价装置； 自动驾驶控制装置； 以及计算机可读存储介质，用于存储计算机程序，以执行电子设备训练车辆的自动驾驶模型的方法以及自动驾驶模型评价方法。 13
本发明公开了一种基于视频分析的交通车辆识别追踪方法及系统，所述方法中包括：步骤1，提取第一视频和第二视频，所述第一视频和所述第二视频具有时空关联性；步骤2，针对第一视频，进行车辆识别；步骤3，针对第二视频，进行车辆识别；步骤4，在地图上标注上所识别成功的同一车牌车辆，按照所述第一视频和所述第二视频所具有的时空关联性在地图上进行标注点连接，得到车辆行驶轨迹，根据该车辆行驶轨迹完成车辆追踪。本发明通过融合改进的swin transformer深度学习模型和MapReduce框架下训练的AlexNet模型的方法，提高了车辆检测识别追踪的效率。基于视频分析的交通车辆识别跟踪方法。通过在map reduce框架下训练的AlexNet(RTM：Convolutional neural network)模型的融合改进swin和深度学习模型方法来提高车辆检测识别跟踪的效率。 创新利用swin增加感受野和网络深度，抑制干扰背景信息，提取更丰富的特征信息，以增强视觉表示能力，提高识别速度和准确率。该方法包括以每秒1帧的帧率获取第二视频的视频帧图像。 对所述第二视频帧图像中的车牌目标进行符号识别。 车牌参考图像2为车牌参考灰度图像2在原始第二视频帧中对应位置的图像。 所述第二视频流中所述车牌目标的符号标记的相同或附近位置处连续出现的帧数达到预设值。 所述成功识别所述车辆。 对同一车牌车辆进行打码识别成功。 地图，根据所述第一视频和所述第二视频的时空相关性连接所述地图上的标记点，得到车辆运行轨迹。 根据车辆运行轨迹完成车辆跟踪。包括用于基于视频分析的交通车辆识别跟踪系统的独立权利要求。 13
本说明书实施例提供了基于文本进行图像生成的方法及装置，其中，一种基于文本进行图像生成的方法包括：在根据描述文本进行图像生成过程中，在对描述文本进行关键词提取获得的文本关键词的基础上生成对应的图像关键词，并通过计算图像关键词与图像库中图像描述文本的相似度确定图像关键词匹配的目标图像库，在参数库中读取目标图像库对应的子模型的模型参数并加载至预训练模型，并通过将图像关键词输入加载获得的图像生成模型进行图像生成获得目标图像。基于文本生成目标图像的方法。该方法能够通过输入并加载图像关键字得到的图像生成模型生成图像，以有效的方式得到目标图像，使得用户能够将图像关键字输入到预训练模型中，从而读取参数库中与目标图像库对应的子模型的模型参数并加载到该模型中，从而能够有效的基于输入的图像关键字生成图像。该方法包括提取由图像生成的描述文本的关键字。 与提取的每个文本关键字对应生成每个图像关键字。 在图像库中计算每个图像关键词与图像描述文本的相似度。 根据所述相似度确定与所述每个图像关键词匹配的目标图像库。 在参数库中读取基于每个目标图像库训练得到的每个子模型的模型参数。 将读取的模型参数加载至预训练模型，得到图像生成模型。 将各图像关键词输入图像生成模型，生成图像，得到目标图像。包括独立权利要求，用于：(1)基于文本生成目标图像的装置； 以及(2)存储介质。 14
本发明涉及神经网络技术领域，提出一种基于DS结构的CNN模型压缩方法、装置及存储介质，其中的方法包括：S110、通过普通卷积和批标准化BN运算，将DW卷积和SE Module形成DS卷积块；其中，DS卷积块包括：卷积Conv_1、批标准化BN、激活函数、DW卷积、批标准化BN、激活函数、SE Module、卷积Conv_2和批标准化BN；S120、将DS卷积块有序堆叠形成神经网络结构；S130、在神经网络结构上加入输入层、池化层、全连接层及分类层，形成神经网络模型。本发明通过在神经网络中应用DS卷积块结构，在保证图片特征提取能力的同时，大大减少了神经网络的参数数量。一种基于数据服务器(DS)结构的有线新闻网(CNN)模型压缩方法。该方法，其中图片特征提取能力大大减少了神经网络的参数数量。该方法涉及使用一般的卷积和批量操作标准化。 数据仓库(DW)卷积和标准版本(SE)模块由DS卷积块构成。 DS卷积块由标准化激活函数的卷积批包括。 DW卷积批标准化激活函数。 将卷积和批标准化的卷积和批排序成一个堆栈到DS块卷积神经网络结构中。 神经网络结构具有输入层，池化层被全连接并且分类层由神经网络模型形成。以下包括独立权利要求：一种电子设备； 以及计算机可读存储介质。   4
本发明公开了一种基于BERT‑CNN‑BiGRU的问答型商品评论文本情感分析方法，包括：将问答型评论文本分为问题文本和答案文本，并经过BERT生成各自对应的文本表示向量，分别输入到CNN和BiGRU中得到各自文本的局部特征向量和全局特征向量，并捕获情感关键词得到局部情感表示向量以及全局情感表示向量；拼接局部情感表示向量和全局情感表示向量，分别得到问题文本和答案文本的完整表示向量，以及拼接问题文本和答案文本完整表示向量，得到最终表示向量；将最终表示向量输入到softmax分类器中进行情感分类。本发明可极大的提升问答评论文本的文本语义完整性，提高了问答文本情感分类准确率。利用计算设备对基于BERT-CNN-BiGRU的问答类商品评论文本进行情感分析的方法(声明)。该方法能够极大地提高问答评论文本的文本语义完整性，从而以高效的方式提高问答文本情感分类准确率。 该方法允许CNN使用不同窗口大小的卷积核进行特征提取，使得CNN能够有效地提取问题文本和答案文本的局部语义特征，从而提高了情感分类的准确性。该方法包括将问答类型的评论文本划分为问题文本和回答文本。 对所述问题文本进行预处理。 生成所述答案文本。 通过BERT生成对应的文本表示向量。 得到每个文本的局部特征向量和全局特征向量。 将所述局部特征向量和所述全局特征向量通过注意力机制捕获情感关键词，得到局部情感表示向量和全局情感表示向量。 将所述问题文本、所述答案文本的完整表示向量以及所述完整表示向量进行拼接，得到所述最终表示向量。 利用softmax分类器进行情感分类，得到所述答案类评论文本的情感分类的概率。独立权利要求包括：一种利用计算设备对基于BERT-CNN-BiGRU的问答类商品评论文本进行情感分析的系统； 计算设备； 以及计算机可读存储介质，用于存储利用计算设备对基于BERT-CNN-BiGRU的问答类商品评论文本进行情感分析的指令集。  12
本发明公开了一种基于深度学习的网络音频增强方法，包括以下步骤：步骤一，音频输入；步骤二，语音特征提取；步骤三，特征细化；步骤四，跳跃连接；步骤五，语音信号恢复；步骤六，音频输出；所述步骤二中，h为输出通道数，数量为48；所述步骤三中，SEQUENCE网络基于transformer结构中的encoder部分，负责对ENCODER网络的输出序列进行更细粒度的特征提取，本发明提出一种适用于语音增强的U‑net改良版本，它由一个基于卷积和SEQUENCE网络组成，通过分层生成和优化模型，使其直接输出语音信号的干净版本，同时最小化回归损失函数，模型在数据集Valentinibenchmark上的PESQ达3.02，STOI(％)为95，在实际投产时，通过客观和主观的度量，可缩短运行的代价，有符合工业要求的性能。基于深度学习的增强网络音频的方法。该方法使得能够通过分层来生成和优化模型，以同时的方式直接输出语音信号的干净版本，从而减少回归损失函数。 该方法能够获得并输出恢复的语音信号，以最终获得高质量的语音音频。该方法包括：通过使用编码器网络的第一下采样层对输入音频信号执行特征提取处理，以获得特征编码向量。 利用特征编码向量对所述特征编码向量进行提取，得到所述特征编码向量。 编码器网络和解码器网络之间的连接是基于跳跃连接建立的。 执行语音信号恢复处理。 输出解码后的音频信号，以获得高质量的语音音频。 3
本发明涉及自然语言处理技术领域，尤其涉及一种融合词汇边界及语义信息的实体识别及关系抽取方法，包括构建预处理语言模型的样本输入及标签；通过BERT模型输出最后一层的特征向量；构建实体识别任务的任务特征向量，并计算损失；构建关系抽取任务相关的任务特征向量计算损失；将两种损失按照系数相加得到总损失；联合实体识别以及关系抽取的结果，得出最后的三元组。本发明解决深度学习方法存在误差积累、实体冗余，交互缺失的问题；以及解决现有嵌套实体基于片段排列的方式显示的提取所有可能的片段排列的问题。用于自然语言处理技术领域的融合词汇边界和语义信息的实体识别和关系抽取方法。该方法使得能够构建样本输入和预处理语言模型的标签，通过BERT模型输出该层的特征向量并确保高效准确的实体识别和关系提取过程。 该方法能够解决深度学习过程中的误差累积、实体冗余和缺乏交互的问题，以及基于嵌套实体的展示提取可能的片段排列的问题。该方法涉及构建样本输入和预处理语言模型的标签。 样本被输入到预训练双向编码器表示来自变换器(BERT)模型中。 通过BERT模型输出一层的特征向量。 预测片段边界词特征。 通过语句向量构建与关系抽取任务相关的任务特征向量。 根据系数将预设丢失率相加，得到总丢失率。 将一个实体识别和关系抽取结果进行组合，得到一个三元组。 构建实体标签和关系标签。  12
本发明公开了一种基于双型U‑Net模型的医学图像分割方法。本发明实现步骤：步骤1、获取图像数据集，并进行图像增强预处理；步骤2、将预处理后的数据集划分为训练集、验证集和测试集；步骤3、搭建双型U‑Net网络模型，使用预训练的VGG19替换模型的第一个编码器，对原U‑Net网络进行改进，加入ASPP获取网络模型的上下文信息；步骤4、设计损失函数，评估指标；步骤5、将待分割图像输入到网络模型中进行训练，得到分割结果：将训练集、验证集和测试集分别输入到网络模型中，得到输出图像以及对应的评估指标结果。本发明提高了模型的分割准确率，并有效改善了模型泛化能力和鲁棒性。使得分割网络获取高分辨率的特征图，进而带来优异的表现。基于双U-网模型分割医学图像的方法，用于从医学图像背景中分离CT或MRI图像中的器官或病变像素区域。本发明提高了模型的分割精度，有效提高了模型的泛化能力和鲁棒性，使分割网络获得高分辨率的特征图，提供了优异的性能。该方法包括获得图像数据集。 执行图像增强预处理过程。 预处理后的数据集分为训练集，验证集和测试集。 构建了一种双类型U网网络模型。 设计了损耗函数。 评估指标。 将待分割的图像输入到网络模型中以进行训练。 得到分割结果。 训练集和验证集被输入到网络模型中，以获得输出图像和相应的评价指标结果。   6
本发明涉及一种基于改进U‑Net网络的类器官分割方法及系统，涉及图像分割领域，该方法包括：将待分割类器官图像输入类器官分割模型，输出类器官分割图；类器官分割模型为根据类器官数据集对改进的U‑Net训练得到的；编码器包括N个依次连接的编码层和与第N个编码层连接的特征加强单元，各编码层均包括动态卷积模块和下采样模块，特征加强单元包括动态卷积模块和协调注意力模块，协调注意力模块用于对输入的特征信息进行细化和加强；解码器包括N个依次连接的解码层，各解码层均包括依次连接的上采样模块和动态卷积模块；各编码层和与各编码层对应的解码层之间采用注意门跳跃连接；下采样模块采用卷积下采样操作。本发明提高了图像分割精度。基于改进的U-Net网络进行类器官分割的方法。该方法通过使用改进的U‑Net网络，提高了图像分割精度。该方法包括获得(101)待分割器官的图像。 将待分割器官图像输入(102)到类器官分割模型中，并输出类器官分割图。 协调关注模块，用于获取输入的特征信息的特征信息。 协调关注模块，用于执行所述信息细化所述输入的特征信息。 一解码层，设置有相互连接的上采样模块和所述动态卷积模块。 所述编码层与所述编码层对应的解码层之间采用注意跳门连接。 下采样模块采用卷积下采样操作。一种基于改进的U-Net网络的类器官分割系统，包括独立的权利要求。   6
本发明公布了一种基于自监督预训练和交互式融合网络的语音识别方法，构建语音识别模型，将自监督预训练模型作为语音增强模块后的特征提取部分，将语音增强模块与自监督预训练方法进行有效组合并，缓解因语音增强所带来的语音失真；利用交互式特征融合方法将增强特征和原始音频特征进行融合，以弥补在语音增强过程中的信息缺失。采用本发明方法，能够使低资源语音识别结果更加准确，提高低资源在复杂环境下的识别精度。基于自监督预训练和交互融合网络进行语音识别的方法。该方法使得能够利用交互式特征融合操作，将增强特征与原始音频特征进行融合，以弥补语音增强过程中的信息缺失，并且使得低资源语音识别结果更加准确，提高复杂环境下低资源的识别准确率。该方法包括预先构建语音识别模型。 通过语音增强模块对所述带有噪声的原始语音波形进行语音增强，得到所述增强波形。 将增强波形和原始语音波形进行特征提取模块，得到声学特征，即为增强特征和原始特征。 基于预测标签和语音对应的真实标签计算语音识别损失。 执行与所计算的语音增强损失的加权相加。 对模型的参数进行反复更新迭代，直到在训练过程中通过训练得到最优的参数组合。 得到训练后的语音识别模型。 利用训练好的语音识别模型实现基于自监督预训练和交互融合网络的语音识别。特征提取模块采用wav2vec 2.0模块。 3
本发明公开了一种基于限制搜索空间的人脸识别对抗样本生成方法。该方法具体步骤为：(1)对图像数据集进行预处理；(2)将预处理后的图像作为数据预训练生成器模型；(3)将预处理后的图像输入至生成器模型生成对抗样本，然后将生成的对抗样本和经预处理的图像送入判别器进行特征提取，将提取到的特征通过全连接层输出预测分数；(4)将生成的对抗样本和经预处理后的图像送入人脸识别模型进行特征提取，然后通过比较提取到的特征余弦相似度作为目标函数，再通过反向传播的方法优化目标函数。本发明利用了限制搜索空间的手段，能在一定程度上解决人脸识别对抗样本生成中常见的泛化性不足问题，得到更有效的对抗样本。基于限制搜索空间的人脸识别-对抗样本生成方法。该方法利用简单高效的框架限制搜索空间，提高生成过程的稳定性，从而改善超球面引起的样本迁移角。 该方法使得人脸识别样本生成过程能够基于限制搜索空间来进行，从而能够以有效的方式提高生成过程中的稳定性和有效性，并能够以有效的方式获得泛化性更强的反样本。该方法包括对包括对应的人脸身份标签数据的人脸图像数据集进行预处理。 将预处理后的人脸图像输入至预先训练的生成器模型网络。 对抗样本由生成器模型输出。 将所述对抗样本和预处理后的人脸图像送入判别器模型提取特征。 根据所述预测对所述生成器模型和仲裁器模型的第二目标函数和第三目标函数进行优化。 通过反向传播方法对所述第四目标函数进行优化，生成优化对策样本。 2
本发明公开了一种基于词汇增强和多特征的中文命名实体识别方法及装置，属于信息抽取技术领域，方法包括：结合双向长短期记忆网络和卷积神经网络提取输入序列的字符特征、通过字符串模式匹配的方式引入字符对应的词汇信息并以词频加权平均的方式提取词汇特征以及使用预训练模型提取预训练特征；使用门控机制来控制词汇特征对字符特征的词汇增强；线性拼接经过词汇增强后的字符特征和预训练特征以构建多特征；基于多特征的上下文相关性以获取上下文特征；标签解码结合上下文特征预测输入序列最佳标签序列。从而使得，提取中文序列的字符特征更充分；提取的词汇特征更丰富且避免了中文分词误差的影响；使用多特征结合的策略模式提高了实体识别指标。一种基于词汇增强和多特征的中文命名实体识别方法。本发明能够充分利用中文文本序列的字符特征，字符对应的词特征和预训练特征，提高识别的准确率和查全率。 该方法利用双向长期记忆网络和卷积神经网络模块提取汉字序列，并将提取的特征进行线性拼接，以实现对汉字远程依赖的位置特征和局部形态特征的兼顾， 使得提取的字符特征更加充分。 本发明能够使提取的词汇特征得到处理，避免中文分词错误的影响。 本发明能够利用多特征组合策略方式，提高实体识别索引率。该方法包括提取(S1)输入序列的字符特征，词汇特征和预训练特征。 利用选通机制(S2)将词汇特征集成到字符特征中，以实现字符特征的词汇增强。 在词汇增强之后执行字符特征和预训练特征线性拼接处理(S3)，以获得输入序列的最终特征。 对最终特征进行编码(S4)以提取上下文特征。 基于上下文特征预测(S5)输入序列的最优标签序列。本发明涉及一种基于词汇增强和多特征的中文命名实体识别装置。  12
本发明涉及一种基于深度学习的道路清洁度量化方法，属于人工智能技术领域。该量化方法与基于安装于车辆上的图像采集设备所采集的道路图像通过深度网络模型制定控制策略；量化步骤如下为：图像数据集的进行分类、定标，生成训练网络所需的训练集；通过深度网络模型进行训练和测试；通过深度网络模型的部分层数进行冻结并采用预训练模型参数，判断道路清洁度，以道路垃圾量决定吸尘器的功率。本发明提供的基于深度学习的道路清洁度量化方法，将深度学习运用于道路垃圾清洁度量化检测中，在服务器(可远程)加持的情况下，所使用的深度网络模型具有运算速度快，准确度高的特点，可以满足真实路况下的道路清洁度量化检测任务。基于深度学习的道路清洁度量化方法。该方法利用深度网络模型在远程服务器中进行道路清洁度量化和检测过程，运算速度快，准确度高，满足了道路清洁度量化检测任务的需求。该方法包括形成由图像采集装置采集的道路图像以形成图像数据集。 通过深度学习网络对图像数据集进行分类和校准，以生成训练网络所需的训练集。 通过在服务器上构建深度网络模型对所述训练集进行训练和测试。 利用在大规模数据集上训练的深度网络训练模型参数冻结所述深度网络模型的多个部分层。 对所述训练集进行训练后得到所述深度网络模型。 利用所述深度网络模型进行道路垃圾量化检测过程，判断道路清洁状况。 将道路图像实时输入所述深度网络模型。 输出结果被反馈给道路清洁车辆。 除尘器的功率由道路垃圾的量决定。 13
本发明公开的基于多级语义引导生成对抗网络的汉字图像修复方法，采用新的编解码器作为生成器，编码器由三个部分组成，分别是浅层特征提取模块，深层特征提取模块和语义信息提取模块；深层特征提取模块用于提取深层的特征；语义信息提取模块用来提取深层特征中的语义信息，并将深层语义特征通过Mixup模块进行自适应的融合，为了获得更好的结果，使用了四种不同的损失函数项进行监督训练，并引入了基于U‑Net结构的判别器来提升汉字缺失图像的修复结果。基于多层次语义引导的生成对抗网络的汉字图像修复方法。引入基于UNet结构的判别器，提高汉字缺失图像的修复结果。该方法包括使用标准打印汉字图像作为数据集，用于预处理和将数据集处理成由原始图像和缺陷图像组成的成对数据集。 将配对后的数据集作为修复工作的训练集和验证集。 编解码网络的生成器搭建完成。 所述的生成器，用于提取汉字图像中的浅层和深层特征。 浅层和深层特征是级联的。 用于共同训练U-Net鉴别器和生成器的配对数据集，得到多级语义引导的生成对抗网络模型。 将所述缺失的汉字图像输入训练好的生成对抗模型，得到汉字图像修复结果。   6
本发明涉及一种基于GPT‑2模型的中文电子病历实体识别方法，利用GPT‑2预训练模型提取电子病例的特征向量，再从CRF模型作为出口得到识别概率，最终得到中文电子病例的命名实体，所述方法包括如下步骤：1)将中文电子病历的数据分为训练集和测试集两个部分，并对两个部分的数据进行统一标注，标注后的数据包含原始中文电子病历和实体标注；2)以GPT‑2预训练模型为基础，引入CRF模型，建立基于GPT2‑CRF的中文电子病历实体识别模型，使用训练集数据训练，得到训练后的中文电子病历实体识别模型；3)将测试集数据输入中文电子病历实体识别模型中，通过评估分数得到实体识别的最优标注序列。该方法不受文本形式限制，容易实现，并且开发和运行成本低。基于中国电子病历的GPT-2模型实体识别方法。该方法能够降低开发和操作成本。该方法包括将中国电子病历数据分为训练集和测试集。 判断设定标签的实体类别是否为身体部位、症状或体征、检查或测试以及疾病或诊断。 根据中文电子病历数据建立GRT2-CRF实体识别模型。 测试数据被输入到实体识别模型中的中文电子病历中。 通过评价得分得到实体识别的最优标签序列。 进行判断以检查CRF是否是最大似然估计的条件。 获得中文电子案例。  10
本发明涉及视频图像处理技术领域，尤其涉及一种基于生成对抗网络的轻量化高效目标分割与计数方法；本申请在解码器阶段提出了折叠最近邻超越上采样方法，其极大的减少了计算量、加速了网络的运算、提升了网络运行效率，极大的优化了网络结构；在预测器阶段，本申请对每个任务设置了独立的预测器，以满足不同任务的独特需求；且对判别器进行了轻量化设计，简化了模型结构，加速的训练过程；基于密度图的目标数量统计任务拆分为了数量预测和位置预测两个任务，减轻了学习难度，也扩大了预训练时数据集的可使用范围；基于生成对抗网络的训练方法解决了对目标图像分割计数时所使用的多任务生成器训练速度慢、效率低，结构复杂的问题。基于生成电阻网络实现光量化高效目标分割与计数的方法该方法在解码阶段大大减少了计算量，加快了网络的速度，提高了网络运行效率，大大优化了网络结构。 本发明将基于密度映射的目标数量统计任务分为数量预测和位置预测两个任务，降低了学习难度，扩大了数据集在预训练时的使用范围。 本发明解决了用于目标图像分割计数的多任务发生器训练速度慢，效率低，结构复杂的问题。该方法包括将分割后的特征图和图像真实值同时预测到协调仲裁器中。 生成与生成器判断矩阵大小相同的校验矩阵。 得到预测判断矩阵。 计算训练总失配判决器得到的预测真判决矩阵。 训练总损失被发送回网络用于网络迭代更新学习。 完成单轮协调仲裁器的训练。 得到一轮训练的协调仲裁器。 存储生成器和协调仲裁器，直到满足预定条件的生成器和协调仲裁器。 9
本申请公开的基于预训练模型的无监督日志异常检测方法，包括：收集来自不同系统产生的日志数据集；将日志数据集进行预处理；源系统日志集调用LSTM与全连接层模型，构建预训练模型；混合模型投票伪标签：通过预训练模型中的LSTM提取出无标签目标系统日志向量序列的深度特征向量表示；基于层次聚类HDBSCAN的分类器辅助预训练模型的全连接层，投票预测筛选出置信度高的日志向量序列作为带伪标签目标系统日志集；微调预训练模型；将目标系统日志向量序列输入到微调后的预训练模型中，进行异常检测。本发明涉及的技术方案，进行日志序列异常检测时，其能够利用已知的源系统数据集，在不使用目标系统日志标签的前提下保障检测效果，降低标签标记成本。基于预训练模型的无监督日志异常检测方法。该方法使得能够提供一种基于预训练模型的无监督日志异常检测方法，使得该方法能够在不使用目标系统日志标签的前提下，使用已知的源系统数据集来保证检测效果，因此降低了标签标注成本。 该方法允许一个混合模型投票伪标签通过LSTM有效提取非标签目标系统对数向量序列的深度特征向量表示，从而避免了数据过少导致的模型分类效果不好的问题。该方法包括收集从不同系统产生的日志数据集。 所述日志数据集中设置有源系统日志集和目标系统日志组。 在源系统日志上提供标签。 构建预训练模型。 一个长短短期存储器(LSTM)和一个全连接层模型被称为。 标签作为LSTM和全连接层模型的输入数据。 进行模型训练。 将训练好的模型作为预训练模型。 通过LSTM有效地提取无标签目标系统logs矢量序列的深度特征矢量表示。 基于层次聚类HDBSCAN分类器构建全连接层以辅助原始预训练模型。 通过全连接层输出正常日志消息序列和异常日志消息序列，完成异常检测。  11
本说明书提供了一种数字内容的生成方法及相关设备。该方法包括：向用户输出展示与待生成的数字内容相关的多个问题，以及与所述多个问题中的各个问题对应的多个可选答案；获取所述用户从所述多个问题对应的多个可选答案中选择出的多个目标答案，并基于所述多个目标答案生成文本提示词；将生成的所述文本提示词输入基于文本提示词生成数字内容的预训练模型，以由所述预训练模型基于所述文本提示词生成对应的数字内容，并向用户输出展示所述数字内容。用于基于用户输入的提示来生成诸如物品、图像和音频的数字内容的方法。该计算机设备不依赖于用户输入提示词，而是通过交互式的提示词生成方式，使用户能够从显示的多个问题的多个可选答案中选择符合自身意图的答案，并基于用户的答案生成更加专业、丰富、准确的提示词，从而辅助普通用户获得高质量的数字内容。该方法涉及向用户输出(S301)展现出与要生成的数字内容的相关性的多个问题，以及对应于多个问题中的相应问题的多个可选择答案。 从多个问题对应的多个可选择答案中获取(S302)用户选择的多个目标答案，并基于多个目标答案生成文本提示词。 将生成的文本提示词输入(S303)用于基于文本提示词生成数字内容的预训练模型，以使预训练模型基于文本提示词生成对应的数字内容，并将数字内容输出显示给用户。独立权利要求包括以下内容：(1)用于生成数字内容的系统； (2)用于生成数字内容的设备； (3)用于生成数字内容的计算机设备； 以及(4)存储用于生成数字内容的程序的计算机可读存储介质。  11
本发明公开了一种基于深度学习方法的大学计算机基础知识图谱构建方法；采用BERT‑IDCNN‑CRF算法训练知识点实体识别模型，从大学计算机基础课本文本内容中自动抽取知识点实体；采用BERT‑BiLSTM‑CNN算法训练关系识别模型，自动抽取知识点实体之间的关系；基于word2vec生成知识点实体词向量，通过计算知识点实体之间的相似度进行实体消歧。大大减少了人工构建大学计算机基础知识图谱的工作量，省时省力。基于深度学习的大学计算机基础知识图谱构建方法。该方法减少了人工构建大学计算机基础知识图谱的工作量，节约了时间和人力成本。该方法涉及利用BERT‑IDCNN‑CRF算法训练知识点实体识别模型。 从高校计算机基础教材的一个文本内容中自动提取知识点实体。 采用BERT-BiLSTM-CNN算法建立关系识别模型。 自动提取所述知识点实体之间的关系。 基于word2vec生成知识点实体词向量。 通过计算知识点实体之间的相似度进行实体消歧处理。  12
本发明公开了一种基于多类别特征融合的食材图像分类方法，属于食材分类技术领域，具体步骤包括：步骤一：获取拍摄背景接近、彼此无重叠的食材图片；步骤二：根据食材图片获取每幅图片的LBP局部二值特征、Gabor小波特征、HSV颜色特征三个低层特征；步骤三：从两个不同的卷积神经网络预训练模型中将权重参数迁移到定义的新模型中，并提取经过训练后的两个新模型中全连接层输出的深层特征进行特征融合；步骤四：通过计算待检索图像与数据集中样本图像之间的匹配度，得出深层特征分类结果与低层特征分类结果，将结果进行决策融合，通过分配不同权重得出适用于实际使用数据集的分类模型。基于多类别特征融合的食物图像分类方法。该方法能够实现食材的智能分类，解决了目前食材分类过程中采用人工分类的问题，提高了相应的自动化过程，提高了分类的可靠性，实现了食材尤其是样品的快速投放，在多种类型的情况下，具有更好的分类效果。该方法涉及获得食物图片的拍摄背景接近和不重叠。 获取所述食物图片的局部二值特征。 将权重参数从两个不同的预卷积神经网络训练模型迁移到定义的新模型。 提取训练好的模型中全连接层输出的深层特征，进行特征融合。 计算待搜索图像与数据集中的样本图像的匹配度。 得到深度特征分类结果和下层特征分类结果。 通过分配不同的权重对数据集得到分类模型。   5
本申请提供一种基于人工智能大模型的方面级情感分析方法及相关设备。所述方法包括：获取评价数据；根据所述评价数据，得到目标分析指令；将所述评价数据和所述目标分析指令输入到预先选择的人工智能大模型中，得到对应的目标方面级情感分析结果。本申请的方案，基于所获取的评价数据而设定的目标分析指令，利用人工智能大模型对评价数据进行方面级情感分析，满足不同应用领域的情感分析需求，具备通用性，并且能够显著提高处理效率和准确率，节省成本开销。在人工智能大模型基础上分析方面级情感的方法。保证解决对情感词典中情感词对应的评分值进行统计得到分析结果后，成本较高，分析效率较低且分析结果的准确性较差的问题。该方法包括获得评估数据。 根据所述评估数据得到目标分析指令。 将所述评价数据和所述目标分析指令输入至所述预选人工智能大模型，得到对应的目标方面级别情感分析结果。 对所述评价对象信息进行分类，得到对应的类型标签。 根据类型标签对预设的第一分析指令进行更新，得到目标分析指令。独立权利要求包括：(a)具有用于获得评估数据的获得模块的方面级情感分析设备; (b)具有用于存储计算机程序的存储器的电子设备; (c)用于存储计算机程序指令的计算机程序产品;  11
本发明公开了一种基于深度学习的遮挡物体分割方法，属于人工智能领域。包括：构建自定义的遮挡推理层，对存在遮挡的物体进行深度次序排序；利用自定义的遮挡推理层，对现有的分割网络mask rcnn中的FCN分支网络进行改进，搭建了一种遮挡物体分割网络；预训练网络得到网络的初始化参数；利用预训练好的权值，初始化遮挡物体网络，利用反向传播算法不断更新网络的参数。利用训练完成的模型即可得到遮挡物体之间的最优深度次序排序和所有物体的几何形状模板。本发明提出的遮挡物体分割网络显式地考虑了反馈及推理过程，从而无须提供各个角度遮挡的样本，与现有的深度学习分割方法相比，所需要的样本更少。基于深度学习的遮挡物体分割方法。不需要来自各个角度的遮挡样本。 利用遮挡后的数据训练改进分割网络和原始分割网络。该方法涉及构建自定义遮挡推断层以按深度顺序对对象进行排序。 自定义遮挡推理层用于改进现有分割网络基于掩模区域的卷积神经网络(RCNN)中的全卷积网络(FCN)分支网络。 为遮挡对象构建分割网络。 对网络进行预训练，得到网络的初始化参数。 训练好的权值用于初始化遮挡对象网络。 利用反向传播不断更新网络的参数，得到网络最终的卷积和反卷积权值以及物体的几何形状模板。 利用训练好的网络对图像进行分割。   4
本公开提供一种基于大语言模型的交易对象推荐方法、装置、设备和介质，包括：响应于数据库中第一数据交易方发起的交易对象推荐请求，获取第一数据交易方的交易需求信息以及数据库中剩余的多个第二数据交易方的数据资源信息；基于第一大语言模型对第一数据交易方的交易需求信息进行语义特征提取，得到第一数据交易方对应的用户需求特征；基于第二大语言模型对每个第二数据交易方的数据资源信息进行语义特征提取，得到每个第二数据交易方对应的数据资源特征；匹配第一数据交易方对应的用户需求特征与每个第二数据交易方对应的数据资源特征，得到交易对象推荐列表；向第一数据交易方发送交易对象推荐列表。从而，有效提升交易对象推荐效率。所述方法和设备可用于基于计算机设备(权利要求书)中的大型语言模型来推荐交易对象。可以有效提高交易对象的推荐效率。 交易对象推荐列表可以有效地发送给数据交易方。该方法涉及响应于第一数据转移方在数据库中发起的交易对象推荐请求，获取(S110)第一数据交易方的交易需求信息和数据库中剩余的多个第二数据交易方的数据资源信息。 所述交易需求信息用于描述所述第一交易方进行数据交易时进行数据交易所需的数据(S120)。 将用户需求特征与每隔第二次转账业务对应的用户资源特征进行匹配(S130)，得到交易对象提议列表。 将所述第二数据交易方基于所述匹配度的顺序从高到低排列(S140)在所述交易对象推荐列表中。 向第一数据交易方发送交易对象推荐列表(S150)。独立权利要求还包括用于：基于大语言模型的交易对象推荐装置； 以及计算机可读存储介质，其包括用于基于大型语言模型推荐交易对象的指令集。  11
本申请公开一种基于MCAL的内存访问方法、装置及多核芯片，其中，所述内存访问方法，以MCAL中通用定时器GPT(General Purpose Timer)为例子说明，包括：为i+1个核心分别设置编号为0至i的i+1个通用定时器变量；将分配至第i个通用定时器变量的第i个核心的核内部内存的内存首地址，设置为通过外部总线访问的实际物理地址；对第i个通用定时器变量所映射的第i个核心的核内部内存的内存首地址进行偏移，以使第i个通用定时器变量重新映射至通过内部总线访问的内部总线地址；根据i+1个通用定时器变量构造结构体变量指针数组；通过第i个通用定时器变量经由内部总线访问第i个核心的核内部内存。用于多核芯片的基于微控制器抽象层的存储器存取方法。该方法能够基于微控制器抽象层MCAL规范的汽车开放系统架构autoSAR通过特定的访问方式，实现不同核通过不支持硬件重映射的多核芯片对应的内部总线访问各自的核内存储器。该方法涉及将分配给第0通用定时器变量的第0核心的核心内部存储器的存储器第一地址设置(102)为通过内部总线访问的内部总线地址。 将第i个核的核内存储器分配给第i个通用定时器变量的第一存储器地址设置(103)为通过外部总线访问的实际物理地址。 偏移第i个通用定时器变量映射的第i个核心的核心内存储器的第一存储器地址(104)，以使第i个通用定时器变量重新映射为通过内部总线访问的内部总线地址。 构造结构可变指针阵列(105)。 在第i个核心调用结构变量指针数组访问第i个核心的核心内部存储器的情况下，第i个通用定时器变量被用于(106)通过内部总线访问第i个核心的核心内部存储器。独立权利要求包括：(1)一种基于MCAL的存储器存取设备； 以及(2)存储用于存储器访问的程序的存储介质。  11
本发明提供一种基于拓扑结构约束的半监督医学影像标志点定位方法，其特征在于，包括：步骤S1，对图像进行预处理，得到初始训练集。步骤S2，将初始训练集输入到深度神经网络进行训练，根据有无标注信息，对样本分开进行监督训练和自监督训练。步骤S3，将待测图像输入到训练完成的深度神经网络，预测坐标偏移图和预测热点图。步骤S4，利用投票法对预测热点图所表示标志点在图中出现的概率，对高于设定阈值的像素点进行投票，并根据投票结果标出待测图像上的最终标志点坐标。其中，深度神经网络包括多任务U‑Net网络、多分辨率注意力模块以及多分支空洞卷积模块。基于拓扑结构约束的半监督医学图像标记点定位方法。所述半监督医学图像标记点定位方法通过对图像进行预处理以获得初始训练集，从而能够利用非标记数据提高神经网络定位标记点的准确性。半监督医学图像标记点定位方法包括采集图像和预处理以获得初始训练集。 所述初步训练集包括包含标记点坐标的标记信息的样本图像和不包含所述标记信息的样本图像。 将所述初始训练集输入深度神经网络进行训练。 将样本图像输入深度神经网络，完成训练。 得到所述待测图像对应的预测坐标偏移图和预测热点图。 所述预测热点图用于指示图中每个像素位置出现标记点的概率。 根据所述预测坐标图确定所述预测标记点与所述真实标记点之间的坐标偏移量。   4
本申请公开了一种知识库管理方法、系统、设备及介质，方法包括：确定知识信息，并确定知识信息的录入方式和存储方式；根据录入方式将知识信息录入至数据库，并根据存储方式对知识信息进行识别和存储；确定预先设置的定时任务，根据定时任务对数据库的知识信息进行读取。本申请通过对知识库中的知识信息进行学习、整理、整合，从而将知识库松散的知识信息组合连接起来。并利用知识提取、分析能力，对系统中存在的知识进行更好的分类，相比较传统人为分类，可以更灵活，更精准。利用大语言模型的自然语言处理技术、自然语言生成技术、自然语言理解和推理技术，对知识进行抽取、表示、整合、共享。用于管理部门、单位和公司的知识库的方法。利用知识抽取和分析能力更好地对系统中的知识进行分类。 方法更加灵活、精确。 该方法利用大型语言模型的自然语言处理技术、自然语言生成技术、自然语言理解推理技术进行知识的抽取、表达、整合和共享。所述方法包括确定(S101)知识信息。 确定所述知识信息的录制方式和存储方式。 根据所述记录模式将所述知识信息记录(S102)到数据库。 根据所述存储方式识别并存储所述知识信息。 确定所述预设定时任务(S103)。 根据所述定时任务读取所述数据库的知识信息。独立权利要求包括以下内容：知识库管理系统； 知识库管理装置； 以及非易失性计算机存储介质，其存储用于管理知识库的程序。  11
一种基于多角度U‑Net的医学图像分割方法，包括以下步骤：步骤1、获取对应分割图像的数据集，进行预处理；步骤2、生成待训练样本；步骤3、搭建多角度U‑Net网络模型，使用步骤2中生成的训练样本训练该网络模型；然后将待分割医学图像输入到构建好的网络模型，从而生成对应模态的目标三维图像。本发明的多角度卷积模块融合多角度2D可分离卷积与深度可分离卷积的优点，将空间和通道信息分开映射，实现了空间与通道的分离，同时加入残差结构，解决了梯度消失和梯度爆炸的问题，在训练更深网络的同时，又能保证良好的性能。本发明实现对医学图像的自动、准确描述。基于多角度U-Net的医学图像分割方法。该方法集成了多角度二维可分离卷积和深度可分离卷积，将空间和通道信息分别映射，实现了空间和通道的分离，同时加入残差结构，解决了梯度消失和梯度爆炸的问题，在训练更深的网络的同时保证了更好的性能。 该方法能够实现对医学图像的自动且准确的描述。该方法包括进行图像预处理，训练集中的原始图像经过空间重采样、灰度值归一化等处理，生成相应的身体组织和背景图像。 通过裁剪生成的图像和图像对应的标签得到包含目标组织的最小非零区域。 生成训练样本。 给定的面片尺寸用于将最小的非零区域裁剪成固定尺寸的面片。 提取具有不同概率的斑块作为训练样本。 训练网络模型。 构建多角度U-Net网络模型。 所述训练样本用于训练所述网络模型。 生成所述模型对应的目标三维图像。   6
本发明涉及人工智能软件技术领域，尤其涉及一种基于大型语言模型的办公自动化问答方法及其系统，通过将大型语言模型，关键词抽取模型和办公系统结合，可以体现如何将语言模型应用到工作生产环境中解决上述问题；能够根据用户提出的问题进行对应的回答，根据用户的需求去系统中获取对应的数据，然后组织语言进行回答，并且可以根据用户的需求，更新系统数据。基于大型语言模型执行问答办公自动化的方法，用于实时翻译和人机问答。通过将大型语言模型、关键词提取模型和办公系统相结合，可以展示如何将语言模型应用到工作生产环境中来解决问题。该方法涉及构建用户回答语料训练集和训练(S1)大型语言模型。 构建将答案语句与答案关键词相关联的训练集，训练关键词提取模型(S2)。 允许用户(S3)基于训练好的大规模语言模型进行提问并得到答案。 基于关键词提取算法从所述问题的答案中提取(S4)关键词，以获得与所述特定业务需求相关的关键词信息。 利用业务映射算法解析所提供的关键词组合，并基于所获得的关键词调用相应的后端服务(S5)以获得A数据。 所述后端服务返回的结果与所述大型语言模型返回的原始答案相结合，并将所述答案返回(S6)给所述客户端。独立权利要求包括用于：(1)基于大型语言模型执行提问和回答办公自动化的系统； 以及(2)计算机设备。  11
本发明公开一种应用程序GUI测试方法、系统、电子设备及存储介质，涉及移动应用测试技术领域，该方法包括：判断当前GUI图像是否存在缺陷；存在则将缺陷种类存入当前轨迹记忆中开启下一轨迹记忆，判断是否达到测试停止条件；不存在则判断当前轨迹记忆是否截止；截止则开启下一轨迹记忆，判断是否达到测试停止条件；若不截止或未达到测试停止条件，则从记忆仓库中搜索重要记忆；将重要记忆、图像信息记忆、目标设定和探索倾向输入多模态大模型得到当前探索倾向和当前操作，并分别添加到记忆仓库和当前轨迹记忆中，将当前操作施加到当前GUI上；更新当前GUI图像为下一GUI图像并进行测试。本发明提高了应用程序GUI测试的效率。一种测试应用程序图形用户界面(GUI)的方法。由于该方法将当前GUI图片更新为下一个GUI图片并进行测试，因此提高了应用程序GUI测试的自动化水平和效率。该方法涉及使用(1)具有缺陷和相应缺陷类型的多个GUI图像作为即时微调多模式大模型。 获取当前GUI图像和对应的当前图像信息(2)。 在当前GUI图像上标记(3)当前数字。 进行判断(4)，检查当前GUI图像是否存在缺陷，得到第一判断结果。 如果所述第一判断结果为是，则将对应的缺陷类型存储(5)到当前轨迹存储器中。 如果第二判断结果为是，则停止当前轨迹记忆(6)，并启动下一轨迹记忆。 从内存仓库中搜索(7)图像当前GUI的重要内存。 将当前操作存储到当前轨迹存储器中。 将所述当前操作应用于所述当前GUI。 将当前GUI图像更新为下一个GUI图像，并返回，得到当前GUI图像和对应的当前图像信息。独立权利要求包括以下内容：一种应用程序GUI测试系统； 电子装置； 以及存储有用于测试应用程序GUI的程序的存储介质。   6
本申请涉及一种多尺度特征融合遥感影像分割方法、装置、设备和存储器。所述方法包括：获取遥感影像，并进行标注，得到训练样本；构建多尺度特征融合遥感影像分割网络，该网络包括：用于将训练样本分割成固定大小的小块，将其展开成一维向量并嵌入位置编码得到输入序列的输入网络；用于利用多层Transformer模块提取输入序列不同层次的编码器；用于通过融合多尺度特征图得到样本预测结果的解码器；利用训练样本对该网络进行训练，得到训练好的多尺度特征融合遥感影像分割模型，并利用该模型得到待测遥感影像的预测结果。该方法充分利用编码器提取的多尺度特征图，将局部分类与层次分割相结合，能够适应遥感影像中目标复杂多变的特点。多尺度特征融合遥感影像分割方法在多尺度特征融合遥感影像分割装置(均要求保护)中使用。该方法充分利用编码器提取的多尺度特征图，结合局部分类和层次分割，适应遥感影像中目标复杂多变的特点。该方法包括获得(100)被标记以获得训练样本的高分辨率遥感图像。 构建多尺度特征融合遥感影像分割网络(102)。 解码器通过多次卷积和上采样最终得到样本预测结果。 根据训练样本的标注和将训练样本输入多尺度特征融合遥感图像分割网络得到的样本预测结果，对多尺度特征融合遥感图像分割网络进行训练(104)，得到训练好的多尺度特征融合遥感图像分割模型。 得到待测遥感影像(106)，将所述待测遥感影像输入训练好的多尺度特征融合遥感影像分割模型，得到所述待测遥感影像的预测结果。独立权利要求包括如下：所述多尺度特征融合遥感影像分割装置； 以及存储有用于所述多尺度特征融合遥感影像分割方法的程序的计算机可读存储介质。   6
本申请涉及一种基于bert的政府公共数据智能入库方法及系统，其方法包括：基于爬虫获取政府公共数据的文章标题；基于预设的一类规则表组对所述文章标题进行初步分类，获取第一已分类标题和未分类标题；基于预设的bert预训练模型和所述第一已分类标题获取分类模型，基于所述分类模型对所述未分类标题进行二次分类，得到第二已分类标题；基于所述第一已分类标题和所述第二已分类标题确定已分类公共数据；基于预设的二类规则表组对所述已分类公共数据进行信息标准化处理，存储进数据库。本申请具有便于对政府公共数据进行智能入库，提高数据分类的效率和准确性的效果。基于Bert的政府公共数据智能存储方法该方法便于对政府公共数据进行智能存储，提高了数据分类的效率和准确性。 政府公开数据以简单汇总的方式展示，方便查看和查询。该方法包括基于爬虫获得(S101)政府公共数据的文章的标题。 基于预设规则表组对文章的标题进行初步分类(S102)。 获取第一分类标题和未分类标题。 基于所述预设的Bert预训练模型和所述第一分类标题得到分类模型(S103)。 基于所述分类模型对所述未分类标题进行二次分类，得到第二分类标题。 基于所述第一分类标题和所述第二分类标题确定(S104)所述分类公开数据。 基于预设的第二类规则表组对分类后的公共数据进行信息标准化处理(S105)。 所述公共数据存储在所述数据库中。包括以下独立权利要求：一种基于Bert的政府公共数据智能存储系统； 基于Bert智能存储政府公共数据的终端设备； 以及存储用于基于Bert智能存储政府公共数据的程序的计算机可读存储介质。  11
本发明涉及前端技术领域，揭露了一种网页内容提取方法、装置、电子设备，包括：根据搜索网页集内所包括的访问链接构建得到Web图，根据所述Web图从所述搜索网页集中提取得到预设数量的搜索网页，得到内容待提取网页集，对所述内容待提取网页集内每个内容待提取网页执行OCR识别，得到第一待校正文本集，利用预训练完成的文本识别模型，识别所述内容待提取网页集的文本，得到第二待校正文本集，对所述第一待校正文本集与所述第二待校正文本集执行校正，得到网页内容。本发明可解决当网页内容过多导致识别网页内容效率较低及OCR识别技术识别准确率有待进一步提高的问题。所述方法对于通过使用电子设备(要求保护)基于页面权重提取网页内容是有用的。该方法：解决了网页内容过多导致识别网页内容的效率较低的问题； 提高了光学字符识别(OCR)技术的识别准确率; 并且大大减少了网页数量。所述方法包括：启动搜索引擎并接收关键词，在所述搜索引擎中搜索与所述关键词相关的搜索网页集合，为所述搜索网页集合中的每个搜索网页设置相同的初始权重，并根据所述搜索网页集合中的每个搜索网页包括的访问链接构建网页图，依次计算所述每个搜索网页的更新权重，并根据所述更新权重更新所述初始权重，得到每个搜索网页对应的历史权重； 根据所述排序对搜索到的预设数量的网页进行提取，得到待提取内容的网页集合，利用预先训练的文本识别模型对待提取内容的网页集合的文本进行识别，得到第二待修正文本集合，并对第一待修正文本集合和第二待修正文本集合进行修正，得到网页内容。独立权利要求还包括：一种基于页面权重的网页内容抽取装置； 以及计算机可读存储介质，包括用于基于页面权重提取网页内容的指令集。  11
本发明公开一种基于多模态交通大模型的交通态势感知预测方法以及系统，涉及人工智能技术领域。方法包括：获取多模态融合数据；根据多模态融合数据对交通大模型进行模型训练优化，获得训练完成的交通大模型；根据训练完成的交通大模型对不同交通环境下的车辆信息进行交通态势感知，获得交通态势感知信息；根据交通态势感知信息对交通态势进行预测，获得交通预测信息；根据交通预测信息对城市交通进行管理。本方法，融合了多种不同模态下的交通数据，并对应形成交通大模型，进行交通态势感知信息的获取，从多个不同维度对交通场景进行了特征描述，避免了传统方法中采用单一数据导致的无法实现复杂交通场景分析的问题。人工智能领域的基于多模态交通大模型的交通态势感知预测方法。该方法使得能够将多种不同模式的交通数据进行组合，并对应形成交通大模型，进行交通态势感知信息的获取，从多个不同维度对交通场景进行特征描述，避免了传统方法无法实现使用单一数据带来的复杂的交通场景分析的问题。该方法涉及获得多模态融合数据。 根据所述多模态融合数据对交通大模型进行模型训练优化。 得到训练后的交通大模型。 根据训练好的交通大模型对车辆信息在不同交通环境下的交通态势进行感知，得到所述交通态势感知信息。 根据所述交通状况感知信息对交通状况进行预测，得到所述交通预测信息。 根据所述交通预测信息对城市交通进行管理。包括独立权利要求人工智能领域的一种基于多模态交通大模型的交通态势感知预测系统。 13
本发明公开了一种基于语义表征的无监督域适应图像分类方法，包括：步骤1)预训练和自训练：使用源域预训练模型，并结合自训练学习初步获取目标域的伪标签；步骤2)提取类别语义表征：通过改变语义向量方向，决策类别的有效语义表征，提取到有效类别语义表征；步骤3)模糊跨域语义表征：以图像域标签为指导，改变跨域样本的语义向量方向，获得跨域语义表征，进一步模糊这些跨域语义表征；步骤4)重构分析：对有效类别语义表征和模糊后的跨域语义表征分别生成新的样本表征，并进行重构分析；步骤5)训练分类器和域判别器：使用新样本表征训练分类器和域判别器，计算分类损失和对抗损失；步骤6)模型优化：梯度计算，优化更新模型参数。用于执行基于语义表示的无监督域自适应图像分类过程的方法。该方法包括在卷积神经网络上对源域图像样本进行预训练，得到基于源域图像样本表示的主干网络。 提取每个类的有效类型语义表示。 进行模糊跨域语义表征处理。 通过使用生成器生成用于有效类型语义表示和模糊跨域语义表示的样本表示。 结合编码器来计算重构损失。 基于样本表征训练分类器和域判别器，以计算分类损失和对策损失。 利用最终模型进行梯度计算、优化和模型参数更新过程，得到图像分类结果。 14
本发明公开了一种文本匹配和检索方法，包括以下步骤：S1、通过训练集语料库进行孪生神经网络训练，获得网络权重；S2、将文本和语料库输入到具有网络权重的孪生神经网络中，得到文本句向量和离线语料库句向量；S3、根据文本句向量和离线语料库句向量，通过Annoy检索算法输出相似文档。本发明针对文本的词嵌入进行了优化，ALBERT的预训练模型有更好的词嵌入效果，同时使用平均池化操作可以有效获得句子全局特征，孪生神经网络的使用可以更好的评估文本转向量的效果，进而进行下游任务的微调。同时在文本检索上，annoy算法的使用使得检索时间复杂度降低，有效降低检索时间。用于执行文本匹配和检索的方法。 可用于自然语言处理领域。 也可以用于计算文章之间的相似度。该方法能够优化文本的嵌词，使得ALBERT的预训练模型具有更好的嵌词效果，从而有效地利用平均池运算得到句子全局特征，并评估文本翻转量的效果，以进行下游任务的精细调整，从而利用annoy算法对文本进行搜索，以降低搜索时间复杂度，有效地减少搜索时间。该方法通过训练集语料进行双胞胎神经网络训练，得到网络权值。 将文本和语料输入具有网络权值的连体神经网络，得到文本句向量和离线语料句向量。 根据所述文本句向量和所述离线语料句向量通过烦检索算法输出相似文档。 对所述训练集语料中的第一文本和第二文本进行文本预处理。 通过ALBERT预训练模型嵌入预处理后的第一文本和第二文本。  12
本发明提出一种基于文档关系抽取的知识图谱构建方法和装置，属于知识图谱构建技术领域，解决了目前文档级别关系抽取方法在构建文档图时需要依赖依存句法分析树，导致自然语言处理工具产生的误差会向后传播的问题。该技术能够从文档段落中抽取知识三元组，将非结构化的数据转化为便于存储和理解的结构化数据，为知识图谱的构建提供技术支持。该模型直接构建实体文档图并使用实体间自注意力矩阵作为文档图的邻接矩阵，降低了自然语言处理工具的影响。并且由于实体自注意力矩阵来自Bert，无需复杂计算，大大降低了模型参数以及模型训练时间，然后在此技术基础上构建一个高质量且知识面广的医疗知识图谱。知识图关系提取构建方法，用于电子商务领域，金融领域，医疗领域中提取关于实体自关注文档关系提取的知识图。本发明直接构造实体文档图，并将实体间的自关注矩阵作为文档图的邻接矩阵，减少了自然语言处理工具的影响。 由于实体自注意矩阵来自BERT，不需要复杂的计算，大大减少了模型参数和模型训练时间，进而建立了高质量，大范围的医学知识地图。本发明公开了一种基于实体自关注的文档级关系提取模型，包括编码模块，实体推理模块，自适应阈值模块和分类模块。 编码模块使用BERT将文本数据编码为向量，并提取实体向量。 实体推理模块实现了实体之间的信息传播。 自适应阈值模块用于学习每个类别的分类阈值。 分类模块利用自适应阈值模块输出两个实体之间的语义关系。 从测试集中选择文档。 从文档中提取要预测的实体对。 通过训练好的模型预测实体对之间的关系，得到实体-关系三元组。本发明还涉及一种基于文档关系提取的知识图构造装置。  11
一种基于残差网络和U‑Net分割网络的卫星图像分割方法，其步骤为：构建残差网络ResNet34；构建U‑Net分割网络；构建训练样本集；训练残差网络ResNet34；训练U‑Net分割网络；将待分割的卫星图像输入到残差网络ResNet34进行二分类，判断包含船只目标；使用U‑Net分割网络对分类结果中的正样本进行二值分割；对于分类结果中的负样本，直接输出单值掩码图；本发明利用残差网络ResNet34对卫星图像进行二分类，使用U‑Net分割网络仅对分类结果中的正样本进行分割，并在U‑Net分割中嵌入SE‑ResNet模块，提取更加精细的分割掩码，实时性高，分割精度高。基于残差网络和U网分割网络的卫星图像分割方法。该方法能够提取精细分割掩模，确保高实时性，增加图像分割精度。该方法包括构建剩余网络ResNet34。 构建U网分割网络。 训练样本集构建。 构建训练残差网络ResNet34。 对所述U-Net分割网络进行训练。 将一张待分割卫星图像输入残差网络ResNet34进行分类操作。 判断所述待分割卫星图像是否包含船舶目标。 若所述待分割卫星图像中包含所述船舶目标，则利用所述U-Net分割网络对包含船舶目标的正样本进行二值分割操作。 直接输出针对所述待分割卫星图像的单值掩码。   6
本申请涉及计算机技术领域，提供了一种联邦学习方法、系统、设备及介质，方法包括：通过多个第一客户端分别基于无标注训练样本对第一本地模型进行训练，将训练后的第一本地模型发送至服务器，服务器对第一本地模型进行整合处理，得到预训练模型，多个第二客户端分别从服务器下载预训练模型，将预训练模型作为第二本地模型，基于有标注观测样本对第二本地模型进行微调，将微调后的第二本地模型发送至服务器，服务器对预训练模型和第二本地模型进行整合处理，得到目标模型。本申请实施例在联邦学习中加入使用无标注样本训练的客户端，结合预训练微调的联合训练方式，既能提高目标模型的泛化性，又能高效利用无标注数据，节省标注成本。一种基于计算机领域的联邦学习方法。本发明提高了目标模型的通用性，有效利用了无标签数据，节约了标注成本。该方法包括通过第一客户端基于未标记的训练样本训练第一本地模型。 训练的第一本地模型被发送到服务器。 通过服务器接收第一客户端发送的第一本地模型。 整合第一局部模型以获得预训练模型。 预训练模型通过第二客户端从服务器下载。 基于标记的观测样本，通过使用预训练模型作为第二局部模型来执行对第二局部模型的微调过程。 集成预训练模型和第二局部模型以获得目标模型。独立的权利要求书包括： (1)基于计算机领域的联邦学习系统； (2)包括处理器和存储器的电子设备，用于执行基于计算机字段的联邦学习方法； 以及 (3)计算机可读存储介质，用于存储执行基于计算机字段的联邦学习方法的计算机程序。  11
本发明涉及一种跨平台恶意代码检测方法及系统，包括：(1)使用多个平台上良性程序样本，训练一个预训练模型来捕捉程序指令上下文中的结构、语义相关性以及不同平台程序指令间的结构、语义共性；(2)在预训练模型之上，使用多个平台有限规模的良性程序样本和恶意程序样本构建跨平台恶意代码检测模型，对跨平台恶意代码检测模型进行参数微调，将预训练模型中的知识迁移到跨平台恶意代码检测模型中；(3)使用构建的跨平台恶意代码检测模型，对不同平台上的未知程序样本进行检测，判断其为恶意或良性。本发明使用多个平台的程序样本进行模型训练，充分利用不同平台程序在结构、语义上下文上的共性，缓解了单一平台恶意代码训练样本不足的问题。跨平台恶意代码检测方法。该方法利用多个平台的程序样本进行模型训练，充分利用不同平台程序在结构和语义上下文方面的共性。 该方法缓解了单一平台恶意代码训练样本不足的问题。该方法涉及使用多个平台上的良性程序样本来训练预训练模型，以捕获程序指令的上下文中的结构和语义依赖性，以及不同平台上的程序指令之间的结构和语义共性。 在预训练模型之上利用有限规模的良性程序样本和多个平台的恶意程序样本构建跨平台恶意代码检测模型。 对所述跨平台恶意代码检测模型的参数进行微调，将所述知识从所述预训练模型转移到所述跨平台恶意代码检测模型中。 利用构建的跨平台恶意代码检测模型对不同平台的未知程序样本进行检测，判断其是恶意还是良性。以下包括独立权利要求：1。 计算机设备； 2. 存储有用于跨平台恶意代码检测的程序的计算机可读存储介质； 3. 一种跨平台恶意代码检测系统。  11
一种刀具寿命预测方法，包括：采集刀具质量数据和机加工数据，并对采集的多源数据进行数据预处理；构建刀具领域知识图谱本体模型，对多源数据进行整理得到本体模型；构建刀具领域知识图谱，在本体模型的基础上，以预处理后的多源数据为图谱数据，构建以集中的刀具、工件、材料名称及加工工艺中工序和加工特征为节点，以刀具、工件、材料固有的特征属性为节点属性的知识图谱；构建因果关系增强知识图谱，对多源数据通过基于因果科学论的后门调整策略，建立质量知识结构因果图模型，并采用干预式和积网络的质量知识因果关系增强学习模型，获得因果关系增强知识图谱；构建预训练大模型；利用预训练大模型进行刀具磨损退化趋势及寿命预测。刀具寿命预测方法。该方法提高了因果知识间关联效应的鲁棒性，为质量问题分析提供更可靠的因果知识支持。该方法包括构建(S400)因果关系增强知识图。 通过基于因果科学的后门调整策略对所述多源数据建立质量知识结构因果图模型。 采用干预型和产品网络质量知识因果关系增强学习模型获取用于支持刀具磨损退化溯源分析的因果关系增强知识图谱。 构建预训练大模型(S500)，为预测分析提供支持。 预测刀具的使用寿命(S600)，利用预训练大模型记录待检测刀具和对应的加工数据，快速获取待检测刀具的磨损退化趋势和使用寿命预测结果。  11
本发明涉及医疗图像处理技术领域，具体地说是一种基于U‑Net的残差双卷积与混合卷积的肠息肉分割网络方法，包括对图片进行数据增强，对残差双卷积模块进行搭建，对混合卷积模块进行搭建，对整体结构进行搭建以及对整体模型进行训练并评估模型，本发明将U‑Net编码部分中用于特征提取的卷积层与残差网络中的残差部分相结合，在原卷积的基础上将空洞卷积与点卷积融合为混合卷积，考虑到混合卷积中的空洞卷积与点卷积分别具有空间位置提取能力与特征强化能力，将混合卷积放置在U‑Net下采样与上采样层间，用于传递并强化空间位置信息，形成了混合卷积模块MixConv，在肠息肉语义分割上具有优越性能。基于U-Net的残差对偶卷积和混合卷积肠息肉分割网络实现方法。该方法能够提高肠息肉语义划分性能，实现U‑Net下采样和上采样层之间的混合卷积，用于传递和增强空间位置信息。该方法包括对图像进行数据增强操作，以解决CVC-Cl inicDB数据集规模小的问题。 建立残差对偶卷积模块，用于处理语义分割模型训练过程中的退化问题。 建立混合卷积模块，并与空心卷积相结合，在原始卷积的基础上提取空间信息。 基于U-Net形成整个结构。 训练整个模型以评估整个模型。 通过python中的Wandb包对接Wandb网站。 通过利用数据增强之后的CVC-Cl inicDB数据集，对于U-Net和U-Net+MixConv，通过管芯和F1值的图显示来执行管芯和F1值的图分析操作。   6
本申请提出一种防止学者论文库过拆分的历史错误纠正方法与系统，该方法包括 : 对学者名称进行重新构建；根据能够唯一确定作者的信息对目标学者论文库和待分配的论文簇进行直接匹配；对于匹配未成功的论文簇，通过BERT‑Bi‑LSTM‑CRF模型识别论文的作者相关信息和摘要中的实体信息；分别计算待匹配的论文包括的作者所属机构信息和期刊信息的匹配度；分别计算每个候选对齐论文簇与目标学者论文库的相似性特征，判断每个候选对齐论文簇与目标学者论文库是否对齐；将集成学习模型判定为对齐的候选对齐论文簇进行合并，并对未对齐的论文簇进行人工标注。该方法可解决消歧过程产生的过拆分错误，提高了过拆分错误纠正的速度、精确度和召回率。一种防止学生超车的历史纠错方法。本发明解决了消歧过程中产生的过拆分错误，提高了过拆分纠错的速度，精度和查全率，适用于不同类型的科技大数据系统平台，通用性强。 该历史纠错系统避免了专家讨论库的拆分。所述历史纠错方法包括重构学习者姓名。 本发明快速获取目标学者讨论库和对应的多个待分发文章簇。 计算每个候选对齐文章簇与目标学者讨论库的相似度特征。 基于对应于每个候选对齐文章簇的相似性特征来构造对应的相似性向量。 根据相似向量训练集成学习模型。 判断该训练的综合训练模型是否与候选对齐文章簇和目标学生讨论库对齐。 根据评分结果对进入训练集中的文章簇的人工评分结果进行人工评分。 模型精度更新。独立的权利要求书包括： (a)一个历史纠错系统，用于防止学生文化评论分裂； (b)非瞬时计算机可读存储介质；  12
本发明公开了一种基于深度学习的黑色素瘤图像分割方法，采用优化后的U‑Net分割网络与Diffusion概率扩散网络相结合，实现了对黑色素瘤图像的高效分割。本发明结合了深度学习和传统图像处理技术，显著提高了分割精度和速度，其准确率高于目前主流分割方法。为方便医生和患者查看分割结果与原始图像，本发明还采用可视化界面，便于分析和判断；界面支持数据导出，有利于后续研究与处理。通过提供API接口，本发明可以方便地集成到现有医疗系统和移动应用中，为临床医生提供实时、准确的辅助诊断工具，有助于提高诊断效率和降低误诊率。除了黑色素瘤病灶区域的图像分割，本发明还可推广至其他皮肤病病灶的检测与分析，具有广泛的应用前景。黑色素瘤图像分割方法，用于检测和分析皮肤病病灶如含有色素的黑色素细胞的黑色素病灶区域。提高了分割精度和速度，准确度高于目前主流的分割方法。 该方法方便地集成到现有的医疗系统和移动应用中，为临床医生提供了一个实时、准确的辅助诊断工具，通过提供API接口，有利于提高诊断效率，降低误诊断率。该方法涉及对原始黑色素瘤图像的像素值进行标准化处理，调整图像尺寸以适应网络输入需求，并对调整后图像的像素值进行归一化处理。 对图像进行数据增强处理，提高模型泛化能力和训练效果。 扩散生成模型与U-Net相结合。 将结果返回到前端，并且显示分割图像，使得用户在处理图像之后了解黑素瘤的位置和程度。 将黑色素瘤图像分割算法投入到实际医疗应用中，通过与医生和患者的持续交互，评估模型的分割性能，调整模型结构，使临床医疗图像在实际中有针对性的优化，提高黑色素瘤辅助诊断的准确性和效率。  7
本申请公开的属于人工智能技术领域，具体为一种基于大规模语言模型的多模型协作方法，包括模型准备、任务理解和拆解、模型匹配、子任务执行、任务反馈迭代执行等多个步骤，本申请不仅仅能够调用其他的语言模型对文本数据做映射处理，还可以自动根据任务调用其它非语言模型，不仅仅能处理文本数据和任务，还可以处理图像和语音的数据和任务，可以让大语言模型和其他模型一起协作，去自动完成特定的复杂任务，解决当前大语言模型不能解决的问题，提高解决任务的效率。基于大规模语言模型的多模型协作方法。该方法能够使大型语言模型配合其他模型自动完成特殊的复杂任务，从而解决了大型语言模型无法解决的问题，提高了解决任务的效率。 该方法允许应用程序调用其他语言模型来映射文本数据，并根据任务自动调用其他非语言模型，以高效的方式处理文本数据和任务以及图像和语音数据和任务。该方法涉及在异构推理终端上执行小模型的推理计算，以便计算稳定性。 小模型在推理终端上快速计算并通过适配不同框架的设备返回相应子任务的结果。 通过子任务返回的结果进行任务反馈迭代执行过程。 LLM确定子任务是否完成。 当LLM判断总的问题被解决时，总的任务的问题仍然没有被解决。 返回中间过程的一部分和最终结果。  11
本发明提供基于深度混合模型迁移学习的评论情感分类方法及系统，所述评论情感分类方法包括以下步骤：步骤S1，采集商品评论，并对商品评论的源领域数据样本集进行预处理；步骤S2，将预处理后的数据映射为词向量；步骤S3，对商品评论的源领域数据样本集进行深度混合模型预训练；步骤S4，对商品评论的目标领域数据样本集进行深度混合模型的微调；步骤S5，对目标领域的商品评论进行情感分类。本发明训练速度快且训练难度低，只需要几轮训练便可以得到较高分类精度，并且在噪音较多或者数量较少的数据集训练时也能得到较好的分类效果，对数据集依赖性小，鲁棒性良好；本发明还有效提高了可迁移能力，达到了提高迁移学习后的分类精度等目的。基于混合模型迁移学习的情感分类评价方法。该方法训练速度快，训练难度低，只需要几轮训练即可获得较高的分类准确率，在噪声较多或量较少的数据集中训练时也能获得较好的分类效果。 提高了移动能力，经过迀移学习，提高了分类精度。该方法涉及收集(S1)商品评论，并对商品评论的源领域数据样本集进行预处理。 预处理的数据被映射(S2)成词向量。 对商品评论的源域数据样本集进行深度混合模型预训练(S3)。 对源域处理后的词向量数据进行卷积运算。 节点输出经卷积运算后输入到门环单元网络。 将所述门环单元网络的节点输出输入所述注意力机制的加权变换矩阵，得到预设维度向量并变换为二维向量。 对商品评论的目标领域数据样本集进行深度混合模型的精调整(S4)。 对所述目标领域的商品评论进行所述情感分类(S5)。还包括一种基于混合模型迁移学习的情绪分类评估系统。  12
本发明公开了一种基于知识增强的深度对话语义角色标注方法及系统，该方法包括：获取数据集并对数据集进行预处理，得到预处理后的文本；获取三元组并对三元组进行筛选，得到过滤后的三元组；将过滤后的三元组与预处理后的文本结合，得到句子树结构；将句子树结构转换为序列并输入到BERT编码器，输出词向量；对预处理文本进行处理，得到索引向量；将词向量和索引向量输入到预构建的语义角色标注模型，输出预测标注结果。该系统包括：预处理模块、三元组模块、树结构模块、词向量模块、索引向量模块和结果模块。通过使用本发明，提升标注的准确度。本发明作为一种基于知识增强的深度对话语义角色标注方法及系统，可广泛应用于自然语言处理技术领域。一种基于知识增强的自然语言处理领域的语音深度语义角色标注方法。本发明提高了标注的准确性，可广泛应用于自然语言处理技术领域。方法包括获得数据集和预处理数据集以获得预处理文本。 根据预处理后的文本获得三元组。 根据预设规则对三元组进行筛选，得到过滤后的三元组。 将过滤后的三元组与预处理后的文本合并，得到句子树结构。 将句子树结构转换为序列。 输出字向量。 基于索引编码器处理预处理文本以获得索引向量。 词向量和索引向量被输入到预先构建的语义角色标记模型中。此外，本发明还涉及一种基于知识增强的对讲深度语义角色标记系统。 8
本发明提供了一种会话文本匹配方法及装置、存储介质、设备，其中方法构建基于sentence‑Bert构架的向量编码模型，并搭建包含两个向量编码模型的siamese孪生神经网络结构的预训练模型；预训练模型用于执行文本分类任务和/或文本相似度计算任务；预先收集训练语料，利用训练语料对预训练模型进行训练，以得到微调完成的目标向量编码模型；获取待匹配目标语句，将待匹配会话文本输入目标向量编码模型，得到待匹配会话文本对应的向量编码；利用预先创建的具有索引功能的目标向量数据库对向量编码进行相似度匹配，将相似度最高的标准问文本作为待匹配会话文本的目标匹配结果。通过本发明，实现了快速增加标准问，又满足了严格区分问询意图的要求。匹配会话文本的方法。快速增加标准问题，满足严格区分查询意图的要求。 用于执行文本分类任务和文本相似度计算任务的含有两个向量编码模型的连体孪生神经网络结构的预训练模型。会话文本匹配方法涉及基于pc-Bert框架构建向量编码模型。 构建具有向量编码模型的连体孪生神经网络结构预训练模型。 所述预训练模型用于执行文本分类任务和文本相似度计算任务。 预先收集训练语料。 用于对所述预训练模型进行训练得到精调整后的目标向量编码模型的训练语料。 得到待匹配的目标语句。 将所述待匹配的会话文本输入所述目标向量编码模型。 获取所述待匹配的会话文本对应的向量编码。 利用索引函数对所述矢量码进行相似度匹配的预先建立的目标矢量数据库。 将相似度最高的标准问题文本作为待匹配的会话文本的目标匹配结果。本发明公开了一种会话文本匹配装置，包括：模型建立模块，用于建立基于空腔-伯特框架的向量编码模型; (b)计算机可读存储介质，其存储由处理器执行的计算机程序; (c)计算机设备具有存储在存储器中的计算机程序。  12
本发明提供一种基于有监督对比学习与回复生成辅助的对话情感识别方法，首先，由于构建的预训练模型CoG‑BART，采用对话级Transformer模块对待测对话进行上下文建模，从而解决了话语之间的长距离依赖问题，同时由于整体模型架构均由Transformer组成，因此引入了更少的结构先验假设；其次，由于采用了有监督对比学习来训练模型，在充分利用标签信息的情况下，不仅能够增加模型训练时的稳定性并增强模型的泛化性，还使得相同情感的样本间内聚，不同情感的样本相互斥，因此改进了相似情感难以区分的问题；最后，由于辅助性回复生成任务能够根据给定的上文信息获取更准确的下文，从而使得模型在判断话语情感时能考虑更加丰富的上下文信息，提升模型识别对话的情感标签的精确性。一种基于监督比较学习和答案生成辅助的对话情感识别方法。该方法能够利用对话级模块进行上下文建模过程来构建预训练的Cog-Bart模型，从而降低远程依赖难度和情感识别难度， 利用一种模型结构引入结构先验假设， 利用标签信息训练预训练的Cog-Bart模型， 本发明在检测语音情感时，利用辅助回复生成任务根据上下文信息，提高了预训练Cog-Bart模型的稳定性和上下文文本获取的准确性，增强了预训练Cog-Bart模型的通用性，提高了情感标签的准确性。该方法包括根据编码器和解码器构造训练前对比和生成增强的思维双向情感再处理(COG-BART)模型(S1)。 通过使用预训练Cog-Bart模型对训练会话执行(S2)语音编码处理，以获得训练会话中的隐藏语音状态。 根据语音的隐藏状态和上下文文本，利用预训练Cog-Bart模型执行(S3)辅助答复生成任务，以计算生成损失。 根据语音的隐藏状态计算(S4)监视对比学习损失和交叉熵损失。 根据生成损失，监视对比学习损失和交叉熵损失计算(S5)总训练损失。 输入对话(S6)。 通过对话情感识别模型来识别情感，以输出情感标签。 根据上下文文本训练句子对话操作。 8
本发明提供一种基于BERT编码的数学应用题求解系统及方法，涉及应用求解技术领域。本系统包括编码模块、解码模块、监督模块以及微调模块。本方法使用MacBERT : 作为中文题目的编码器，BERT作为英文题目的编码器；编码过程首先获取文本序列Q，并将文本序列Q映射成逐个字向量所构成的向量表示矩阵，对向量表示矩阵中各个字向量取平均得到文本序列的整体表示向量，使用树形解码器来生成表达式树；利用分类器捕捉导致生成错误表达式的题目表示，如果分类器输出结果为1，表示解码器生成的表达式与题目相对应，如果输出结果为0，则说明编码器生成的题目表示向量导致了错误表达式的生成，需要被进一步优化；对系统进行训练，从而实现数学应用题的求解。基于BERT编码的数学应用问题求解系统。对误差求解表达式生成的问题代码表达式进行优化，以提高模型效果，当两者不匹配时。 通过编码器得到每个题目对应的数学关系，使得具有相同算子的题目和算子的各个数字更加接近。该系统具有编码模块、解码模块、监控模块和修整模块。 编码模块负责对数学应用题目进行编码，即将自然语言形式的数学应用题目转换为向量形式的编码结果。 解码模块，接收编码模块输出的编码结果，推导出每个数学应用题对应的数学表达式。 所述监控模块为检验数学表达正确性的正则化项。 微调模块，利用所述编码结果预测求解所述话题对应的数学表达式中各个数学符号的个数并求解。 编码器在求解开始之前感测对应于主题的数学逻辑。包括独立权利要求，用于基于BERT编码的具有监控模块的数学应用问题求解方法。  12
本发明提出一种变电现场作业违规行为检测方法：首先，采集变电现场作业违规行为图像，手动分割作业相关目标，并对图像所属的违规行为类别进行标定，建立变电现场目标分割数据集和违规行为分类数据集；然后，基于目标分割数据集对U‑Net模型进行训练和分类，获取变电现场目标的分割结果；为减少图像背景区域和不相关物体的干扰，将分割后的二值目标图像与原图像执行与运算，得到目标区域的灰度图像；最后，根据该目标区域的灰度图像运用CNN模型进行分类，获取最终的违规行为检测结果；应用本发明提供的变电现场作业违规行为检测方法，可减少图像背景区域和不相关物体的干扰，能自动、有效检测变电现场作业违规行为，提高风险防控能力。用于检测变电站现场操作中的不规则性的方法。本发明减少了图像背景区域和非相关对象的干扰，自动有效地检测出变电现场工作的违章行为，提高了风险防控能力。该方法包括收集变电站现场操作的非法图像和手动分割变电站现场操作目标。 构建变电站现场操作目标分割数据集，校准图像内容所属的变电站现场操作行为类别，并构建违章行为分类数据集。 基于变电站现场目标分割数据集训练U-Net模型，并对输入图像进行预处理。 获得灰度级图像，并获得二值化目标图像。 执行二元目标图像和预处理的输入图像之间的AND操作以去除背景区域和不相关对象。 获得目标区域的灰度图像。 基于工作现场违章分类数据集训练电缆新闻网络(CNN)模型。 将目标区域的灰度图像输入CNN模型，实现最终的野外作业违章检测。 0
本申请提供一种语音分类方法、装置及存储介质，涉及数据处理技术领域，能够解决对语音分类的精确度和效率较低的问题。该方法包括：提取目标通话录音对应的初始文本；采用大语言模型去除初始文本中的错误字符，得到目标文本；在目标文本包含预设关键字的情况下，采用目标分类模型对目标文本进行分析，得到目标概率值，目标概率值用于表征目标文本属于目标类型的可能性；在目标概率值大于第一预设阈值的情况下，采用大语言模型对目标文本进行分类，得到目标分类结果，目标分类结果用于指示目标文本是否属于目标类型。本申请实施例用于对运营商客服录音进行分类的过程中。用于数据处理领域的语音分类方法。该方法能够解决语音分类精度和效率较低的问题。该方法涉及获取与目标通话记录对应的初始文本(S201)。 利用所述大型语言模型(S202)去除所述初始文本中的错误字符，得到所述目标文本。 在所述目标文本包括预设关键词的情况下，利用所述目标分类模型(S203)对所述目标文本进行分析。 得到所述目标概率值。 所述目标概率值用于表征所述目标文本属于所述目标类型的可能性。 在所述目标概率值大于所述第一预设阈值的情况下，利用所述大语言模型(S204)对所述目标文本进行分类。 得到目标分类结果。 所述目标分类结果用于指示所述目标文本是否属于所述目标类型。独立权利要求还包括用于：对语音进行分类的装置； 以及计算机可读存储介质，其包括用于对语音进行分类的一组指令。 3
本公开提供了一种推荐产品信息的生成方法，可用于金融领域或其他领域。该方法包括：将所述多个候选产品的产品信息文本输入标签预测模型中，以确定所述多个候选产品中每一个候选产品的产品标签，其中，所述标签预测模型是基于残差块优化的Transformer模型预先训练得到的；获取目标客户的客户标签；将所述目标客户的客户标签和所述多个候选产品的产品标签进行匹配，得到匹配结果；以及基于所述匹配结果，生成针对所述目标客户的推荐产品信息。本公开还提供了一种推荐产品信息的生成装置、设备、存储介质和程序产品。用于银行和金融领域的推荐产品信息生成方法。该方法使得能够以有效的方式基于匹配结果生成针对目标客户端的推荐商品信息。 该方法使得标签确定单元能够以高效的方式选择历史购买商品集合中商品标签数量最多的标签作为目标客户端的客户端标签。该方法包括获得(S210)多个候选产品的产品信息文本。 将多个候选商品的商品信息文本输入(S220)至标签预测模型，以确定多个候选商品中每个候选商品的商品标签。 获取目标客户端的客户端标签(S230)。 将所述目标客户端的客户端标签与所述候选商品的商品标签进行匹配(S240)，得到匹配结果。 基于所述匹配结果生成(S250)针对所述目标客户端的推荐商品信息。 获取目标客户端的客户端信息文本。 将所述客户端信息文本输入所述标签预测模型，确定所述目标客户端的客户端标签。独立权利要求包括以下内容：推荐产品信息的生成装置； 电子设备； 计算机可读存储介质，其上存储有可执行指令； 以及用于生成推荐产品信息的方法的计算机程序产品。  11
本发明公开了一种基于抽取式的文本分类方法，涉及到文本分类技术领域，包括S1：样本构造；S2：基于深度预训练模型的实体识别。本发明把文本分类任务转化成实体识别任务，通过实体识别模型从文本中抽取文本的类别标签，把多种类型的文本分类任务转化成统一的实体识别任务，避免了传统方法需要为不同的文本分类任务分别建模的问题；本发明为单标签文本分类任务、多标签文本分类任务和层级多标签文本分类任务分别设计了抽取式的样本生成方式，输入内容包含了文本内容和标签内容，标签不再是独立于文本的符号，模型通过注意力机制可以更好地学习标签与标签之间、标签与文本之间的语义关系，从而实现更好的分类效果。基于抽取的文本分类方法。该模型通过注意力机制更好地学习标签与文本之间的语义关系，以达到更好的分类效果。该方法包括假定用于文本分类任务的预定义类别标签(S1)。 基于深度预训练语言模型双向编码器表示(BERT)基于深度预训练模型建立实体提取模型(S2)。 每个字符在文本text2中进行分类，确定属于BIO中的哪个类别，因此需要BERT输出每个字符，然后通过全连接网络和softmax得到每个字符属于三类BIO的概率。 计算每个字符属于每个实体的概率与真实实体标签之间的交叉熵损失。  11
本发明公开了一种解耦的试题表征及应用方法，包括问题定义与形式化、收集数据并对数据进行预处理、建立模型；其中，数据预处理包括试题过滤、知识概念过滤和抽样；建立模型包括编码模块、评价模块和迁移模块，编码模块负责根据试题的文本生成试题的概念表征向量和个性表征向量；评价模块负责在预训练表征模型时评价试题表征的质量并训练优化模型参数；迁移模块将预训练的试题表征向量应用于具体的下游任务，将个性表征向量中的知识迁移到下游任务模型以提高任务模型的效果。该方法能够为试题检索、试题难度估计、个性化试题推荐等智慧教育领域的实践提供技术支持，效果好、效益高，大大提高了工作效率。用于机器学习，人工智能和智能教育技术领域的解耦试题表征及应用方法。本发明为试题搜索，试题难度评估，个性化试题推荐和智能教育实践领域提供技术支持，效果好，效益高，大大提高了工作效率。该方法涉及定义和形式化问题。 采集数据并对数据进行预处理。 建立模型。 编码模块负责根据试题文本生成试题的概念表示向量和个体表示向量。 评估模块负责评估试题表征的质量，并在预训练表征模型时训练优化模型参数。 将个体特征向量中的知识迁移到下游任务模型，以改善任务模型的效果。  11
本发明公开了一种基于序列识别的视频异常事件检测方法，包括：S1、数据集划分：将异常视频数据集划分为训练集和测试集；S2、视频预处理：将视频截取为RGB帧和光流帧；S3、视频特征提取：加载在数据集上预训练好的I3D模型，修改I3D模型网络结构，将RGB帧输入修改后的I3D模型并从中提取视频特征向量；S4、数据增广：对视频特征向量进行不同起始位点的截取，并进行补长，得到若干条等长的视频特征向量；S5、利用双向LSTM网络获得视频特征编码；S6、利用序列识别模型对视频进行分类：将视频特征编码输入到序列识别模型中，得出预测结果。本发明的方法不局限于有限的感受野上，可以显著提高视频异常事件检测的效果。一种基于序列识别的视频异常事件检测方法。本发明可以显著提高视频异常事件检测的效果。该方法包括调整视频帧的大小和频率。 视频被截取为RGB帧和光流帧。 将预训练的I3D模型加载到数据集上。 修改I3D模型网络结构。 RGB帧被输入到修改的I3D模型中，并且视频特征向量被提取。 在不同的起始点截取视频特征向量，并进行长时间的补充，最终得到等长的视频特征向量。 通过使用双向LSTM网络获得视频特征编码。 视频特征向量被输入到双向LSTM网络以获得视频特征码。 利用序列识别模型对视频进行分类。 将视频特征码输入到序列识别模型中以获得预测结果。 9
本申请公开了一种用于自动问答系统的分类模型训练、自动问答方法及装置，涉及人工智能领域。方法包括：利用弱监督数据集对分类模型进行预训练，得到预训练分类模型，弱监督数据集中包括第一询问数据以及弱监督标签；通过预训练分类模型对目标数据集进行分类，并基于分类结果确定目标数据集的目标损失，目标数据集中包含第二询问数据以及标注标签；对目标损失和预训练过程中弱监督数据集的弱监督损失进行损失融合，得到融合损失；基于融合损失对预训练分类模型进行微调，得到目标分类模型。通过引入弱监督数据集进行模型预训练，并在微调阶段融入弱监督数据集的信息，在保证模型训练质量的前提下降低模型训练过程对标注数据的依赖。该方法对于使用计算机设备(要求保护的)的自动问答系统的分类模型训练是有用的。该方法：能够保证模型训练质量； 并且降低了模型训练过程对标记数据的依赖性。用于自动问答系统的分类模型训练方法包括：利用弱监督数据集获得预训练分类模型，确定弱监督数据集具有第一查询数据和弱监督标签，从第一查询数据对应的回复数据中提取弱监督标签，利用预训练分类模型对目标数据集进行分类，基于分类结果确定目标数据集的目标损失，以及基于对目标分类模型的融合损失对预训练分类模型进行微调。还包括独立权利要求，用于：一种自动问答方法； 用于自动问答系统的分类模型训练装置； 自动问答装置； 以及计算机可读存储介质，包括用于自动问答系统的分类模型训练的指令集。  11
本公开提供了一种事件触发词抽取方法及装置，该方法在预训练阶段引入事件元素角色与中文事件专用术语等向量信息，采用了词语级别的掩码语言模型处理机制，构建出更符合中文事件触发词抽取特点的EBERT模型，使得模型获得更可靠的中文语言表示。在EBERT预训练模型的基础上拼接双向长短期记忆网络，通过该网络来提取中文新闻长文本的上下文关键特征，增强向量表达，得到全局序列信息。将全局序列信息输入条件随机场，使用条件随机场校验序列标签，输出中文事件触发词抽取结果，提升了触发词的识别效果和抽取效果。事件触发词提取方法。该方法将全局序列信息输入条件随机场，利用条件随机场对序列标签进行验证，输出中文事件触发词提取结果，提高了触发词的识别和提取效果。该事件触发词提取方法包括通过词表提取模型获取目标文本的动态向量，该词表提取模型由预设触发词和预设专有词表预先训练得到。 通过语言表示模型获取所述动态向量的语义表示向量，所述语言表示模型通过掩码语言模型预先训练得到。 通过长短期记忆网络从所述语义表征向量中提取触发词特征，并基于所述触发词特征得到标签预测概率向量。 通过条件随机场对所述标签预测概率向量进行计算，得到所述目标文本对应位置的序列标注结果。包括用于事件触发词提取设备的独立声明。  12
本发明提供一种基于预训练模型的学术文本语义特征提取方法、系统和存储介质，所述方法包括：获取学术资源文本数据；将获得的学术资源文本数据输入至预训练模型，得到多维的学术文本语义特征向量；所述预训练模型是基于多重负样例损失函数对Bert预训练模型进行微调、将微调后的Bert预训练模型作为教师模型通过知识蒸馏来训练学生模型得到的学生预训练模型；将所述多维的学术文本语义特征向量进行降维压缩，输出最终的学术文本语义特征。本发明在提高向量生成质量的同时加快了向量生成的速度，适用于学术大数据场景下的文本向量生成。基于预训练模型对学术文本进行语义特征提取的方法。该语义特征提取方法提高了向量生成的质量，加快了向量生成的速度，适用于学术大数据场景下的文本向量生成。语义特征提取方法涉及获取学术资源文本数据。 将获取的学术资源文本数据输入预训练模型，得到多维学术文本语义特征向量。 预训练模型为基于多负荷样本损失函数对Bert预训练模型进行微调得到的学生预训练模型。 通过将精细调节的Bert预训练模型作为教师模型，通过知识蒸馏训练学生模型。 对所述多维学术文本语义特征向量进行降维压缩并输出最终学术文本语义特征向量。包括独立权利要求：(1)基于预训练模型的学术文本语义特征提取系统； (2)一种计算机存储介质，其存储有用于实现所述基于预训练模型对学术文本进行语义特征提取的方法的指令。  12
本发明提供了一种基于预训练模型的场景适配学习方法及系统，包括：场景接入步骤：根据场景实际的业务需求，接入场景的实际数据；场景配置步骤：通过接入的场景数据快速进行场景数据的模版配置；数据生成步骤：模版配置准备完成后，进行数据生成，完成数据增强和带标注信息的训练数据准备；模型训练步骤：根据生成的训练数据，进一步训练预训练模型，提升预训练模型的精确度。本发明通过预训练的模型和当前场景的生成数据，我们可以快速获得该场景下的高质量模型，同时，因为有预先训练好的模型，可以大大节约训练的时间。基于预训练模型的场景自适应学习方法。该方法使得通过预先训练的模型和当前场景生成数据能够快速得到该场景下的高质量模型从而减少训练时间。该方法包括根据场景的实际服务需求访问实际场景数据。 通过访问的实际场景数据进行实际场景数据的模板配置。 在模板配置准备完成后生成数据。 数据增强和训练数据准备过程由标签信息执行。 根据生成的训练数据对预训练模型进行训练，其中，实际场景数据是指样本的真实标识场景数据包括编号、图片和号牌。 确定位置空间的坐标。包括基于预训练模型的场景自适应学习系统的独立权利要求。 14
本发明提供一种电商商品的品目预测机器人及其实现方法，先通过海量无标注语料对下载的所述bert预训练语言模型bert‑base‑chinese进行预训练，得到预训练后bert模型；再经过模型微调过程对预训练后bert模型进行微调，从而得到最佳模型，并保存最佳模型的模型参数列表。最后通过运行所述最佳模型，加载所述最佳模型的模型参数列表，核验模型对商品归类的准确率；直到准确率不低于阈值时结束，此时得到的bert模型即为所述电商商品的品目预测机器人。本发明根据品目库标准，依托大数据，通过人工智能算法模型实现商品品目预测，能快速、精准、智能地从大规模商品数据中识别商品类目，助力企业采购数字化、自动化、智能化转型升级，为供应链端商品治理归类降本增效。使用计算机预测商品的电子商务机器人的方法。该方法能够实现商品产品预测通过人工智能算法模型快速准确地从大规模商品数据中智能识别商品类别，助力企业采购数字化、自动化、智能化改造升级，为供应链端商品处理分类降协同。该方法包括加载初始模型参数列表并配置初始学习率参数值。 操作分类器。 由所述分类器确定商品标题信息的输入。 确定推理结果。 重新配置学习率参数和模型参数列表。 分类器继续操作。 选择分类器推理能力最高的bert模型作为最佳模型。 存储最佳模型的模型参数列表。 进行模型评估处理。 测试数据集，设置有商品属性、相关参数名称和品牌，所述测试数据集为数据集的一定数量的商品标签信息。独立权利要求包括：一种使用计算机预测商品的电子商务机器人的方法； 以及一种利用计算机实现商品电子商务机器人的方法。  12
本发明提供了一种社交电商用户画像的建立方法，它解决了现有技术存在的干扰噪音多的问题。其方法包括：步骤S1：在中文语料库中进行自监督训练得到预训练模型；步骤S2：对社交电商公开文本数据集预处理后进行分类标注；步骤S3：将预训练模型在类别标注完成的数据集上进行微调训练，得到用户画像模型。本发明优点在于有效减少干扰噪音，合理使用社交电商专业领域文本信息，提升用户画像建立的精准度。该方法对于建立社交电子商务用户简档是有用的。该方法：有效降低干扰噪声； 合理利用社交电子商务专业领域的文本信息； 并提高了用户画像建立的准确性。建立社交电子商务用户配置文件包括：(i)在汉语言语料库中进行自监督训练，得到预训练模型; (ii)对预处理后的社交电子商务公开文本数据集进行分类标注; (iii)对分类标注完成的数据集进行预训练模型的微调训练，得到用户画像模型。 3
本发明涉及图像处理技术领域，尤其涉及一种半监督的低光图像增强系统。包括可见度提升模块和保真度恢复模块；可见度提升模块采用Retinex理论对图像进行分解，并引入信息熵约束；保真度恢复模块通过残差网络和U‑Net相结合方式构建，并引入L2损失、结构相似性指数、梯度损失和色彩恢复损失作为约束。本发明在网络的第一阶段，采用基于信息熵和Retinex的方法来提高图像的可见度，阶段是一个轻量级的自监督的网络，只需要输入低光图像和分钟级训练就能实现亮度提升；在网络的第二阶段，利用U‑Net和残差网络来消除第一阶段增强结果中存在的噪声和退化等问题，从而提升增强图像的视觉特性，打破了直接处理低光图像困难的问题。用于计算机视觉任务的图像处理技术领域的半监督微光图像增强系统。该系统将微光图像增强任务解耦为基于信息熵和Retinex两个阶段，提高图像的可视性，实现轻量级自监督网络。 该系统利用U-Net和残差网络消除了第一级增强结果中的噪声和退化问题，从而提高了增强图像的视觉特性。该系统具有用于增强输入图像的可视性的可视性提升模块。 保真度恢复模块恢复输入图像的保真度。 可见性提升模块利用Retinex理论对图像进行分解，并引入信息熵约束来训练网络的分解。 所述能见度提升模块采用残差网络和U-Net结合模式构建保真恢复模块，引入L2损失、结构相似度指数、梯度损失和颜色恢复损失作为约束。 所述保真恢复模块设置有卷积层和编码解码层。   6
本发明适用于肽识别技术领域，提供了一种抗癌肽识别方法及系统，识别方法包括以下步骤：输入给定的肽序列，对肽序列进行数据增强，得到原始序列；第一通道使用Bi‑LSTM从原始序列中提取特征；第二通道将原始序列转化为化学分子式的形式，并使用SMILES简化化学分子式，将SMILES表示的序列输入至预训练的BERT模型，得到深度抽象特征；第三通道融合BPF、DPC、PAAC和K‑mer四种特征，共同提取原始序列不同层面的特征；拼接三个通道提取的特征，通过全连接层对输入的肽序列进行分类。本发明中ACP‑BC模型具有较强的稳健性和通用性，在预测ACP和非ACP方面具有巨大的潜力。一种用于生物信息学领域的癌症肽(ACP)的抗癌肽鉴定方法。ACP-BC模型具有很强的鲁棒性和通用性，在预测ACP和非ACP方面具有很大的潜力。该方法包括对输入的肽序列进行数据增强以获得原始序列(S1)，(ii)使用Bi-LSTM从原始序列中提取特征(S21)，和(iii)将原始序列转换为化学分子式(S22)，(iv)使用SMILES简化，(v)融合BPF、DPC、PAAC和K-mer四种特征(S23)，(vi)提取原始序列不同层的特征; (vii)拼接由步骤(S3)(i)、(viii)和(vix)提取的特征，并通过全连接层对输入序列进行分类。本发明还涉及一种抗癌肽识别系统。  7
本发明提供了一种零样本学习深度模型的量化方法，主要包括以下步骤：获取已经训练完毕的全精度预训练模型；利用知识匹配生成器从全精度预训练模型的批归一化层BN层中获取原始训练数据的分类和分布信息；使用所述校准数据集驱动所述全精度预训练模型的量化；生成新的伪数据驱动知识匹配生成器的优化；持续交替对抗地优化量化模型和知识匹配生成器，直到模型量化性能稳定收敛。相较于现有技术，本发明提出对权重和量化参数进行逐层联合迭代优化，能够使模型每层量化层输出与全精度层输出之间的误差最小化。零样本学习深度模型定量方法。该方法使得能够提出权重和量化参数的逐层联合迭代优化，这可以最小化模型的每层的量化层输出与全精度层输出之间的误差。该方法包括获得被训练的全精度预训练模型。 利用知识匹配生成器获取所述全精度预训练模型的批次。 获取所述原始训练数据的分类分布信息。 生成多批伪数据作为校准数据集。 利用校准数据集来驱动全精度预训练模型的量化。 生成新的伪数据以驱动知识匹配生成器的优化。 对知识匹配生成器进行K-迭代优化。 继续量化模型和知识匹配生成器交替对抗优化，直至模型量化性能稳定收敛。  11
本发明公开了一种动态工艺知识库智能化构建与更新方法及系统，将工艺知识多维分类数据集输入RoBERTa‑WWM标准中文预训练模型中进行处理，得到词向量序列；将词向量序列输入GRU网络，并对词向量序列中的词向量进行深度编码，得到特征向量V2；借鉴ResNet网络架构，利用全连接层将CLS标志位对应的特征向量V1和特征向量V2进行向量降维；利用分类器对已降维的特征向量进行分类；利用工艺知识图存储模型将分类好的工艺知识分别表征为图模型中的点和边；利用cypher语言，将多维度分类的工艺知识以图的形式存入图数据库中实现工艺知识自动补全和更新。对工艺知识的分类准确率高，能实现对工艺知识及其关联关系的动态可视化存储及更新。动态过程知识库的智能构建与更新方法。将多维度分类后的技术知识通过cypher语言以图的形式存储在图谱数据库中，实现技术知识的自动补充和更新。 该方法对过程知识的分类准确率高，可实现过程知识及关联关系的动态可视化存储和更新。该方法涉及构建过程知识的多维分类数据集。 将所述过程知识输入中文预训练模型进行处理，得到CLS标志位对应的特征向量。 将所述特征向量输入GRU网络。 对词向量序列中的词向量进行深度编码，得到另一个特征向量。 采用全连接层对所述特征向量进行向量降维。 将多维度分类后的技术知识以图谱的形式存储到图谱数据库中，对技术知识进行自动补全和更新。 采用cypher语言将多维度分类后的技术知识以图的形式存入图库，对技术知识进行自动补全和更新。本发明还涉及一种动态过程知识库的智能构建与更新系统。  12
本发明实施例公开了一种基于大语言模型的自动组卷方法、电子设备及存储介质。方法包括：响应于自动组卷功能的触发操作，展示关于试卷基本信息和各默认题型的第一提示语设置入口，以引导用户设置试卷的整体考纲并输入大语言模型，由大语言模型自动生成各考题；将各考题分题型展示，并展示针对各题型和各考题的第二提示语设置入口，以引导用户设置对各题型和/或各考题的调整要求；同时展示针对各考题的人工编辑入口，用于对各考题进行人工修改；响应于各第二提示语设置入口的触发操作，由大语言模型重新生成各新考题；响应于各人工编辑入口的触发操作，将各考题替换为人工修改的各新考题；将最终的各考题组成试卷。基于大语言模型的自动卷组装方法。所述方法包括：响应于提示设置录入的触发操作，在大型语言模型中输入题型和试题的调整需求。 通过大语言模型重新生成新的试题。 将所述试题替换为每个新的试题，响应于所述手动编辑进入的触发操作，手动修改所述新的试题。 由试题形成最终试卷。 根据试题信息和试卷信息优化大型语言模型的汇编试卷方向。独立权利要求包括用于：(1)电子设备； (2)一种计算机可读存储介质，包括执行基于大型语言模型的自动滚动方法的一组指令。  11
本发明公开了一种基于条件对抗样本的模型投毒方法及系统，属于人工智能安全技术领域，解决现有技术容易出现无效投毒的情况，从而造成数据被防御，无法使模型的性能降低。本发明获取训练数据集，其中，训练数据集包括多个不同类别的子集，各子集包括多个正常样本；在训练数据集中任选一个子集或多个子集，给子集中各正常样本初始化两个扰动；基于已预训练的检测模型对正常样本和两个扰动进行检测，若满足要求，得到正常样本与两个扰动之和，即条件对抗样本，若不满足要求，更新扰动后再次执行步骤3；将得到条件对抗样本的正常样本替换为条件对抗样本，替换完成后得到新的训练数据集，并基于新的训练数据集训练检测模型。本发明用于模型投毒。人工智能安全技术领域中的一种基于条件对抗实例的模型中毒方法。本发明解决了现有技术容易出现无效病毒，从而导致数据防御性差，不能降低模型性能的问题。 该方法得到的条件不改变样品投资的标号，只改变其正常的样品内部特性，对模型性能有较强的影响。 该方法针对样本提供了一种基于条件模型的训练方法，解决了无效案例的问题，并且不导致数据的防御性，使得训练后的新训练数据集的新模型性能降低。该方法包括获得训练数据集。 训练数据集包括多个不同类别的子集，并且每个子集包括多个正常样本。 选择训练数据集中的一个子集或多个子集。 初始化子集中每个正常样本的两个干扰。 基于预先训练好的检测模型F检测正常样本和两个扰动，如果满足要求，则得到正常样本和两个扰动之和。 得到条件对抗样本的正常样本被条件对抗样本替换。 替换完成后获得新的训练数据集，并基于新的训练数据集训练分类模型。 检测模型F和分类模型的目标函数相同。本发明还涉及一种基于条件对抗样本的模型中毒系统。  11
本发明公开了一种基于级联Transformer的脑肿瘤分割方法，能够高精度地分割脑肿瘤多模态磁共振(MR)图像，本方法将两个不同结构的U‑Net级联为一个二阶段网络，使网络能够由粗略到精细的分割脑肿瘤。考虑到脑肿瘤MR图像存在着尺寸、位置不固定等问题，因此在第二阶段将全方位动态卷积引入到一至三层的编码器和解码器中，能够使得网络根据输入动态决定卷积核参数以适应不同脑肿瘤MR图像间差异巨大的情况，同时还考虑到脑肿瘤长距离依赖对于精确分割脑肿瘤较为重要，在第二阶段的四至六层中使用Swin Transformer作为编码器和解码器，能够良好的捕获脑肿瘤长距离依赖同时兼顾Transformer的复杂度问题。本方法通过增强网络的全局与局部特征信息提取能力使得分割结果更加精确，能够为医生诊断提供有效帮助。基于级联的脑肿瘤分割方法。该方法增强了网络的全局和局部特征信息提取能力，使分割结果更加准确，为医生诊断提供有效帮助。该方法包括将脑肿瘤多模态磁共振(MR)图像处理成网络的输入数据集。 网络结构以级联为基础。 对网络结构进行训练，并存储网络模型。 加载所述网络模型。 对网络模型进行测试，得到脑肿瘤分割结果并进行后处理，得到最终的分割结果。 输入数据集按照一定比例分为训练集和测试集。 采用包括随机缩放、随机转向、高斯噪声、高斯模糊和随机亮度过程的多重数据增强过程对训练集进行数据增强处理。  7
本申请提供一种机器人移动控制方法及装置和可读存储介质，涉及机器人控制技术领域。本申请通过调用大语言模型对获取到的针对目标机器人的自然语言移动指令进行识别，得到目标机器人的目标终点位置，并在目标机器人所在的原始语义地图中以目标终点位置为赋值中心进行地图奖励赋值，得到对应的赋值语义地图，而后根据该赋值语义地图以及目标机器人实时采集到的环境深度图像，以最小化路径节点奖励和值为目的，基于大语言模型调用预存的高级语言移动控制函数驱动目标机器人移动到目标终点位置处，从而利用大语言模型及目标机器人实时采集到的环境深度图像，灵活调整目标机器人的移动路径，并达到通过自然语言控制机器人自主导航的效果。通过自然语言进行机器人自主导航的机器人移动控制方法。调用预先存储的高级语言移动控制函数，驱动所述目标机器人移动至所述目标终点位置，以达到利用大语言模型和实时采集的环境深度图像，灵活调整目标机器人的移动路径，并通过自然语言达到控制机器人自主导航的效果。该方法涉及获得(S210)针对目标机器人的自然语言移动指令。 调用大型语言模型来识别(S220)自然语言移动指令。 获取所述目标机器人的目标末端位置。 在所述原始语义图中获取对应的赋值语义图。 根据所述评价语义图和机器人实时采集的环境深度图像，以最小路径节点奖励和值为目的(S230)。 调用预先存储的高级语言移动控制函数，驱动机器人移动至目标终点位置。独立权利要求书包括用于：(1)机器人移动控制装置； 以及(2)存储用于机器人移动的程序的可读存储介质。  11
本发明公开了一种基于BERT‑BiGRU‑CRF的中文命名实体识别方法。该方法包括三个阶段，第一阶段预处理海量文本语料，预训练BERT语言模型；第二阶段预处理命名实体识别语料，利用训练好的BERT语言模型对命名实体识别语料进行编码；第三阶段将编码后的语料输入BiGRU+CRF模型中进行训练，利用训练好的模型对待识别语句进行命名实体识别。本发明通过构建基于BERT‑BiGRU‑CRF的中文命名实体识别方法，通过BERT预训练语言模型增强字的语义表示，根据字的上下文动态生成语义向量，有效表征了字的多义性。提高了中文命名实体识别的精度，且与基于语言模型微调的方法相比减少了训练参数，节省了训练时间。基于BERT-BiGRU-CRF的中文命名实体识别方法。提高了中文命名实体识别的准确率，减少了训练参数，从而节省了训练时间。该方法涉及获取语言模型的训练语料数据。 对所述原始语料进行字符级别切分。 构建句子对正负样本。 根据训练语料库数据训练来自变换器(BERT)语言模型的双向编码器表示。 基于BERT-BiGRU条件随机场(CRF)的中文命名实体识别模型是根据基于BERT的语言模型和标注语料构建的。 采用基于BERT-BiGRU-CRF的中文命名实体识别模型对识别数据进行处理，得到命名实体识别结果。  12
一种基于提示微调预训练大模型的行人属性识别方法，属于计算机视觉技术领域，解决现有技术中没有充分利用行人图像与属性标签之间的关系而导致的次优以及泛化能力差的问题。本发明采用CLIP的视觉和文本编码器提取图像特征和属性特征，通过多模态Transformer模块对两个模态特征融合后，经过前馈网络得到预测结果，通过将行人属性识别问题建模为视觉语言融合问题，使用预训练的视觉语言大模型作为主干网络，提取模态间联系更好的视觉和文本特征，再通过多模态的Transformer建模视觉和文本之间的联系，充分利用了属性语义信息，并且可以看出通过提示微调的方式保留了预训练大模型较好的泛化能力，模型实用性更强。基于提示型微调预训练大模型的行人属性识别方法。 用途包括但不限于年龄、身高、发型和衣物。该方法使得能够对输入的待分类的行人图像和待评估的行人属性进行预处理，并且因此确保简单且高效地识别行人属性。该方法包括对输入的待分类行人图像和待评估行人属性进行预处理。 将所述行人图像送入预先训练好的大模型，得到视觉特征和文本特征。 将获得的视觉特征和文本特征发送至多模式模块。 进行模态融合及信息交互，将所述视觉特征与所述文本特征混合，得到融合交互后的特征。 将与所述文本特征对应的位置融合后取出令牌。 令牌被传输到分类器以获得每个属性的得分。 确定所述分数是否大于阈值。 将每个属性与所述阈值进行比较，以输出预测结果。 14
本发明提供一种事件脉络生成方法、设备及介质，以提高事件脉络的准确性、可读性、简洁性、完整性。本方法包括：根据用户需求，制定主题关键词，采集主题相关数据生成主题相关数据集合，基于主题相关数据集合计算事件传播力，获取传播节点，生成初始传播列表；初始传播列表经过时间抽取器，初步提取出符合事件脉络生成的传播事件，组成传播事件列表；传播事件列表基于bert预训练模型抽取事件知识，然后聚类，去除相似事件，生成传播脉络列表；传播脉络列表与主题相关数据集合进行相似性匹配，获取数据信息并计算传播脉络特征，基于传播脉络特征计算事件参与度，对传播脉络列表进行筛选入库，生成事件脉络知识库。针对互联网上新闻媒体平台发布各种规模新闻的事件情境生成方法。该方法能够提高事件脉冲的准确性、可读性、简单性和完整性。 该方法可以让用户在事件控制和动态跟踪上花费更少的时间，使机器提取的事件脉冲发展和重要知识与人工处理的效果更加结合，从而保证用户可以同时关注一组事件，使每个事件的重要信息和发展一目了然，避免了大量的勾结和总结。该方法涉及根据用户需求开发(S1)主题关键词，并收集主题相关数据以生成主题相关数据集。 计算事件传播功率(S2)以获得传播节点并生成初始传播列表。 符合事件环境的传播事件最初被提取(S3)以形成传播事件列表。 在传播情境列表和主题相关数据集之间执行相似度匹配(S5)，以计算传播情境的特征。 通过组合事件方差、事件峰值斜率和事件密度来计算(S6)事件分布值。 计算构成事件语境的当前传播语境事件的参与度(S7)。 将通信上下文中的事件进行筛选并根据参与度放入(S8)数据库中，完成事件上下文知识库并推送给用户。包括独立权利要求：(1)一种计算机设备包括用于事件上下文生成方法的指令； 以及(2)—种存储用于事件上下文生成方法的程序的计算机可读存储介质。  12
本发明公开了一种数控机床程序交互纠错方法及系统，涉及数控机床精密加工技术领域，数控机床程序交互纠错方法包括以下步骤：获取数控系统ISO代码词典并存入数据库中，通过数据库对待传输程序的原始文本进行ISO格式化、ISO代码数据收集；通过bert模型校正网络将待传输程序的原始文本与ISO代码数据库进行格式与内容对比，获得待传输程序的标记文本，待传输程序的标记文本中将错误内容进行标记；操作者对待传输程序的标记文本进行检验；本发明通过对程序文本的格式内容进行检查，并与采集的数据库进行对比，并对自身纠错效率进行优化，在对比前根据程序体量大小进行取点纠错或部分纠错，提升纠错效率，降低生产成本。该方法对于修正数控机床程序交互误差是有用的。该方法：能够检查节目文本的格式内容； 与采集的数据库进行比对； 优化自校正效率； 根据节目量大小采取点纠错或部分纠错； 提高了纠错效率； 节省了节目传输时间； 大大减少了用户与Fanuc数控系统在程序交互过程中产生的程序错误问题，以便于数控程序错误造成的生产损失； 提高了生产效率； 并降低了生产成本。该方法包括：获取数控系统ISO代码字典并存入数据库； 通过数据库对待传输节目的原文进行格式化， 采集国际标准化组织(ISO)代码数据， 通过BERT模型校正网络将待传输节目的原文与国际标准化组织(ISO)代码数据库进行比对， 获取待传输节目的标记文本，将所述待传输节目的标记文本中的错误内容标记出来，由操作人员对所述待传输节目的标记文本进行校验，校验后得到所述待传输节目的纠错文本。还包括独立权利要求用于数控机床程序交互纠错系统。  11
本发明提供一种谣言数据检测方法及装置，所述方法包括：获取待检测数据；基于预设条件对待检测数据进行分词处理以获取多个分词处理结果，利用预训练模型将各处理结果转化为向量矩阵，并将各向量矩阵分别转换为目标结构图；基于第一深度模型从各目标结构图中分别提取传播结构特征，从传播结构特征中获取融合特征；基于第二深度模型从融合特征中获取时序特征，再从融合特征和时序特征中获取目标特征向量；将目标特征向量作为输入特征输入到分类器中进行检测以获取检测结果；本发明所述方法以传播结构特征和时序特征作为检测算法的输入特征，提升了谣言数据检测的准确率。社交网络流言数据检测方法。该方法能够利用传播结构特征和时序特征作为检测算法的输入特征，提高流言数据检测精度。该方法包括获得待检测数据。 基于预设条件对所述待检测数据进行分词处理，得到分词处理结果。 利用预训练模型将所述分词处理结果转换为向量矩阵，所述向量矩阵包括源文本数据和评论文本数据。 根据预设构建规则将所述向量矩阵转换为目标结构图。 基于第一深度模型提取目标结构图的传播结构特征。 将提取的传播结构特征进行融合，得到融合特征。 从基于第二深度模型的融合特征中获取时序特征。 按照预设分配机制对所述融合特征和所述时序特征分配权重，得到目标特征向量。 将包含所述目标特征向量的所述待检测数据输入预先存储的分类器进行检测，得到检测结果。包括独立权利要求：(1)一种社交网络谣言数据检测装置； (2)一种电子设备，包括用于检测社交网络流言数据的存储器； 以及(3)非暂态计算机可读存储介质，其存储有用于检测社交网络流言数据的计算机程序。  12
本申请公开了一种地图兴趣点的训练模型确定方法、装置及电子设备，涉及深度学习领域的自然语言处理和大数据技术领域，所述方法包括：获取与兴趣点POI相关的至少一类预训练任务；根据预训练任务，确定第一阶段的训练模型；根据第一阶段的训练模型的参数以及至少一类与POI相关的专有任务，确定第二阶段的训练模型。本申请可以提高在地图POI名称领域的所有下游自然语言处理任务的性能，并且可以作为通用的一个模型参数进行发布，极大提高地图POI的处理效率。一种用于由电子设备确定地图兴趣点的训练模型的方法(权利要求)。本发明能够提高地图POI名称字段中所有下游自然语言处理任务的性能和地图POI的处理效率。方法包括获得与兴趣点(POI)相关的预训练任务。 根据预训练任务确定第一阶段的训练模型。 根据第一阶段的训练模型的参数确定与POI相关的特殊任务。 确定训练模型的第二阶段。 根据第一阶段的训练模型的参数确定与POI相关的预训练任务。还包括独立的权利要求： 确定地图兴趣点训练模型的装置； 以及 包括一组用于确定地图兴趣点的训练模型的指令的非瞬态计算机可读存储介质。  11
本发明涉及人工智能，提供了基于语义解析的摘要提取方法、装置、设备及介质，先对待提取文本基于TF‑IDF及频率值筛选条件提取第一筛选结果，然后获取待提取文本包括的每一分句以根据掩码转换策略进行掩码替换，得到每一分句相应的转换分句，将每一分句相应的转换分句均输入至预训练BERT模型得到相应的句向量，根据每一分句的句向量计算得到相似度矩阵，最后基于相似度矩阵和Textrank算法计算每一分句的评分并筛选出评分排名未超出评分排名阈值的目标分句评分及分别相应的分句组成文本摘要。实现了基于TF‑IDF提取的重要词优化BERT模型的掩码语言处理任务，输出有侧重点的句向量，之后基于Textrank提取更为准确的重点分句组成文本摘要，所提取的文本摘要更加准确。该方法可用于通过使用计算机设备(要求保护)基于语义分析来提取摘要。本发明公开了一种基于TF-IDF(TermFrequence-InversedDocumentFrequency)提取的重要词，从变压器(BERT)模型中优化双向编码器表示的掩码语言处理任务； 输出具有侧重心点的句子向量； 基于文本级别提取准确的关键语句，形成文本摘要，使得提取的文本摘要更加准确。该方法包括获得与文本摘要提取指令相对应的待提取文本。 对待提取文本进行分词和停词处理，以获得句子分割结果。 获得每个转换句子的句子向量。 根据句子向量获得相似度矩阵。 对应于相似度矩阵获得输出结果。 得分排序中的输出结果不超过目标得分的预设得分排序阈值。 对应于每个句子确定每个目标句子得分以形成文本摘要。本发明还涉及一种基于语义分析的摘要提取装置； 以及一种计算机可读存储介质，包括一组用于执行基于语义分析的抽象提取方法的指令。  11
本发明公开了基于实体感知的关系抽取方法、装置、设备及存储介质，步骤：为实体构建标记序列，并将标记序列与文本拼接得到输入序列；构建输入序列的掩码矩阵；使用预训练语言模型编码输入序列得到文本向量序列；取出已知实体的首尾向量拼接并映射得到实体向量表示；将各个实体向量两两拼接预测实体对关系。本发明的基于实体感知的关系抽取方法，在不改变预训练模型结构的基础上，通过重新定义预训练模型预留字符，结合掩码机制和位置编码，在文本编码层融合了多实体信息，实现了融合实体信息的一次编码模型，相比于现有技术，其步序较为简单，抽取效率较高，对设备计算能力要求较低，可适用于各种预训练语言模型，其适用性较好，极具应用前景。一种基于实体感知的关系提取方法。该方法通过掩码机制和位置编码的结合，能够重新定义预训练模型预留字符， 从而使文本编码层与多实体信息融合，实现了主编码模型的实体信息融合，提供了一种步骤顺序简单，提取效率高，对设备计算能力要求低，适用性好，提取效率高的关系提取技术。一种关系提取方法，包括：为实体构造标记序列；将所述标记序列与文本拼接，得到输入序列。 构建输入序列的掩码矩阵，利用预训练语言模型对输入序列进行编码，得到文本向量序列HL。 取出已知实体的头向量和尾向量，并映射得到实体向量表示。 拼接每个实体向量的两个拼接预测实体对。 标记字符被添加在原始文本之后。 标记字符的样式被提供了类型-位置。独立的权利要求书包括： (1)一种基于实体感知的关系提取装置； (2)具有处理器的计算机设备； (3)具有存储的指令的计算机可读存储介质，用于实现基于实体感测的关系提取方法。  12
本发明提供了一种基于BERT的政务公文本体概念抽取方法，包括以下步骤：(1)获取政务公文数据；(2)对公开的政务公文数据进行文本数据预处理；(3)建立术语的语言学规则；(4)进行公文本体术语提取；(5)估计公文本体术语的类别数目；(6)针对公文本体术语，进行词向量表示；(7)完成术语的聚类；(8)抽取公文本体概念；(9)实现本体概念抽取效果的评估与验证。本发明统筹政务工作的有效技术手段，为政务公务的共享交换、信息检索、信息抽取、政务图谱构建等应用提供强有力的支撑与保障，并提高了公文术语的聚类效果，为公文本体概念抽取的精度提供坚实的保障和支持。基于BERT的政府文件主体概念提取方法。该方法使得能够为政府事务共享交流、信息检索、信息抽取、构建政府地图等应用提供有力的支持和保障。 该方法能够提高公文术语的聚类效果，为公文概念提取的精度提供坚实的保障和支持。该方法涉及获得政府文件数据。 对所述政府文件数据进行预处理。 针对术语建立语言规则。 对政府文件数据中的术语建立语言约束。 从政府文件数据中提取官方文件术语。 将提取的公文术语向量化，得到公文术语的类别数。 根据向量化表示对所述公文术语进行聚类。 从每种类型的术语集合中选择文档概念。 文档风格概念完成。 特殊字符和低频词被消除。  12
本发明涉及一种基于模型转移技术无损快速判别野生冬虫夏草的方法，步骤如下：(1)分别使用2种近红外光谱仪采集样品的近红外光谱；(2)对采集的光谱划分样本集，并剔除异常值，得到校正集和验证集；(3)分别选择2种近红外光谱仪的最佳光谱预处理方法，解决基线漂移及无用的背景光谱信息影响；(4)采用改进的主成分分析法的模型转移方法，确定最佳转移集样本数、转移方向；(5)根据步骤(3)中的最佳光谱预处理方法和步骤(4)中的最佳转移集样本数，对验证集进行模型转移，并对模型进行评价。本发明在保护冬虫夏草原始形状的情况下，结合模型转移技术快速筛选野生的冬虫夏草，扩大模型在不同仪器上的适用性。基于模型转移技术对野生冬虫夏草进行无损快速鉴别的方法。该方法结合模型转移技术对野生冬虫夏草进行快速筛选，在保护冬虫夏草原形的情况下，扩大了模型在不同仪器上的适用性。一种基于模型转移技术的野生冬虫夏草无损快速鉴别方法，包括以下步骤：a)用2台近红外光谱仪采集样品的近红外光谱; (b)将采集到的光谱划分为样本集，去除异常值，得到校正集和验证集; (c)选择2种最优的近红外光谱仪光谱预处理方法，并求解基线漂移和未利用的背景光谱信息的影响; (d)通过使用改进的主成分分析方法的模型转移方法确定最优转移集样本数和转移方向; (e)基于最优光谱预处理方法和最优转移集样本数对验证集进行模型转移，得到判别结果，并对模型进行评价。   6
本发明提供一种基于多帧信息融合具有遮挡感知的自动精液分析方法。本发明首次提出边缘敏感的U‑Net模型与基于联合概率数据关联的遮挡感知跟踪器结合，实现精确、稳定的精子检测和追踪。得益于本发明基于像素级轮廓分割及基于多帧目标轮廓的重叠推断，本发明可以能将距离较近但又未重叠的两个或多个精子精准区分，并提供准确的头部定位；能对目标的重叠的发生、进行、结束作出准确的预测和判断；能够有效地匹配重叠前后的精子，保证追踪的一致性。本发明可以被便捷地整合到现有的计算机辅助精子分析系统中，提供准确性更好、鲁棒性更好的精液分析数据。一种基于多帧信息融合和屏蔽传感的精液自动分析方法，用于使用计算机评估胚胎医师的雄性生殖功能。本发明利用基于联合概率数据关联的边缘敏感U-网模型结合屏蔽感知跟踪器，实现精液的准确，稳定检测和跟踪，从而为精液分析数据提供更好的准确性和鲁棒性。该方法包括读取精液样本视频数据(S1)。 视频数据被预处理。 通过训练边缘敏感的U-网模型(S2)获得精子或精子群落的轮廓。 连续地确定重叠条件(S3)。 跟踪和更新目标的状态。 根据最终跟踪结果计算精液活性参数和精液样品中的精液浓度(S4)。 根据视频数据的分辨率信息自动切割视频数据的中心有效区域。   6
本发明公开了一种基于轻量化网络的掌纹感兴趣区域提取方法及系统，该方法包括：收集掌纹图像，构建掌纹数据库；基于Yolov5‑lite对掌纹图像进行初定位；基于改进的U‑Net网络对初定位掌纹图像进行关键点检测，得到关键点；基于关键点的连线与水平线的夹角校正初定位掌纹图像；基于连线和连线的中垂线构建直角坐标系；在直角坐标系内对校正后的初定位掌纹图像进行区域截取，得到掌纹感兴趣区域。该系统包括：数据收集模块、初定位模块、关键点定位模块、角度校正模块、坐标系构建模块和区域分割模块。通过使用本发明，构建两阶段的网络模型，降低模型运行成本，实现在嵌入式设备中部署，进而实现实时快速的掌纹识别。本发明可广泛应用特征识别技术领域。基于轻量级网络的掌纹感兴趣区域提取方法。构建了两级网络模型，降低了模型的运行成本，实现了在嵌入式设备中的部署，实现了实时、快速的掌纹识别。该方法包括采集掌纹图像，构建掌纹数据库，基于Yolov5‑lite对掌纹图像进行目标检测，得到初级定位掌纹图像。 基于改进的U-Net网络对所述初始定位掌纹图像的关键点进行检测，得到第一关键点和第二关键点。 基于所述第一关键点和所述第二关键点的连线与水平线的夹角对所述初始定位掌纹图像进行校正。 基于所述连线和所述连线的垂直ector构建直角坐标系。 在直角坐标系中对修正后的初始定位掌纹图像进行区域截取，得到掌纹感兴趣区域。包括独立权利要求的一种基于轻量级网络的掌纹感兴趣区域提取系统。   4
本发明公开一种增强大模型对外挂知识库记忆能力的方法，涉及语言模型优化技术领域；微调大模型，增强大模型对外挂知识库记忆能力：步骤1：将每个样本文本划分为不同段落，所述段落包括指令段落、输入段落和响应段落，步骤2：根据指令段落提取指令特征，步骤3：根据不同指令段落的权重将指令特征与解码器的全局隐藏输出表示相融合，形成指令数据集，步骤4：将指令数据集输入大模型，通过lora方式根据微调大模型，增强大模型对外挂知识库记忆能力；通过增强大模型对外部知识库的记忆力，使其在任务上的表现更加优越。在自然语言处理领域、机器翻译和对话生成领域的文本生成任务中增强大模型外部知识库记忆能力的方法。通过增强大模型对外部知识库的记忆，使大模型在任务上的性能更加优异。该方法包括将每个样本文本划分(步骤1)为不同的段落，该段落包括指令段落、输入段落和响应段落。 根据指令段落提取指令特征(步骤2)。 将指令特征与解码器的全局隐藏输出表示进行融合(步骤3)，根据不同指令段落的权重形成指令数据集。 将指令数据集输入(步骤4)到大模型中，根据lora模式对大模型的微调，增强大模型对外部知识库的记忆能力。本发明还公开了一种增强大型模型外部知识库存储能力的装置。  11
本公开提供了一种模型训练方法、目标跟踪方法、装置，涉及人工智能技术领域，尤其涉及深度学习、图像处理、计算机视觉技术等领域，可应用于光学字符识别(Optical Character Recognition，OCR)等场景。具体实现方案为：根据图文数据对第一模型进行第一预训练，得到第一模型在第二预训练中加载的预训练参数，根据第一图像样本集合及第二图像样本集合，构建训练数据，根据训练数据和预训练参数对第一模型进行第二预训练，得到第二模型。采用本公开，提高了模型精度。用于在人工智能领域中训练光学字符识别(OCR)模型的方法。 使用包括但不限于深度学习领域，图像处理领域和计算机视觉技术领域。本发明能够根据训练数据和预训练参数对第一模型进行第二次预训练，得到第二模型，提高了模型精度。 该方法使得训练模块能够基于第一训练数据对第二模型进行第二训练，从而提高模型的精确度。该方法包括根据图文数据对第一模型执行第一预训练。 获得预训练参数，并将其加载到第一模型的第二预训练中。 根据第一图像样本集和第二图像样本集执行训练数据构造处理。 根据训练数据和预训练参数对第一模型进行第二预训练，以获得第二模型。 预训练参数用于由图文数据表示目标对象类型。 提取图像数据。本发明还涉及一种目标跟踪方法。 (2)一种用于在人工智能领域中训练光学字符识别(OCR)模型的装置； (3)目标跟踪装置； (4)包括处理器和存储器的电子设备，用于在人工智能领域中训练OCR模型； (5)计算机程序产品具有用于在人工智能领域中训练OCR模型的指令集。 14
本发明公开了一种继电保护定值校核方法、装置和设备，包括：响应定值校核请求，获取待校核定值文件和调度定值文件，采用正则表达式提取待校核定值文件并生成多个第一数据树，通过开源库提取调度定值文件并按照生成多个第二数据树，将全部第一数据树和全部第二数据树输入预训练的大语言模型匹配确定叶子节点组，再通过大语言模型对各叶子节点组中的定值进行一致性比对，生成校核报告。整个继电保护定值校核过程基于大语言模型的语义理解能力，提升定值校核的准确率的同时进一步提高了定值校核的效率。继电保护定值校核方法。该方法提高了设置校核的准确性，提高了设置校核的效率。该方法涉及响应于设置验证请求，获取(101)待验证设置文件和预定设置文件。 利用(102)所述正则表达式从所述待校验定值文件中逐级提取所述定值，生成树状数据结构的多个第一数据树。 通过开源库遍历(103)调度设定值文件提取设定值，根据树形数据结构生成多个第二数据树。 将所述第一数据树和所述第二数据树输入(104)至预先训练的大语言模型中进行逐级匹配，确定匹配成功的叶子节点组。 通过所述大语言模型比较(105)每个所述叶子节点组中的所述固定值值是否一致，并生成验证报告。包括独立权利要求：(1)继电保护定值校核装置； (2)一种电子设备。 0
本申请涉及一种模型训练方法、装置、设备及计算机可读介质。该方法包括：将训练样本输入第一模型，并获取第一模型的全连接层输出的第一识别结果；将训练样本和第一识别结果输入第二模型，并获取第二模型的全连接层输出的第二识别结果，第一模型的参数量大于第二模型的参数量，第一模型的识别准确度大于第二模型的识别准确度；利用第一识别结果、第二识别结果和训练样本的预标注数据构建目标损失函数；利用目标损失函数调整第二模型中的参数，以使第二模型的识别准确度达到目标阈值，第二模型的输出结果与第一模型的输出结果相同时，识别准确。本申请解决了模型参数量大导致识别效率低的问题。模型训练方法。该方法解决了由于模型参数量大而导致的辨识效率低的问题。该方法涉及将训练样本输入到第一模型中。 利用所述第一模型的全连接层得到第一识别结果输出。 将所述训练样本和所述第一识别结果输入第二模型。 利用所述第二模型的全连接层得到第二识别结果输出，其中，所述第一模型的参数量大于所述第二模型的参数量。 通过所述第一识别结果和所述第二识别结果以及所述训练样本的预先标注数据构建目标损失函数。 调整所述第二模型中的参数，以判断所述第二模型的识别精度是否达到目标阈值。包括以下独立权利要求：模型训练装置； 电子设备； 以及存储用于训练模型的指令集的计算机可读介质。  11
本公开提供一种图像增强方法及装置、计算机可读介质和电子设备，涉及图像处理技术领域。该方法包括：获取待处理图像；将所述待处理图像输入到目标图像增强模型中，得到目标增强图像，所述目标图像增强模型是通过具有不同曝光时间的训练图像数据以及基于知识蒸馏的预训练过程得到的。本公开能够通过经过知识蒸馏得到的、轻量化的目标图像增强模型生成目标增强图像，降低模型推理时间，并且提升了目标图像增强模型对待处理图像的噪声抑制以及暗处细节恢复的能力，有效提高目标增强图像的图像质量。在智能手机中使用电子设备(索取)的图像增强方法。该方法使得能够通过知识蒸馏得到的目标图像增强模型生成目标增强图像，因此减少了模型推理时间，并且提高了待处理图像的噪声抑制和暗细节恢复能力，因此有效地提高了目标增强图像的图像质量。该方法涉及获得(S210)待处理的图像。 将所述待处理图像输入(S220)至所述目标图像增强模型，以获得所述目标增强图像。 所述目标图像增强模型是通过不同曝光时间的训练图像数据和基于知识蒸馏的预训练过程得到的。 得到所述训练图像数据。 其中，训练图像数据包括在同一拍摄场景下拍摄的不同曝光时间的图像数据。独立权利要求包括：图像增强装置； 存储用于图像增强的程序的计算机可读介质； 以及电子设备。 14
本发明提出了一种基于改进U‑Net模型的遥感建筑物影像提取方法。使用U‑Net模型作为骨干网络，在模型的跳跃连接阶段，加入协调注意力门控模块，以更好定位建筑物主体信息并有效整合不同级别语义信息。在模型的桥梁连接部分，引入了高效连续金字塔模块，使用分组的小尺度空洞卷积进行特征提取，并在组内进行特征分层叠加，强化了模型对于捕获建筑物主体间可能存在的空间上下文关系的能力。在模型的解码器部分，引入双向联级深度监督模块，按照从深到浅和从浅到深两个方向依次融合相邻解码器阶段所得的预测图，以实现对不同网络层特定监督，有效提升了模型的多尺度建筑物主体提取能力。基于改进U-Net模型的建筑物图像提取方法。协调注意力门控模块将通道注意力分解为两个一维特征编码过程，分别沿两个空间方向聚合编码器的输入特征，生成包含建筑主体两个不同空间方向的空间信息的坐标注意力热力图，可以互补应用于输入特征图，增强感兴趣对象的表征。 该方法提供了协调注意力选通模块，将编码器传入跳过连接的特征选通激活，不仅可以减少语义通道的不同层次特征融合，有效整合建筑物本身的颜色、纹理等； 并且同时能够更加准确的定位建筑主体结构的相对位置。该方法涉及对原始遥感建筑物图像进行预处理。 构建U-Net模型。 在跳过连接单元中增加了协调注意力门控模块。 对每层卷积编码结果进行门控激活。 在解码器单元中引入了双向电平监测结构。 以所述双向联合监测结构得到的边缘特征图和模型输出预测图作为监测依据，对所述改进的U-net模型进行优化训练。 所述步骤处理后的图像用于完成遥感建筑的图像提取。   6
本发明公布了一种基于PSPNet的遥感数据土地覆盖分类方法，采用多尺度融合分割模块构造多尺度特征，对土地覆盖类型进行分析，快速建立辨识模型，通过自适应损失算法，弥补样本稀疏类别不平衡造成的信息损失，自适应样本权重，采用预训练网络迁移的方法，通过图像数据库丰富样本多样性，实现对不同类型雷达遥感图像的辨识分割，其算法复杂度低，计算周期短，可适应样本稀疏不平衡下的遥感图像，并对其像素点进行精准语义分割，将土地图片进行区域类型分类，在图像处理领域具有普适性和高可移植性。该方法涉及采集土地覆盖类型的遥感影像数据。 对已知土地覆盖类型的遥感影像数据样本集进行数据预处理操作。 预处理后得到图像。 近红外通道和红色通道融合后得到一个像素点。 得到遥感影像数据样本集公共nse图片样本。 表示一个原始遥感图片像素点。 图像被分成包含像素的小块。   6
本发明提出基于U‑Net的自监督单目深度估计算法，解决U‑Net网络未充分利用全尺度特征图的问题，提高了网络对于边界处和遮挡处的深度预测精度，其包括以下步骤：1)构建由卷积层和池化层以及下采样层所组成的编码器来提取输入图像特征，充分利用不同尺度的特征信息；2)构建由卷积层、池化层、上采样层和通道信息融合层组成的解码器来利用接收到的编码器层特征，从而生成精密的深度图；3)通过将编码器的多通道信息分组连接到解码器，从而实现深层特征和浅层特征融合，以减少视觉伪影；4)通过逐像素平滑度损失和图像重投影损失结合来优化模型。增强的基于U-Net的自监督单目深度估计算法。该算法通过使用通道注意力模块增强重要通道信息的权重，改进了原有编码器和解码器的结构，充分利用了解码器对多尺度特征图的信息，在保证速度的同时有效提高了检测精度。该算法具有用于构造编码器的指令集。 卷积层、池层和下采样层用于提取输入图像特征。 利用接收到的编码器层特性构建卷积层、池层、上采样层和信道信息融合层。 生成精确的深度图。 编码器的多路信息包连接到解码器。 通过组合逐像素平滑度损失和图像再投影损失来优化模型。 改变频道关注模块的频道号。   6
本发明公开了一种文本抽取方法、装置、设备及存储介质，属于机器学习技术领域。本发明通过获取待抽取文本，并基于待抽取文本确认对应的抽取条件，根据抽取条件生成对应的实体标签数据，再将待抽取文本和实体标签数据输入预训练的全局首尾神经网络模型，通过全局首尾神经网络模型抽取出目标文本。在本发明实施例的文字提取的过程中，采用阅读理解技术，根据不同的待抽取文本确定抽取条件，在得到抽取条件后匹配记有类别的描述信息的实体标注数据，再通过预训练的全局首尾神经网络模型进行抽取，以解决金融领域里信息抽取中实体嵌套的问题，提高了识别准确率。用于机器学习技术领域的文本提取方法。该方法使得通过预先训练的全局端到尾模型神经网络对目标文本进行提取，以解决金融领域信息提取中的实体嵌套问题，因此提高了识别准确率。该方法包括获得(S10)待提取的文本。 基于所述待提取文本确认对应的提取条件。 根据所述抽取条件生成(S20)与所述待抽取文本对应的实体标签数据。 将所述待提取文本输入(S30)预先训练的全局端到神经网络模型，用于提取目标文本。 基于不同类型的文档构建对应的抽取问题，并获取对应的待抽取实体的所有类型。 生成实体类型描述文本。 基于对所述实体标签中的文档中的文本的实体类描述文本生成训练集数据。独立权利要求包括：(1)文本提取装置； 以及(2)用于存储用于提取文本的指令集的存储介质。  12
本申请公开了一种预训练模型的训练方法、装置、存储介质和设备，随机选取一个或多个词语进行遮挡处理，并将被选取到的词语标识为待测词。对于每个待测词，若低频词字典记录有待测词，则从低频词字典中查找与待测词对应的低频向量，并将低频向量，标识为待测词的辅助向量。将待测词进行向量转换，得到待测词的词向量和位置向量。将词向量、位置向量和辅助向量进行相加，得到特征向量。将特征向量输入至编码器中，得到输出向量。将输出向量作为任务损失函数的输入，计算得到待测词的预测结果，不断调整任务损失函数的各项参数，直至预测结果的正确率大于预设阈值时，确认预训练模型训练成功。本申请所示方案，能够有效提高预训练模型的模型效果。用于训练自然语言处理领域的预训练模型的方法。该方法使得能够不断调整任务损失函数的各个参数，直至预测结果的准确度大于预设阈值，因此有效提高了预训练模型的模型效果。该方法包括从来自相同语言材料的每个单词中随机选择多个单词以进行屏蔽。 将选定的词语标记为待测词语。 在预先构建的低频词词典中针对每个待测词语记录该词语时，查找与该词语对应的低频向量。 零向量被标记为词的辅助向量。 对所述待测试词进行向量转换，得到所述词向量和所述位置向量。 将特征向量输入到编码器以获得由编码器导出的输出向量。 输出向量作为任务损失函数的输入。 对所述词语的预测结果进行计算，得到预测结果。 参数不断调整。 检测预测结果的准确率约大于预设阈值。 预训练模型训练完成。独立权利要求还包括：一种用于训练预训练模型的装置； 以及计算机可读存储介质，用于存储用于训练自然语言处理领域中的预训练模型的指令集。  12
本发明公开了一种基于对比学习和大语言模型的图数据语义搜索方法。该方法包括：获取用户问题的关键文本；基于多模语义相似模型，从图数据库获取与所述关键文本匹配的目标图数据；利用大语言模型对所述目标图数据进行文本重构，得到所述目标图数据的重构文本；所述重构文本和所述目标图数据的语义相同；将所述重构文本确定为所述用户问题的语义搜索结果；其中，所述多模语义相似模型通过对比学习的训练方法，对多模态的图向量和文本向量融合训练得到。本发明实施例可以降低运维难度，提高答案搜索的准确性。用于通过使用电子设备(要求保护的)例如数字计算机基于对比学习和大型语言模型执行图像数据语义搜索的方法。 用途包括但不限于膝上型计算机、台式计算机、工作台、个人数字助理、服务器、刀片服务器、大型计算机、移动设备、个人数字处理和蜂窝电话。该方法使得能够降低运维难度，提高答案搜索的准确性，利用大语言模型对目标图数据进行文本重构，得到重构文本，从而能够简化图数据语义搜索系统的操作，也能够降低系统的维护难度。该方法包括获得用户问题的关键文本。 基于多模式语义相似度模型从图像数据库中获取与所述关键文本匹配的目标图像数据。 利用大语言模型对所述目标图形数据的文本进行重构，得到重构文本，所述重构文本与所述目标图像数据的语义相同。 将所述重构文本确定为所述用户问题的语义搜索结果，其中，所述多模态相似度模型是通过比较学习的训练过程对所述多模态的图像向量和文本向量进行融合训练得到的。独立权利要求还包括：一种用于利用电子设备进行基于对比度学习和大语言模型的图像数据语义搜索的装置； 以及计算机可读存储介质，所述计算机可读存储介质包括用于通过使用电子设备执行基于对比度学习和大型语言模型的图像数据语义搜索的指令集。  11
本发明提出一种基于多头注意力机制和二维卷积操作的文本分类方法，涉及自然语言处理的技术领域，首先进行预处理操作，然后构建神经网络，将预处理操作后的文本输入神经网络，得到字粒度级别的字向量，体现了不同汉字字符在文本中的重要程度，接着形成多头注意力机制层，采用一种预训练字向量与多头注意力机制融合作为语义表示的配合方式，得到文本表示张量，然后进行二维卷积操作，提取文本特征，融合不同的多头注意力机制的专注点，利用卷积操作特征向量对神经网络进行文本分类训练，并调整多注意力机制层的权重，得到训练好的神经网络，最后测试得到分类结果，可以在较小的数据集上取得良好的分类效果和泛化能力，且拟合较快。基于多头注意机制和二维卷积运算的文本分类方法，用于计算机科学领域和人工智能领域的自然语言处理。 使用包括但不限于智能语音问答系统，欺诈短信识别，网络评论情感识别。计算量小，训练速度快，同时兼顾了良好的文本分类效果。 在较小的数据集上取得了良好的分类效果和推广能力。 配件快速。该方法包括确定文本数据集，以及将文本数据集划分(S1)为训练集和测试集。 预处理训练集中的文本(S2)。 建立神经网络(S3)。 文本被输入(S4)到神经网络的嵌入层以获得词向量。 形成字向量矩阵(S5)。 融合文本增强语义表示以获得文本融合语义表示，对文本融合语义表示执行二维卷积运算，并且输出卷积运算的特征向量(S6)。 使用卷积运算特征向量来训练用于文本分类的神经网络，并且调整多注意力机制层的权重(S7)以获得训练的神经网络。 对测试集中的文本进行预处理，输入训练好的神经网络，得到分类结果(S8)。本发明涉及一种基于多头注意机制和二维卷积运算的文本分类方法，包括以下步骤：(1)基于多头注意机制和二维卷积运算对文本进行分类； (2)存储基于多头注意机制和二维卷积运算的文本分类程序的计算机可读存储介质； (3)基于多头关注机制和二维卷积运算的文本分类系统。  12
本发明涉及一种基于深度学习和高斯混合的工业产品表面缺陷检测方法。借助在ImageNet上预训练的模型提取输入数据的表征信息；使用高斯混合模型拟合正常数据的表征分布；计算测试样本与正常数据表征分布之间的马氏距离作为该样本的异常值，利用少量缺陷数据获得阈值；借助阈值与异常值判断样本是否为缺陷产品。本发明实现了对工业产品表面缺陷更好的检测效果。基于深度学习和高斯混合的工业产品表面缺陷检测方法。该方法实现了对工业产品表面缺陷较好的检测效果。该方法涉及预先在ImageNet ILSVRC2012数据集上训练EffectiveNet-B5网络模型。 在工业产品的表面上收集图像数据，并且执行图像清洁操作。 选取一个正常产品数据，即无缺陷产品的图像并采用预先训练好的网络模型提取图像表征信息。 使用高斯混合模型来拟合无缺陷产品表征信息的分布。 使用最小量的缺陷产品数据，计算表征信息与高斯混合模型之间的距离的加权和作为离群值并且选择最小值作为缺陷检测阈值。 计算一个测试样本的异常值并利用所述缺陷检测阈值判断该样本是否为缺陷产品。   6
本发明提供了面向产业领域科技服务资源图谱的实体识别方法，其通过训练一个命名实体识别模型来进行实体识别，该模型包括：BERT模型，用于提取输入文本中每个字符的字符向量，得到第一字符向量序列；BiLSTM模型，用于根据含词性的字符向量序列提取各字符的上下文信息得到输入文本对应的第二字符向量序列，含词性的字符向量序列是通过对第一字符向量序列添加各字符的词性特征得到；GCN模型，用于将图邻接矩阵与第二字符向量序列进行融合得到第三字符向量序列，图邻接矩阵是通过对输入文本进行依存句法分析得到的，表示字符间依存关系；CRF模型，用于根据第三字符向量序列进行特征解码，得到命名实体识别结果；本发明可提升命名实体识别模型的精度。用于在电子设备中使用的命名实体标识模型(要求保护)。该方法能够提高实体识别模型的精度。该模型具有用于提取包含多个字符的输入文本中的每个字符的字符向量，得到与输入文本对应的第一字符向量序列的BERT模型。 所述BERT模型提取每个字符的上下文信息，得到所述输入文本对应的第二字符向量序列。 利用GCN模型将所述输入文本对应的图像邻接矩阵与所述第二字符向量序列进行融合，得到所述输入文本对应的第三字符向量序列。 利用CRF模型，用于根据所述输入文本对应的第三字符向量序列进行特征解码，得到命名实体识别结果。独立权利要求还包括用于：命名实体识别模型训练方法； 一种命名实体识别方法； 以及计算机可读存储介质，所述计算机可读存储介质用于存储用于识别命名实体的指令集。  12
本发明公开了一种基于孪生交互和微调表示的中文语义匹配方法，首先以RoBERTa‑WWM‑EXT预训练模型完成文本的向量初始化，针对初始特征向量构造内嵌了软对齐注意力机制(SA‑Attention)和BiLSTM训练层的孪生结构，用以增强句对之间的语义交互性。其次将两个待匹配文本连接起来接入RoBERTa‑WWM‑EXT预训练模型进行向量化，将连接的向量化结果输入LSTM‑BiLSTM网络层做增强训练，用以强化句子内部的上下语义关系。然后搭建可微调RoBERTa‑WWM‑EXT初始向量的训练模型，用以产生经过标签监督微调的文本向量，从而进一步增强向量对文本间语义关系的表示力度，最终达到提升中文语义匹配准确率的目的。基于孪生交互和微调表示的中文语义匹配方法。该方法使得能够构建能够对RoBERTaWWMEXT初始向量进行微调的训练模型，以生成经过标签监督微调的文本向量，增强了向量表达文本之间语义关系的强度，最终达到提高中文语义匹配准确率的目标。该方法包括将两个待匹配文本连接到一个RoBERTa-WWM-EXT预训练模型上。 文本的向量初始化完成。 交叉输入向量，嵌入双向长短期记忆训练层的软对齐注意力机制和孪生结构。 将文本连接成单句。 在RoBERTa-WWM-EXT预训练模型的基础上增加了线性转换层和SoftMax激活层。 构建可对文本的初始向量的表示参数进行微调的语句对预分类模型。 将数据集连接到完成的句子对预分类结构。 训练句子对预分类模型。 提取一个Logits输出层作为文本对的微调后的特征向量。 向量被连接以参与主有限伙伴关系的前两个全连接层的训练。  12
本发明公开了一种动态认知诊断联合深度学习模型的认知干预系统，提供经典量表对患者认知水平进行评分，并提供认知干预项目对患者认知水平进行诊断；认知干预项目在使用之前采用QuesNet模型预训练，实现无监督异构干预项目表征；在进行认知干预项目的任务时，利用EKT模型结合QuesNet模型对认知干预项目预训练的结果进行用户知识状态追踪；通过基于用户的协同过滤算法，可以按照现有各用户的知识追踪，向相似用户推荐对其效果好的项目，也可依据QuesNet与EKT模型的结果对效果差的项目进行改进剔除。本发明可实现对干预项目的综合评估以及干预过程对用户认知水平的动态诊断，以及提供个性化干预方案的动态设计方案。动态认知诊断结合深度学习模型的认知干预系统应用于教育游戏竞赛领域、医疗诊断领域、智能客服和个性化医疗康复领域。可实现干预项目的综合评价和干预过程中用户认知水平的动态诊断。 可以提供个性化干预方案的动态设计方案。 项目的效果差异可以根据Quesnet和EKT模型的结果进行改进。 所述认知干预系统设有用于基于当前用户的协同过滤算法的推荐模块。 可以推荐对相似用户效果好的物品，拒绝效果不好的物品。该系统具有用于预训练认知干预项目的问题网络模型。 推荐模块，设置有基于用户的协同过滤算法的推荐模块。 推荐模块根据当前用户的知识追踪，将效果好的物品推荐给相似用户。 EKT模型根据问句模型和EKT模型的结果，对效果不好的项目进行改进和拒绝。  11
本公开提供了一种基于大模型的意图识别方法、装置、电子设备和存储介质，涉及人工智能领域，具体涉及NLP、大模型、大语言模型LLMs、深度学习等技术领域。具体实现方案为：根据输入语句，获取至少一个第一语句意图对；其中，第一语句意图对中包括与输入语句相似的候选语句及候选语句所属的候选意图；根据至少一个第一语句意图对，生成第一提示信息；基于第一提示信息，对输入语句进行意图识别，得到输入语句所属的目标意图。基于大模型的意图识别方法。该方法使得能够基于提示信息识别输入语句的意图，以高效的方式获得输入语句的目标意图。 该方法允许用户选择候选意图所属的候选语句，使得用户能够选择出与目标语句相似的候选语句，因此提高了意图识别过程的准确性。该方法涉及获得输入句子。 根据所述输入语句得到第一语句的意图对，所述意图对包括与所述原始输入语句相似的候选语句和所述候选语句所属的候选意图。 根据至少一个意图对生成提示信息。 基于所述提示信息对所述输入语句的意图进行识别，得到一个输入语句的目标意图。 根据所述问答对和所述意图识别范围生成第一提示信息。独立权利要求还包括用于：(1)基于大模型的意图识别装置； (2)电子设备； (3)非瞬时计算机可读存储介质，用于存储基于大模型的意图识别指令集； 以及(4)计算机程序产品，其包括用于基于大型模型识别意图的指令集。  11
本发明提供一种图像分类方法、装置、电子设备与存储介质，其中方法包括：确定待分类的图像；基于分类模型，对所述图像进行多属性分类，得到所述图像的多属性分类结果；所述分类模型是在预训练编码器的基础上，基于第一样本图像及其对应的样本多属性分类结果训练得到的；所述预训练编码器是基于多个图像处理任务进行自监督学习得到的模型中的编码器。本发明提供的方法、装置、电子设备与存储介质，训练流程简单，方法复用性强，节省了数据的标注成本，同时极大提升了模型在多属性分类任务上的分类精度，在此基础上，应用分类模型对输入的图像进行多属性分类，实现了通过同一网络模型识别出图像的不同属性。图像分类方法。训练过程简单， 该方法可重用性强， 节约了数据的标注成本， 同时，大大提高了模型对多属性分类任务的分类精度，在此基础上，应用分类模型对输入图像进行多属性分类，实现了同一网络模型识别图像的不同属性。该方法包括确定(110)要分类的图像。 基于分类模型，对图像执行(120)多属性分类，以获得图像的多属性分类结果。 分类模型是基于第一样本图像和对应的样本多属性分类结果，基于预训练编码器训练得到的。 预训练编码器是基于多个图像处理任务的自监督学习得到的模型中的编码器。独立的权利要求书被包括在以下内容中： 1. 图像分类装置； 2. 一种包括处理器和存储器的电子设备； 以及 3. 一种存储用于处理图像的计算机程序的非瞬态计算机可读存储介质分类方法。 14
本发明公开了一种基于三平面融合边缘U‑Net的脑肿瘤分割方法，包括步骤：将获取的脑肿瘤MR图像分为训练集和验证集，并对训练集图像进行预处理；基于U‑Net架构，通过对脑肿瘤MR图像进行三平面的分割，以边缘辅助模块作为跳跃连接构建边缘U‑Net模型，将提取的图像特征和边缘特征进行融合；采用交叉熵损失函数和边界损失函数相结合的组合损失函数，对边缘U‑Net模型进行训练，获得最佳模型；将预处理脑肿瘤图像数据集和边缘特征图像数据集一起作为不同平面的数据，输入到三个网络结构中以训练最优参数，得到最优的网络分割结果；根据最有分割结果得到三维概率图。本发明能提高分割的精度和分割出整体肿瘤的不同部分。基于三平面融合边缘U-Net的脑肿瘤分割方法。该方法提高了分割的准确性，对整个肿瘤的不同单元进行分割。该方法包括将采集的脑肿瘤磁共振(MR)图像分成训练组和验证组。 对所述训练集图像进行预处理，得到第一预处理脑肿瘤图像数据集和第二边缘特征图像数据集。 采用组合交叉熵损失函数和边界损失函数的组合损失函数训练边缘卷积神经网络(U-Net)模型，优化边缘U-Net模型的参数，得到最佳模型。 将所述第一预处理脑肿瘤图像数据集，和所述第二边缘特征图像数据集作为不同平面的数据，分别输入到所述边缘U-Net网络模型的三个网络结构中，训练出最优参数并得到最优网络分割结果。 根据所述最优分割结果得到三维概率图。  7
本发明实施例提供一种中文纠错模型的训练方法、中文纠错方法及装置，所述训练方法包括：基于第一训练数据集对初始模型进行预训练，得到第一预训练模型；基于第一训练数据集和第二训练数据集对第一预训练模型进行精调，得到中文纠错模型；第一训练数据集包括多个样本四元组，样本四元组是由中文语料、拼音序列、笔画序列以及图片序列四个元素组成的；第二训练数据集包括多个相似样本四元组，相似样本四元组是基于任一中文语料中的相似字对该中文语料中与其对应的字进行替换得到的。本发明实施例提供的中文纠错模型的训练方法、中文纠错方法及装置，提高了训练数据的生成效率和丰富性，使得训练出来的中文纠错模型纠错效果较好。本发明涉及一种利用电子装置训练汉语素材纠错模型的方法，特别是一种利用电子装置训练汉语素材纠错模型的方法。该方法提高了训练数据的生成效率和丰富度； 具有良好的纠错效果。该方法包括基于第一训练数据集对初始模型进行预训练以获得第一预训练模型。 基于第一训练数据集和第二训练数据集微调第一预训练模型以获得中文纠错模型。 第一训练数据集具有多个样本四元组。 样本四元组具有汉语素材，拼音序列，笔画序列和图像序列四个要素。 通过基于任何汉语材料中的相似词替换汉语材料中的相应词来获得相似样本四元组。还包括独立的权利要求： 一种汉语校正方法； 中文纠错模型训练装置； 中文纠错装置； 以及 一种非临时性计算机可读存储介质，包括一组用于执行中文纠错模型训练方法的指令。  11
本发明实施例公开了一种用于物联网防护的注入攻击监测方法及系统，方法包括：构建初始BERT模型；获取http请求数据集，根据http请求数据集对构建初始BERT模型进行训练，生成目标BERT模型；获取待监测的目标http请求的url，将目标http请求的url输入目标BERT模型，根据目标BERT模型的输出结果，获取注入攻击监测结果。本发明实施例把自然语言模型改造以适应这个特定的任务，将脚本注入问题当作自然语言模型的分类问题来处理，计算处理的最小单元从单词缩小为字符，使监测结果更精准有效，甄别注入类攻击行为。本发明提供的监测方法在物联网安全防护中应用方便，效果良好。使用诸如网站，应用或开放的注入攻击监视系统的用于物联网(IOT，物联网)保护的注入攻击监视方法API 。监测结果更加准确有效，筛选出注入式攻击行为。 本发明在物联网安全中应用方便，效果好。 计算过程的最小单位从单词减少到字符。该方法涉及构造初始BERT模型。 安HTTP 获得请求数据集。 根据HTTP请求数据集训练所构造的初始模型。 生成目标模型。 一种URL 靶的HTTP 获得要监视的请求。 所述的URL 靶的HTTP 获得要监视的请求。 所述的URL S个靶HTTP 请求被输入到目标模型中。 根据BERT模型的输出结果得到注入攻击监测结果的结果。独立的权利要求书包括： (1)物联网保护注入攻击监测系统； (2)非易失性计算机可读存储介质。  12
本发明提供了一种动态分析的工业品相似度计算方法和系统，包括：步骤S1：在Bert模型中添加输入层，对输入到Bert模型的行业数据先进行预处理再进行输入；步骤S2：对Bert模型进行参数优化，先使用通用参数进行模型训练，得到实际模型训练类别，再结合训练参数特点，预设指标后对损失函数进行收敛，得到实际模型训练结果；步骤S3：对实际模型训练结果进行相似度计算，得到符合预设条件的工业品。本发明从业务方面解决了因买卖双方对工业品的定义存在差异而导致商业关系匹配困难的痛点问题，并且适用于多种业务场景。一种用于数据处理领域的动态分析的工业产品相似度计算方法。本发明解决了因买方和卖方对工业产品的定义不同而导致的业务关系难以匹配的问题，适用于多种业务场景。 本发明从公司成本上提高了相关工作人员的效率，大大降低了人工成本，只需修改数据源应用于相应的服务场景即可。该方法包括在BERT模型中添加输入层。 对输入到BERT模型的工业数据进行预处理。 对BERT模型进行参数优化处理，得到实际的模型训练课程。 结合训练参数特征。 对损耗函数进行收敛，得到预设指标后的实际模型训练结果。 对实际模型训练结果进行相似度计算，得到满足预设条件的工业产品。本发明还涉及一种动态分析的工业产品相似度计算系统。  12
一种基于用户反馈的大语言模型对话生成方法及装置、计算机可读存储介质、终端，所述方法包括：接收当前会话轮次输入的问题；将所述问题输入第一预设大语言模型，得到第一预测结果，其中，所述第一预设大语言模型至少用于根据输入的问题预测用户的初级反馈信息；根据所述问题、所述第一预测结果和预设记忆库生成输入数据，其中，所述预设记忆库存储有用户对历史上至少一次会话轮次的对话的纠正反馈；将所述输入数据输入第二预设大语言模型，得到第二预测结果，其中，所述第二预设大语言模型用于根据输入数据预测对应当前会话轮次的增强对话回复以及对所述问题的理解。本发明可以使得对话系统变得更加智能，具有知识实时性和个性化。基于用户反馈的大语言模型对话生成方法。该方法使得会话系统更加智能化。 解决了现有过程由于语言文本偏差导致召回率较低的问题，从而提高了召回率，进一步提高了反馈信息的准确性。该方法包括接收(S11)当前会话转向输入的问题。 将所述问题输入(S12)第一预设语言大模型，得到第一预测结果，所述第一预设语言大模型用于根据输入的问题预测用户的初级反馈信息。 根据所述问题、所述第一预测结果和所述预设记忆库生成(S13)所述输入数据，所述预设记忆库中存储有用户历史上一次会话轮次的修正反馈。 将所述输入数据输入(S14)第二预设大型语言模型，得到第二预测结果，所述第二预设大型语言模型用于根据所述输入数据预测当前会话轮次对应的增强会话回复对问题的理解。独立权利要求包括以下内容：(1)基于用户反馈的大型语言模型对话生成装置； (2)一种计算机可读存储介质，其存储有基于用户反馈的大型语言模型对话生成程序； 以及(3)终端。 8
本发明公开了基于预训练模型的文本相似度识别方法及系统，对第一和第二文本分别进行编码处理得到第一和第二文本向量；对第一和第二文本向量进行编码，得到第一文本的原始句向量和字向量、第二文本的原始句向量和字向量；将第一文本的字向量转换为第一文本的更新句向量；将第二文本的字向量转换为第二文本的更新句向量；将第一文本的原始句向量与第一文本的更新句向量进行结合，得到第一文本的最终句向量；同理，得到第二文本的最终句向量；为第一和第二文本的最终句向量分别添加注意力分数；将添加注意力分数的第一和第二文本的最终句向量进行维度转换，将进行维度转换后的两个句向量进行分类得到识别结果。基于预先训练的模型识别文本相似度的方法。该方法使句子向量获取方法多样化，为文本相似度任务提供了一种高效的方法并有效提高了准确率。该方法包括分别对第一文本和第二文本进行编码，得到第一文本向量和第二文本向量。 对第一文本向量和第二文本向量进行再次编码，得到第一文本的原句向量、第一文本的词向量、第二文本的原句向量和第二文本的词向量。 将所述第一文本的词向量转换为所述第一文本的更新后的句向量。 将所述第二文本的词向量转换为所述第二文本的更新后的句向量。 将所述注意力分数分别添加到所述第一文本和所述第二文本的最终句向量中。 对添加注意力分数的第一文本和第二文本的最终句子向量进行维度转换，并对维度转换后的两个句子向量进行分类，得到相似或不相似的识别结果。包括独立权利要求：(1)基于预训练模型的文本相似度识别系统； (2)电子设备； 以及(3)存储用于基于预训练模型识别文本相似度的程序的存储介质。  12
本发明涉及一种基于BERT无监督文本分类的舆情分析方法和系统。该方法的步骤包括：定义类目关键词列表；利用BERT模型和无标注语料扩展类目关键词列表，根据扩展的类目关键词列表构建类目指示词表；通过类目指示词表和无标注语料训练BERT模型，用于预测类目指示词所属的类目；利用训练所得的BERT模型预测舆情文本所属的类目；根据BERT模型的预测结果进行舆情分析。本发明通过BERT语言模型和大规模无标注语料，能够得到效果较好的文本分类模型并实现舆情分析，可以用于热点话题发现、有害信息检测、自动生成舆情信息分类训练集等应用场景。基于BERT无监督文本分类进行从政务领域扩展到企业服务、个人服务、行业研究等领域的舆情分析的方法。该方法能够在不大规模标注语料的情况下，获取大规模标注语料，提高分类效果，提高情感分析能力，提高舆情分析能力，训练得到效果良好的文本分类模型。 该方法可用于热点话题发现、有害信息检测、自动生成舆情信息分类训练集和应用场景。该方法包括定义类别关键字列表。 采用BERT模型和无标注语料对类别关键词列表进行扩展，根据扩展后的类别关键词列表构建类别指标词表，通过类别指标词表和无标注语料训练BERT模型，预测类别指标所属类别。 利用训练后的BERT模型对所述舆情文本的类别进行预测。 基于所述BERT模型的预测结果进行舆情分析。包括独立权利要求：(1)基于BERT无监督文本分类的舆情分析系统； (2)电子设备； (3)一种计算机可读存储介质，其存储有用于执行基于BERT无监督文本分类的舆情分析的程序。  12
一种数据处理方法，涉及人工智能领域，包括：获取第一文本；第一文本为用户的文本处理请求；根据第一文本，通过第一信息来源获取与第一文本相关的第二文本，以及通过第二信息来源获取与第一文本相关的第三文本；根据提示prompt、第二文本和第三文本，通过大语言模型，得到第二文本和第三文本中的目标文本；prompt指示基于第二文本和第三文本的关系从第二文本和第三文本中确定正确的文本内容；根据目标文本和第一文本，通过大语言模型，得到第一文本的回复文本。本申请通过构建提示来引导大语言模型从不同来源的文本中确定正确的文本，并将该文本作为大语言模型的输入，得到回复文本，可以提高回复文本的准确性。一种人工智能数据处理方法，利用数字计算机或数字计算机控制的机器，模拟、延伸和扩展人类的智能，感知环境，获取知识，利用知识获得最佳效果。本申请通过构建提示，引导语言大模型从不同来源的文本中确定正确的文本，并将该文本作为语言大模型的输入，得到回复文本，提高了回复文本的准确性。该方法涉及获得(501)第一文本。 第一文本为用户的文本处理请求。 根据所述第一文本获取(502)通过所述第一信息源与所述第一文本相关的第二文本。 获取通过所述第二信息源与所述第一文本相关的第三文本。 根据所述提示、所述第二文本和所述第三文本获取(503)通过所述语言大模型在所述第二文本和所述第三文本中的目标文本。 提示指示基于第二文本和第三文本之间的关系，从第二文本和第三文本中确定正确的文本内容。 根据所述目标文本和所述第一文本获得(504)所述第一文本通过语言大模型的回复文本。独立权利要求包括用于：数据处理装置； 计算机存储介质，其存储用于人工智能的计算机程序； 用于人工智能的计算机程序产品； 一种用于人工智能的芯片。  11
本发明公开了一种图像处理方法、装置、设备及可读存储介质，该方法包括：获取目标图像；将目标图像输入至量化后的目标深度神经网络模型进行分类/检测，得到输出结果；按照与输出结果对应的策略，对目标图像进行处理；其中，量化得到目标深度神经网络模型的过程，包括：获取预训练得到的浮点型的深度神经网络模型；提取深度神经网络模型的权重特征；利用权重特征，确定出量化策略；按照量化策略，对深度神经网络模型进行量化，得到目标深度神经网络模型。在该方法中，量化得到目标深度神经网络模型的过程减少占用资源，缩短耗时，同时也能保障模型性能，从而使得图像分类/检测的性能得到保障，进一步可提高图像分类处理的性能。图像处理方法。该方法减少了占用资源，缩短了处理时间，保证了模型性能，从而保证了图像分类/检测的性能，提高了图像分类处理的性能。方法包括获得目标图像。 将所述目标图像输入量化后的目标深度神经网络模型进行分类/检测。 得到输出结果。 根据所述输出结果对应的策略对所述目标图像进行处理。 预先训练得到所述深度神经网络模型的浮点类型。 提取所述深度神经网络模型的权重特征。 根据所述权重特征确定量化策略。 对所述深度神经网络模型进行量化，得到所述目标深度神经网络模型。独立权利要求还包括：图像处理装置； 以及包括用于图像处理方法的指令集的可读存储介质。   4
本发明涉及一种商品属性抽取方法及其系统，包括 : 采用远程监督的方法获得训练集；通过self‑training结合局部标注的方法不断对训练集进行重新标注，获得修正后的属性标注语料；建立属性抽取模型，使用BERT‑bilstm作为编码器，对所述属性标注语料的句子和属性值进行编码，获得句子和属性值的编码结果；对所述句子和属性值的编码结果进行注意力机制变换，获得注意力机制变换后的编码结果；使用局部标注CRF方法对注意力机制变换后的编码结果进行BIO标签获取，优化属性抽取模型。其可以提取任意属性，实现大规模属性抽取，具有很好的扩展性。一种商品属性提取方法。本发明可以提取任意属性，从而实现大规模的属性提取，具有较好的扩展性。该方法包括通过远程监控方法获得训练集。 获得校正的属性标记语料库。 建立属性提取模型。 对所述属性标签语料库的句子和属性值进行编码。 获得句子和属性值的编码结果。 对句子的编码结果和属性值执行关注机制转换。 所述编码结果是经过注意机制转换后得到的。 对注意力机制转换后的编码结果执行内外开始(BIO)标签获取。本发明还涉及一种商品属性提取系统，包括数据预处理模块。  12
本公开关于一种资源召回方法、装置、设备及存储介质，涉及人工智能技术领域。该方法包括：基于预训练的特征提取模型的第一子模型，获取目标资源的目标特征向量；其中，目标特征向量用于指示目标资源的第一含义和第二含义，第一含义不同于第二含义；预训练的特征提取模型使用目标资源的特征向量中与正样本匹配的特征值进行预训练；基于预训练的特征提取模型的第二子模型，获取候选资源的候选特征向量；基于目标特征向量与候选特征向量的匹配度，确定与目标资源对应的至少两个类别的召回资源；其中，一个类别的召回资源与第一含义匹配，另一个类别的召回资源与第二含义匹配。一种用于由诸如移动电话的电子设备(所要求保护的)执行用于人工智能技术领域的目标资源回叫的方法。该方法通过预训练的子模型提取目标资源的目标特征向量，得到表征目标资源多义的特征向量， 提高目标特征向量的多样性表达能力，通过候选特征向量与候选资源的匹配程度来确定回叫资源。 本发明通过表达多义的特征向量匹配，提高了回叫资源的类型多样性，提高了使用回叫资源的搜索系统或推荐系统的丰富性，提高了对象账户的使用体验，从而将候选资源的类型确定为回叫资源。所述方法涉及获得目标资源的目标特征向量(S301)，其中所述目标特征向量用于指示所述目标资源的第一和第二含义。 预先训练特征值与目标资源的特征向量中的正样本相匹配的特征提取模型。 提取特征提取模型的子模型。 获得候选资源的候选特征向量(S302)。 根据目标特征向量与候选特征向量的匹配程度，确定与目标资源对应的类别的回叫资源(S303)，其中回叫资源的类型与第一含义匹配。独立的权利要求书包括： (1)用于由电子设备执行目标资源调用的设备； (2)计算机可读存储介质，其存储用于由电子设备执行目标资源调用的一组指令； (3)一种计算机程序产品，其存储一组用于由电子设备执行目标资源调用的指令。  11
本发明涉及智能办公技术领域，具体为基于AI PaaS平台的Elasticsearch文本向量化搜索系统，包括AI PaaS平台模块、Elasticsearch引擎模块、文本优化模块以及搜索输出模块；所述AI PaaS平台模块，搭建AI PaaS平台，创建文本搜索项目，设置搜索权限和访问权限，将选用的语言大模型集成到AI PaaS平台中，并采用FastAPI框架来构建Web应用，将AI PaaS平台装载到Web应用中；所述Elasticsearch引擎模块，采用Elasticsearch作为文档数据存储引擎，基于Elasticsearch引擎对大量文本数据进行搜索和分析，通过匹配关键字、理解和应用复杂的查询语句查询文本数据，通过文本向量化技术，搜索引擎能够更智能地理解用户查询，提供更准确的搜索结果，基于向量化的方法还能够实现相似性匹配，为用户推荐与其查询语义相关的文档，从而提升搜索体验。基于AIPaaS平台的Elasticsearch(分布式搜索和分析引擎)文本向量化搜索系统，用于在智能办公室中的计算机设备中使用，用于提供人工智能服务，并且用于提供预训练模型、自然语言处理服务和图像处理服务。搜索引擎模块使用Elasticsearch(分布式搜索与分析引擎)作为文档数据存储引擎，基于Elasticsearch(分布式搜索与分析引擎)引擎对大量的文本数据进行搜索分析，通过匹配关键词，理解并应用复杂的查询语句对文本数据进行查询，通过文本向量化技术，使得搜索引擎能够更加智能的理解用户查询，提供更加准确的搜索结果，基于向量化方法，进一步能够实现相似度匹配，为用户推荐与查询语义相关的文档，从而提升搜索体验。该系统具有AIPaaS平台模块，用于构建AIPaaS平台，建立文本搜索项，设置搜索权限和访问权限，将选定的语言大模型集成到AIPaaS平台中并利用FastAPI框架构建Web应用，将AIPaaS平台加载到Web应用中。 Elasticsearch(分布式搜索和分析引擎)引擎模块被配置为搜索和匹配Elasticsearch(分布式搜索和分析引擎)数据库中存储的文本。 文本存储优化模块，采用文本切分和向量存储技术，优化文本在弹性搜索引擎中的存储。 搜索输出模块在ElasticSearch(分布式搜索和分析引擎)引擎用户交互界面处向用户输出搜索到的文本信息。还包括一种计算机可读存储介质，其包括用于利用基于AIPaaS平台的Elasticsearch(分布式搜索和分析引擎)文本矢量化搜索系统的一组指令。  11
本发明提供一种图文预训练模型的训练方法、训练装置及电子设备，涉及深度学习技术领域，该方法包括：构建初始图文预训练模型，初始图文预训练模型包含生成器模块和判别器模块，生成器模块和判别器模块均包含图像编码器、文本编码器和跨模态融合编码器，跨模态融合编码器用于融合图像编码器和文本编码器输出的特征；针对每种预训练任务，基于生成器模块的生成结果对判别器模块进行训练，并基于训练后的判别器模块，得到目标图文预训练模型。使得最终得到的目标图文预训练模型能够与下游任务完全匹配，从而能够在各种图文下游任务中取得更好的效果。用于使用电子设备(权利要求书)例如个人计算机、服务器和网络设备来训练图像文本预训练模型的方法，所述电子设备用于在计算机视觉领域和自然语言处理领域中使用。最终得到的目标图文预训练模型能够与下游任务完全匹配，从而在各种图文下游任务中获得更好的效果。 训练装置能够基于生成器模块的生成结果对判别器模块进行训练，以使目标模型能够与下游任务完全匹配。该方法包括构建(100)初始图像-文本预训练模型。 所述初始图文预训练模型中设置有生成器模块和判别器模块。 生成器模块和判别器模块中设置有图像编码器、文本编码器和跨模态融合编码器。 所述跨模态融合编码器用于融合图像编码器和文本编码器输出的特征。 基于生成器模块的生成结果在每个预训练任务处对仲裁器模块进行训练(101)，以基于训练后的仲裁器模块得到目标图文预训练模型。独立权利要求还包括用于：图文预训练模型的训练装置； 以及一种非瞬态计算机可读存储介质，包括用于使用电子设备训练图像文本预训练模型的指令集。  11
本发明涉及一种基于选择性多分支空洞卷积的腺体细胞图像分割方法，输入腺体细胞图像数据集，以改进的UNet作为主干网络，构建基于选择性多分支空洞卷积的腺体细胞分割网络，所述网络以上下文编码网络捕获更多高级特征，以通道注意力模块自适应重新校准通道特征响应并突出最相关的特征通道，以多尺度选择模块放大有效信息和抑制冗余信息，选择合适尺度的空洞卷积分支；以输入的腺体细胞图像数据集对构建的分割网络进行训练，得到稳定的分割网络；输入待分割腺体细胞图像，以稳定的分割网络进行腺体细胞分割。本发明具有更好的泛化能力，特别适用于结直肠息肉中腺体的尺度大小、形状变化差异大的情况。基于选择性多分支空洞卷积的腺细胞图像分割方法，用于医学图像处理领域的计算机辅助诊断系统，用于评价结直肠癌的等级或分化程度。该方法能够提供一种能够解决现有技术中由于腺体结构不规则或恶性严重而导致腺体分割精度差的分割网络，不仅提高了分割精度，而且提高了网络的泛化能力。 该方法允许通道注意模块(CA)自适应地重新校准通道特征响应并突出最相关的特征通道，同时，提供了放大有效信息并抑制冗余信息的多尺度选择模块(MSM)，选择合适尺度的空腔卷积支路，可以更有效和准确地划分不同尺度的腺体。该方法包括输入腺细胞图像数据集。 以改进的UNet为骨干网络，基于选择性多分支空洞卷积构建腺细胞分割网络。 该网络用上下文编码网络捕获更高级的特征，用通道注意模块自适应地重新校准通道特征响应并突出显示最相关的特征通道。 所述多尺度选择模块用于放大有效信息和抑制冗余信息，并选择合适的尺度膨胀卷积支路。 用输入的腺细胞图像数据集对构建的分割网络进行训练，得到稳定的分割网络。 输入待分割的腺细胞图像，用稳定的分割网络对腺细胞进行分割。   6
本公开提供了模型训练方法、装置、电子设备以及存储介质，涉及人工智能技术领域，尤其涉及大型语言模型、联邦学习和深度学习技术领域。具体实现方案为：接收服务器下发的M个目标提示模块各自的第一模型参数；以M个目标提示模块各自的第一模型参数和N个提示模块中剩余的N‑M个提示模块各自的当前模型参数作为大型语言模型的初始参数，利用联邦学习设备中存储的多个数据样本训练大型语言模型，以得到M个目标提示模块各自的第二模型参数；向服务器发送M个目标提示模块各自的第二模型参数，服务器被配置为基于联邦学习系统包括的多个联邦学习设备各自发送的M个目标提示模块各自的第二模型参数，更新N个提示模块各自的模型参数。用于训练模型即大型语言模型的方法，使用电子设备(要求保护的)。方式传输模块的模块的模型参数，替代相关技术，有效降低沟通成本，提高大型语言模型的提示调整效率。所述方法(200)包括将所述N个提示模块中的所述M个目标提示模块各自的第一模型参数和所述N-M个残差提示模块各自的当前模型参数作为大规模语言模型的初始参数(S220)。 利用联邦学习设备中存储的多个数据样本对所述大规模语言模型进行训练，得到所述M个目标提示模块各自的第二模型参数。 将所述M个目标提示模块的第二模型参数发送(S230)至服务器。 服务器，用于基于联邦学习系统包括的联邦学习装置发送的所述M个目标提示模块的第二模型参数，更新所述N个提示模块的模型参数。独立权利要求书包括用于：(1)模型训练装置； (2)电子设备； (3)非瞬时计算机可读存储介质，其存储有用于训练模型的计算机指令； 以及(4)用于训练模型的计算机程序产品。  11
本发明涉及人工智能技术，揭露了一种文本分类方法，包括：对原始文本数据进行预处理得到文本向量；对所述文本向量进行标签匹配，得到带有标签的文本向量和不带有标签的文本向量；将所述带有标签的文本向量输入BERT模型获得词向量特征；根据所述词向量特征，利用卷积神经网络模型对所述不带有标签的文本向量进行训练，得到带有虚拟标签的文本向量；利用随机森林模型对所述带有标签的文本向量和带有虚拟标签的文本向量进行多标签的分类，得到文本分类结果。本发明还提出一种文本分类装置以及一种计算机可读存储介质。本发明可以实现精准高效的文本分类功能。文本分类方法。该方法能够以精确且高效的方式实现文本分类。该方法包括对原始文本数据进行预处理，得到文本向量。 对所述文本向量进行标签匹配处理，得到已标注文本向量和未标注文本向量。 标记的文本向量被输入到双向编码器表示变换器(BERT)模型中以获得词向量特征。 根据所述词向量特征利用卷积神经网络模型训练所述未标注文本向量。 得到虚拟标签文本向量。 利用随机森林模型对所述标注文本向量和所述虚拟标签文本向量进行多标签分类处理。 得到文本分类结果。包括以下独立权利要求：文本分类装置； 以及计算机可读存储介质，用于存储执行测试分类方法的文本分类程序。  12
本申请适用于人工智能技术领域，尤其涉及一种基于人工智能的预训练优化方法、装置、设备及介质。该方法使用第一情感预测模型提取句级语音中的帧级特征，将句级语音的句级情感标签作为帧级特征的情感类别，对帧级特征进行编码和预测，以编码的结果与预测的结果的负余弦相似度最小化为目标，训练预设编码器，将帧级特征输入训练好的预设编码器，输出更新帧级特征，对所有的更新帧级特征进行聚类，并根据聚类结果确定对应帧数据的伪标签，以此为依据对第二情感预测模型进行训练，通过预设编码器和预设预测网络最大化相同标签下的特征之间的相似性，通过聚类进一步加强低维特征与情感信息的相关性，从而提高模型对情感信息的预测准确性。基于人工智能进行预训练优化的方法。通过聚类增强低维特征与情感信息的相关性，提高模型对情感信息的预测精度。该方法涉及针对训练集中的任意一个句子级别语音，利用第一情感预测模型提取训练集中每一帧数据句子级别语音对应的帧级别特征。 获取所述训练集中所有帧数据的更新后的帧级别特征。 根据所述更新后的帧数据和对应的情绪类别对所述更新后的帧级特征进行聚类。 根据聚类结果更新所有更新后的帧级别特征对应的情感类别。 将更新结果确定为所述帧数据对应的伪标签。 利用所述训练组对第二情感预测模型进行训练，得到预训练的第二情感预测模型。 所述第一情感预测模型和第二情感预测模型设置有时间步长对齐的特征编码器。独立权利要求包括：一种基于人工智能的训练前优化装置； 一种计算机设备包括：存储器； 一种计算机可读存储介质。 3
本发明涉及基于GLM大数据模型引擎分析决策的机器自动审批方法，包括以下步骤，S1：用户提交申请信息上传到基于GLM大数据模型引擎系统；S2：大模型引擎对用户提交的申请信息进行完整度判断，不完整的驳回用户修改，信息完整则继续下一步；S3：大数据模型引擎根据申请用户的历史审批数据训练后进行预判，对用户的申请进行自动审批；对于不符合标准规范的申请自动驳回用户修改，对预审通过的并标注“拟同意”字样；S4：预审通过后，审批进入人工确认环节，由GLM引擎对所有预审通过的记录汇总生成数据综述，由审批人最终批量审批是否通过。本发明最终审核出的申请信息更加精确，对审批人的要求变低，节省了审批人的时间，从而使得整体的审批效率更高。基于全球移动通信系统(GLM)大数据模型引擎分析决策的机器自动审批方法，用于企业经营管理过程中。该方法最终审核的申请信息更加准确，降低了对审查员的要求，节省了审查员的时间，整个审批效率更高。该方法包括将用户提交的应用信息上传到基于全球移动通信系统(GLM)大数据模型的引擎系统。 通过大模型引擎判断用户提交的应用信息的完整性。 由训练后的大数据模型引擎根据用户的历史审批数据进行预判，对用户的应用进行自动审批。 对于不符合标准规范的申请，自动拒绝用户修改，对于通过的预审，标记“准同意”字样。 人工确认环节由预审通过后审批进入，预审通过的记录由GLM引擎汇总生成数据汇总，最终批次审批由审查员通过。  11
本公开提出一种文生图模型、超网络的生成方法及装置，涉及计算机技术领域，尤其涉及计算机视觉、自然语言处理、大模型、深度学习等人工智能技术领域，可应用于基于人工智能的内容生成场景。方法包括：获取包含目标主体的目标图像及文本数据；将目标图像输入预先生成的超网络，获取超网络输出的第一网络参数；基于第一网络参数，对初始文生图模型进行更新，获取更新后的文生图模型；将文本数据输入更新后的文生图模型，获取更新后的文生图模型输出的预测图像；基于预测图像与目标图像的差异，对更新后的文生图模型进行微调，获取与目标主体关联的个性化文生图模型。用于生成文化生物图谱模型和超网络的方法，用于计算机视觉、自然语言处理、大模型和深度学习等人工智能领域。该方法涉及获得包括目标主体的目标图像和文本数据，并且因此确保简单且高效地生成文化生物图谱模型和超级网络。该方法包括获取(101)包括目标主体的目标图文数据。 将所述目标图像输入(102)预先生成的超级网络，得到所述超级网络输出的第一网络参数。 基于所述第一网络参数更新(103)所述初始文本图像模型。 得到更新后的文本图像模型。 将文本数据输入(104)更新的文本图像模型。 通过更新后的文本图像模型得到预测图像输出。 基于所述预测图像与所述目标图像之间的差异对所述更新后的文学图像模型进行精细调整(105)。 获取与所述目标主体相关联的个性化文学图像模型。独立权利要求包括以下内容：一种用于生成超级网络的方法； 用于生成文化生物图谱模型的装置； 用于生成超级网络的装置； 电子装置； 非瞬时计算机可读存储介质，其存储用于生成文化生物图谱模型的程序； 以及用于生成文化生物图谱模型的计算机程序产品。 14
一种基于子任务划分网络的联合关系抽取方法，属于信息抽取技术领域，将关系抽取任务定义成一个填表任务，使用BERT将文本进行编码，编码后的向量经过子任务划分网络划分成实体适用向量和关系适用向量，然后分别送入解码器中抽取出两个矩阵，即实体矩阵和关系矩阵，通过对矩阵进行解码即可抽取出关系三元组。利用划分子任务的方法，划分为实体识别和关系抽取两个子任务，让两个子任务之间相互积极影响，在CMeIE和DuIE1.0两个数据集取得了目前已知最优性能的结果，利用消融实验验证了本发明所提出的不同模块对模型效果的提升和贡献，证明了本发明所提出的模型在联合抽取任务的优越性和有效性。基于子任务划分网络的联合关系抽取方法，用于信息抽取领域。该方法使得划分子任务，提取两个子任务进行实体识别和关系，利用这两个子任务相互之间提供积极的影响，得到两个数据集中当前已知的最优性能的结果，基于烧蚀实验验证过程不同模块对模型效果的改进和贡献，证明模型在联合提取任务中的优势和有效性。该方法包括将关系提取任务定义为表填充任务。 利用BERT模型对文本进行编码。 通过子任务划分网络将编码向量划分为实体合适向量和关系合适向量。 将实体适合向量和关系适合向量分别发送给解码器以提取两个矩阵。 将这两个矩阵命名为实体矩阵和关系矩阵。 通过对矩阵进行解码来提取关系三元组。  12
本公开提供了一种自动应答处理方法、装置、电子设备及介质。该自动应答处理方法包括：获取会话平台上的目标触发事件；获取目标对象在所述会话平台上的匹配历史事件特征；获取所述目标对象在所述会话平台上的第一标签；基于所述匹配历史事件特征和所述第一标签，生成所述目标对象在所述会话平台上的总体特征；将所述目标触发事件和所述总体特征输入第一大语言模型，得到所述会话平台对所述目标触发事件的个性化应答；显示所述个性化应答。本公开实施例能提高自动应答处理方法的自动应答的个性化和准确性。本公开实施例可应用于应答处理、智能应答等各种领域。自动应答处理方法，用于机器翻译和机器问答领域。该方法能够提高自动应答处理方法的个性化和自动应答的准确性。 所述方法允许用户将所述目标触发事件，以及所述通用特征输入到第一大型语言模型中，以获得会话平台对所述触发事件的个性化回复，从而以有效的方式展示所述个性化回复。该自动应答处理方法包括在会话平台上获取目标触发事件。 获取目标对象在会话平台上的匹配历史事件特征。 在所述轨道平台上获取所述目标对象的第一标签。 基于匹配的历史事件特征和第一标签，生成目标对象的整体特征。 将所述目标触发事件和所述通用特征输入第一大型语言模型，得到对所述目标事件的个性化响应。 显示所述个性化响应。 将所述历史会话记录，以及所述上下文信息输入第二大型语言模型，得到所述历史会话记录的目标元素信息。包括独立权利要求，用于：(1)自动响应处理装置； (2)电子设备； (3)计算机可读存储介质，用于存储所述计算机程序； (4)一种计算机程序产品，包括所述计算机程序。 8
本发明公开了一种基于大模型的多任务处理方法、系统及计算设备，涉及互联网及人工智能技术领域。方法在计算设备中执行，包括：获取输入的初始指令，根据所述初始指令拆解生成多个场景对应的多个任务；对于每个任务，获取与所述任务的场景相对应的任务提示信息，并将所述任务提示信息和所述任务，输入与所述任务适配的大模型进行处理，得到任务处理结果；根据每个任务的任务处理结果合并生成最终处理结果。根据本发明的技术方案，针对不同场景的多个任务，可以分别利用与各任务相适配的大模型来处理各任务，从而实现了混合使用多种大模型来处理多任务，提高了模型处理任务的准确性和效率。基于大模型进行多任务处理的方法。提高了模型处理任务的准确性和效率。 通过与每个任务匹配的大模型对任务进行处理，实现了多个大模型混合处理多个任务。方法(300)涉及获得(310)输入初始指令。 根据针对每个任务的初始指令生成对应于多个场景的多个任务。 获取(320)与所述任务的场景相对应的任务提示信息。 将所述任务提示信息和所述任务输入(330)与所述任务匹配的大模型进行处理，得到任务处理结果。 将各任务的任务处理结果进行合并(440)，生成最终处理结果。独立权利要求包括以下内容：多任务处理系统； 计算设备； 以及存储用于处理多任务的程序指令的可读存储介质。  11
本发明实施例中提供了一种结合学术文本结构的文本检测方法，属于数据处理技术领域，具体包括：步骤1，对学术文本不同结构划分重要性比例，并构建文本特征向量基本属性；步骤2，使用预设的统计方法计算学术文本不同结构中每个句子的属性频数；步骤3，对学术文本的结构特征向量加权；步骤4，将加权特征向量拆分后得到的结构特征向量的上下文关系进行拼接，组合成窗口特征向量输入BERT神经网络进行训练，得到文本检测模型；步骤5，将待检测文本输入文本检测模型，得到其属于不同文本类型的概率。通过本发明的方案，提高了文本检测的适应性、可解释性和精准度。数据处理领域中结合学术文本结构检测文本的方法。提高了文本检测的适应性、可解释性和精度。该方法包括划分学术文本的不同结构的重要性比例(步骤1)。 构建文本特征向量的基本属性。 计算情感极性的平均值。 根据CF-SIDF值和平均情感极性分数计算每个结构中单个句子的句子特征向量。 对学术文本的结构特征向量进行加权(步骤3)。 对分割加权特征向量得到的结构特征向量的上下文关系进行拼接(步骤4)。 得到文本检测模型。 输入待检测的文本检测模型(步骤5)，得到属于不同文本类型的概率。  12
本发明公开了一种基于卷积神经网络‑转换器混合架构的图像分类方法。该方法包括：利用预训练卷积神经网络提取图像的特征并生成指示目标位置轮廓的注意力掩码，该注意力掩码表征对应元素属于目标类别的概率；将所述注意力掩码作为先验信息指导转换器网络，以关注辨识性区域来确定图像类别，其中所述转换器网络是以设定的损失函数为优化目标经训练获得。本发明能自动发现目标辨识性的区域，并学习该区域的特征以供区分类别，从而提升了细粒度图像分类的准确性。一种基于卷积神经网络-变换器混合架构的图像分类方法。本发明能够自动发现目标识别区域，确定该区域的特征，确定区分类型，从而提高细粒度图像分类的准确性。 该方法能够直接获取图像全局信息，并获取图像的任意区域之间的关联信息，提高了网络性能。 本发明建立预卷积神经网络模型作为关注模型，从嵌入原始图像的先验知识中确定图像的目标位置信息，确定识别区域的位置和特征学习，显著提高图像分类精度。该方法涉及通过使用预训练卷积神经网络模块来确定图像的特征。 生成关注掩模，其中，关注掩模指示目标位置简档，并且关注掩模表示相应元素属于目标类别的概率。 以关注掩码作为先验信息指导换流器网络。 通过使用关注识别区域来确定图像类别。 通过训练作为优化目标的设定损耗函数来建立转换器网络。 绘制通道特征图。 对应于每个小块形成一维特征向量。 建立剩余连接以获得中间张量。 中间张量被标准化。 根据分类向量和分类特征向量的余弦距离来确定图像的类型。独立的权利要求书包括： (1)计算机可读存储介质，用于存储用于执行基于卷积神经网络-转换器混合架构的图像分类方法的一组指令； (2)包括存储器和处理器的计算机设备，用于执行基于卷积神经网络-转换器混合架构的图像分类方法。   4
本发明公开了一种基于Unet和Transformer相融合的脑部胶质瘤分割方法，具有这样的特征，包括以下步骤：步骤1，对待测图像进行预处理获得预处理图像；步骤2，将预处理图像输入到基于U‑Net和Transformer的脑部胶质瘤分割模型中得到整个肿瘤区域、肿瘤增强区域以及肿瘤核心区域。其中，步骤1中，待测图像为多张脑部胶质瘤图像。步骤2中，基于U‑Net和Transformer的脑部胶质瘤分割模型为通过如下训练步骤获得：步骤2‑1，将预处理图像的展平成一系列2D的片序列并进行位置编码；步骤2‑2，将预处理图像作为训练集分别输入到卷积神经网络、Transformer网络以及U‑Net网络中；步骤2‑3，采用随机梯度下降法，基于最小化损失函数训练网络结构，得到训练后的基于U‑Net和Transformer的脑部胶质瘤分割模型。用于对脑肿瘤患者进行脑神经胶质瘤分割的方法。该方法能够获得基于U-Net和训练的脑胶质瘤分割模型。该方法包括将预处理图像输入到基于U‑Net和brain的脑胶质瘤分割模型(S2)，以获得整个肿瘤区域、肿瘤增强区域和肿瘤核心区域。 预处理后的图像被展平成一系列二维(2D)片材序列。 进行位置编码。 将预处理后的图像作为训练集输入到卷积神经网络模块、网络和U-Net网络。 脑胶质瘤分割模型采用随机梯度下降法，基于最小损失函数训练网络结构得到。包括脑神经胶质瘤分割系统的独立权利要求。  7
本发明公开了一种基于自注意力的深度神经网络编码光子晶体的方法，提出了POViT模型，并将其应用到编码光子晶体；方法包括步骤：获取光子晶体的几何结构参数图像；光子晶体具有若干个空气孔，其几何结构参数图像的每个像素包括：空气孔的位置和半径；对几何结构参数图像进行维度重塑，得到若干个补丁图像；将补丁图像输入嵌入模块和位置编码模块，得到符号序列；将符号序列输入transformer编码模块，得到编码特征；将编码特征输入全连接层模块中，得到品质因子Q和模式体积V。POViT应用自注意力Transformer模型到光电设计领域，提高了预测光子晶体的Q因子和模式体积V的速度和准确度。一种基于自注意力深度神经网络的光子晶体编码方法。POViT将自注意力变压器模型应用于光电设计领域，从而提高了预测光子晶体因子和模体积的速度和精度。所述编码方法包括获取光子晶体的几何结构参数图像，所述光子晶体包括多个空气孔，所述多个空气孔排列形成周期性空气孔阵列。 对所述几何结构参数图像进行尺寸整形，得到若干块图像，将所述块图像输入嵌入模块和位置编码模块，得到符号序列。 根据所述面片图像在所述几何结构参数图像中的对应位置对所述符号序列进行排序。 将符号序列输入变换器编码模块，得到编码特征。 将编码后的特征输入全连接层模块，得到品质因数和图案体积。包括独立权利要求：(1)一种包括存储器和处理器的计算机设备； (2)一种计算机可读存储介质，其上存储有计算机程序。   6
本发明提供一种基于深度学习的全球陆地蒸散发时空融合的方法，首先整合多源蒸散发产品和地表特征，以加权平均蒸散发产品作为训练目标；通过注意力机制融合特征，再经过空间、时间编码器和解码器进行模型预训练；然后在预训练模型基础上，以通量站点观测数据作为训练目标，进行模型微调。本发明将空间地理特征、时序特征、地表属性特征纳入全球陆地蒸散发产品的融合过程，提供了一个全球高分辨率连续多年陆地蒸散发的基准产品，具有良好的数据自适应性和鲁棒性、出色的回归预测能力和较强的泛化能力，显著提升全球陆地蒸散发估算的精度，降低产品的不确定性。该模型还可以方便地应用于其他遥感、水文、气象数据的时空估算和融合。基于深度学习的全局土地蒸散发时空融合方法。该方法将空间地理特征、时间序列特征、地表属性特征纳入全球陆地蒸散发产品的融合过程，为连续多年的陆地蒸散发提供了全球高分辨率的基准产品，具有良好的数据适应性和鲁棒性、优异的回归预测能力和较强的泛化能力，显著提高了全球陆地蒸散发估计的精度，降低了产品的不确定性。 该模型很容易应用于其他遥感、水文、气象数据的时空估计与融合。该方法涉及将空间地理特征、时间序列特征、地表属性特征纳入全球地面蒸散发融合过程中，为全球地面蒸散发估计提供基准产品。 将所述多个全球陆地蒸散发估计产物与地表通量站点观测数据相结合。 该模型是利用地球表面特征作为辅助信息的全球陆地蒸散发样本集合进行预训练的。 初始化模型参数。 再利用地表通量站观测数据对模型进行微调，建立具有全球陆地地表特征的时空融合模型。 14
本发明属于自然语言处理领域，公开了一种基于标签语义对齐的文本新类发现方法及相关装置，通过预训练的BERT模型提取各待分类文本的特征，得到各待分类文本的向量表示；将各待分类文本的向量表示进行聚类，得到若干聚类簇及各聚类簇的中心向量；遍历各聚类簇的中心向量，通过Word2vec模型输出与各聚类簇的中心向量表示最相似的单词，得到各聚类簇的类别并作为各聚类簇中各待分类文本的类别；通过引入标签语义嵌入作为监督信号，将文本的特征空间与标签的语义空间对齐，不仅为模型训练提供了高质量的监督信号，同时可以为聚类结果生成有效的新类名称，有效的解决了当前新类发现研究中存在的缺少高质量监督信号，及不能生成有效的新类名称等问题。基于标签语义对齐的文本发现方法。通过引入标签语义嵌入作为监测信号，将文本的特征空间与标签的语义空间对齐，不仅为模型训练提供了高质量的监测信号，同时，可以为聚类结果生成有效的新类名。 该方法有效解决了目前新类发现研究缺乏高质量监测信号，无法生成有效类名的问题。该方法涉及通过预先训练的BERT模型提取(S1)每个待分类文本的特征，得到每个待分类文本的向量表示。 对向量表示进行聚类(S2)，得到多个聚类簇和每个聚类簇的中心向量。 遍历每个聚类的中心向量(S3)。 通过Word2vec(RTM：自然语言处理应用)模型输出与中心向量最相似的词。 得到每个聚类后的簇的类型。 将训练文本和训练文本对齐，对训练文本进行训练，得到训练文本。独立权利要求包括以下内容：基于标签语义对齐的新文本类发现系统； 计算机装置； 以及存储基于标签语义对齐发现文本的程序的计算机可读存储介质。  12
本发明提供一种基于中文临床表型细粒度命名实体识别方法及系统，属于临床病历信息处理技术领域，通过自然语言预训练模型BERT进行临床文本的字符级嵌入特征抽取；利用双向长短词记忆模型BiLSTM对字符级嵌入特征和临床文本的序列特征进行整合并进行特征编码，得到标签；利用条件随机场CRF进行标签的解码预测，得到命名实体识别结果。本发明建立了用于细粒度命名实体实验的临床细粒度表型实体标准数据集，其区分了阴性症状和阳性症状，为临床分析提供更为精确的结构化数据。一种识别中国临床表型细粒度命名实体的方法。该方法能够建立临床细粒度表型实体标准数据集，用于细粒度命名实体实验，区分阴性症状和阳性症状，为临床分析提供准确的结构化数据。该方法涉及通过诸如来自变换器(BERT)的双向编码器表示的自然语言预训练模型来提取临床文本的字符级嵌入特征。 采用双向长短期记忆(BiLSTM)模型对所述临床文本的字符级嵌入特征和序列特征进行整合。 进行Fhe特征编码，得到标签。 使用条件随机场(CRF)进行解码和预测，以获得命名实体识别的结果。 采用Viterbi算法得到最优标记序列。包括独立权利要求：(1)一种用于识别中国临床表型细粒度命名实体的系统； (2)一种用于识别中国临床表型细粒度命名实体的计算机设备； (3)一种用于识别中国临床表型细粒度命名实体的电子设备； (4)一种用于识别中国临床表型细粒度命名实体的计算机可读存储介质。  12
本发明公开了一种基于多模态生成式对话的甲状腺自主扫查系统，包括：硬件装置以及用于控制硬件装置动作的自主扫查单元；硬件装置包括：机械臂、力传感器、夹爪、上位机、显示设备和医用超声设备；自主扫查单元内置于上位机内，自主扫查单元包括：图像分析模块、多模态问答模块、决策模块、控制模块。本发明利用生成式的多模态大语言模型实现甲状腺的全自主扫查；在扫查过程中不需要人为设定路径、不用人工设置参数；采用零力拖动的方式确定扫查初始位置；根据传感器数据和超声图像协同调整探头的位置和姿态；通过行为编码把连续的机械臂绝对运动变成离散的相对运动，避免标定时精度误差造成扫查失败。基于多模态生成型对话的甲状腺自主扫描系统，用于临床诊断和监测。通过动作代码将连续的机械臂绝对运动变为离散的相对运动，避免了标定时精度误差导致的扫描失败。该系统具有与机械臂配合使用的力传感器，夹爪设置在机械臂的动作端。 该系统包括图像分析模块、多模式问答模块、决策模块和控制模块。 决策模块，用于将所述图像分析的结果与所述问答模块的答案进行求和。 生成最终决策由控制模块执行，同时，记录图像分析的结果并将结果汇总到最终超声报告中。 控制模块负责执行决策模块生成的操作，使得操作的安全性得到保证。 所述模块之间通过数据接口进行指定数据的交互和通信，所述模块中的组件通过共享存储的方式进行所有数据的交互。 8
本公开涉及人工智能技术领域，尤其涉及一种属性级情感分析方法。本公开包括：提出了一个端到端的属性级情感分析方法，结合情感词典，从目标文本中分离出关键词文本。目标文本经由BERT模型向量化后得到目标文本向量，采用双向门控循环单元对目标文本向量提取目标文本的语义信息。关键词文本经由BERT模型向量化后得到关键词文本向量，经由注意力计算后与目标文本向量融合，预测目标文本的属性词及情感极性。本公开实施例结合情感词典和深度学习方法，使模型更关注情感词信息，显著提升了端到端的属性级情感分析任务的准确度。相比传统的基于规则的情感分析方法和主流的基于深度学习的情感分析方法，本公开的实施例具有更理想的效果。基于深度学习的属性级情感分析方法，应用于人工智能领域。该模型更加关注情感词信息，明显提高了端到端属性级情感分析任务的准确性。 该模型更大程度地利用了BERT模型隐藏层中的上下文信息并结合情感词典，使得模型在文本中更加关注情感信息。该方法包括预处理(S101)要经受情感分析的文本数据以获得目标文本，以及标记该目标文本数据。 目标文本是要进行情感分析的预处理文本。 确定域或一般情感词典(S102)。 情感词典以显示或隐含的方式具有情感词和情感词极性。 根据情感词典从目标文本中分离关键字文本(S103)。 通过对目标文本进行矢量化处理来输入(S104)所构造的用于计算的深度学习模型，以获得目标文本的计算结果。 通过对关键词文本进行向量化处理，输入(S105)所构造的用于计算的深度学习模型，以获得关键词文本计算结果。 融合目标文本计算结果和关键词文本计算结果(S106)以获得目标文本情感分析结果。  12
本发明公开了一种基于深度学习的知识点提取方法、系统、装置及介质，方法包括：通过爬虫方法和/或OCR文本识别方法获取原始数据集；对所述原始数据集进行预处理，获取知识表征数据；根据所述知识表征数据，确定Bert预训练模型；根据动态mask方法和混合mask方法，对所述Bert预训练模型进行优化；根据优化后的Bert模型，提取原始数据集中的知识点。通过Bert预训练模型，能够免去繁琐的特征工程步骤，并能够解决一词多义的问题；本发明通过对bert模型进行优化，提取知识点，更加准确，可广泛应用于深度学习技术领域。利用知识点提取装置(索取)进行基于深度学习的知识点提取的方法。避免了繁琐的特征工程步骤，并且能够解决模糊问题，通过Bert预训练模型。 知识点提取系统通过优化bert模型，提取知识点，更加准确，被广泛应用于深度学习技术领域。该方法包括通过爬行方法和/或光学字符识别(OCR)文本识别方法获得原始数据集。 对所述原始数据集进行预处理，得到知识表示数据。 根据所述知识表示数据确定所述Bert预训练模型。 根据动态掩模方法和混合掩模方法对所述Bert预训练模型进行优化。 提取所述原始数据集中的知识点，根据所述优化后的Bert模型。 根据所述知识表示数据构建Bert预训练模型。 通过预设参数对所述Bert预训练模型进行微调，确定微调后的Bert预训练模型。以下包括独立权利要求：一种基于深度学习的知识点抽取系统； 以及存储介质，用于基于深度学习进行知识点提取。  12
本发明实施例提供了一种情感语音合成方法、装置、电子设备和介质，涉及语音合成技术领域，该方法包括：对预设的录制完成的图像、音频和录制使用的文本进行情绪检测得到情绪检测结果，并将情绪检测结果与对应音频进行匹配得到带有情感标签的标注音频段，将带有情感标签的标注音频段作为训练数据集对预训练模型进行微调训练得到候选情感语音合成模型，以此为情感标签所训练出的模型合成音的情感表达也会更加精准，微调训练可以更加快速的将少量录音人的情感特征进行迭代训练，最后使用对抗网络对候选情感语音合成模型进行训练，得到最终情感语音合成模型，能够提升模型的语音合成情感表达效果。情感语音合成法。采用对抗网络对候选情感语音合成模型进行训练，得到最终的情感语音合成模型，能够提高模型的语音合成情感表达效果。情感语音合成方法涉及对预设的录制图像、音频和用于录制的文本进行情感检测，得到文本中每句话对应的检测结果。 将检测结果与音频进行匹配，得到带有第一情感标签的标注音频段，并将标注音频段作为训练数据集。 利用所述训练数据集对所述预训练模型进行微调训练，得到候选情感语音合成模型。 采用生成式对抗网络对候选情感语音合成模型进行训练，得到最终情感语音合成模型。 将所述预设文本数据输入所述最终情感语音合成模型进行情感语音合成，得到情感合成音频。独立权利要求包括用于：(1)用于情感语音合成的设备； (2)一种电子设备，包括处理器，以及存储器； (3)一种计算机可读存储介质，其存储有计算机程序。 3
本发明属于深度学习技术领域，具体涉及一种用于分类的Transformer网络模型，公开了一种基于Transformer进行音视频联合场景分类方法包括，通过利用Transformer单元对嘈杂的音频、视频和音视频分别进行早期融合和特征提取；对融合后的特征表示利用EfficientNetV2_S单元进行视频侧的预训练网络；通过利用分类单元进行音频特征、视频特征以及音视频联合特征三者加权求和所得的特征输入到分类器中进行场景分类。本发明提出了将原本的注意力机制替换为Transformer结构，将原本的预训练模型从ResNet50替换为EfficientNetV2_S，提高了分类的准确度，通过Transformer单元的运用提高了场景分类的准确率，提升了多模态之间的关联性。一种基于分类网络模型的音视频联合场景分类方法，用于深度学习技术领域。通过简单单元的使用提高了场景分类的准确率并提高了多个模式之间的相关性。 用开关结构代替原有的注意力机制，用来自ResNet50的EneentNetV_S代替原有的预训练模型，提高了分类的准确性。该方法涉及通过使用简单单元将噪声音频和视频划分为编码器层和解码器层来对噪声音频和视频执行早期融合和特征提取。 在视频侧对融合后的特征采用EneentNetV2-S单元进行预训练网络。 将所述视频特征和所述音视频组合特征输入所述分类器，以通过所述分类单元对所述场景进行分类。独立权利要求包括：一种使用所述音视频联合场景分类方法的系统； 一种计算机设备包括：存储器； 一种用于对音视频联合场景进行分类的计算机可读存储介质。 9
本公开公开了知识预训练模型的训练方法、装置和电子设备，涉及语音、自然语言处理、深度学习技术领域。具体实现方案为：获取训练文本，训练文本包括结构化知识文本和对应的文章，结构化知识文本包括头节点、尾节点和头节点和尾节点之间的关系；根据训练文本对待训练的知识预训练模型进行训练。该方法中，待训练的知识预训练模型能够同时学习到常识知识和丰富的语义知识，可实现常识知识和语义知识的联合训练，且不需要将训练实体嵌入到待训练的知识预训练模型，知识预训练模型的性能增益不受到训练实体的嵌入质量的限制，知识预训练模型可从训练文本中的文章中获取丰富的上下文信息，并可进行动态调整，灵活性较高。所述方法包括：获取训练文本，所述训练文本包括结构化知识文本和对应的文章。 所述结构化知识文本设置有首节点、尾节点以及首节点和尾节点之间的关系。 根据所述训练文本训练待训练的知识预训练模型。 从所述训练文本中获取所述结构化知识文本和对应的文章。 将所述结构化知识文本和对应的文章存储在数据库中。  11
本申请涉及一种基于BERT的自适应文本分类方法及装置，属于中文信息处理技术领域，包括：获取语料样本数据并对语料样本数据进行预处理；构建预设网络模型；将所述预处理后的样本数据输入预设的网络模型，并使用预设的损失函数进行监督训练，得到分类模型；设置所述分类模型的输出阈值，得到设置后的分类模型，所述输出阈值控制分类结果的提前输出，所述设置后的分类模型用于对输入的文本进行分类。相较于传统的BERT模型，可在不损失精度的情况下，缩短模型推理时间。本发明可用于中文信息处理领域的自适应文本分类。本发明能够减少模型推理时间，提高文本分类精度。该方法包括获得样本数据语言前数据。 获得预处理的样本数据。 构建预设的网络模型。 所述预设网络模型具有主体部分和分支部分。 主部分具有来自基于变压器(BERT)的网络的双向编码器表示和主分类器。 分支部分是在主体部分的最后一层的输出位置增加分支分类器而形成的。 预处理后的样本数据被输入到预设的网络模型中。 设定分类模型的输出阈值。 获得所设置的分类模型。 输出阈值控制分类结果的提前输出。 分类模型用于在使用设置之后对输入文本进行分类。本发明还涉及一种基于BERT的自适应文本分类装置。  12
本发明公开一种融合Bert预训练语言知识的神经机器翻译方法，涉及自然语言处理技术领域。提出了一种有效将预训练语言模型Bert与神经机器翻译模型融合的方法，首先提取Bert输入序列的多层表征，利用多层表征构建掩码知识矩阵，将Bert知识作用于神经机器翻译模型编码端词嵌入层。其次，通过自适应融合模块，提取预训练语言模型中的有效信息，与神经机器翻译模型交互融合，通过实验，相较于Transformer基线模型，所提方法获得了1.41～4.20的BLEU提升，证明该方法能在NMT模型中有效利用预训练语言知识。在文本分类、阅读理解等自然语言处理领域融合Berts预训练语言知识的神经机器翻译方法。自适应融合模块提取预训练语言模型中的有效信息，与神经机器翻译模型进行交互融合，经过实验，与基线模型相比，从而得到1.41-4.20的BLEU改进，并有效运用预训练语言NMT模型中的知识。该方法涉及利用Bert预训练语言模型来编码源语言句子。 构建自适应融合模块，将Bert多层表示知识与变压器基线模型编码表示进行融合。 自适应融合模块由两部分组成，分别是单头注意力机制和选择性融合模块。 单头注意力机制利用神经机器翻译(NMT)模型编码端的输出信息集中于Bert中的有效信息，降低了Bert输出与NMT模型编码端输出之间的差分干扰。 选择性融合模块自适应融合单头注意力机制输出的Bert信息和NMT模型编码端输出的信息。 自适应融合模块的输出送入变压器模型解码器，通过解码预测生成下一个词的概率。  12
本申请提供了一种问答对数据生成方法、装置、电子设备及可读存储介质，所述问答对数据生成方法包括：将长文档输入预设的文本分类模型，并获取所述文本分类模型输出的数据结构化分组；其中，所述文本分类模型用于对所述长文档按照标题级别结构进行分类，所述数据结构化分组包括标题级别大组，所述标题级别大组包括下属内容小组；将所述数据结构化分组输入大语言模型，并获取所述大语言模型生成的问答对数据。可以提升知识覆盖率，从而提高大语言模型的问答对数据生成效果，获得更加准确的问答对数据。生成问答对数据的方法。该问答对数据生成方法通过提高知识覆盖率，以提高大型语言模型的问答数据生成效果，获得更准确的问答对数据。问答对数据生成方法涉及将长文档输入预先设置的文本分类模型，获取文本分类模型输出的数据结构化组。 所述文本分类模型用于根据标题级别结构对所述长文档进行分类，所述数据结构化组包括标题级别大组。 标题级别大组包括从属内容组。 将所述数据结构化组输入所述大型语言模型，获取所述大型语言模型生成的问答对数据。独立权利要求包括用于：(1)生成问答对数据的装置； (2)具有处理器的电子设备； (3)一种可读存储介质，所述可读存储介质存储有用于实现所述问答对数据生成方法的指令。  11
本发明实施例公开了一种预训练语言模型的构建方法、装置、电子终端及存储介质，该方法包括：获取对话数据；根据各预训练任务的任务要求对对话数据进行处理，得到训练数据以及训练数据在各预训练任务下的标签数据；各预训练任务包括：全词掩码预测任务、角色预测任务、轮次内顺序互换预测任务和轮次间顺序互换预测任务；基于训练数据确定语言模型的输入数据，通过语言模型对输入数据执行各预训练任务，得到各执行结果；根据各执行结果以及训练数据在各预训练任务下的标签数据，对语言模型进行训练，得到预训练语言模型；预训练语言模型用于对对话数据进行编码。可提高预训练模型针对对话数据的处理性能。金融、通信、电子商务等领域的智能语音服务中使用的电子终端(Seart)中的预训练语言模型的构建方法。所述方法能够以高效的方式提高所述预训练语言模型对所述对话数据的处理性能。该方法包括获得(S110)对话数据。 所述对话数据包括多轮对话内容。 根据每个预训练任务的任务需求对所述对话数据进行处理(S120)。 获取每个预训练任务下的训练数据和训练数据的标签数据。 每个预训练任务包括全词掩码预测任务、角色预测任务、轮内序列交换预测任务和轮间序列交换预测任务。 基于训练数据来确定(S130)语言模型的输入数据。 通过语言模型执行对输入数据的预训练任务，得到执行结果。 根据所述执行结果和所述训练数据在所述预训练任务下的标签数据，对所述语言模型进行训练(S140)，以得到训练前语言模型。 该预先训练的语言模型用于对对话数据进行编码。包括以下独立权利要求：一种构建预训练的语言模型的装置； 电子终端； 以及存储用于构建预训练语言模型的程序的计算机可读存储介质。 8
本发明提供了一种基于自动编码器的事故简报快速生成方法，一：数据准备，并对数据进行清洗和预处理，确保数据质量和准确性；二：模型训练，将事故数据输入模型中进行自动编码器的训练，提取出数据中的关键特征和语义信息。三：关键信息提取，通过LSTM‑CRF模型，对事故相关文本进行关键信息提取，以便后续简报生成；四：事故简报生成，基于抽取的信息和语境，结合预定义的事故简报模板，快速生成事故简报。本发明利用了预训练语言模型BERT‑AE的强大能力，通过自动编码器的训练和事故数据的抽取，实现了快速生成电网配网事故简报的目标。该方法不仅提高了事故处理的效率和准确性，同时还可以减轻人工编写事故简报的工作量，具有广泛的应用前景和经济效益。应用于配电网领域的基于自动编码器的事故简报快速生成方法。该方法利用预训练语言模型BERT-AE的强大能力，通过自动编码机的训练和事故数据的提取，实现了快速生成电网配网事故简报的目标。 该过程提高了事故处理的效率和准确性，也减少了人工编制事故简报的工作量，具有广泛的应用前景和经济效益。该方法包括收集电网配电系统中的事故数据，并且对该过程进行预处理。 使用来自变换器(BERT)-AE模型的双向编码器表示来训练。 通过长短期记忆-条件随机场(LSTM-CRF)模型提取事故相关文本的关键信息。 将提取的关键信息输入训练好的BERT-AE模型，快速生成事故简报。 在文本序列中分布字符级别或词级别对各个位置的标注。 根据CRF模型的标签分配结果提取文本中的实体信息。  11
本申请涉及计算机技术领域，提供了一种文本分类的方法、装置、电子设备及可读存储介质。该方法包括：获取待分类文本以及与待分类文本对应的特征图像；使用多模态预训练模型待分类文本进行特征提取，得到文本特征向量；使用图像识别模型对特征图像进行特征提取，得到初步图像特征向量；基于文本特征向量对初步图像特征向量进行级联融合得到融合特征向量；将融合特征向量输入至分类模型中，得到分类结果。本申请通过图像特征对文本特征补充的方式，解决了文本分类方法中分类准确度不高的技术问题。对文本进行分类的方法。该方法通过在文本特征中补充图像特征，解决了文本分类方法中分类准确率低的技术问题。该方法包括获取(S201)待分类文本和与待分类文本对应的特征图像。 利用多模态预训练模型提取(S202)待分类文本的特征，得到文本特征向量。 利用图像识别模型对所述特征图像进行特征提取(S203)，得到初步图像特征向量。 基于所述文本特征向量对所述初步图像特征向量进行级联融合(S204)，得到融合特征向量。 将所述融合特征向量输入(S203)分类模型，得到分类结果。独立权利要求包括用于：(1)用于对文本进行分类的装置； (2)电子设备； 以及(3)存储用于对文本进行分类的程序的计算机可读存储介质。 14
本申请实施例属于自然语言处理技术领域，涉及一种正负样本对构造方法、装置、计算机设备及存储介质。此外，本申请还涉及区块链技术，用户的目标正负样本对可存储于区块链中。本申请利用预训练模型的隐含层中自带的随机失活功能作为构造样本对的增广方式，由于隐含层的增广方式是将部分权重或输出随机归零，从而有效解决传统的转译、删除、插入、调换等增广方式容易引入负面噪声的问题，使得构造得到的样本对仍然保留有原始待增广文本的语义特征，其相似的样本分布十分接近并且样本的分布比较均匀，同时，为下游任务提供更加优质的句向量。一种正负样本对构建方法，用于自然语言处理技术领域。 可用于文本分类、文本生成、语义相似度计算、提供训练数据、提高任务性能等方面。该方法使得能够使用预训练模型隐含层的随机灭活函数作为构建样本对的增广方式，从而有效解决传统的平移、删除、插入、改变增广方式容易引入负噪声问题，使得构建得到的样本仍然保持了待增广的原始文本的语义特征，相似样本分布非常接近且样本的分布均匀，同时，为句子向量任务提供了更好的质量。该方法包括在进行模型对比学习训练过程时，接收携带有待训练的编码器模型的样本获取请求。 读取文本数据库。 在文本数据库中获取待增强的文本数据。 根据所述文本数据构建初始正负样本对。 根据所述编码模型中牵连层的随机灭活函数对所述初始正负样本对进行前向传播操作，得到离散均匀的目标正负样本对。本发明还公开了一种正负样本对构建装置，包括：(1)一种正负样本对构建装置; (2)一种计算机设备，包括存储器和处理器； (3)一种计算机可读存储介质。  11
本发明提供的一种银行业大语言模型训练方法，所述训练方法包括：步骤S1：构建模型训练数据集；步骤S2：基于银行词表训练模型分词器；步骤S3：基于llama预训练模型增量训练，构建大模型底座；步骤S4：使用提示工程进行指令微调；步骤S5：强化学习微调大模型。基于具体银行的业务、知识、数据去训练大语言模型。能够理解银行频繁使用的金额、理财产品名称、办理流程等专业词汇；使用客服对话数据及银行内部知识库做指令训练，使得模型具备客服问答、检索式知识问答等能力；面对不断发展的业务具备快速迭代能力。一种银行业的银行大型语言模型训练方法，应用于银行语言模型训练领域。该方法使得能够基于特定银行的业务、知识和数据对大型语言模型进行训练，使得模型能够理解银行经常使用的金额、理财产品名称、交易流程等专业词汇，从而使得模型具有客服问答、检索类知识问答的能力，从而为不断发展的业务提供快速迭代能力。该方法涉及构建模型训练数据集。 基于银行词表训练模型分词器。 基于llama预训练模型增量训练构建大型模型库。 通过使用提示工程对指令进行微调。 大模式加强。 以章节和句子粒度对数据集进行过滤。 在全数据上通过局部敏感哈希方法对子章和句子进行粒度过滤。 通过组合词汇获得组合标记。 将经训练的分词器与原始llama分词器组合。  11
本发明涉及一种基于图神经网络的特定目标情感分类任务，包括采集数据集并初始化BERT模型，通过BERT模型得到每个目标词的一维特征向量，将目标词的特征向量输入到图卷积神经网络模型中，构造网络拓扑图, 并计算邻接矩阵，根据邻接矩阵通过三种方式来获取网络拓扑图中节点的三种特征，引入关系分类任务，整个模型在分类上分为两个阶段两个任务，两个任务分别是目标主体的情感极性分类和目标主体之间的关系分类。本发明采用图神经网络，对句子中出现的多个主体进行构图，同时对多个目标进行处理，更符合人类判断情感极性的认知规律，有助于保证模型的效果，与此同时引入关系分类任务进行辅助分类，更进一步提升了分类的准确率。该方法对于基于图神经网络对特定目标情感进行分类是有用的。该方法：采用图神经网络对句子中出现的多个主体的图片进行构图并同时处理多个目标，更符合人类判断情感极性的认知规律； 有助于保证模型的效率； 并引入关系分类任务进行辅助分类，进一步提高了分类的准确性。方法包括：(1)收集数据集; (2)人工标记数据集; (3)初始化BERT模型; (4)将步骤1或步骤2得到的标记数据集作为BERT模型的输入; (5)表达原始句子的序列; (6)取每个目标词对应位置的输出; (7)最大池化; (8)构建网络拓扑图; (9)得到节点的不同特征; (10)结合三图拓扑结构特征; (11)第一阶段关系分类; (12)构建第一、第二和第三关系图; (13)进行图卷积运算; (14)进行第二阶段关系分类; (15)将损失函数值的加权和作为最终损失函数值; (16)可视化损失函数值; (17)识别情感标签。  12
本申请公开基于自然语言对话的表数据处理方法，涉及数据处理领域，接收客户端发送的数据表名称和内容指令；查询数据表的表结构，根据表结构将其转换为文本数据，并和内容指令组织成目标文本；将目标文本输入处理自然语言对话的大语言模型，将目标文本进行解析，生成执行脚本；连接数据库查询目标数据并基于执行脚本进行处理，将目标数据的执行结果按照数据表的格式发送到查询界面进行表格化显示。这一过程由云端自动生成执行脚本，用户无需根据要操作的内容和功能手动编写脚本语言来查询数据库，特别是面向非专业技术人员使用更友好，且提供的可视化界面可以直接生成表格数据，相比传统的代码化数据，结果更为直观。通过使用基于自然语言对话的云服务器(权利要求书)来处理表格数据的方法。该过程由云端自动生成执行脚本，用户不需要根据所要操作的内容和功能手动编写脚本语言来查询数据库，特别是对于非专业技术人员使用更加友好，提供的可视化界面可以直接生成表格数据，相比于传统的代码数据，结果更加直观。该方法包括接收由客户机输入和发送的数据表的名称(S1)。 在所述数据表上执行待执行的内容指令。 连接数据库(S2)，以查询目标数据并基于执行脚本进行处理。 将所述目标数据的执行结果按照所述可数据的格式发送至查询接口进行表格展示。 接收所述执行脚本的说明文本用于学习。 在所述查询界面上显示(S4)所述解释文本。还包括用于通过使用基于自然语言对话的云服务器来处理表格数据的一组指令的计算机可读存储介质。  11
本发明公开了一种基于深度学习的模型训练方法，建立深度学习模型，利用大规模穿戴式心电数据进行预训练，以选择一个指标优异且可靠的预训练模型。能够克服传统方法利用形态学特征、统计特征计算相似度的不足。还提出一种基于深度学习的心电图相似度计算方法，使用预训练模型提取心电数据的深度特征，并计算特征间的余弦相似度，随之建立基准点，深度学习的提取特征更加鲁棒可靠，相似度精度更高，针对高维特征采用了余弦相似度的计算方式，优于较传统的形态相似度计算方式。最后绘制个人心电图相似度图，分析心电数据时间变化趋势，给医护人员和使用者参考，快速捕捉到异常心电图。计算机实现的基于深度学习的心电图相似度计算方法。所述深度学习的提取特征更加鲁棒可靠，相似精度更高，对高维特征采用余弦相似度计算模式。 对心电图数据的时间变化趋势进行分析，并给出医护人员和使用者的参考，快速捕捉异常的电心率。该方法包括获取原始心电图数据。 对数据进行预处理，得到原始训练数据。 构建深度学习模型。 利用所述原始训练训练数据对所述深度训练模型进行动量比对学习训练，得到预先训练的特征提取模型。 带通滤波器用于滤除原始心电数据的噪声。 采用归一化操作去除原始心电数据的偏移效应，得到原始训练数据。独立权利要求包括如下内容：(1)一种基于深度学习的心电图相似度计算方法； (2)一种基于深度学习的心电图相似度计算装置； 以及(3)存储用于训练模型的程序的计算机可读存储介质。  11
本发明一种基于5G网络机器视觉的车辆导航系统，涉及车辆导航技术领域。包括卫星导航模块，视频采集模块，数据处理模块，通信模块，云端，人机交互模块构成，以电信号方式连接。本发明在卫星定位信号丢失或者定位偏差的情况下，基于5G网络通过机器视觉方式实时获取路况信息，对抓取的视频进行路牌信息识别，定位车辆的位置，通过识别的信息比对已规划过的路线进行导航校正，结合云技术和机器视觉技术，确保车辆在自动驾驶过程中的连续性和准确性，并可在定位信号缺失或移动信号缺失情况下进行持续导航。经过数据验证证明可靠并可以提高定位精度和导航准确性。更好的实现实时定位，提高导航精度，增加行驶或自动驾驶安全性。第五代基于网络机器视觉的车辆导航系统。该系统保证了车辆自动驾驶的过程的连续性、可靠性和准确性，并且能够提高定位精确率和导航精度和导航精确率，增加了自动驾驶安全性。该系统具有电信号连接的卫星导航模块(1)、视频采集模块(2)、数据处理模块(3)、通信模块(4)、云端(5)和人机交互模块(6)。 卫星导航模块在卫星信号丢失时支持当前路径惯性导航。 所述视频采集模块设有高清数字双目摄像头，用于传输数据处理模块进行数据处理后获取实时图像信息。 13
本发明公开了一种基于协调注意力深度神经网络的菊头蝠识别方法，涉及动物学图像识别技术领域。获取菊头蝠正脸及侧脸图像作为数据集；将数据集划分为训练集和测试集；对训练数据集图像进行预处理及数据增强；构建EfficientNet‑CA神经网络模型；所述EfficientNet‑CA模型是将EfficientNet‑B0模型的核心模块MBConv(移动翻转瓶颈卷积)模块中的Squeeze‑and‑Excitation(挤压与激励)模块替换为称为协调注意力的Coordinate Attention模块，构成EfficientNet‑CA模型；为提高训练精度与速度，使用ImageNet上的动物数据集对EfficientNet‑CA进行预训练，得到预训练模型，并将预训练模型的全连接层输出类别更改为8类；最后输入测试集对训练好的模型进行测试。该网络克服了Squeeze‑and‑Excitation(挤压与激励)模块只考虑编码通道间信息，而忽略位置信息的问题。菊花 基于协同注意深度神经网络的头拍识别方法，应用于动物图像识别技术领域，用于人工标注关键特征信息。本发明提高了训练精度和速度，解决了位置信息忽略的问题。一种基于协同注意深度神经网络的球拍识别方法，包括以下步骤：(i)获取球拍的人脸图像和侧面人脸图像的数据集；菊花 头和作为数据集的头的脸部图像， (ii)将数据集按3：1的比例随机分成训练集和测试集， 最终训练集图像的数量是694， 每个菊花头类型约为85幅图像， (iii)通过图像训练训练EfficentNet-CA图像分类模型， (iv)通过Imagenet上的动物数据集来特异性地训练EfficentNet-CA，以获得预训练的模型， (v)通过训练数据集训练EefficentNet-CA，得到预训练模型；(vi)将测试集图像输入到训练后的EefficentNet-CA，输出图像在某一类别中的概率。   4
本发明提供一种伪标签无监督数据训练方法、装置、设备及介质，方法包括使用CLIP预训练模型对图像库中的无标注图像数据进行样本初步标注；根据初步标注结果和类别置信度，对不同的类别挑选样本进行人工标注得到人工标注图像数据；利用人工标注图像数据，通过交叉熵损失函数对分类模型进行有监督训练，将训练后的分类模型复制成两份，一份作为教师网络模型，另一份作为学生网络模型；通过教师网络模型为无标注图像数据生成伪标签，计算基于聚类伪标签的自适应阈值，利用自适应阈值对教师网络模型生成的伪标签进行过滤，并使用过滤后的伪标签训练学生网络模型。本发明的优点：能够降低人工标注成本，便于生成多样化、且高质量的伪标签。方法进行伪标签无监督数据训练。该方法降低了人工打标的成本，高质量地生成各种假标签。 对分类模型进行若干轮有监督的训练，提高了分类模型的性能该方法涉及使用剪辑预训练模型对图像库中的未标注图像数据的样本进行初始标注，其中生成初始标注结果。 根据初始标记结果和类型置信度选择针对不同类型的样本。 对选取的样本进行人工打标，得到人工打标图像数据。 将人工标注图像数据通过交叉熵损失函数到分类模型进行监控训练。 将分类后的训练模型复制为两部分，并作为教师网络模型，另一部分作为学生网络模型。 生成通过所述教师网络模型对所述未标注图像数据的伪标注。 计算基于聚类伪标签的自适应阈值。 所述教师网络模型利用所述自适应阈值对生成的伪标签进行过滤。 利用过滤后的伪标签训练学生网络模型。独立权利要求包括用于：伪标签无监督数据训练装置； 电子装置； 一种计算机可读存储介质，其存储有用于伪标签无监督数据训练的计算机程序。 14
本发明公开了一种基于不确定性感知的多模态命名实体识别方法。包含备选标签生成和标签修正两个步骤。在备选标签生成中，首先使用预训练模型对输入文本进行特征提取，得到包含丰富上下文信息的特征表示；然后将该特征送入贝叶斯神经网络输出备选标签和对应的不确定性。在标签修正阶段，使用预训练模型对文本和图像进行特征提取，得到特征表示；其次提出了一种多模态融合框架，通过多头注意力机制实现文本和图像的特征融合。最后将融合特征送入条件随机场输出修正标签，并用该标签对备选标签进行修正。相比于现有方法，本发明方法能够有效抑制不相关图像引入的噪声，在社交媒体信息挖掘、信息抽取等领域具有广阔应用前景。基于不确定性感知和计算机视觉领域的多模式命名实体识别方法。 也可以用于诸如Facebook(RTM：社交媒体应用)和Twitter(RTM：消息传递应用)的社交媒体中。该方法能够有效抑制非关联图像引入的噪声，拓宽了社交媒体信息挖掘和信息提取领域的应用前景，将融合特征送入条件随机场输出校正标签，对备选标签进行校正。该方法包括将文本特征向量输入贝叶斯神经网络。 输出替代标签和对应的标签不确定度。 构建多模态交互融合框架多模态交互模型(MIM)。 文本特征和图像特征被发送到所述MIM中。 输出多维融合特征。 特征维度转换过程通过线性层进行。 在解码网络条件随机场中输入校正标签。 利用校正标签对候选标签进行校正。  12
本发明涉及自然语言序列标注技术领域，公开了一种基于深度神经网络的信息抽取方法，BERT‑BiLSTM‑CRF模型能够解决信息抽取任务中存在的一词多义与同物异名问题，以及信息抽取任务中存在的待抽取信息长短不统一和待抽取信息有错别字、描述简短等问题，通过批量过采样的方式增加批量中少数类样本信息的数量，使得模型在训练的过程中可以有效学习到少数类样本信息的特征，从而在一定程度上解决数据类别分布不均衡的问题，使得少数类样本信息的抽取效果有显著提升。一种基于深度神经网络的信息提取方法。该方法能够通过批量过采样来批量增加少量样本信息的数量， 使得模型在训练过程中能够有效地学习样本信息少的特点，在一定程度上解决了数据类型分布不均衡的问题，从而提高了样本信息的提取效果。该方法包括在非监督域中连续地进行预训练和基于批量过采样的监督训练。 在开放域预训练语言模型的屏蔽语言模型(MLM)的非监督域中继续预训练。 在CRF模型领域中，BERT模型和BILSTM-CRF模型在继续预训练之后被组合。 监督Bert-Bilstm-CRF模型的训练。  12
本发明公开了一种基于GCS‑Net进行OCT图像脉络膜自动分割方法，包括以下步骤：数据获取和预处理；构建GCS‑Net网络模型，采用U‑Net结构作为基础网络，在编码路径与解码路径之间的每层跨越连接层采用组间通道膨胀模块(GCD)进行连接，在解码路径中每层反卷积层后采用组间空间膨胀模块(GSD)进行层间连接；对训练好的GCS‑Net网络模型进行测试，将待分割图像输入构建好的模型中，输出对应的脉络膜分割图。上述两个模块采用两种方式分别自动选择组间的多尺度信息，显著提高了脉络膜自动分割的准确性，且适用对象可扩展至病理性近视或含视神经乳头的视网膜图像，本发明有利于提高脉络膜定量分析的准确率以及有利于全面获取三维大视野数据中脉络膜的形态信息。基于GCS-Net实现OCT图像脉络膜自动分割的方法。该方法能够实现组间多尺度信息的自动选择，从而显著提高脉络膜分割的准确性，并将应用对象扩展到病理性近视或具有视神经乳头的视网膜图像，提高脉络膜定量分析的准确性和对三维宽视野数据中脉络膜形态信息的全面获取。该方法包括利用训练集样本构建GCS-Net网络模型，对GCS-Net网络进行训练，所述GCS-Net网络采用U-Net结构作为底层网络。 组间通道扩展模块将输入特征映射划分成多个组。 对多个组的特征图进行不同扩展率的扩展卷积运算。 将分组后的特征图与输入的特征图组合，进行残差运算，输出模块的预测图。 将待分割图像输入构建的模型中。 由所述待分割图像输出脉络膜分割图。   6
本申请属于网络技术与安全技术领域，具体涉及一种攻击检测方法、攻击检测装置、计算机可读介质及电子设备。该方法包括：获取待检测请求序列，并对待检测请求序列进行分词处理，得到待检测请求序列的分词；对分词进行编码处理，得到分词对应的序列编码；对序列编码进行特征提取，得到第一隐层特征；获取预训练的片段定位器，对第一隐层特征和片段定位器进行特征提取，得到第二隐层特征；对第二隐层特征进行回归处理，得到待检测请求序列的攻击片段的片段起点位置、片段终点位置以及片段类型。本申请能够实现对于攻击片段的片段位置和片段类型的预测，能够有效地检测出隐藏在请求中的攻击片段，进而能够提高对于网络攻击的防范效果。一种检测网络攻击的方法。本发明实现了对攻击段的段位置和段类型的预测，能够有效地检测出请求中隐藏的攻击段，从而提高了网络攻击的防范效果。所述方法包括：获得待检测的请求序列；以及对所述待检测的请求序列执行(S210)分词处理，以获得所述待检测的请求序列的分词。 对所述分词进行编码处理，以获得与所述分词相对应的序列码。 对序列码执行特征提取以获得第一隐藏层特征。 获得/使用预先训练的片段定位器来定位在待检测的请求序列中具有预定特征的预定数量的片段。 对第一隐藏层特征和片段定位器执行特征提取以获得第二隐藏层特征。 对第二隐藏层特征进行回归处理，以获得待检测请求序列的攻击段的段起始位置，段结束位置和段类型，其中，段类型表示该段的攻击类型。本发明还涉及一种用于检测攻击的方法和装置。 (2)存储用于检测网络攻击的程序的计算机可读介质； 以及(3)电子设备。  11
本发明提供一种行人跟踪方法、系统、设备及存储介质，包括：获取目标行人的多个图像信息；将各所述图像信息输入预训练的第一识别模型，提取各所述图像信息的行人特征，将提取的行人特征与目标库中的行人信息进行比对，得到比对结果；其中，所述行人特征包括人脸特征和人体特征；判断所述比对结果是否大于设定阈值：若大于，则认为追踪成功；否则，采用预训练的第二识别模型提取各所述图像信息的全局特征和属性特征，计算所述全局特征和所述属性特征的距离，若距离大于综合阈值，则认为追踪成功。本发明采用融合人脸识别技术和人体识别技术的方式，且识别过程中无需用户参与，极大地提高了目标行人识别的效率和准确度。一种行人跟踪方法，用于地下车站，例如交通跟踪安全频率，也可用于行人跟踪系统，例如智能手表、智能手机、平板电脑、膝上型电脑、个人数字助理(PDA)等，也可用于人工智能领域。该方法采用人脸识别技术和人体识别技术融合的方式，无需用户参与识别过程，大大提高了目标行人识别的效率和准确率。该方法包括获取目标行人的多个信息。 提取每个图像信息的行人特征。 将提取的行人特征与目标库的行人信息进行比对，得到比对结果。 所述行人特征包括人脸特征和人体特征。 确定比较结果是否大于设定阈值。 利用预先训练的第二识别模型提取每个图像信息的全局特征和属性特征。 如果距离大于综合阈值，则跟踪成功。还包括用于以下的独立权利要求：用于跟踪行人的系统； 包括用于跟踪行人的指令集的计算机设备； 以及包括用于跟踪行人的指令集的计算机可读存储介质。 14
本发明提供了一种语音识别模型的训练方法、语音识别方法及装置，涉及语音识别的技术领域，该语音识别模型的训练方法包括：获取包括多个语音序列的语音样本集，对语音样本集中的多个语音序列进行帧计算，以提取语音序列的Fbank特征向量，对Fbank特征向量进行降采样处理和掩码运算，生成掩码特征向量；将掩码特征向量输入至预训练模型，以完成语音识别模型的预训练过程。本发明提供的语音识别模型的训练方法、语音识别方法及装置，在训练过程中，由于使用的是无标注语音序列，大大减少了语音识别模型的训练过程中对标注数据的依赖，在保证识别效果的同时，也降低了使用成本。用于使用电子设备训练语音识别模型的方法(权利要求书)。降低了语音识别模型训练中对标注数据的依赖。 保证了识别效果，降低了使用成本。该方法涉及获得(S202)语音样本集合。 对所述滤波器组(Fbank)特征向量进行所述指定倍数的下采样处理(S204)，以生成所述Fbank特征向量对应的下采样特征向量。 对所述下采样特征向量执行掩模操作(S206)以生成掩模特征向量。 将掩模特征向量输入(S208)到预训练模型并且通过预训练模型的编码器和MPC层输出对应于Fbank特征向量的预测向量。 计算所述预测向量和所述Fbank特征向量的损失函数(S210)，并根据所述损失函数调整所述语音识别模型中编码器的参数。 在所述损失函数收敛至所述预设值之前，调整所述参数后不断训练所述语音识别模型。 语音识别模型的预训练过程结束。以下包括独立权利要求：一种语音识别方法； 语音识别模型的训练装置； 语音识别装置； 以及存储用于训练语音识别模型的程序的计算机可读存储介质。 3
本发明涉及文本分析技术领域，公开了一种基于AIGC的同屏智能输入方法及装置，该方法应用于同屏输入法，该同屏输入法的输入界面集成至少两个输入区域，该方法包括：基于输入界面获取用户所输入的输入字符串；根据所有输入区域对应的字符类型，切分输入字符串，得到输入字符串对应的分词结果；基于预先训练好的语言处理模型，根据输入字符串对应的分词结果，生成输入字符串对应的候选词集合；根据获取到的目标候选词，确定输入字符串对应的目标输入词，目标候选词为用户从候选词集合中所选择的候选词。可见，实施本发明能够同屏输入多类型字符，提高文字输入效率，有利于提高用户的文字输入体验。一种在计算机、手机、个人数字助理(PDA)等智能终端中通过同屏智能输入装置进行基于AIGC的同屏智能输入的方法(权利要求)。该方法能够实现在同一屏幕上输入多种类型的字符，提高了字符输入效率，改善了用户的字符输入体验。 该方法允许用户高效地进行同屏智能输入，从而提高了用户在屏幕上输入字符的体验。该方法涉及获取(101)用户基于输入接口输入的输入字符串。 所述输入文本串中设置有输入文本。 根据所有输入区域对应的字符类型对所述输入文本进行分词(102)，得到所述输入文本根据所述字符类型对应的分词结果。 基于预先训练的语言处理模型生成(103)与输入文本对应的候选词集合。 所述候选词集合中设置有候选词。 根据获得的目标候选词确定(104)所述目标输入词，所述目标候选词由用户从所述候选文本集合中选择。 其中，目标候选词为用户从候选词集合中选择的候选词。包括以下独立权利要求：1。 进行同屏智能输入的装置； 以及2。 计算机存储介质，其存储有进行同屏智能输入的程序。 1
本发明公开了一种行业资讯正负面模型构建方法和系统、行业资讯正负面识别方法和系统，其中，行业资讯正负面模型构建方法包括：根据每一条行业资讯数据得到资讯分词数据；根据资讯分词数据得到资讯去停用词数据；根据资讯去停用词数据经过行业分类模型进行筛选得到资讯分类筛选数据；对资讯分类筛选数据进行行业知识库过滤得到资讯句式过滤数据；对资讯句式过滤数据进行模型知识蒸馏得到训练数据集和测试数据集；通过训练数据集进行bert模型训练得到正负面初始模型，通过测试数据集进行模型优化得到行业资讯正负面最终模型。该方法在资讯进入模型层前先通过行业分类模型和行业知识库过滤，保证进入模型的资讯符合行业特征，提高了模型构建的准确性。一种通过使用电子设备(要求保护)来构造行业信息正负模型的方法。本发明能够在信息进入模型层之前通过行业分类模型和行业知识过滤，保证进入行业特征的模型的信息，从而提高模型构建的准确性。所述方法涉及获得行业信息集，其中所述行业信息集包括多个行业信息数据。 所述信息分词数据对应于各行业数据而获得。 每条信息字数据用于停止字去除过程。 对每条信息出库字数据，使用行业分类模型的数据预测和滤波，得到信息分类数据滤波。 根据信息句型过滤数据进行模型知识提取，得到行业信息的训练数据集和测试数据集。 基于训练数据集进行BERT建模和训练，得到行业正负值初始模型。 根据测试数据集，对行业信息正负最终模型进行优化，得到正负最终模型。本发明还涉及一种工业信息正反识别方法。 (2)利用电子设备构建行业信息正反模型的系统； (3)行业信息正反识别系统； 以及(4)一种计算机可读存储介质，包括一组指令，用于通过使用电子设备来构造行业信息正负模型。  11
本申请提出一种基于预训练语言模型的相似语句生成方法和装置，其中，方法包括：获取待处理语句；将待处理语句输入已训练的生成模型，获取多个候选相似语句；根据待处理语句和多个候选相似语句，生成多个判别语句对；将多个判别语句对输入已训练的判别模型，获取判别结果，以及根据判别结果从多个候选相似语句中获取目标相似语句。由此，自动生成兼具形式多样且语义一致的相似问题，提高相似语句生成质量和效率。一种基于预训练语言模型生成相似句子的方法。本发明自动生成形式多样，语义一致的相似问题，提高了相似句子生成的质量和效率。该方法包括获得(101)要处理的句子。 将待处理的句子输入(102)到训练的生成模型中，以获得多个候选相似句子。 根据待处理句子和多个候选相似句子生成(103)多个判别句子对。 将多个判别语句对输入(104)到训练的判别模型中，获得判别结果，并根据判别结果从多个候选相似语句中获得目标相似语句。独立的权利要求书被包括在以下内容中： (1)一种基于预先训练好的语言模型生成相似句子的装置； (2)基于预先训练的语言模型生成相似句子的电子设备； (3)存储用于基于预先训练的语言模型生成相似句子的程序的非临时性计算机可读存储介质； 以及 (4)一种计算机程序产品，用于基于预先训练的语言模型产生相似句子。  11
本发明公开了一种信息提取模型的训练方法及装置，该方法包括：获取标注后的文本数据，并将文本数据输入至预训练信息提取模型中，得到文本编码结果并输入至预设数量的第一全连接层中，得到头实体位置向量；分析头实体位置向量以及文本编码结果，得到目标文本向量，并将目标文本向量输入至第二全连接层，得到尾实体位置向量以及文本数据的实体关系；基于头实体位置向量、尾实体位置向量以及文本数据，计算预训练信息提取模型的损失信息，并根据损失信息对预训练信息提取模型进行训练，以得到目标信息提取模型。可见，实施本发明能够有利于提高信息提取模型训练的准确性和效率，以及有利于提高通过训练所得的信息提取模型进行信息提取的准确性。训练信息提取模型的方法。提高了信息抽取模型训练的准确性和效率。 由于预训练模型是基于头部实体位置向量、尾部实体位置向量和文本数据，根据损失信息训练得到目标模型，因此提高了信息提取的准确性，训练得到的目标信息提取模型的准确性。 通过利用从标注后的文本数据中提取的信息，提高了训练信息提取模型的效率和准确率。 计算训练模型的损失信息，并基于损失信息对信息提取模型进行训练，从而可以提高训练模型训练的准确性和效率。 从而提高了训练信息提取器模型的准确性、效率和准确度。该方法包括：获取(101)已标注的文本数据，并将该文本数据输入预先训练的信息提取模型，其中，文本编码结果包括多个文本编码向量。 头部实体位置向量包括头部实体开始向量和头部实体结束向量。 对头部实体位置向量和文本编码结果进行分析(103)，得到目标文本向量，将目标文本向量输入(104)至第二全连接层，得到尾部实体位置向量和文本数据的实体关系，尾部实体位置向量包括尾部实体起始向量和尾部实体结束向量。 基于头部实体位置向量、尾部实体位置向量和文本数据计算(105)预训练的信息提取模型的损失信息，并根据损失信息训练预训练的信息提取模型以获得目标信息提取模型。对于以下包括独立权利要求：(1)信息提取模型的训练装置； 以及(2)一种存储用于训练信息提取模型的程序的计算机存储介质。  12
本发明公开了一种基于预训练语言模型的上下文敏感的释义生成方法及系统，该方法包括：获取训练数据集；其中，训练数据集中包括被释义词、被释义词所在的上下文，以及被释义词对应的释义；构建用于为被释义词生成释义的释义模型；其中，释义模型基于编码器‑解码器框架，释义模型的编码器为预训练的语言模型；基于所述训练数据集，对所述释义模型进行训练；通过训练好的释义模型，基于待释义的被释义词和所述待释义的被释义词的上下文的分布式向量表示，生成所述待释义的被释义词的释义。本发明具有逻辑清晰、效率高、准确率高的优点，解决了现有技术无法为被释义词准确生成释义的问题。该方法可用于基于预先训练的语言模型来生成上下文敏感的释义。该方法能够提供清晰的逻辑，高效和高精度，并且能够准确地生成所发布的同义词的解释。基于预先训练的语言模型生成上下文相关的释义包括获得训练数据集，其中训练数据集包括被释放的同义词。 确定所释放的同义词的上下文。 构造解释模型，用于生成对所释放的同义词的解释。 该解释模型基于编码器-解码器帧来建立。 通过训练好的解释模型来训练解释模型。 基于发布的同义词的上下文的分布式向量表示来生成发布的同义词的含义。本发明还涉及一种基于预先训练的语言模型的上下文相关的释义生成系统。  11
本发明公开了一种融合注意力机制的U‑Net医学影像轮廓自动提取网络，包括RGB图像输入模块，RGB图像输入模块的输出端连接于特征提取模块的输入端，特征提取模块包括特征编码模块、特征解码模块和注意力模块；特征提取模块的输出端连接于MLP的输入端，注意力模块包括空间注意力和通道注意力，用于抑制非关注区域的神经元；MLP输出元设定为2个神经元，分别表示前景和背景的概率，并在其后依次接上Softmax和Marching Square。本发明融合注意力模块，提高了边缘轮廓提取精度，初步解决传统框架产生模糊边缘的问题，并减少了背景噪声的干扰，从而基本满足了医疗领域对医学影像轮廓提取的精度要求；简化了传统框架的流程，大大节约得到目标模型的时间和成本。融合关注机制U-Net医学图像轮廓自动提取网络，应用于医学图像分割领域。该网络集成了关注模块，提高了边缘轮廓提取精度，初步解决了传统帧产生边缘模糊的问题，降低了背景噪声的干扰，基本满足医学领域对医学图像轮廓提取精度的要求。 该网络简化了帧的处理，使得训练和推理的时间较少，大大节省了获取目标模型的时间和成本。 通过步进平方算法，最终提取轮廓，该算法简单快捷，并可进行并行处理。该网络具有RGB图像输入模块，RGB图像输入模块的输出端连接到特征提取模块的输入端，特征提取模块具有特征编码模块，特征解码模块和关注模块。 特征提取模块的输出端与MLP的输入端连接。 关注模块基于空间关注和通道关注来抑制神经元关注区域。 MLP对特征信息进行分类和提取。 输出元素表示前景终端和背景终端的概率。   6
一种基于深度学习的脑肿瘤图像分割模型构建方法，属于图像分割方法领域。现有图像分割模型网络层数过深引起的退化现象、网络分割精度低以及网络参数量多。本发明通过U‑Net网络结构和残差模块结合方式，设计基于U‑Net网络结构的图像分割模型；将三维卷积和残差模块相结合，以对多模态三维脑肿瘤图像进行自动分割；设计多模态加权融合模块。本发明网络层数过深所引起的退化现象。使用卷积残差块和恒等残差块来替换一部分卷积核，在加深网络的同时引入残差结构，可以有效提升网络分割精度。此外还采用三维卷积对脑肿瘤进行分割，结合三维卷积和残差网络结构对脑肿瘤进行自动分割。一种基于深度学习的脑肿瘤图像分割模型构建方法。在网络深化的同时引入残差结构，可以有效提高网络划分精度。 本发明的网络层数太深，不会造成退化现象。 卷积残差块和恒定残差块用于替换一部分卷积核。该方法通过将U-Net网络结构与残差模块相结合，设计基于U-Net网络结构的图像分割模型，所述U-Net网络结构包括编码单元、解码单元和桥接单元。 编码单元包括四个编码模块和下采样操作。 解码单元包括四个解码模块和上采样操作。 进行设计多模加权融合模块的过程。 将不同模式的MRI图像信息整合后送入网络进行训练。 通过每个模式的训练结果在所有模式划分结果中所占的比例来确定每个模式的多模式融合权重，将多个模式的图像按照权重进行线性融合，得到融合了不同模式信息的图像，将融合后的图像输入网络进行训练和测试，并对输出结果进行评估。  7
本申请公开了一种文档版面识别方法，包括：对原始文档数据进行文本框信息提取和层级关系提取，得到训练数据；构建包含Embedding层的Albert模型，并作为初始识别模型；其中，所述Embedding层由文本特征、布局特征、图像特征以及页码特征构建得到；采用所述训练数据对所述初始识别模型进行训练，得到识别模型；采用所述识别模型对待识别文档进行识别，得到所述待识别文档中各个文本框的区域类别和层级关系。提高对文档版面进行自动化分析的准确性和精度。本申请还公开了一种文档版面识别装置、终端装置以及计算机可读存储介质，具有以上有益效果。该方法可用于识别文档的布局，即包括问题，段落，图片，表格和眉毛的富文本文档。提高了文档版面自动分析的准确度和精确度。 本发明提供了一种具有上述有益效果的文档布局识别装置，终端设备和计算机可读存储介质。所述方法包括：对原始文档数据进行文本框信息提取和层级关系提取，得到训练数据。 构造包含嵌入层的Albert模型。 通过使用训练数据训练初始识别模型以获得识别模型来训练初始识别模型。 通过使用识别方法来识别待识别文档。 获取待识别文档中每个文本框的区域类型和层级关系。本发明还涉及一种文档布局识别装置； 以及计算机可读存储介质，包括用于识别文档布局的指令集。  11
本发明公开了一种基于深度卷积神经网络的菌落分割计数方法及系统，菌落分割计数方法包括以下步骤：在暗箱环境下，采集低噪声菌落图像数据，通过Labelme软件进行修改并进行菌落标注，获取初始图像数据；基于mobileNetv2的基础模块，采用UNet模型的跳跃连接方式，并在模型编码器的结尾添加一个ASPP结构，构建多尺度聚合模型，多尺度聚合模型用于通过将高维度语义信息和低维度边缘信息进行结合，对初始图像数据进行菌落分割，获取菌落分割图像数据；通过适用性分水岭算法，对菌落分割图像数据进行处理后，采用四连通域检测的方式进行菌落计数；本发明具有高自动化，高精度，高效率的自动化检测计数功能。基于深度卷积神经网络的菌落分割计数方法，采用QXC-30全自动菌落计数器，MELIEER的EC2自动菌落计数器等菌落自动计数仪。本发明实现了高自动化，高精度，高效率的自动检测计数功能，实现了对不同规模菌落目标的高精度分割和精确菌落计数。该方法包括收集低噪声群体图像数据。 用Labelme软件对集落进行标记，获得初始图像数据。 本发明基于移动通信系统的基本模块，采用UNET模型的跳转连接方法，实现了移动通信系统的跳转连接。.NET (RTM : 计算机软件框架)V2和高级标准协议(ASPP)结构被添加在模型编码器的末端。 构建了一种结合高维语义信息和低维边缘信息的多尺度聚合模型。 对初始图像数据进行菌落分割，得到菌落分割图像数据。 对群体分割图像数据进行处理后，采用适用性分水岭算法以四连通域检测为单位对群体进行计数。独立的权利要求书被包括在以下内容中： 一种基于深度卷积神经网络的菌落分割计数方法； 以及 一种基于深度卷积神经网络的菌落分割计数系统。   4
本发明公开了一种基于掩码图注意力机制的交通路网编码表征学习方法，利用BERT模型的上下文信息提取能力，扩大图注意力机制的邻接空间信息提取阶数，使模型能完成对路网交通流数据的深度表征，对路网空间特征进行有效提取。所述RNERT模型采用掩码(mask)预训练算法，学习路网空间特征提取的共性能力。对于缺失数据补全任务直接使用RNERT预训练模型进行补全计算；对于路网交通流预测，基于图注意力编码表示的交通路网门控循环网络(GRU‑RNERT)，对其中的时空多维度特征进行提取。一种用于交通流处理的基于掩模图像注意力机制的交通路网编码表征学习方法。该方法使得图像注意力机制的相邻空间信息提取顺序放大，使得模型能够完成路网交通流数据的深度表征，从而有效地提取了一个路网的空间特征。该方法是将双向编码表征模型与图注意力网络相结合，构建基于掩模图注意力机制的交通路网编码表征模型。 通过掩膜预训练模式训练模型的路网空间特性，提取普适能力，支持不同的交通任务。 经过一定时间后通过所述RNERT模型预先训练一个交通网络损失值。 基于RNERT构建交通路网门控流通网GRU-RNERT。 在循环神经网络中嵌入一个空间特征提取单元，参与一个选通单元计算过程。 提取交通网络交通流中的时空多维特征。  12
本发明涉及数据程序分析领域，提供一种基于AI Chain的隐性数据流感知DFG生成方法、系统及存储介质，包括模拟人从程序中提取DFG的过程，将DFG生成任务分解为多个子任务，每个子任务交由一个单独的大型语言模型来完成；基于大型语言模型的上下文学习能力，针对每个子任务，构建prompt，形成一个个AI模块；将prompt以串联或者并联的方式组装形成一条AI Chain，进而生成DFG。本发明利用大型语言模型的语言理解和模式匹配能力，捕捉变量的def‑use流信息，并预测运行时发生的隐性数据流，通过大型语言模型的上下文学习能力，能够实现对程序中的隐性数据流的精准捕获；增强了生成DFG的鲁棒性和可控性。基于AI链的隐式数据流感知DFG生成方法。利用大语言模型的语言理解和模式匹配能力，捕获变量的def-use流信息并预测运算中产生的隐性数据流，可实现程序中隐性数据流的准确捕获。 增强了生成DFG的鲁棒性和可控性。该方法涉及将DFG生成任务分解为多个子任务，其中每个子任务由单个大型语言模型完成。 基于大级别语言模型的上下文学习能力，为每个子任务构建一个提示，形成人工智能(AI)模块。 提示进行串联或并联组装，形成AI链，生成DFG。 对每个变量进行程序切片，得到相应的切片代码，def-use流融合，针对每段切片代码。 提取相应的def-use流信息。包括以下独立权利要求：一种针对程序分析字段的基于AI链的隐藏数据流感知DFG生成系统； 以及存储用于生成基于AI链的隐式数据流感知DFG的程序的计算机可读存储介质。  11
本申请公开了一种拥挤场景下人物计数方法及装置。方法包括：获取监控场景下的视频信息；标注视频信息中人物的头像；构建卷积神经网络模型，并设置卷积神经网络模型的结构及训练参数；通过生成网络消除视频信息中的复杂场景的影响，并得到当前帧特征；通过卷积神经网络对图像信息中的连续视频帧提取特征；通过LSTM网络串联连续视频帧特征，并加强当前帧特征的鲁棒性；利用加强了鲁棒性的当前帧特征，使用LSTM网络连续回归出最终的人物的位置坐标；根据最终的人物的位置坐标，得到最终的检测和计数结果。因而达到了能够通过使用生成网络消除不利影响和考虑视频帧的时序信息，并且利用LSTM设计并实现了目标检测和人群计数方法的目的。用于在拥塞场景中计数人员的方法。该方法通过使用生成的网络，消除了不良影响的时序信息并考虑了视频帧，满足了LSTM的目标检测和人数统计处理的目的。该方法涉及获取监控场景的视频信息。 对所述视频信息中人物的人像进行标记。 构建卷积神经网络模型。 设置所述卷积神经网络模型的结构和训练参数。 通过生成网络消除视频信息中复杂场景的影响。 获取当前帧特征。 降低了视频信息中图像质量的不利影响因素。 从所述图像信息中的连续视频帧提取所述特征。 通过LSTM网络对视频帧特征进行对齐，利用LSTM网络不断返回最终角色的位置坐标。 根据最终字符的位置坐标得到最终的检测和计数结果。本发明还公开了一种用于在拥堵场景下对人员进行计数的装置。   4
本发明提供了一种基于AIGC的舆情分析编排系统，其特征在于，包括数据采集模块、热度分析模块、情感分析模块和分析结果管理模块；所述数据采集模块用于采集网络信息数据并在网络信息数据中筛选出各关键词组和关键信息；所述热度分析模块用于根据关键信息分析所述各关键词组在网络中的影响热度；所述情感分析模块用于根据关键信息对各关键词组的舆情正负面进行分析，所述分析结果管理模块用于向用户可视化展示各关键词组热度和舆情影响；本发明采用多维度的情感分析方式，可最大程度上了解到用户的真实情感。基于AIGC技术的舆情分析整理系统，用于对文本、图像、语音和视频等多模态数据进行分析处理。该系统便于用户查看并做出相应的措施，并且能够利用多维度的情绪分析模式获知用户的真实情绪，保证舆情分析的准确性。所述系统具有情绪分析模块，用于根据关键信息分析关键短语的舆情。 分析结果管理模块根据影响力热度和舆情正负分析，将所述关键短语的热度和情感的影响力直观地展示给用户。 一种数据采集模块，设置有采集子模块、预处理模块和预存储模块。 所述采集子模块在设定的采集周期内，采集互联网的数据平台上公开的网络信息，所述采集的网络信息包括所述数据平台的搜索引擎获取的所述关键短语。 所述预处理模块对所述网络信息进行清洗和筛选，得到关键信息。 所述预存储模块存储所述关键短语和所述关键信息。 1
本发明适用于相似搜索词的预测技术领域，提供了一种相似搜索词的判断方法、系统、存储介质及计算机设备，相似搜索词的判断方法包括：获取若干共点击数据；根据两个所述共点击数据中的所述在所述搜索词下点击的url以及所述在所述搜索词下点击所述url的点击数，判断两个所述搜索词的相似度，将相似度高的两个搜索词划为一个正样本；将相似度低的两个所述搜索词划为一个负样本；若干所述正样本以及若干所述负样本形成训练集；将所述训练集作为输入，对语义预训练模型进行训练，获取最终模型。借此，本发明实现了推广广告主的广告，还可以提升平台的收入。一种使用计算机设备判断相似搜索词的方法。本发明能够获得与用户搜索词相似度高的搜索词，从而提升广告主的广告，从而提高平台的收益。该方法包括获得(S301)一些总点击数据。 每个共同点击数据包括搜索项，在搜索项下被点击的URL，以及在搜索项下对URL的点击次数。 根据两个共同点击数据中在搜索项下点击的URL和在搜索项下点击URL的次数来判断(S302)两个搜索项的相似性。 将两个相似度高的检索词分类为正样本。 将两个相似度低的检索词分类为阴性样本。 多个正样本和多个负样本构成训练集。 将训练集作为输入(S303)。 训练语义预训练模型以获得最终模型。本发明还涉及一种用于确定相似搜索词的方法和系统。 以及存储用于执行用于判断相似搜索词的方法的程序的存储介质。  11
本发明涉及时序数据处理技术领域，具体涉及一种电网时序数据预训练及预测方法、装置、预训练模型。预训练方法包括：获取预设时间段的电网时序数据划分得到历史时序数据和未来时序数据；将历史时序数据和未来时序数据进行掩码；将掩码历史时序数据输入至编码器学习，得到重建历史时序数据和历史时序特征；将历史时序特征和掩码未来时序数据输入至解码器预测，得到预测未来时序数据；采用预设损失函数计算历史时序数据和重建历史时序数据以及未来时序数据和预测未来时序数据的损失，实现对编码器和解码器参数的优化。通过实施本发明，基于编码器和解码器的重建与预测联合优化，达到了预训练和微调的一致性。提升模型针对时序数据的预训练效果。利用计算机设备(权利要求书)对电网时序数据进行预训练和预测的方法。该方法能够基于编码器和解码器的重构和预测的联合优化，实现预训练和微调的一致性。 该方法提高了模型针对时序数据的预训练效果。该方法涉及获取电网在预设时间段内的历史时间序列数据和未来时间序列数据，得到历史历史时间序列和未来历史序列数据。 在所述历史历史序列和所述未来历史序列数据之间获取掩码，得到掩码历史时间序列和所述掩码未来历史序列数据。 将掩码历史时间序列输入编码器进行学习，得到重构历史时间序列数据和历史时间序列特征。 将所述历史时间序列和预测未来时间序列数据输入解码器进行预测，得到预测的预测未来历史时序数据。还包括独立权利要求，用于：电网时序数据预训练模型； 一种电网时序数据预测方法； 电网时序数据预测装置； 以及一种计算机可读存储介质，所述计算机可读存储介质包括利用计算机设备对电网时序数据进行预训练和预测的指令集。  11
本发明公开一种基于CTC的非自回归端到端语音翻译方法，步骤为：构建编码器‑解码器结构的非自回归端到端语音翻译模型；构建语音识别模型和机器翻译模型作为预训练模型，使用音频文件和源语言文本数据训练语音识别模型；使用源语言文本和目标语言文本数据训练机器翻译模型；以语音识别模型和机器翻译模型作为预训练模型，使用两个模型的参数来初始化非自回归语音翻译模型的参数；在语音翻译数据集上对参数进行微调，完成训练过程；语音翻译模型的编码器进行编码，解码器根据编码器的输出结果进行解码，生成最终的目标语言文本。本发明增强了语音翻译模型的编码能力，在获得与自回归模型取得相似性能的情况下，能够获得较大的速度提升。基于CTC的非自动回归端到端语音翻译方法。该方法增强了语音翻译模型的编码能力，以获得与自回归模型相似的性能，从而可以减少非自回归语音翻译模型中语音和文本表示的不一致性。该方法基于CTC技术的模型结构，利用自注意力机制构建非自回归端到端语音翻译模型的编码器-解码器结构。 构建语音识别模型和机器翻译模型作为预训练模型。 利用语音识别训练模型训练音频文件和源语言文本数据。 所述语音翻译训练模型的编码器根据输入的语音特征进行编码。 根据编码器的输出结果，采用CTC贪婪搜索策略生成最终的目标语言文本。 3
本申请公开了一种数据处理方法、装置、设备及存储介质，所述方法包括：获得预训练数据集；所述预训练数据集为n×k×m的矩阵，其中，所述m表示所述预训练数据集对应的时段的数量，所述k表示所述训练数据集对应的指标的数量，一个所述时段包括n个时刻；通过异常检测模型的预处理层对所述预训练数据集进行纵向分割，得到第一训练数据集；通过所述预处理层对所述预训练数据集进行横向分割，得到第二训练数据集；基于所述第一训练数据集和所述第二训练数据集训练异常检测模型，得到目标检测模型。对于本申请的方案，异常检测时准确度高，且通用性好。一种金融部门数据处理方法。本发明通过异常检测模型的预处理层对预训练数据集进行纵向分割，得到第一训练数据集，从而准确地得到目标检测模型，从而有效地提高了异常检测的准确性。该方法包括预训练数据集。 数据集是N×K×M×M的矩阵， 其中M表示对应于对应于预训练数据集的数据集的时间段的数量，K表示对应于该时间段中的训练数据集的索引的数量。 通过异常检测模型的预处理层对数据组进行纵向分割，得到基于训练异常检测模型的第一训练数据组。 目标检测模型用于确定一个时间段内检测数据的检测参数，并确定检测参数是否异常。本发明还涉及一种用于处理金融系统中的数据的电子设备，该电子设备包括存储器和处理器； (2)一种存储介质，用于存储一组用于处理金融部门中的数据的指令。  11
本发明公开了一种用于越南语的命名实体识别方法，其特征在于，包括如下步骤：1)模型训练；2)数据字典构建，所述模型训练包括：1‑1)数据输入；1‑2)BERT层训练；1‑3)GRU层训练；1‑4)CRF层训练，所述数据字典构建包括：2‑1)数据字典修正；2‑2)结果验证。这种方法越南语命名实体识别准确率高。该方法对于识别越南的命名实体是有用的。该方法准确度高。一种识别越南命名实体的方法，包括：(i)使用模型进行模型训练，该模型为六层结构，包括从上到下连接的输入层、变换器的双向编码器表示(BERT)层、门控环路单元(GRU)层、条件随机场(CRF)层、字典校正层和输出层; (b)将数据输入到训练模型中的BERT层，生成词向量并将它们输入到训练模型中的GRU层; (c)输出每个标签的预测得分; (ii)(a1)人工收集代表名称，人工标注实体标签，并校正CRF层的预测结果; (a2)用准确度集对验证集的结果进行验证，其中测试集的格式与训练集A的格式完全相同，验证方法是将识别出的正确实体的数量除以识别出的实体的总数。  12
本发明涉及一种基于语义相似度的问答系统搜索匹配方法及其应用，问答系统中包括标准问题及答案，对应标准问题设置若干相似问题；构建样本集合，对预训练模型进行调整、训练；将问答系统中的问题向量化，对新的用户问题向量化，进行余弦相似度计算，根据相似度得分对问答系统中的所有问题排序，输出预设条数的问题；方法应用于税务问答系统。本发明解决了传统模型面临的一词多义、单词歧义、分词准确率等问题，并且能够充分的获取句子中包含的语义信息，大幅提升模型的性能，训练和预测阶段全程可并行，提升模型预测准确度，提升搜索推荐指标、增强模型的泛化能力，提升用户体验，减少维护成本；特别适用于税务咨询领域。一种基于语义相似度的问答系统的搜索匹配方法。该方法避免了使用传统的基于词向量的搜索排序模型， 大大降低了维护成本，避免了模型堆栈造成的误差传播，也提高了模型的预测精度，增强了模型的泛化能力，改善了用户体验，降低了维护成本。 本发明解决了传统模型存在的词歧义，词歧义和词切分精度等问题，能够充分获取句子中包含的语义信息，大大提高了模型的性能，并且训练和预测阶段能够并行。该方法包括建立预训练模型。 构建样本集，调整预训练模型，并基于调整结果执行训练。 获得训练的模型。 问题答案系统中的所有问题被输入到训练好的模型中，并使用训练好的模型来向量化和存储所有问题。 获得新的用户问题，将其输入到另一个训练模型，并用该训练模型向量化该新的用户问题。 余弦相似度是在所处理的向量和所存储的所有向量之间计算的。 根据相似度得分对答题系统中的所有问题进行排序，并输出预设数量的问题。  12
一种基于元学习的图像识别持续学习方法，通过迁移学习方式用实际使用场景图像的微调数据集训练预训练模型，得到微调模型，再调整微调模型架构得到few‑shot模型；然后使用few‑shot模型推理待预测图像，得到分类结果；再对分类结果进行人工矫正，将人工矫正的矫正数据和待预测图像加入微调数据集中，从而实现持续学习。本发明通过采用元学习进行迁移学习，通过大量容易采集数据得到预训练模型，迁移到少样本的实际使用场景图像中对其进行分类。而且本发明采用持续在线学习的模式，在使用过程中，对于分类结果定期人工矫正，修正后的数据自动加入微调数据集，快速迭代微调模型。基于元学习的连续学习图像识别方法。所述方法：利用元学习进行迀移学习； 通过采集大量数据容易得到预训练模型并迁移到样本较少的实际使用场景图像中进行分类； 采用连续在线学习的模式； 能够定期对分类结果进行人工修正； 能够自动将修正后的数据添加到细调数据集合中； 并能快速迭代细调模型。该方法涉及基于迀移学习模式，利用实际使用的场景图像的细调数据集，对预训练模型进行训练，得到细调模型，对细调模型框架进行调整，得到横拍。 对利用水平拍摄模型进行待预测的图像进行推理，得到分类结果。 对所述分类结果进行人工校正。 将人工校正后的校正数据和待预测图像加入到细调数据集中，从而实现不断学习。 14
本发明涉及一种基于强化学习的改进文本到图像生成的自动编辑提示的方法。该方法使用奖励网络和编辑网络。奖励网络估计与编辑提示相对应的生成图像的质量以及它们之间的语义对齐程度。为了预训练奖励网络，使用从DiffusionDB等已建立的数据库中获得的提示图像对齐分数和图像美学分数作为标签。基于GPT架构的编辑网络为输入提示符生成修饰符。它在离线强化学习中训练，在给定目标奖励的条件下产生期望的提示。本发明方法可以有效地编辑提示符，而无需重复运行生成模型。实验结果表明，经过本发明方法编辑的提示可以生成与原始输入语义一致、符合人类偏好的高质量图像。基于强化学习的改进文本转图像生成自动编辑提示方法。该方法允许奖励网络在不实际运行生成器的情况下仅基于输入提示来估计潜在生成的图像的质量，提出了提供各种短语以修改输入提示而不是从头生成新提示的编辑网络，因此实验结果表明，网络编辑提示在保留原始语义和符合人类偏好方面是有效的。该方法通过输入一段描述用户意图的文本，并输出处理后的文本，使得以文本为条件的预训练的图像生成模型生成更符合人类美学、满足用户需求的图像。 在给定奖励条件下通过自回归在输入提示中加入修饰符，迭代生成T步提示序列。 通过预先训练的奖励网络初步给出或估计对应的奖励，快速修改任意用户提供的文字提示，输出修改提示，使得对应生成的图像具有较好的视觉效果，同时符合来源的语义提示。   6
本发明公开了一种满足差分隐私的高质量轨迹深度生成方法，包括：构建轨迹深度生成模型，获取公共数据集与真实数据集；基于公共数据集、真实数据集以及基于差分隐私的随机梯度下降算法对轨迹深度生成模型进行训练，获得训练后的轨迹深度生成模型；基于训练后的轨迹深度生成模型获得轨迹数据集。本发明首先利用保护数据集所在城市的公共数据集来预训练生成器和判别器，然后正式对抗训练生成器和判别器，并且在训练判别器的过程中基于DP‑SGD对判别器的梯度加噪；与满足差分隐私的传统轨迹生成方法相比，在同样的隐私预算下更多的捕获到了原始轨迹的特征，产生有用性更高的轨迹数据集。弥补了现有的轨迹深度生成模型隐私没有保障的不足。满足差分隐私的高质量轨迹深度生成方法。该方法利用受保护数据集所在城市的公共数据集预训练生成器和判别器，正式对抗训练生成器和判别器，并在训练判别器的过程中基于DPSGD对判别器的梯度添加噪声。 在相同的隐私预算下捕获的原始轨迹的特征越多，从而产生更有用的轨迹数据集。 该方法弥补了现有轨迹深度生成模型隐私性没有保证的不足。该方法涉及构建轨迹深度生成模型，获取公开数据集和真实数据集。 基于所述公共数据集、所述真实数据集以及基于差分隐私的随机梯度下降算法对所述轨迹深度生成模型进行训练，得到训练后的轨迹深度生成模型。 基于训练后的轨迹深度生成模型得到轨迹数据集。 轨迹深度生成模型包括生成器和判别器。 13
本公开提供了一种文本分类方法、分类装置、电子设备和存储介质，涉及机器学习技术领域。其中，文本分类方法包括：基于对原始文本的因果约束关系挖掘操作生成因果事件图谱；将因果事件图谱和预设文本库进行匹配操作，基于匹配结果配置因果事件图谱的提示模板；基于目标数据集执行多感知并行的模型预训练，得到多个预训练模型；基于多个预训练模型以及对应的模型权重和提示模板得到预测分类模型；基于预测分类模型对待分类文本进行预测分类并输出预测分类标签；对预测分类标签和备选目标标签进行相似度计算，以基于计算结果确定目标分类标签。通过本公开的技术方案，基于预设文本库所包含的结构化知识有利于降低提示模板的构建成本。用于机器学习的文本分类的方法。 用途包括但不限于手机、游戏主机、平板电脑、电子书阅读器、智能眼镜。降低了提示模板的构建成本，基于预设文本库中包含的结构化知识，有利于降低构建成本。 所述文本分类装置用于将所述因果事件图与所述预定文本库进行匹配操作，并基于所述匹配操作的匹配结果配置所述因果事件图的提示模板，从而降低了生成所述提示模板所需的计算成本和时间，也提高了对待分类文本分类的准确性。 通过减少预训练模型的数量以及相应的模型权重和提示模板来降低计算代价。该方法涉及基于匹配结果来配置(S204)因果事件地图的提示模板。 基于所述提示模板配置作为目标数据集的原始文本。 基于所述目标数据集进行多感知并行模型预训练(S206)，得到多个预训练模型和对应的模型权值。 基于所述多个预训练模型及对应的模型权重和所述提示模板进行细调模型训练(S208)，得到预测分类模型。 基于所述预测分类模型并输出预测分类标签的待分类文本响应于获得的待分类文本进行预测分类(S210)。 对预测分类标签和备选目标标签进行相似度计算(S212)，以基于计算结果确定目标分类标签。独立权利要求包括以下内容：文本分类装置； 电子装置； 一种计算机可读存储介质，其存储用于机器学习的文本分类的计算机程序。  11
本发明公开了一种用于移动端的轻量级目标检测方法及系统，属于深度学习目标检测领域；所述的方法具体步骤如下：S1利用MOGO‑SSD网络架构搭建Depthwise与Pointwise的组合卷积；S2利用ImageNet数据集进行权重预训练；S3保留训练后的参数，作为预训练模型进行二次优化；S4将二次优化后的训练模型用于目标数据检测；在本发明方法中，采用SSD目标检测算法，SSD可以替代普通网络中的全局池化和全连接层，抽取6层不同尺度的卷积特征用作检测，大尺度特征图(较靠前的特征图)可以用来检测小物体，而小尺度特征图(较靠后的特征图)用来检测大物体，可以有效提高网络的检测速度和精度。移动终端轻量级目标数据检测方法。该方法能够通过使用SSD目标检测算法替换普通网络中的全局池和全连接层，提取卷积特征，通过大尺度特征图检测小对象，通过小尺度特征模式检测大对象，从而提高网络检测速度和精度。该方法包括通过使用MOGO-单炮多盒检测器(SSD)网络体系结构来构造深度方向数据集和点方向数据集。 利用图像网络数据集进行权重预训练过程。 执行训练参数保留处理。 对预训练模型进行二次优化处理。 由所述预训练模型执行目标数据检测过程。 获得信道的空间特性。 对信道进行卷积运算。 对训练好的参数进行二次训练优化处理。包括用于移动终端轻量级目标数据检测系统的独立权利要求。   4
本发明提供一种基于深度学习的智能金相检测评级方法及系统，包括以下步骤：采集金属样片图像；在U‑net全卷积神经网络的基础上进行改进，得到改进后的全卷积神经网络的构建；通过改进的全卷积神经网络对所采集的金属样片图像进行自动分割，得到金相分割图；通过深度神经网络对得到的金相分割图进行自动评级分类；本发明采用深度学习的算法，在U‑net全卷积神经网络的基础上进行改进，避免了传统图像手工提取特征的繁琐和不稳定，同时基于梯度下降法的参数优化提高了提取特征适用性；本发明基于深度神经网络，大大提高了系统计算时间，避免了繁琐的分类计算；本发明分割和分类正确率高、且一键融合分割和评级，避免了传统方法的多步骤操作，灵活便捷。该方法对于基于深度学习的智能金相检测和评级是有用的。该方法：在U‑net全卷积神经网络基础上进行改进，避免了传统图像手动提取的繁琐且不稳定的特征； 提高了提取特征的适用性； 提高了系统计算时间，避免了繁琐的分类计算； 具有分割分类准确率高，分割与评级一键融合； 避免了多步操作； 且灵活方便。一种基于深度学习的智能金相检测与评级方法，包括以下步骤：通过采集金属样本图像并将模拟信号图像转换为红、绿、蓝三通道彩色图像来采集金属样本图像; 对U-net全卷积神经网络进行基础改进，得到全改进卷积神经网络的构建; 利用全改进卷积神经网络对采集到的金属样本图像进行自动分割，得到金相分割图; 利用深度神经网络对得到的金相分割图进行自动评级分类; 显示分割和分类结果。还包括用于基于深度学习的智能金相检测与评级的系统的独立权利要求。   4
本发明涉及非机动车管理技术领域，且公开了一种基于多尺度图像增强和YOLOv5s算法的雾天非机动车检测方法，包括如下步骤：步骤1、对数域转化；步骤2、指数化；步骤3、图像色彩恢复；步骤4、图像特征提取；步骤5、目标特征融合；步骤6、非极大值抑制，本发明对雾天拍摄的非机动车图像使用多尺度图像增强算法进行去雾预处理，降低雾气对目标物体的遮蔽，提高目标轮廓的清晰度，使得图像主体特征更加突出，非机动车目标的检测会更加精确，使用soft‑NMS算块代替原始NMS非极大值抑制算法，减少重叠区域目标的丢失，降低漏检率，在特征金字塔中使用SPPFCSPC模块改进主干网络，增大模型的感受野，提高特征提取的速度。用于交通系统的基于多尺度图像增强和YOLOv5s算法的雾天非机动车检测方法。该方法使得能够利用多尺度图像增强算法对雾天拍摄的非机动车图像进行去雾预处理，因此减少了雾气对目标物体的遮挡，提高了目标轮廓的清晰度，使得图像主体特征更加突出，从而提高了对车辆目标的检测更加准确。 soft-NMS计算块取代了原有的NMS非极大值抑制算法，减少了重叠区域目标的损失，降低了漏检率。 特征金字塔中采用SPPFCSPC模块，对主网络进行改进，增加模型的感知场和提高特征提取速度。该方法包括转换对数域(步骤1)。 执行数字化处理(步骤2)。 恢复图像颜色(步骤3)。 提取图像特征(步骤4)。 进行目标特征融合处理(步骤5)。 进行非最大值抑制处理(步骤6)。 对对数域图像进行高斯金字塔多尺度分解，得到一组不同尺度的图像。 对雾图像进行对数变换。 将雾图像从线性空间转换到对数空间。 13
本申请涉及人工智能领域以及数字医疗领域，提供了一种基于预训练模型的自然语言处理方法以及相关设备，该方法在微调阶段，基于多个文本处理任务对应的训练样本和提示模板生成输入文本和输出文本，并以预测输出文本为训练目标，基于输入文本对预训练模型进行微调，且在推理阶段，同样基于文本处理任务对应的提示模板对文本数据进行改写，生成文本生成任务的输入文本，利用微调后的预训练模型对输入文本进行推理计算得到输入文本在文本生成任务下的第一处理结果，最后根据第一处理结果即可得到文本数据在第一文本处理任务下的第二处理结果，使得预训练模型在推理阶段能够以一个模型应对多种自然语言处理任务，降低线上部署设备资源的消耗。用于人工智能领域和数字医疗领域的基于预先训练的语言模型的自然语言处理方法。根据第一处理结果可以得到第一文本处理任务下的文本数据的第二处理结果，使得预训练模型在推理阶段可以处理多个带模型的自然语言处理任务，减少在线部署设备的资源消耗。该方法包括获取(S110)第一文本处理任务的文本数据。 根据所述第一文本处理任务得到预定义的第一提示模板(S120)。 根据文本数据和第一提示模板生成(S130)文本生成任务的第一输入文本。 将第一输入文本输入(S140)微调后的目标语言模型，得到第一输入文本在文本生成任务下通过目标语言模型的第一处理结果。 根据所述第一处理结果得到所述第一文本处理任务下的文本数据的第二处理结果(S150)。 生成文本生成任务的第二输入文本和第二输出文本。 以所述第二输出文本的预测为训练目标基于所述第二输入文本对所述预先训练的语言模型进行微调，得到所述目标语言模型。独立权利要求包括用于：(1)基于预训练模型的自然语言处理装置； (2)电子设备； (3)一种计算机可读存储介质，其存储有用于实现所述基于预先训练的语言模型的自然语言处理方法的计算机程序。  11
本公开涉及一种古诗词生成方法、装置及存储介质，解决的相关技术中图片古诗词转换时无法准确的捕捉图片中的信息，转换后的诗句过于死板，缺乏灵活性以及网络的构建成本过高的问题。本方法包括：取图片；提取所述图片中的目标对象的特征向量；将所述特征向量输入到文本生成模型中，得到所述文本生成模型输出的古诗词，其中，所述文本生成模型经过无监督文本语料预训练，并通过图片诗词样本训练得到的，所述图片诗词样本包括图片样本以及作为所述图片样本的标签的古诗词。一种利用计算机装置产生古歌词的方法。该方法能够准确捕捉图像中的信息，并减少转换后的歌词过于死板，缺乏灵活性和网络建设成本过高。该方法包括获得图像。 提取图像中的目标对象的特征向量。 特征向量被输入到文本生成模型中。 通过文本生成模型得到古词输出。 文本生成模型由无监督文本语料库预先训练。 训练图画歌曲样本。 它具有画样和作为画样标签的古歌词。还包括独立的权利要求： 古歌词生成装置； 以及 计算机可读存储介质包括一组用于生成古歌词的指令。  12
本发明涉及人工智能模型技术领域，具体为一种基于知识图谱的大模型知识更新方法和装置，包括以下步骤：收集领域的高质量数据；利用领域数据对大语言模型进行微调；利用关系抽取模型对收集到的高质量数据进行处理；接受用户问题；将用户问题利用实体抽取模型识别问题中的实体，形成实体集合；在知识图谱中查找与实体相关的描述信息；有益效果为：本发明提出的基于知识图谱的大模型知识更新方法和装置，基于GPT‑3等大语言模型，使用提示学习和微调，离线构建垂直领域知识图谱，将补充知识与原用户问题结合，从而避免大语言模型知识滞后的问题，具有训练成本低、高效、知识更新维护简单等优点。一种基于知识图谱的人工智能大语言模型知识更新方法，通过对海量文本数据进行训练，为人们提供智能的文本处理工具。 用途包括但不限于机器翻译、自动摘要、对话系统和文本生成字段。该方法利用即时学习和微调，离线构建垂直领域知识图谱，将补充知识与原始用户问题相结合，避免了语言模型知识滞后大的问题。 该方法保证了训练成本低、效率高、知识更新维护简单。该方法包括收集现场的高质量数据。 通过使用字段数据对大型语言模型进行微调。 通过关系抽取模型对采集到的高质量数据进行处理。 接收用户问题，所述用户问题使用实体提取模型识别问题中的实体以形成实体集合。 搜索知识图谱中与所述实体相关的描述信息。 对所述用户问题和所述实体相关描述信息进行扩展，生成当前问题。 自动问答模型用于接收生成的当前问题。 生成答案。 将答案返回给用户。独立权利要求还包括一种基于知识图谱的人工智能大语言模型知识更新装置。  11
本发明提供一种基于边缘生成的图像修复方法，能够有效解决图像修复中修复区域固定，生成图像模糊的问题。所述方法包括：生成缺损图像，提取缺损图像的边缘轮廓；构建边缘生成网络和内容生成网络，其中，内容生成网络采用U‑Net结构；在训练阶段：输入缺损图像和提取的边缘轮廓对边缘生成网络进行训练，输入已训练好的边缘生成网络生成的图像边缘特征、已训练好的纹理生成网络提取的缺损图像的纹理信息和缺损图像对内容生成网络进行训练；在修复阶段，将边缘生成网络生成的待修复图像的边缘特征、纹理生成网络提取的待修复图像的纹理信息和待修复图像输入到已训练好的内容生成网络，实现图像的原貌修复。本发明涉及人工智能、图像处理领域。用于修复生成的基于边缘图像的方法。该方法能够实现原始图像的复原。该方法包括通过处理图像来获得训练集图像。 生成缺陷图像。 提取所述缺陷图像的边缘轮廓。 生成构造边缘的网络和内容生成网络。 利用所述网络内容和判别网络生成边缘生成网络。 利用所述网络生成的内容的真实性和所述内容生成网络来生成判断网络。 通过边缘网络提取具有边缘轮廓的输入缺陷图像。 通过训练的生成网络图像边缘特性生成输入边缘。   6
本发明公开了一种命名实体识别方法、系统、存储介质及终端，包括使用多种遮蔽方法对句子中单词的令牌token进行遮蔽，并训练BERT‑Convolution模型；将token转换为多种token embedding，并将多种token embedding相加作为BERT‑Convolution模型的输入；使用BERT‑Convolution模型根据上下文对每个token进行词向量编码，其中，对token embedding进行动态卷积并将卷积得到的词向量特征与自注意力机制得到的结果进行拼接；BERT‑Convolution模型输出为N*D的词向量信息，再通过全连接层进行向量变换，输出每个实体标签的分数向量；将分数向量组成的分数矩阵输入到CRF层中，使用Viterbi算法进行解码，找到一条概率最大的实体标签路径。本发明可以提升BERT中Self‑attention机制对局部信息注意力，更准确地提取实体，同时优化了Self‑attention机制中的计算复杂度。从一段非结构化文本材料中识别命名实体，并判断所述标签的类别，如公共领域的实体标签、姓名、地名和组织名称的方法。该方法能够改进局部信息关注的BERT自关注机制，更准确地提取实体，并优化了自关注机制的计算复杂度，从而大大节省了自关注机制的计算开销，并因此减少了冗余头的数量。 该方法允许令牌进行动态卷积并将卷积得到的词向量特征与自动作机制得到的结果进行拼接，将局部信息嵌入全局信息中，从而以准确的方式提取出输入句子的实体局部信息。该方法包括输入(S1)待识别的句子。 多重屏蔽方法用于屏蔽句子中单词的令牌。 以长度限定为Ntoken对句子进行分词预处理(S2)。 令牌被转换为多个令牌。 将多个令牌添加到所述BERT-卷积模型的输入中。 根据用于每个令牌字向量编码的上下文，使用伯特卷积模型(S3)。 通过全连接层执行矢量变换(S4)。 输出每个实体标签的分数向量，其中d为维数。 将由分数矢量构成的分数矩阵输入到CRF层(S5)。 采用维特比算法进行解码。 以最大概率资助实体标签路径。 根据所述概率最大的实体标签路径识别所述句子中的实体。包括以下独立权利要求：命名实体识别系统； 存储用于识别命名实体的程序的存储介质； 以及终端。  12
本发明实施例提供一种模型处理方法及装置。所述模型处理方法包括：使用多组数据训练所述初始网络模型得到预训练模型，所述初始网络模型包括由多层结构形成的目标结构和由多层结构形成的补偿结构，所述预训练模型为训练所述初始网络模型后所述目标结构对应的网络模型；将目标数据输入所述预训练模型进行计算得到中间输出数据；以及使用所述中间输出数据训练所述目标网络模型得到搭接模型，所述预训练模型和所述搭接模型拼接后可形成用于对待识别数据中的目标特征进行识别的识别模型。处理模型的方法。将所述预训练模型和所述lap模型拼接形成用于识别所述待识别数据中目标特征的识别模型是可以的。该方法涉及使用多组数据训练(S101)初始网络模型以获得预训练模型，初始网络模型包括由多层结构形成的目标结构和由多层结构形成的补偿结构。 将目标数据输入(S102)到预训练模型中以计算中间输出数据。 利用所述中间输出数据对所述目标网络模型进行训练(S103)，得到lap模型，将所述预训练模型和所述lap模型拼接，形成用于识别所述待识别数据中目标特征的识别模型。本发明还涉及一种模型处理装置。  11
本发明公开了一种基于知识增强和知识迁移的句子语义相关度判断方法，根据语料集中已标注的训练数据和验证数据构造相应的无监督训练语料，并利用该语料对预训练BERT进行再次训练，从而得到包含任务相关领域知识的预训练语言模型TBERT；一方面根据BERT的输入要求将待判断的两个句子构造成句子对作为TBERT的输入，通过多层Transformer模型的学习句子对的全局上下文信息及其关系，从而得到句子对的全局语义相关信息；另一方面通过一个孪生BERT网络分别学习各个句子的局部语义信息，然后结合距离函数计算它们之间的语义相关度信息，从而得到包含句子局部语义及距离信息的语义向量，并最后合并得到最终的句子语义相关度表示。一种基于知识增强和知识迁移的句子语义相关度判定方法。获取多层模型的全局上下文信息和学习句对的关系，从而获取句对的全局语义相关信息。所述方法包括：根据目标任务语料库集合中标注的训练数据和验证数据，通过一定的策略构建相应的非标注训练语料库。 基于来自变换器(BERT)模型的预训练双向编码器表示，通过使用构建的任务相关语料库和屏蔽语言模型(MLM)以及BERT中的下一句子预测(NSP)训练目标来训练BERT。 构造一个句子对作为待判断的两个句子的TBERT的输入。 使用双生Tbert网络来独立地学习每个句子的语义表示。 通过全连接网络层进行句子语义相关度词向量的维度转换。 使用Sigmoid函数来获得最终的句子相关结果。  12
本发明涉及自然语言处理技术领域，特别涉及一种中文电子病历手术操作文本的ICD自动编码方法及装置，该方法包括：以结构化电子病历中的手术操作文本作为输入，基于BERT无监督预训练模型，构建包含无监督上下文语义信息的节点与边，得到每条手术操作文本的无监督语义图；将构建的无监督语义图输入门控图神经网络，进行全局信息交互，得到上下文语义信息和全局语义信息融合的语义图；基于得到的语义信息融合的语义图，聚合各节点的表征，得到聚合的特征向量；根据聚合的特征向量进行分类，确定手术操作文本对应的ICD编码。本发明集成了手术操作文本中上下文语义信息和全局信息，能够基于文本本身取得更好的表征性能，实现对手术操作精准编码。用全球医院的疾病管理，医疗保险，医疗保健等医疗保健任务中所用的电子设备对中文电子病历操作文本进行国际疾病分类(ICD)自动编码的方法。本发明能够将上下文语义信息和全局信息整合到操作操作文本中，从而基于文本获得更好的表现性能，有效实现操作操作的精确编码。 本发明允许用户基于BERT无监督预训练模型将结构化电子病历中的外科手术文本作为输入进行输入，从而高效地针对电子病历中的外科手术结构化短文本自动实现ICD精确编码。该方法包括将结构化电子病历中的外科手术文本作为输入。 基于BERT无监督预训练模型来构造节点和边。 得到语义信息融合的语义图。 基于语义图的语义信息融合得到聚合的特征向量。 根据所述特征向量确定与所述外科手术文本相对应的ICD代码。独立的权利要求书包括： 一种利用电子设备对中文电子病历操作文本进行ICD自动编码的装置； 以及 一种计算机可读存储介质，包括一组用于通过使用电子设备对中文电子病历操作文本执行ICD自动编码的指令。  12
本申请属于工业互联网技术领域，具体涉及一种基于分类网络模型的图像处理方法、装置、设备和介质。根据获取到的模型构建参数集和历史训练数据集，先构建具有多个先后顺序阶段的分类网络模型，然后使用分类网络模型对重新获取到的原始图像进行处理，得到原始图像的处理结果。该方法解决了Vision Transformer模型在图像分类任务中无法准确区分同一类别中不同物种的图像元素的问题，从而提高了图像分类处理的准确率。同时，该方法还提高了分类网络模型的泛化能力，从而使其能够适应各种不同的图像处理任务。基于分类网络模型处理图像的方法。该方法解决了视觉分辨模型在图像分类任务中无法准确区分同一类别中不同物种的图像元素的问题，以提高图像分类处理的准确性。 提高了分类网络模型的泛化能力，使其适用于不同的图像处理任务。该方法包括获得(S101)模型构建数据集。 模型构建数据集包括参数集，历史训练数据集由模型构建。 根据所述模型构建参数集和所述历史训练数据集(S102)。 构建分类网络模型。 分类网络模型包括具有序列的多个训练阶段。 实时获取(S103)原始图像，并根据所述多个训练阶段对所述原始图像进行像素处理，得到多个待处理图像。 根据多个待处理图像和分类网络模型确定(S104)原始图像的处理结果。独立权利要求包括如下内容：(1)一种基于分类网络模型的图像处理装置； 以及(2)计算机存储介质，其存储用于基于分类网络模型处理图像的程序。 14
本发明公开了一种医学图像腺体分割方法，包括以下步骤：获取待分割的图像，并根据检测数据特点进行预处理；对预处理后的图像，选用U‑net为基础网络，重新设计编码器解码器结构，将普通卷积换成深度可分离卷积，减少网络的数据量，并且在解码器模块中嵌入ECA注意力机制；将编码器得到的特征图作为边缘信息模块的输入，得到边缘信息；将得到的边缘信息及多尺度特征得到的特征图进行信息融合；将融合特征图进行分割，然后将处理好的数据集进入搭建的深度学习网络，得到图像中的分割部分。本发明的一种医学图像腺体分割方法，摒弃人工特征提取过程，可精准分割器官，准确率高、检测时间短、抗干扰性强，在融合过程保留更多空间信息，实现精准分割。种医学图像的腺体分割方法该医学图像腺体分割方法摒弃了人工特征提取过程，能够对器官进行准确分割，准确率高，检测时间短，抗干扰性强，在融合过程中能够保留更多的空间信息，实现准确分割。该方法包括获取待分割图像，并根据检测数据的特征进行预处理。 选取U-net作为预处理图像的基础网络，重新设计编码器和解码器的结构，将普通卷积变为深度可分离卷积，降低了网络的数据量，并在解码器模块中嵌入了高效的cac注意机制。 将编码器得到的特征图作为边缘信息模块的输入，得到边缘信息。 将得到的所述边缘信息与所述多尺度特征得到的特征图进行信息融合。 对融合特征图进行分割，然后，将处理后的数据集进入构建的深度学习网络，得到图像中的分割部分。   6
本发明公开了一种基于脉冲神经网络的探测器着陆点定位方法，包括以下步骤：对星体表面的陨石坑DEM数据进行预处理；采用基于人工神经网络模型ANN的U‑Net网络架构对训练集数据进行训练；将人工神经网络模型ANN的UNET转换为脉冲神经网络模型SNN的UNET模型；对图像进行编码，并采用基于SNN的UNET模型进行测试集检测；通过模板匹配算法，进行陨石坑匹配和定位，构建地形路标库，实现定位。本发明通过将脉冲神经网络首次应用于深空探测领域，通过识别陨石坑，实现探测器着陆点的定位。该方法对于基于脉冲神经网络定位检测器着陆点是有用的。该方法通过识别陨石坑，将脉冲神经网络应用于深空探测领域，以有效的方式定位探测器落点。该方法包括预处理星体表面上的陨石坑DEM数据。 训练集数据由基于人工神经网络模型的UNET网络框架训练得到。 将所述人工神经网络模型的UNET转换为脉冲神经网络模型的UNET模型。 对图像进行编码。 通过使用UNET模型检测测试集。 采用模板匹配算法对陨石坑进行匹配定位。 构建地形道路标志库，实现定位。   6
本发明公开了一种反讽识别方法、装置、计算设备及存储介质，该方法包括：根据各个有标注文本的反讽标签信息，构建各个有标注文本的标准推理结果；根据各个有标注文本及其标准推理结果，对大语言模型进行微调处理，得到目标语言模型；利用目标语言模型对任一无标注文本进行反讽推理处理，根据该无标注文本的反讽推理结果，确定该无标注文本的伪标签信息；根据各个无标注文本及其伪标签信息对中间识别模型进行微调处理，得到目标识别模型；中间识别模型用于提取输入文本的文本表示向量；利用目标识别模型进行文本的反讽识别处理。通过上述方式，实现了基于少量数据的有标注样本数据扩充，提升了模型的反讽识别性能，提升了模型构建的效率。反饱腹症鉴别法。扩展了基于少量数据的标记样本数据，提高了模型的饱腹识别性能，提高了模型构建的效率。 所述文本的反饱腹感识别处理是根据未标注文本的饱腹感推理结果，利用所述目标识别模型对任一未标注文本进行饱腹感推理处理。该方法涉及根据每个标注文本的饱食标注信息，构建(S110)大型语言模型对每个标注文本的标准推理结果。 根据各标注文本和标准推理结果对所述大型语言模型进行微调(S120)，得到目标语言模型。 利用(S130)所述目标语言模型对任一未标注文本进行讽刺推理处理，根据所述未标注文本的讽刺推理结果确定所述未标注文本的伪标注信息。 根据各未标注文本及其伪标注信息对中间识别模型进行微调(S140)，得到目标识别模型，中间识别模型用于提取输入文本的文本表达向量。 利用所述目标识别模型进行所述文本的反饱腹感识别处理(S150)。独立权利要求包括以下内容：一种反饱腹感识别装置； 计算设备； 以及计算机存储介质，其存储有反饱腹感识别程序。  11
本发明公开了一种基于句法分析的句子语法纠错方法及系统，方法包括通过基础预训练模型将无标注语料进行编码，获得第一句子向量，根据无标注语料和词语依存关系，将第一句子向量进行依存预测模型预训练，获得依存预测模型；根据第一预设规则，将无标注语料的单词进行掩码替换，获得掩码语料，将掩码语料进行掩码语言模型训练，获得掩码语言模型；根据文本编辑器、依存预测模型和掩码语言模型，建立句法加强文本编码器；通过句法加强文本编码器将待纠错句子进行句子编码，获得第二句子向量；通过句法解码器对第二句子向量进行解码，获得待纠错句子对应的纠正句子。本实施例增强语法分析感知和语义表示能力，提高句子语法纠错的准确性。句子句法纠错方法包括通过基础预训练模型对非标准语料进行编码，得到第一句子向量。 根据第一预设规则对无标签语料的词语进行替换。 根据所述词语获取蒙版语料。 所述蒙版语言材料用于训练蒙版语言模型。 根据文本编辑器、依赖性预测模型和掩码语言模型建立语法增强文本编码器。 通过所述语法增强文本编码器对待纠正语句进行语句编码处理，得到第二语句向量。 通过语法解码器对第二句子向量进行解码。 得到与所述待校正语句对应的校正语句。  12
本发明公开了一种模仿人类视觉系统对伪装目标检测与分割方法，该包括如下步骤：S1、制作预训练数据集；S2、构建基于模仿人类视觉系统对伪装目标检测与分割的模型，所述模型包括编码器模块、桥接模块、邻域连接解码器模块和部分解码器模块；S3、通过编码器模块提取显著性信息；S4、通过桥接模块扩大全局感受野；S5、通过领域连接解码器模块生成粗糙位置图；S6、通过部分解码器模块生成精确的位置图；S7、训练构建好的基于模仿人类视觉系统对伪装目标检测与分割模型。方法主要由编码器模块，桥接模块，邻域连接解码器模块和部分解码器模块组成，通过对神经网络进行训练，得到最优参数，实现对伪装目标的自动检测与分割。模拟人类视觉系统对伪装目标进行检测和分割的方法。该方法将残差网络尽可能地结合到特征信息中，避免了由于网络层数增加而导致的梯度损失或爆炸问题，通过桥接模块扩展感受野，得到特征的全局信息，并得到全局特征和原始特征以及上层特征进行解码，从而保持层内语义一致性和跨层拼接上下文信息，以提高网络精度，进而生成粗略的位置图，通过部分解码器产生不同的解码结果，细化特征，得到最终的预测。 该方法允许灵活的网络结构与深度监督相匹配，使得大量的深度网络能够以可接受的精度减少参数量。该方法包括制造预训练数据集。 基于模拟人类视觉系统构建模型对伪装目标进行检测和划分，模型包括编码器模块、桥接模块和邻域连接解码器模块。 提取编码器模块的显著性信息。 通过邻域连接解码器模块生成粗略位图。 由解码器模块的一部分生成精确的位置图。 对构建的模型进行训练，基于模拟人视觉系统检测伪装目标。   6
本发明涉及自然语言处理领域，提供了一种基于多类型问题和多片段答案抽取的机器阅读理解系统，以解决计算机在根据阅读文本回答多类型问题时，需要进行算术计算、计数或者从文本中识别并转换出一个或多个答案片段的情况。主要方案包括：准备阅读文本、多类型问题和标准答案数据；将文本和问题进行分词和序列连接；构建最终词向量的表示，由此可获取输入嵌入列表；利用神经网络模块编码输入序列；获取Transformer模块的输出作为阅读文本的最终表示；利用前馈神经网络预测问题类型；为回答文本片段抽取问题，搭建多层全连接打分网络，以计算每个词作为片段开头和结尾的概率；根据所得概率，解码得出最终答案。一种用于自然语言处理领域的基于多类型问题和多段答案提取的机器阅读理解系统。该系统考虑单段提取和当前的多段提取来回答文本段的提取问题。该系统的主要方案是准备阅读文本，多类型提问和标准答案数据，对文本和提问进行分词和顺序连接，得到连接顺序。 所述系统将所述连接序列转换为输入序列。 利用神经网络模型对输入序列进行编码，得到结构最后一层的输出。 问题类型预测模型通过使用概率分布条件Ptype来计算问题类型的概率分布。 多层全连接评分网络获取答案段起始字和答案段结束字的概率，以确定功能损失，该概率包括开始概率和结束概率。 前向神经网络根据得到的概率得到符号概率分布或计数概率分布对答案进行解码。  11
本发明公开了一种用户轨迹信息挖掘方法。该方法包括：构建包含多个超级节点的轨迹序列，其中所述轨迹序列反映用户不同时间的行动轨迹，每个超级节点表征用户签到的位置、位置属性和用户属性；将所述轨迹序列输入到预训练模型，获得映射后的固定维度的向量化表示，作为用户画像序列；将所述用户画像序列输入分类器或聚类器进行分析，获得用户分类或聚类结果。本发明能够对用户多维度的信息进行全方位挖掘，并将用户轨迹信息映射到固定的低维空间，从而节省了空间开销并同时减少了信息丢失带来的影响。用户轨迹信息挖掘方法。该方法能够实现全方位挖掘用户多维信息，并将用户轨迹信息映射到固定的低维空间，从而节省空间开销，减少信息丢失带来的影响。所述方法包括构建包含多个超级节点的轨迹序列，所述轨迹序列反映了一个动作轨迹的用户不同时间，每个超级节点表示用户标志、位置属性和用户属性的位置。 将所述轨迹序列输入预训练模型。 得到映射的固定维度的向量化表示。 将用户图像序列输入分类器或聚类装置，以对所述用户图像序列进行分析，用于得到用户分类或聚类结果。针对以下内容包括独立权利要求：一种计算机设备，其包括用于执行用于挖掘用户轨迹信息的指令集的存储器和处理器； 以及用于存储挖掘用户轨迹信息的指令集的计算机可读存储介质。 13
本发明涉及临地安防技术体系中稳定探测的技术领域，具体涉及一种基于多输入联合智能单像素成像方法及其装置，包括：获取散斑图案和对应光束穿过物体的光强度值；构建基于U‑Net框架的卷积神经网络；基于设计的损失函数，对卷积神经网络进行训练，直至收敛，并输出最终的图像。本发明利用探测到的光强信息以及散斑信息，将物理模型嵌入神经网络，利用探测器采集的强度值作为参考标准对网络参数进行优化，提升了网络的泛化性和可解释性，一维输入和二维输入联合对参数进行优化，进一步提升了成像质量。用于临时安防技术系统中稳定探测场中多输入组合智能单像素成像的方法。该方法使得利用探测到的光强信息和散斑信息，使得物理模型嵌入到神经网络中，以探测器采集到的强度值作为参考标准优化网络参数，提高网络的泛化性和可解释性，一维和二维输入相结合优化参数，提高成像质量。该方法涉及获得散斑图案和穿过物体的相应光束的光强值，以形成一维光强序列。 获得随机图片。 基于U-Net框架构建卷积神经网络。 将所述一维光强序列和随机图片分别作为卷积神经网络的输入，生成对应的图像。 根据生成图像的强度值与光强值的差值以及生成图像像素的差值设计损失函数。 基于设计的损失函数训练卷积神经网络，直到收敛。 输出最终图像。独立权利要求还包括用于一种多输入组合式智能单像素成像装置。   4
本发明涉及图像数据处理技术领域，具体涉及一种使用街景图像的快速公路路面裂缝检测方法，包括对获取的街景图像进行预处理，得到训练集和测试集；利用训练集使用VGG‑16网络结构对二分类器模型进行改进，得到改进二分类器模型；基于U‑Net网络结构将U形裂缝分割网络进行改进后集成改进二分类器模型，得到街景图像裂缝分割网络；使用训练集和测试集对街景图像裂缝分割网络进行训练和测试，得到最优裂缝分割网络；将待检测路线图像输入最优裂缝分割网络，得到裂缝检测结果，本发明通过最优裂缝分割网络在街景图像中进行学习，提高了对待检测路线图像的检测精确度，解决了现有的图像处理的算法单一，导致裂缝检测精确度低的问题。一种利用街景图像检测快速路面裂缝的方法。本发明能够在街景图像中利用最优裂缝划分网络进行学习，提高待测路线图像的检测精度，解决图像处理算法单一，裂缝检测精度低的问题。该方法包括获得街景图像。 对街景图像进行预处理，得到训练集和测试集。 获得改进的双分类器模型。 对改进后的双分类器模型进行整合，得到街景图像裂缝分割网络。 利用训练集和测试集对街景图像裂缝分割网络进行训练和测试，得到最优的裂缝分割网络。 将待检测的路径图像输入到最优裂缝分割网络中，得到裂缝检测结果。   6
本发明属于电子信息中的数据处理技术领域，具体为一种基于知识图谱和大语言模型的用户心理画像系统及方法，包括：用户交互模块，用于用户与访谈数据模块进行交互；访谈数据模块，访谈数据模块包括访谈语料库和心理量表模块；自然语言处理模块，用于对用户输入的自然语言数据进行处理；知识图谱模块，用于包含关于各种有关心理疾病的知识图谱；用户心理特征模块，用于接收自然语言处理模块与知识图谱模块数据进行比对分析；用户画像模块，根据用户心理特征模块打上的特征标签，进行用户画像；本系统的方法包括六个步骤。本发明用于解决提高用户心理画像的效率和效果问题。基于知识图谱和大语言模型的用户心理肖像系统。该系统提高了用户心理画像的效率和效果。所述系统具有用户交互模块，用于用户与面试数据模块进行交互，并将交互得到的数据传输给自然语言处理模块。 面试数据模块包括面试语料库和心理测量表模块，用于提供用于用户交互的语料库和测量表。 自然语言处理模块对用户输入的自然语言数据进行处理。 知识图谱模块包含与包括不同疾病类型和症状的心理疾病相关的知识图谱。 大语言模型API接口模块、采访数据模块、自然语言处理模块、知识图谱模块进行数据通信。对于基于知识图谱和大型语言模型的用户心理肖像方法，包括独立权利要求。  11
本发明涉及人工智能技术领域，公开了一种文本匹配方法、装置、计算机设备以及可读存储介质，该方法包括：获取预训练文本对应的句向量集合；计算句向量集合对应的句向量均值以及协方差矩阵；对句向量均值以及协方差矩阵进行转换处理，以将句向量集合的空间分布转换为各向同性分布；获取待匹配文本对应的句向量集合，并将待匹配文本对应的句向量集合的空间分布转换为各项同性分布；将转换为各项同性分布的待匹配文本对应的句向量集合，与转换为各项同性分布的预训练文本对应的句向量集合，进行余弦相似度计算，以获取与待匹配文本相匹配的目标文本。通过上述方式调整句向量的分布，提高文本匹配的效果，使得语义定义的范围更完整，可提高匹配精度。匹配文本的方法。该装置调整了句向量的分布，提高了文本匹配的效果，使得语义定义的范围更加完整，提高了匹配精度。该方法涉及获得(S110)对应于预训练文本的句子向量集合。 计算句子向量集合对应的句子向量均值和协方差矩阵(S120)。 转换句子向量均值和协方差矩阵(S130)，以将句子向量集合的空间分布转换为各向同性分布。 获取待匹配文本对应的句子向量集合(S140)。 将所述待匹配文本对应的句子向量集合的空间分布转换为各向同性分布。 对转换为各向同性分布的待匹配文本对应的句子向量集合和转换为各向同性分布的预训练文本对应的句子向量集合进行余弦相似度计算(S150)，以获得与待匹配文本匹配的目标文本。独立权利要求包括以下内容：用于匹配文本的装置； 用于匹配文本的计算机设备； 以及存储用于匹配文本的程序的计算机可读存储介质。  12
本发明提供一种基于深度学习的情绪原因识别方法及系统，首先，将一段文本D中的情绪de与这段文本中的任意语句组合构成新的文本数据Dcp；然后用新的文本数据Dcp训练情绪原因识别模型PECR‑BERT，所述的情绪原因识别模型PECR‑BERT包括基于Transformer的双向编码表示器BERT模型和两个全连接神经网络层；最后用训练后的情绪原因识别模型PECR‑BERT识别文本中情绪de对应的原因语句dc。本发明能够有效地识别文本中情绪语句对应的原因语句，这些信息不仅能够为政府提供决策参考，预防公众负面情绪传播，还可以为用户提供更加个性化的服务，提升商品的用户体验，具有很大的价值与研究意义。一种基于深度学习过程的情感原因识别方法。 使用包括但不限于正向情绪，反向情绪，中性情绪和精细粒度的情绪，例如恶感，负面情绪和烦躁情绪。该方法将情感句子与任意句子中的文本相结合，有效地扩大了训练数据规模，避免了由于深度学习模型问题不能充分优化而导致的数据稀疏， 提高深度学习技术识别过程中情感句对应的原因句的准确率。该方法包括将文本D的一段中的情感与文本中的任何句子组合以形成新的文本数据。 使用新文本数据训练情感原因识别模型。 所述情感原因识别模型被配置为识别所述新文本数据的部分中的情感原因，其中所述情感原因包括基于两个全连接神经网络层的双向编码呈现器模型。 训练情感原因识别模型以识别相应的原因语句。本发明还涉及一种基于深度学习过程的情感原因识别装置。 (2)用于存储基于深度学习过程识别情感原因的计算机指令的存储介质。  12
本发明提供一种基于大模型思维链的定制化培训方法和装置，应用于培训信息化技术领域，包括：获取培训的文本资料，建立培训知识库，并提取培训知识库的关键词，获取全部学员的历史问题列表和目标学员的当前问题，得到长度为预设次数的输入提示序列，并计算每个输入提示的可能性，将可能性最大的输入提示输入预训练的大模型，得到定制化培训信息。本发明针对在线培训过程中，问答环节的教员的人工回复效率低下而机器人问答缺乏专业性的问题。基于大模型思维链提供了定制化培训材料的生成方法，可以提供高质量定制化培训材料。基于大模式思维链的企业定制化在线培训方法。本发明通过获取长度为预设次数的输入提示序列，并计算输入提示的可能性，将可能性最大的输入提示输入到预先训练的大模型中，得到定制训练信息，提高了教师在问答环节的人工回复效率，保证了机器人问答在在线训练过程中不具有专业性，从而高效地提供了高质量的定制训练素材。该方法包括获取训练文本数据并对训练文本数据进行预处理以获取训练知识库(S1)。 从所述训练文本数据中提取关键字(S2)，用于计算所述关键字的重要度，获得所述关键字的权重，并将所述关键字和对应的权重添加到所述训练知识库中，作为所述训练知识库的关键字。 获取整个学生历史问题的文本信息(S3)，对所述文本信息进行预处理，得到历史问题列表。 将历史问题列表中的每个问题添加(S4)到训练知识库中，以基于关键词的权重获取完整的训练知识库。 获取目标学习者的当前问题的文本信息(S5)，用于对目标学习者的当前问题的文本信息进行预处理，以生成当前问题的词向量。基于当前问题的词向量与训练知识库的关键词之间的关联关系，根据用于获得候选问题列表的预设阈值，从完整训练知识库中选择关联训练知识库的关键词和整个关联问题(S6)。 将所述当前问题添加(S7)至所述候选问题列表，用于获取输入提示并以预设元素数量形成输入提示序列。 基于所述输入提示序列和所述训练知识库计算所述输入提示的可能性(S8)，以获得具有最大可能性的所述输入提示。 将具有最大可能性的输入提示输入(S9)至预先训练的大模型，以获得目标学习者的当前问题的大模型的输出。 将相关训练知识库的关键词与当前问题大模型的输出相结合，得到自定义训练信息。 独立权利要求包括：(1)一种基于大模型思维链的企业定制化在线培训装置； (2)一种电子设备； 以及(3)计算机可读存储介质。  11
本公开提供了预训练模型的确定方法、装置、电子设备以及存储介质，涉及计算机视觉和深度学习技术领域，可应用于图像处理、图像识别等场景。具体实现方案为：获取多种候选模型；根据多种候选模型的模型结构进行结构编码，以得到各候选模型的结构编码；采用经过训练的编码器将各候选模型的结构编码映射得到对应的频域编码；根据各候选模型的频域编码，预测各候选模型的模型性能参数；根据各候选模型的模型性能参数，从多种候选模型中确定目标模型作为预训练模型。由此，通过根据多种候选模型的频域编码，从多种候选模型中确定目标模型作为预训练模型，能够减少后续对预训练模型进行训练的训练成本，提高训练效率。用于确定用于图像处理和识别领域以及计算机视觉和深度学习技术的预训练模型的方法。该方法使得能够根据多个候选模型的频域编码从候选模型中确定目标模型作为预训练模型，能够降低后续训练模型的训练成本，提高后续训练模型的降雨效率。该方法涉及获得多个候选模型(101)。 根据候选模型的模型结构进行结构化编码(102)，以获得每个候选模型的结构化编码。 每个候选模型的结构码由训练好的编码器映射(103)，得到相应的频域码。 根据每个候选模型的频域编码预测(104)每个候选模型的模型性能参数。 根据所述每个候选模型的模型性能参数从所述多个模型中确定(105)目标模型作为预训练模型。独立权利要求包括：(1)确定预训练模型的装置； (2)一种电子设备，包括用于确定预训练模型的处理器和存储器； (3)一种非暂态计算机可读存储介质，用于存储用于确定预训练模型的计算机指令； (4)一种计算机程序产品，包括用于确定预训练模型的指令集。  11
本发明公开了一种基于时序卷积网络的简答题智能评阅方法模型及分析方法。首先模型使用预训练语言模型BERT对评分答案和参考答案进行处理，然后为了进一步对获取到的语义特征进行增强，使用特征增强层中的时序卷积网络TCN模型捕获全局的语义关系，最后，使用多个全连接网络对全局语义特征进行整合，输出模型的评分结果。有效地提高了简答题评阅的性能。应用于自然语言处理领域的主观题自动评审的基于时序卷积网络的简短回答题智能评价算法。该算法有效地提高了简单回答问题的性能。该算法具有用于编码分级答案和参考答案的指令集。 在两者之间建立联系的同时提取深度文本语义特征。 利用时间序列卷积网络(TCN)模型提取文本语义特征，捕获全局语义关系。 利用多个全连接网络对捕获到的全局语义特征进行整合。 输出模型的分级结果，所述编码方式为BERT编码。 时序卷积网络采用扩展卷积结构。  12
本发明涉及深度学习技术领域，具体提供一种模型训练方法、非机动车跨镜追踪方法、装置及介质，旨在解决如何高效、及时、准确地实现非机动车的跨镜追踪的问题。为此目的，本发明根据不同镜头采集的非机动车的图像数据进行标注，获得标注数据，应用标注数据对深度学习模型进行训练，获得训练好的教师模型，对教师模型进行知识蒸馏获得学生模型，根据目标域数据，对学生模型进行模型调整，获得训练好的非机动车跨镜追踪模型，能够使得深度学习模型获得更好的识别效果，在几乎不损失精度的情况下，增大模型的推理速度，降低模型空间大小以及特征存储大小，解决了不同来源数据差异导致模型识别精度下降的问题。模型训练方法。该方法能够使深度学习模型获得更好的识别效果，从而提高了模型的推理速度，减小了模型空间大小和特征存储大小，提高了不同来源数据的差异对模型的识别精度。 该方法能够有效、及时、准确地实现非机动车的跨镜跟踪。该方法涉及根据标记数据训练预先设置的深度学习模型(S101)，以获得训练后的教师模型。 所述标记数据是通过对不同镜头采集到的一个非机动车的图像数据进行标记得到的。 对训练好的教师模型进行知识蒸馏(S102)以获得学生模型。 根据所述目标领域数据对所述学生模型的模型进行调整(S103)。 得到最终训练好的非机动车跨镜跟踪模型。包括独立权利要求：(1)一种非机动车跨镜跟踪方法； (2)控制装置； (3)一种计算机可读存储介质，包括用于训练模型的指令集。 13
本公开提供了生成式大语言模型训练方法、基于模型的搜索方法，涉及生成式模型、智能搜索等人工智能技术领域。该方法包括：基于用户查询文本与匹配的服务接口调用序列，构建第一训练集；利用第一训练集对预训练好的第一生成式大语言模型进行有监督微调训练，得到第二生成式大语言模型；基于相同用户查询文本与不同候选输出之间的用户偏好排序和预设模板集合，构建第二训练集；利用第二训练集对预训练好的第三生成式大语言模型进行有监督训练，得到奖励模型；将第二生成式大语言模型，基于奖励模型返回的得分，以强化学习方式进行训练。利用据此训练得到的生成式大语言模型可显著提升搜索场景下的搜索结果准确率和用户体验。用于训练生成型大型语言模型的方法，例如聊天生成预扫描，以及由开放式人工智能机制开发的聊天机器人程序。该方法能够保证训练得到的生成的大型语言模型能够提高搜索场景下的搜索结果准确性和用户体验。 该方法使得搜索引擎能够通过训练方案将输入的用户查询文本转换为匹配的服务接口调用序列，从而使得搜索引擎能够按照先后顺序执行服务接口调用序列，以获取查询结果文本，从而使得用户能够直接获取到具有该结果文本的搜索需求的满足查询，提高了搜索结果的准确性和搜索效率。该方法包括基于用户查询的文本和服务接口调用序列的匹配来构建第一训练集。 使用第一训练集对预训练的第一生成大型语言模型进行有监督的微调训练。 获得第二生成大型语言模型。 基于相同用户查询文本与不同候选输出之间的用户偏好排序和预设模板集构建第二训练集。 所述第二训练集用于对预先训练的第三代类型大语言模型进行监督训练，得到奖励模型。 采用强化学习的方式进行训练，得到基于奖励模型返回得分的目标生成类型大型语言模型。独立权利要求包括：(1)基于生成的大型语言模型的搜索方法； (2)生成型大型语言模型训练装置； (3)基于所生成的大型语言模型的检索装置; (4)一种电子设备，包括处理器和存储器，用于训练生成型大型语言模型； (5)一种非暂态计算机可读存储介质，用于存储用于训练生成型大型语言模型的指令； 以及(6)包括用于训练生成型大型语言模型的指令集的计算机程序产品。  11
本发明公开了一种面向多维数据的分段式检索排序系统设计方法，借助搜索设计的ES检索引擎、Colbert‑search能力模型内容相关度排序、个性化重排、定制层排序四段分层架构，运用ES检索引擎进行打分逻辑的改造，结合Colbert‑search的重排序以及用户数据、查询信息数据的处理，最后所有的定制规则统一包裹在最后一层的逻辑设计里，将不同维度的逻辑和信息分段处理；搜索效果好，提高了数据质量和用户体验，用户数据和被检索的数据信息库都落到了场景化的结果排序中，符合真实用户的期望序列。一种面向多维数据的分段搜索排序系统设计方法。本发明通过搜索分层设计，提高了数据质量和用户体验，有效地满足了真实用户的期望顺序。 该方法允许用户以有效的方式以分层设计来搜索数据。该方法包括在存储器中预先加载(101)检索的数据。 通过使用数据准备扩展模块重写(102)存储器中的数据。 数据被预处理(103)以处理用户搜索内容。 根据数据预处理结果和选择页面选择条件构造(105)查询。 ES搜索引擎被发送(106)到所构造的查询中。 引入语义匹配模型(108)。 按比例得到ES返回结果的综合得分和Colbert-Search能力模型得分，得到综合得分。 根据综合得分排序对综合得分进行排序。 根据用户的行为属性数据执行个性化重新排序(109)，并且重写个性化重新排序(110)。  11
本发明涉及自然语言处理领域，具体涉及一种基于超图神经网络的生物医学事件触发词提取方法与系统。本发明方法首先预处理非结构化的生物医学数据集；接着通过预训练的模型得到生物医学语料库中所有文本信息的特征嵌入，获取每个单词的向量表示；随后将每条句子生成相应的超图结构；再将得到的每条句子的特征嵌入和超图结构输入到超图卷积神经网络中，定义交叉熵损失函数训练模型；最后，在未标注的测试集上进行触发词检测。本发明不同于现有方法采用双向的LSTM来聚合每条句子中的上下文信息，而是创新性的使用超图结构聚合上下文信息，效果卓越，达到了提高生物医学文本中触发词提取准确性的目的。生物医学事件触发词提取方法。该方法能够利用超图结构对上下文信息进行聚合，聚合效果好，提高了生物医学文本中触发词提取的准确性。该方法包括预处理包括句子、单词和标签的生物医学数据集。 得到已标注的结构化训练集和未标注的测试集。 切分工具用于获取句子中的令牌。 得到句子中每个词的特征表示。 窗口大小作为超参数。 基于滑动窗口的方法构建每个句子的超图结构。 对未标记的测试集进行测试。 对所述生物医学事件触发词进行识别。包括独立权利要求：(1)生物医学事件触发词提取系统； (2)计算机系统。  12
本发明公开了一种语言模型预训练方法，其包括如下步骤：对模型中的语料按字、子词进行分词；对生成的各分词随即抽取15％进行位置掩盖、并计算掩盖后的语义分布；以独立的门控制单元对模型中的子词混合进行控制；对语义分布和掩盖词的预测进行同步训练。本发明能够明显改善BERT预训练后模型的预测结果。语言模型训练方法。该方法能够显著提高BERT预训练模型的预测结果。该方法涉及通过词和子词来分割模型中的语料库。 在隐藏之后执行语义分发处理。 用独立的门控制单元在模型中对子字进行控制。 语义分布的预测过程是同步的。 初始化空映射表。 从分词表的当前位置向后扫描。 ID号被找出对应于字符串。 根据出现频率在映射表中对ID标签进行排序。 利用兼容度计算向量加权权重。  11
本发明公开了一种基于BERT的两阶段排序的类案检索方法，包括1)数据的预处理；2)构建BM25模型完成对候选案例的初步排序和筛选；3)候选案例子集构建和相关性比较；4)对BERT模型的微调；5)构建排序网络模型；6)计算损失；7)联合训练；8)计算相似度；9)预测更相似的概率。这种方法能提高类案检索效率和类案检索的准确性。一种基于双向编码的基于来自变换器的双向编码器表示(BERT)的两级分类式病例检索方法，用于各种领域，如公正、医疗和金融。该方法提高了类型案例搜索效率和准确率。 该方法可以应用于广泛的数据集，并且可以以简单且成本有效的方式实现。 可以对BERT模型进行微调，提高BERT搜索的准确性。 通过使用基于BERT的两阶段排序类型案例搜索方法，可以高效率、高准确率地搜索类型案例。 可以对数据进行预处理，构建BM25模型，完成候选案例的初级测序和筛选。 可以进行候选案例子集构建和相关性比较，从而可以提高类型搜索效率，增加类型搜索准确率。 可以减小数据集的大小，从而减少待搜索的候选案例的数量。该方法包括对数据进行预处理的过程，利用Jieba分词库分别对查询用例和候选用例进行切分处理，去除停用词。 进行构建BM25模型完成候选病例初步测序筛选的过程。 进行候选病例子集构建和相关性比对，微调BERT模型，构建测序网络模型，计算损失的过程。 通过利用微调整后的BERT模型和测序网络联合训练即每对候选案例作为样本输入BERT模型执行联合训练的过程，得到深度语义向量表达式。 执行计算相似度和预测更相似概率的过程。  12
本发明涉及一种古汉语书籍的年代判断方法及系统，包括：将古汉语书籍进行预处理，得到设置有年代标签的文本序列；将所述文本序列输入RoBERTa模型进行向量化、非线性运算提取特征和归一化处理后，得到预测的年代标签；将事先标注的真实年代标签与所述预测的年代标签进行比较，评估准确性。本发明采用RoBERTa模型可以获得结合上下文信息的向量表示，其中得到的预测的年代标签与真实标注的年代标签的符合率非常高，从而提高了对古汉语书籍的年代判断的准确率。一种利用终端判断古籍年龄的方法(权利要求)。本发明利用罗伯塔模型结合矢量表示的上下文信息进行获取，提高了获取的预测年龄标签和真实标签，从而提高了古籍的准确率。该方法包括对古籍进行预处理以获得具有时间标签的文本序列集。 文本序列集被输入到用于矢量化的Roserta模型中。 进行非线性运算提取特征和归一化处理，得到预测年龄标签。 将预先标记的实时标签与预测年龄标签进行比较以评估准确性。 从语料库中获取古代汉语书籍。 获得时间序列标签的文本序列。 对嵌入层中的输入文本序列执行令牌嵌入和位置嵌入处理，以确定相应的嵌入向量。本发明还涉及一种利用终端判断中国古籍时代的系统。  12
本发明涉及人工智能技术领域，更进一步地，涉及一种基于大模型与知识库生成的智能客服系统。所述系统包括：知识库构建单元、问答大模型构建单元和客户端；所述知识库构建单元，用于从训练数据中获取用户问题和客服回答对，构建知识库；所述问答大模型构建单元，用于构建问答大模型，包括：特征提取子单元，关联捕捉子单元、上下文编码子单元、输出预测子单元、参数更新单元；所述客户端，用于提供给客户输入用户问题，提交给问答大模型，问答大模型根据输入的用户问题，生成客服回答，将客服回答返回给用户端。本发明提高了客户服务的质量和效率，提升了自动客服回答的准确率，同时降低了运营成本。智能客服系统，用于了解用户意图并提供准确解答。提高了客服的质量和效率，提高了自动客服回答的准确性和降低了运营成本。所述智能客服系统包括知识库构建单元，以从所述训练数据中获取所述用户问题和所述客服答案对。 将所述用户问题和客服答案对中的用户问题和客服答案编码为词嵌入表示。 在所述用户问题的词嵌入表示和对应的客服答案的词嵌入表示的基础上构建知识库。 问答大模型构建单元构建问答大模型。 上下文编码子单元，根据所述关注分数时刻对所述用户问题的词嵌入表示和所述客服答案的词嵌入表示的上下文信息进行编码。  11
本发明提供了一种大语言模型驱动的向量数据库构建方法及系统，属于向量数据库技术领域。所述方法包括：对原始数据进行清洗和归一化处理，生成预处理后的数据；应用基于大语言模型的编码器，将预处理后的数据转换为高维向量；该编码器由多个Transformer层组成，每个Transformer层都包括多头自注意力机制和前馈神经网络，以便捕捉输入数据中的复杂模式和依赖关系；对生成的高维向量进行优化，该优化通过解决一个特定的优化问题来实现；将优化后的高维向量存储到一个基于树结构的高效索引结构中，从而构建向量数据库。这种方法及系统允许高度精确和高效的数据检索，特别适用于大规模数据集。一种矢量数据库的构建方法，用于存储大量高维矢量，并允许用户以矢量检索的方式查询和检索信息。该方法使得能够允许高度准确和高效的数据检索，并且适用于大规模数据集。该方法涉及对原始数据进行清洗和归一化以生成预处理数据。 将预处理后的数据转化为高维向量。 编码器由中继层组成。 每个中继层设置有多头自注意力机制和前馈神经网络，以捕获输入数据中存在的复杂模式和依赖关系。 对生成的一个高维向量进行优化，通过求解以下优化问题实现优化。 将优化后的高维向量存入基于树形结构的高效索引结构中，构建向量数据库。独立权利要求还包括一种基于大型语言模型驱动的矢量数据库构建系统。  12
本申请涉及人工智能，提供一种基于Transformer模型的数据预测方法、装置、服务器及存储介质，该方法包括：获取样本语句的多个字词的词向量组成的词向量矩阵，并调用包括自注意力层的Transformer模型；将词向量矩阵输入自注意力层，以根据词向量矩阵生成查询矩阵、键矩阵和值矩阵，并根据随机失活算法和词向量矩阵生成注意力矩阵，以及根据查询矩阵、键矩阵、值矩阵和注意力矩阵，确定多个字词之间的关注程度的概率分布矩阵；根据概率分布矩阵调整Transformer模型的模型参数，直至模型收敛；获取待预测的目标词向量矩阵，将目标词向量矩阵输入至收敛的Transformer模型进行处理，得到预测向量矩阵。能够提高模型泛化性能，并提高模型预测结果准确度。该方法在人工智能中是有用的。该方法提高了模型泛化性能，从而提高模型预测结果精度。该方法包括获取样本句子的词嵌入矩阵。 建立预设模型。 所述预设模型设置有自注意力层。 将所述词嵌入矩阵输入到所述自注意力层。 根据所述字嵌入矩阵、键矩阵和值矩阵生成查询矩阵。 根据预设的随机灭活算法生成注意力矩阵。 确定所述样本句的多个词语之间的关注度概率分布矩阵。 得到预测向量矩阵。独立权利要求还包括：一种数据预测装置； 服务器； 以及一种计算机可读存储介质，包括用于执行基于模型的数据预测方法的指令集。  12
本发明属于金属缺陷检测技术领域，公开了一种分阶段金属表面缺陷检测方法、系统、介质、设备及应用，利用VGG预训练模型提取图像第k‑1和第k层特征；取出所有训练样本的第k层特征中缺陷区域，将其中的最小特征值定为阈值T；用n*n的滑动窗口取出所有训练样本第k‑1层特征中的缺陷区域，并按行扩展成一维向量，记为正样本集，同时取出和正样本数量相当的背景区域，并按行扩展为一维向量，记为负样本集；将特征向量送入SVM，训练得到分类器。本发明规避了人工设计特征不鲁棒且耗时的难点；同时利用深层丰富的语义特征进行粗定位，利用浅层丰富的位置特征精细定位，在保证精度的情况下提高了检测效率。在阶段式金属表面缺陷检测系统(均要求保护)中使用金属缺陷检测信息数据处理终端检测阶段式金属表面缺陷的方法。该方法能够避免人工设计特征不鲁棒和耗时的困难，并且利用深层丰富语义特征进行粗定位，利用浅层丰富位置特征精定位，在保证精度的情况下提高检测效率。该方法包括利用视觉几何组(VGG)预训练模型来提取图像和k-1层特征。 在训练样本的k-1层特征中取出一个缺陷区域。 将最小特征值设置为阈值。 将一维向量按照行展开。 记录负样本集。 将特征向量送入支持向量机(SVM)进行训练，得到分类器。 在记为Fk-1和第k层的深度特征记为Fk的网络提取数据集中的每幅图像使用了k-1层的深度特征VGG。以下包括独立权利要求：计算机设备； 一种计算机可读存储介质，存储有计算机程序，所述计算机程序由处理器执行所述的舞台金属表面缺陷检测方法； 以及分阶段式金属表面缺陷检测系统。   6
本发明公开了一种网约车营销动态触达方法，包括以下系列步骤：观测端对动态营销目标设置边界极值和触达目标对象条件；识别营销对象携带的个性化条件与触达目标对象条件一致性，最终过滤出可触达营销对象；获取营销对象影响供需个性化特征和所处环境营销供需全局化特征；以个性化和全局化特征作为元信息，通过预训练模型获取最终预测供需指标值α；以α作为指标调整观测端所配置营销触达率等原始配置信息；判断调整后观测端所配营销信息是否超过边界阈值。本发明通过观测端预设营销数据和动态获取营销对象的个性化特征和全局化特征实现营销的动态触达，实现调整供需的目的；保证了最终营销数据和结果的安全性和可靠性。一种在线叫车营销的动态逼近方法。该方法通过在观察端预置营销数据，动态获取营销对象的个性化，球形化特征，达到调节供需的目的，实现营销的动态联系； 保证了最终营销数据和结果的安全性和可靠性。该方法包括由观察端配置动态营销到达和联系后营销配置基本信息。 获得营销对象的个性化特征信息和全局特征信息作为元信息。 输入预训练模型以获得索引值。 以营销配置信息为基础数据。 将观察端的配置数据调整为指标值，其中配置的营销边界阈值作为收敛条件。 对调整后的配置数据执行收敛动作。 锁定营销对象的营销信息和快照处理。 13
本发明公开了一种大模型数据保护方法、系统、设备、存储介质及程序产品，其中方法包括：将对大模型进行特征提取得到的第一适配器和第二适配器发送至第二节点，大模型包括第一适配器、主模型和第二适配器；将接收第二节点发送的第一表征数据，输入至大模型进行模型训练，输出得到第二表征数据，将第二表征数据发送至第二节点，第一表征数据为第二节点依据第二适配器和样本业务数据特征进行处理获得；接收第二节点发送的目标梯度值，依据目标梯度值对大模型进行调整，直至大模型调整完成，目标梯度值为第二节点依据第一适配器、第二表征数据和业务标签确定。本发明实现了在不损害大模型拥有方的模型知识产权的同时又能保障模型需求方的数据隐私。一种大型模型的数据保护方法，例如生成预训练变换器2(GPT-2)-XL、开放预训练变换器(OPT)-1.3B，应用于大型模型数据保护系统(权利要求)的与第二节点相连的第一节点，用于在联邦学习场景中对大型模型进行微调。该方法在不损害大型模型拥有者的模型知识产权的情况下，保证了模型需求方的数据隐私。所述方法包括通过提取大型模型的特征来获得(S10)第一适配器和第二适配器，所述大型模型被发送到第二节点，其中所述大型模型包括所述第一适配器、主模型和所述第二适配器。 接收所述第二节点发送的所述第一表征数据(S20)。 将所述第一表征数据输入到所述大模型中进行模型训练。 输出所述第二表征数据。 向所述第二节点发送所述第二特征化数据，所述第一特征化数据为所述第二节点根据所述第二适配器和所述样本业务数据特征处理得到的数据。 接收所述第二节点发送的目标梯度值(S30)。 根据所述目标梯度值对所述大模型进行调整，直至所述大模型调整完毕，所述目标梯度值为所述第二节点根据所述第一适配器、所述第二表征数据和所述业务标签确定的梯度值。独立权利要求包括以下内容：一种应用于与第一节点连接的第二节点的大模型数据保护方法； 大模型数据保护系统； 大模型数据保护装置； 计算机可读存储介质，其存储用于保护大模型的数据的程序； 以及用于保护大型模型的数据的计算机程序产品。  11
本申请实施例提供了一种数据处理方法、装置、电子设备及存储介质。根据本申请实施例提供的方案，首先通过获取得到的包含正确语料元素和错误语料元素的真实平行语料训练得到反向错误生成模型，并基于反向错误生成模型得到大量的模拟平行语料，从而可以基于所述模拟平行语料进行模型训练得到预训练模型，以及基于真实平行语料对预训练模型进行调整得到纠错模型，提高了训练得到的纠错模型的泛化性能，纠错模型也更准确。数据处理方法。该方法使得能够基于真实并行语料对预训练模型进行调整以获得纠错模型，从而提高纠错模型的泛化性能和纠错模型精度。该方法涉及获得包含正确语言学数据元素和错误语言学数据元素的真实并行语料库。 利用所述真实并行语料训练反向误差生成模型。 得到模拟正确语料元素。 利用所述反向错误生成模型预测所述仿真正确语料元素对应的仿真错误语料元素。 利用所述仿真并行语料训练序列映射模型得到预训练模型。 利用所述真实并行语料进行所述预训练模型调整。独立权利要求还包括：一种数据处理设备； 以及包括用于处理数据的指令集的计算机存储介质。  11
本发明公开了一种基于名词与动词的需求文档的查重方法、装置及存储介质，本发明先提取出需求文档中的动名词，并利用多种查重方法来进行多次查重处理，得到多次查重结果；最后，则可利用多次查重结果来确定出需求文档最终的查重结果；如此，本发明将基于名词和动词的需求文档，与同义词词库、知识图谱、BERT模型等自然语言处理技术相结合，来实现查重处理，相比于传统技术，避免了文档质量对查重的影响，且结合了多种查重技术，可提高查重准确率，非常适用于在文档查重技术领域的大规模应用与推广。基于名词和动词的需求文档复核方法。该方法避免了文档质量对复核的影响，并将多种复核技术相结合，提高了准确率，非常适合在文档复核技术领域大规模应用推广。 该方法通过多次使用核对结果，提高了所需文档最终核对结果的准确性。该方法包括对初始去重词集合进行二次查重和去重处理，得到二次查重结果和二次去重词集合。 使用知识图谱。 对两次去重后的词集合进行三次去重处理(S4)。 所述三次重复搜索结果和所述词集合是经过三次去重复后得到的。 对经过三次重检处理后的词集合进行(S5)四次重检处理，以得到经过四次重检处理后的四次重检结果。 利用所述初始检查结果、第二检查结果、第三检查结果和第四检查结果，得到所述目标需求文档的最优检查结果。包括以下独立权利要求：(1)基于名词和动词的需求文档复查装置； (2)存储有基于名词和动词的要求文档的复核程序的存储介质。  11
本申请实施例公开了一种纹理平铺方法、装置、计算机可读存储介质及计算机设备；通过基于纹理贴图坐标信息对噪声纹理贴图进行采样；基于采样到的灰度值将噪声采样图划分为不同灰度级别的噪声纹理区域；计算各灰度级别的采样坐标偏移值；根据噪声纹理区域将原始纹理贴图划分为多个贴图区域；确定原始纹理贴图上被采样的原始位置；根据原始位置所对应的第一采样坐标偏移值，和相邻贴图区域的第二采样坐标偏移值进行采样，得到第一偏移采样结果和第二偏移采样结果；融合第一偏移采样结果和第二偏移采样结果得到目标采样结果，以对待贴图区域进行纹理平铺处理。可以消除在对大型模型表面进行纹理平铺时产生的重复平铺效果，提升纹理平铺的效果。一种纹理贴图方法，用于通过使用计算机设备(权利要求书)在大面积的表面上贴图多个纹理图，所述大面积的表面例如草坪和丘陵。该方法能够消除大模型表面贴砖时产生的重复贴砖效果，提高贴砖效果。该方法涉及获取纹理映射坐标信息、采样使用的原始纹理映射和噪声纹理映射(101)。 基于所述纹理图坐标信息对所述噪声纹理图进行采样(102)，得到噪声采样图。 将噪声采样图像划分(103)为灰度等级不同的噪声纹理区域。 计算每个噪声纹理区域的采样坐标偏移值(104)。 根据噪声纹理区域划分(105)原始纹理映射的映射区域。 根据所述纹理贴图坐标信息确定(106)所述原始纹理贴图上当前采样的原始位置。 得到第一偏移采样结果和第二偏移采样结果(107)。 得到目标采样结果(108)。独立权利要求还包括用于：纹理平铺装置； 以及一种计算机可读存储介质，包括用于纹理贴图方法的一组指令。 3
本发明公开了一种基于大语言模型的智慧教学系统及教学方法，涉及智慧教学技术领域，通过知识图谱辅助大语言模型，进一步实现智能代理，包括智能导师模块、智能助教模块和智能学伴模块。课前通过智能助教模块实现教师智能辅助备课，学生对话式自主预习和个性化学习路径推荐；课中由智能导师模块实现引导式教学，由智能学伴讨论助手实现分组讨论辅助教学；课后智能助教模块帮助教师生成针对性的智能辅助评价，并对主观题进行智能辅助评判，帮助学生实现个性化学习。本发明可以提升教师教学效率，个性化指导学生学习，同时也能够激发学生学习兴趣，提升学习效果。基于大语言模型的智能教学方法基于智能教具模块用于实现教师智能辅助准备、会话式自主预学习和学生个性化学习路径推荐，应用于人工智能技术，以及深度学习、数据挖掘等先进手段。该方法提高了教师的教学效率，个性化指导学生的学习，激发学生的学习兴趣，提高学习效果。该方法涉及通过大型语言模型将知识图谱转化为向量数据库，并对向量数据库进行完善，为大型语言模型的学习提供数据。 通过大型语言模型为学生推荐学习路径。 根据所述学习路径进行所述预学习。 根据学习路径进行引导式教学。 利用大型语言模型对学习到的知识、掌握程度、课堂表现以及学习路径进行分析，评价学生的实力。 将所述预学习和所述指导教学数据进行整合。 通过大型语言模型协助教师进行评估。 对学习数据进行整合，并做出课后复习方案。 所述课程的知识点、教学模式和采用的设计模式由教师提供，通过大型语言模型生成智能辅助备课方案。包括独立的权利要求，用于一种基于大型语言模型的智能教学系统。  11
本发明公开了一种评论有用性的处理方法、系统、装置和存储介质，可应用于大数据处理技术领域。本发明通过分别构建影响因子模块、由双向编码模型或长短期记忆递归神经网络模型组成的文本处理模块以及由卷积神经网络模型和预训练模型组成的图片数据处理模块，并以影响因子模块、文本处理模块和图片数据处理模块作为不同分支输入单元来构建评论有用性票数预测模型，然后通过对影响因子、文本数据和图片数据进行预处理后，通过训练数据对评论有用性票数预测模型进行训练，再将当前待处理评论数据输入训练好的评论有用性票数预测模型中进行评论有用性分析后得到评论有用性投票数据，从而能够有效提高评论有用性分析结果的准确度。处理评论有用性数据的方法。该方法能够将当前待处理评估数据输入训练好的评估有用票数预测模型进行评估有用分析，得到评估有用票数数据，从而能够有效提高有用分析结果的准确性。该方法通过对影响因素、文本数据和图片数据进行预处理，对评论关联数据进行处理，其中，评论关联数据包括训练数据和当前待处理评论数据。 构建影响因子模块、文本处理模块和图片数据处理模块，所述影响因子模块包括输入层、预处理层、全连接层和激活层，所述图片模块包括卷积神经网络模型和预训练模型。 将影响因子模块、文字处理模块和图片数据处理模块作为不同的分支输入单元，构建有用的票号预测模型。 通过所述预处理后的训练数据训练评估有用票数预测模型。 将预处理后的当前待处理评论数据输入已训练的评论有用票数预测模型，得到评论有用投票数据。独立权利要求包括：(a)用于处理评论有用性数据的系统; (b)评论有用性数据处理装置; (c)存储用于处理评论有用性数据的一组指令的存储介质。   4
本发明公开了一种基于遥感影像的OpenStreetMap路网数据质量评价的方法，该方法首先对OSM路网数据进行了简化，得到初始道路骨架，然后将路网与影像进行配准；利用道路的边缘特征、光谱特征以及植被特征构建贝叶斯网络模型进行验证，将OSM路网数据中可靠的路段作为基础路网骨架；其次通过U‑Net模型在遥感影像中提取道路，用以弥补OSM路网中未覆盖的新增道路骨架，从遥感影像中提取的道路也会经贝叶斯网络模型验证，与已有的基础路网股价融合得到完整的路网骨架。最后，将影像网格化划分子研究区，通过计算三项路网评价因子：位置精度、长度完整性以及网格内部的最小外接多边形，得到评价区域内的OSM路网数据质量的评价参考图。一种基于遥感影像的开放街道地图路网数据质量评价方法。该方法包括选择OSM数据质量评估因子以获得基本道路骨架。 道路数据与遥感影像匹配。 提取有效的道路基层单元。 提取道路边缘特征，植被特征和光谱特征。 获得每个特征的概率。 构建贝叶斯网络。 通过使用基本道路骨架获取样本来更新当前道路样本库。 完成一个道路网络架构作为参考道路。 在每个网格中计算评估因子。 使用模糊推理系统获得评估结果。   6
本发明提供了一种基于深度学习的图像超分辨率重建方法。具体步骤为：(1)图像的超分辨率重构。利用卷积神经网络(CNN)，从大量的训练数据中学习，得到低清晰度图片与高清晰度图片中的映射关系模型，使用映射关系模型，对测试集中图像进行基于CNN的超分辨率重构处理。(2)完成步骤(1)后，得到重构后的图像，再使用其作为低清晰度图像，采用Keras深度学习框架来定义生成器网络和判别器网络并且以VGG19预训练模型进行特征提取来构建SRGAN模型，最后对测试集中图像进行基于SRGAN的超分辨率重构处理。(3)完成步骤(2)即可实现基于深度学习的图像超分辨率重建。本发明方法使用方便、响应速度快、测量精度高、结构简单，并提高了现场检测速度。该方法可用于基于深度学习的图像超分辨率重建。该方法实现图像超分辨率重建过程方便，响应速度快，测量精度高，结构简单； 提高了现场检测速度。该方法包括：获取低分辨率图像和高分辨率图像的映射关系模型；基于所述映射关系模型进行超分辨率重建处理；根据所述超分辨率重建处理的结果，对所述低分辨率图像和所述高分辨率图像进行超分辨率重建处理。电缆新闻网(CNN) (RTM)：美国基本电缆和卫星电视新闻频道)。 利用Keras深度学习框架定义生成器网络和仲裁器网络，利用VGG19预训练模型进行特征提取，构建SRGAN模型。 基于对测试集图像的SrGaN执行超分辨率重建处理。 基于深度学习实现图像超分辨率重建。   6
本说明书公开了一种模型部署的方法及装置，网络设备中部署有智能芯片，该智能芯片中部署有预设的强化学习模型，该网络设备中部署有预设的轻量模型，该轻量模型的模型框架占用的存储空间，小于该强化学习模型的模型框架占用的存储空间，网络设备可以获取自身在设定时长内获得的经验数据，并根据经验数据，对该轻量模型进行训练，得到训练后的轻量模型，最后，根据训练后的轻量模型的网络参数，对强化学习模型进行更新，以使该网络设备通过更新后的强化学习模型，进行任务执行，相比于现有技术，不需要网络设备安装大型的模型框架以及通过智能芯片的软件栈对强化学习模型进行处理，从而节省了网络设备的计算资源，提高了网络设备的计算效率。用于部署用于电子设备的模型的方法(要求保护)。该方法能够直接替换已训练的轻量级模型中原有的增强学习模型的网络参数，从而直接得到能够部署在智能芯片完成训练上的增强学习模型，而不需要安装大的模型框架，并通过智能芯片的软件栈对增强模型进行处理，从而节省了网络设备的计算资源，提高了设备的计算效率。该方法涉及部署具有智能芯片的网络设备。 智能芯片中部署有预设加强学习模型。 所述网络设备部署在预设光线模型上。 所述轻量化模型的模型框架被存储空间占用。 所述模型框架小于所述存储空间占用的增强学习模型的模型框架。 根据经验数据进行所述轻量化模型训练，得到训练后的轻量化模型。 更新所述学习模型，以使所述网络设备通过更新后的所述强化学学习模型进行任务执行。独立权利要求包括：一种用于模型部署的设备； 存储有计算机程序的计算机可读存储介质； 一种电子设备包括存储器。  11
本发明公开了一种输电线路线模参数辨识与自适应矫正方法，检测需调整参数的线路两侧电压、电流信号，传递至对端并利用Bergeron模型计算对端电流计算值，与实测值作差后利用滑窗方式找到周期内最大模型误差值，当其大于启动值时启动参数矫正算法，计算电感参数调整量，并重新利用Bergeron模型计算、通讯并滑窗找寻参数矫正后的新模型误差，直到模型误差小于退出门槛时，更新线路的线模参数。本发明实现了输电线路的线模参数辨识与自适应矫正，以有效增强依赖线路参数的继电保护或故障测距方法的可靠性；应用场景广泛，无需额外加设装置，具备更好的市场价值。一种用于直流输电系统继电保护领域的输电线路模型参数辨识及自适应修正方法。该方法实现了输电线路的线模参数辨识和自适应修正，从而有效增强了依赖于线路参数的继电保护或故障测距方法的可靠性。 应用场景广泛，无需增加额外的装置，因此具有较好的市场价值。该方法涉及对需要调整参数的线路两端进行检测，获取被保护线路两端的电压信号、电流信号和保护线路信息参数。 两端将电压信号和电流信号传输至对端，基于Bergeron模型计算对端电流模量。 在检测周期内利用滑动窗口实时检测Bergeron模型的最大模型误差。 进行所述确定以检查参数校正后的最大模型误差是否小于误差退出阈值。 0
本发明公开了一种大语言模型赋能的智能化软件造价评估方法及系统，方法包括：对软件的应用文档进行预处理，获取问答对数据作为训练数据，问答对数据包括文档段落及其对应的功能点细则明细；将文档段落及其对应的功能点细则明细输入至大语言模型中进行模型训练，并进行垂直领域微调以及引入特定化prompt，得到训练后的大语言模型；将文档段落进行批处理，并行输入至训练后的大语言模型中，获得功能点输出，基于功能点输出进行智能化软件造价评估。本发明最大程度减少人工干预，提高效率，降低错误率。用于评估用于大型语言模型启用的智能软件成本的方法。该智能软件成本评估方法最大限度的减少了人工干预，提高了效率，降低了出错率。智能软件成本评估方法涉及对软件的应用文档进行预处理，获取问答对数据作为训练数据。 问答对数据包括文档段落和对应的功能点详情。 将所述文档段落和对应的功能点详情输入所述语言大模型进行模型训练，并进行垂直领域细调和引入具体提示，得到训练后的语言大模型。 对软件的应用文档进行段落划分，得到字符串文本段落，并行地对输入训练好的大语言模型的字符串文本段落进行批量处理，得到功能点输出。 基于所述功能点的输出对所述智能软件的成本进行评估。独立权利要求包括用于：(1)大型语言模型赋能的智能软件成本评估系统； (2)具有处理器的计算机设备； (3)一种计算机可读存储介质，其存储有用于实现所述用于大型语言模型实现的智能软件成本评估方法的指令。  11
本公开提供了生成式大模型训练方法、基于模型的人机语音交互方法，涉及生成式模型、智能语音、人机交互等人工智能技术领域。该方法包括：基于用户输入语音与匹配的包含有接口调用指令的输出结果，构建第一训练集；利用第一训练集对预设的第一生成式大模型进行有监督微调训练，得到第二生成式大模型；基于相同用户输入语音与不同候选输出之间的用户偏好排序和预设模板集合，构建第二训练集；利用第二训练集对预设的第三生成式大模型进行有监督训练，得到奖励模型；将第二生成式大模型，基于奖励模型返回的得分，以强化学习方式进行训练。利用据此训练得到的生成式大模型可显著提升人机语音交互场景下的回复准确率和用户体验。生成式大模型训练方法。该方法使得能够将根据训练方案得到的目标生成类型大模型应用于人机语音交互场景，语音助手在生成用户输入语音输入目标的大模型后，通过目标生成类型大模型的能力生成相应的结果，并在满足调用服务接口的需求时，自动生成接口调用指令并执行得到返回的调用结果。 该方法使得能够将基于生成的回复文本和通话结果生成的输出文本返回给语音助手，自觉语音助手转换为机器回复语音返回给用户完成人机语音交互，提高了人机语音交互体验。该方法包括基于用户输入语音和包含接口调用指令的匹配输出结果构建第一训练集。 所述接口调用指令调用的服务接口对应于用户输入语音表达的功能使用意图。 利用所述第一训练集对预先训练的第一生成大模型进行有监督微调训练，得到第二生成大模型。 所述第二训练集是基于用户偏好排序和预设的同一用户输入语音与不同候选输出之间的模板集构建的。 利用所述第二训练集对预先训练的所述第三生成大模型进行监督训练，得到所述奖励模型。 基于所述奖励模型返回的得分采用强化学习的方式对所述第二生成大模型进行训练，得到目标生成大模型。包括独立权利要求：(1)一种基于生成大模型的人机语音交互方法； (2)生成型大模型训练装置； (3)一种基于生成大模型的人机语音交互装置； (4)一种电子设备，包括处理器和与所述处理器通信连接的存储器，所述存储器中存储有可被所述处理器执行的指令，所述指令被所述处理器执行，以使所述处理器执行所述的生成式大模型训练方法； (5)一种非暂态计算机可读存储介质，存储有用于使计算机执行所生成的大模型训练方法的计算机指令； (6)一种计算机程序产品，包括计算机程序，所述计算机程序被处理器执行时，生成所述的大模型训练方法的步骤。 8
本发明属于企业知识库技术领域，涉及一种基于大模型和知识图谱的企业知识库问答系统，包括：设备维修相关数据；知识图谱构建模块，其基于设备维修相关数据，采用大模型构建设备维修知识图谱；故障问题及其解决方案生成模块，其基于不同的故障类型，以设备维修相关数据和设备维修知识图谱为输入，采用大模型生成不同的故障问题及其解决方案；问题输入模块一，其供用户输入咨询问题；问题匹配模块，其采用大模型对不同的故障问题进行扩展，以使咨询问题与不同的故障问题相匹配，并将咨询问题与不同的故障问题及其对应的解决方案相关联，从而获得问答对；问答对输出模块，其输出问答对。本发明可以提高企业知识库问答系统的质量和效率。基于大模型和知识图谱的企业知识库问答系统。该系统可以提高企业知识库问答系统的质量和效率。所述系统具有知识图谱构建模块，用于基于装置检修相关数据由大模型构建装置检修知识图谱。 故障问题及解决方案生成模块，将所述装置维修相关数据和所述装置维修知识图谱作为基于不同故障类型的输入，利用大模型生成不同的故障问题及对应的解决方案。 问题输入模块，用于用户输入咨询问题。 问题匹配模块，利用所述大模型扩展不同的故障问题，使得由所述问题输入模块输入的咨询问题与所述不同的故障问题相匹配，并将由所述问题输入模块输入的咨询问题与所述不同的故障问题以及对应的解相关联，以获得问答对。 问答对输出模块，输出所述问答对。  11
本发明公开了一种文本分类方法、系统、终端及存储介质，包括：将待分类文本信息输入已训练完成的Bert模型，得到若干分类结果；提取Bert模型输出层的CLS向量，得到若干句向量；基于若干分类结果及若干句向量，计算句向量的loss，并构建神经网络；将若干句向量的loss加权求和得到总loss，通过神经网络优化器对总loss进行优化，直至收敛。本发明将Bert模型作为backbone，达到提取文本句向量的目的，同时将Bert模型预测得到的分类结果作为一个粗略的结果。后端桥接上新的网络结构，即可以充分利用预训练Bert的文本表征能力，又可以在垂直领域更好的优化分类性能。本发明多层loss的相加，能够更好得记录句向量在过程中的变化，对模型的收敛起到了积极的作用。终端对文本进行分类的方法。该方法能够更好地记录句子向量的变化，对模型的收敛起到积极的处理和作用。该方法将待分类文本信息输入Bert模型，用于得到多个分类结果。 提取Bert模型输出层的句子向量分类(CLS)以获得多个句子向量。 对所述Bert模型输出层的词向量进行聚合，得到多个句子向量。 根据分类结果计算所述句子向量的平均值。 获得类型向量。 句子向量与类型向量相关联。 对所述类型向量进行加权求和处理，得到新的句子向量。 构建神经网络。 通过构建的神经网络对应的优化器对总损失进行优化，直至损失收敛。独立权利要求包括：(1)一种用于通过终端对文本进行分类的系统； (2)一种计算机设备，包括存储器和处理器，用以执行一种终端对文本进行分类的方法； 以及(3)一种计算机可读存储介质，用于存储计算机程序，以执行终端对文本进行分类的方法。  12
本申请公开了一种提取地理位置点空间关系的方法、训练提取模型的方法及装置，涉及大数据技术领域。具体实现方案为：获取第二训练数据，所述第二训练数据包括：文本以及对文本中地理位置点、地理位置点空间关系信息的标注；利用所述第二训练数据训练地理位置点空间关系提取模型，所述地理位置点空间关系提取模型包括嵌入层、Transformer层和映射层；所述地理位置点空间关系提取模型用于从输入的文本中提取地理位置点空间关系信息。本申请能够从互联网文本中提取地理位置点空间关系信息，解决了因地理位置点的坐标误差或楼层关系而导致的空间关系不准确或无法自动生成的问题。该方法对于通过使用电子设备(主张)训练地理位置点空间关系提取模型是有用的。该方法：可以从互联网文本中提取一个地理位置点的空间关系信息； 并防止地理位置点坐标误差或楼层关系造成的空间关系不准确或不准确的困难。训练地理位置点空间关系提取模型包括：获取第二训练数据，所述第二训练数据包括文本以及所述文本中地理位置点的标注和地理位置点的空间关系信息，利用所述第二训练数据训练地理位置点空间关系提取模型，所述地理位置点空间关系提取模型包括嵌入层、转换层和映射层，利用训练好的地理位置点空间关系提取模型从输入的互联网文本中提取地理位置点空间信息； 获取第一训练数据，在利用所述第二训练数据对所述地理位置点空间提取模型进行训练时，基于预训练模型训练得到嵌入层和变压器层。独立权利要求还包括用于：一种训练地理位置点空间关系提取模型的装置； 以及一种非暂态计算机可读存储介质，包括用于训练地理位置点空间关系提取模型的指令集。  11
本发明涉及一种基于多头注意力和图卷积网络结合R‑Drop机制的生物医学关系抽取方法、装置和介质，要点是包括以下步骤：(1)构建医学语料的关系实例，(2)构建句法依存树，(3)使用BERT预训练模型和多头注意力提取文本的加权上下文语义表示，(4)使用ELMo预训练模型和图卷积网络结合句法依存树提取文本的结构化表示，(5)使用解码器对特征表示进行解码，(6)使用R‑Drop机制对神经网络进行正则化，最终得到关系类别。效果是使用端到端的训练方法，可以自动学习医学文本中的语义特征和结构特征；引入R‑Drop机制，提升模型的泛化性能；在不引入外部知识的情况下，取得了较强的关系抽取性能。用于临床诊断、医学知识映射和医学研究的基于多头注意力和图卷积网络结合R-Drop机制的生物医学关系提取方法。生物医学关系抽取方法包括构建医学语言学数据的关系实例，其中构建语法相关树，能够自动学习医学文本中的语义特征和结构特征，提高模型的泛化性能，获得较强的关系抽取性能。生物医学关系抽取方法是通过BERT预训练，由启发式规则对医学语言学数据构建医学实体关系的句子和句子实例。 所述多头注意力网络和关系表示文本的加权上下文语义特征表示。 语义特征表示和结构特征表示是根据结构化特征表示文本抽取通过句子方法抽取的。 由解码器对分层特征表示进行拼接、提取和解码。 用于增强网络以获得生物医学关系类型的R-drop正则化。所述方法包括：(a)一种设备，所述设备具有执行所述存储器中的代码的处理器; (b)用于存储计算机程序的计算机存储介质。  12
本申请提供了一种文本信息中的实体识别方法、装置、电子设备和存储介质，属于实体识别技术领域。所述方法包括：通过聚类方案将多个文本信息进行聚类得到多个类簇；通过预设划分方案将每个所述类簇中的文本信息划分为无标签信息和带标签信息；通过所述聚类方案和所述预设划分方案，对多个所述类簇的无标签信息进行聚类和划分，直至无法得到新的带标签信息；基于预训练模型在所述文本信息的基础上进行继续训练，得到初始训练模型；基于所述初始训练模型对全部所述文本信息进行模型训练，以通过训练后的模型进行所述文本信息中实体的识别。本申请提高标注效率，采用继续训练的方式提高模型泛化能力和训练精度。用于识别文本信息中的实体的方法。本发明实现了服务器的自动标注，无需人工标注数据，提高了标注效率，获取了文本信息中隐藏的先验信息，提高了文本信息中实体识别的准确性，提高了模型的泛化能力。 标记方式简单，不需要设定规则。该方法涉及通过聚类方案对文本信息进行聚类(101)以获得多个聚类。 每个簇具有文本信息。 每个簇中的文本信息通过预定的划分方案被划分(102)为无标签信息和标签信息。 所述预设划分方案与所述文本信息中的同一实体相关联。 通过所述聚类方案和所述预设划分方案对所述簇的无标签信息进行聚类和划分(103)，直到未获得新的带标签信息。 基于文本信息继续训练(104)，用于基于预训练模型获得初始训练模型。 预训练模型是基于大规模通用语料训练生成的模型。 基于初始训练模型对所有文本信息执行(105)模型训练，并且文本信息中的实体由训练的模型识别。本发明还涉及一种用于识别文本信息中的实体的装置； 用于识别文本信息中的实体的电子设备； 以及存储用于识别文本信息中的实体的程序的计算机可读存储介质。  11
本发明公开了一种基于上下文语义的任务自动分解方法和系统，根据已有技术知识大数据进行语义识别与实体数据提取并构建技术知识图谱；对所述任务需求文档数据进行语义分析与关键词提取，得到需求关键词，将所述需求关键词与任务需求文档数据导入基于BERT的上下文分析模型进行预训练并生成关键词向量；基于关键词向量进行聚类分析，基于多个词向量组生成多组技术需求信息；根据多组技术需求信息中的关键词进行实体语义转化并通过技术知识图谱进行关联技术检索，得到多组关联技术信息；基于多组技术需求信息与多组关联技术信息进行任务与资源分析，并生成任务资源分配方案。通过本发明能够实现对需求文档的精细化任务分解与资源匹配。语义分析领域中基于上下文语义的任务自动分解方法。基于多组技术需求信息和多组关联技术信息进行任务和资源分析，生成任务资源分配方案，从而可以实现所需文档的精细任务分解和资源匹配。该方法包括获得任务需求文档数据。 根据已有的技术知识大数据，通过基于RNN的语义识别模型进行语义识别和实体数据抽取。 基于所提取的实体数据来构建技术知识地图。 根据技术需求信息中的关键字进行实体语义转换。 通过所述技术知识图谱进行关联技术检索，得到关联技术信息。 基于技术需求信息和技术信息进行科技资源匹配，并生成任务分配信息。 基于所述任务分配信息进行科技资源匹配并生成任务资源分配方案。还包括独立权利要求一种基于上下文语义的任务自动分解系统。  12
本发明公开了一种新闻评论的情感分析与生成方法，具体包括以下步骤：准备初始数据集，其中包含人工标注小规模数据集A和大规模无监督数据集B；在数据集B的基础上，使用开源情感分类工具，为新闻评论情感分析模型建立大规模伪标签数据集C；基于大规模伪标签数据集C预训练新闻评论情感分析模型；预训练后再在人工标注的小规模数据集A上微调，得到最终的新闻评论情感分析模型；使用最终的新闻评论情感分析模型，重新在数据集B上进行伪标签标注得到大规模伪标签数据集D；基于大规模伪标签数据集D预训练可控式新闻评论生成模型；预训练后在人工标注的小规模数据集A上微调，得到最终的可控式新闻评论生成模型。新闻评论的情感分析与生成方法。该方法：提高情感分析模型的自然语言理解能力和评论生成模型的自然语言生成能力； 减少了人工贴标签的工作量； 并提高了新闻评论情感分析和可控评论生成两个模型的准确率。该方法包括准备初始数据集。 对小规模数据集和大规模无监督数据集进行人工标注。 在利用开源情感分类工具后的数据集基础上建立大规模伪标签数据集。 基于大规模伪标签数据集建立新闻评论情感分析模型，对新闻评论进行训练。 人工对小规模数据集进行预训练和微调后得到最终的可控的新闻评论生成模型。  12
本发明提供了一种针对文本数据的实体及关系串联式提取方法。首先对文本进行预处理，并提取其词向量，然后，将词向量输入文本实体提取模型BiLSTM‑softmax，得到带实体对的文本，接着，对存在歧义的文本进行消歧消解处理，最后，将带实体对的文本输入到关系判别模型，再经关系分类模型得到实体的关系类别。本发明能够针对文本数据进行实体及关系的串联式提取，同时具有长文本处理、实体消歧和指代消解丰富语义的功能，获得了较好的实体提取和关系提取结果。用于促进文本数据的实体和关系串联型提取的方法。该方法使得能够将BiLSTM-CRF模型中的CRF层替换为softmax层，从而在获得较高的文本实体提取精度的同时，大大提高了模型处理速度和计算效率。该方法包括输入文本。 将切分后的文本分别输入词向量模型，得到所述文本对应的词向量。 将文本词向量输入文本实体抽取模型进行实体抽取。 进行确定以检查文本中是否存在歧义。 将所述文本输入实体消歧模型进行消歧处理。 将明确或消歧后的文本输入实体关系判断模型。 所述实体关系类型通过实体关系分类模型获得，所述BiLSTM模型包括BiLSTM层，所述实体关系分类模型是指对只包含实体位置信息的序列数据集进行训练后的BiLSTM模型。  12
本发明涉及人机对话领域，特别涉及一种基于大语言模型的上下文构造方法，在对话过程中通过判断任务类型，将对话进行精准的筛选，再插入到上下文中。这种方法能够帮助智能助理背后的大语言模型，能够精确获得当前要执行的任务，以及这些任务的背景信息，从而能够快速准确地执行任务，提供人机交互的效率，具备显著的有益效果。用于对话机器人的基于大型语言模型的上下文构建方法。该方法帮助智能助理背后的大型语言模型，准确地获取当前要执行的任务以及任务的后台信息，从而快速准确地执行任务，提高了人机交互的效率。该方法包括提供历史对话集，其中历史对话集包括多个对话。 基于时间序列为所述历史会话集合中的每个会话分配时间相关权重。 识别所述用户的所述新输入对话的主题。 基于所述时效权重和所述最近对话集中的各个对话的话题相关系数得到各个对话的综合权重。 以较高的综合权重筛选多个对话。 构建所述当前对话话题对应的上下文关系。 用户的上下文和新输入对话被一起输入到大型语言模型。 将所述大语言模型返回的回复结果输出给所述用户。 对话结束后记录对话内容。 将所述内容向量化，并逐一存储到所述历史会话集合中。 8
本发明公开了结合关键词和语义理解表征的检索式回复对话方法及系统，系统结合了两种层次粒度的向量表征，分别是词袋向量表征和语义理解表征，结合过程中不只考虑了对话中关键词的信息，还考虑了基于上下文的语义理解，极大地提升了检索式回复模型的性能。本发明中采取了中文预训练模型Bert网络模型获取句向量表征，不仅理解句意，并且排除了词向量加权引起的误差。该系统采取了Bert网络模型在自己的单轮对话上训练分类任务——对话是否匹配的任务，通过微调，学习到了Bert中线性层和激活函数的权重。该系统使用了精排模型LGMRanker，可以直接预测与query相关的回复相对顺序，返回一个排好序的列表回来。在人工智能检索型回复对话字段中结合关键词和语义理解表示进行搜索型回复会话的方法。 用途包括但不限于客户服务、语音助理和聊天。该方法将检索类型回复会话的关键词和语义理解表示相结合，有效丰富了检索回复的内容和质量，提高了回复的流畅性和自然性。 该方法能够获得用于理解含义的句子向量表示，并且减少了由词向量加权引起的误差。该方法包括预处理对话文本语言数据(S1)。 得到单句对话文本和单句对话分词信息。 获得单句对话向量表示(S2)。 计算所述单句对话分词信息的词频-逆向文件频率向量表示。 构造层次结构的高速信道模型(S3)。 获取当前查询对话文本的向量表示(S4)作为查询对话文本。 将所述查询对话文本输入所述高速通道模型。 计算每个回复在当前查询对话文本中的句子向量表示(S5)。 选择回复结果顺序中的最优回复(S6)作为当前查询对话文本的回复。还包括用于执行与关键字和语义理解表示相结合的搜索型回复会话的系统的独立权利要求。 8
本发明提供了一种基于元学习的电力机器人巡检场景识别方法及系统，该方法包括：构建元学习模型并基于采集的常见场景图像进行预训练，获取预训练模型；获取罕见情形图像，并基于罕见情形图像对预训练模型进行微调，获取微调模型；将待识别图像输入微调模型中，以使微调模型进行推理，获取识别结果。本发明提供的一种基于元学习的电力机器人巡检场景识别方法，通过常见场景图像对模型进行预训练并基于罕见情形图像对其进行微调，以令得到的微调模型可以实现对巡检场景中的罕见情形的识别。常见场景图像可以大量采集，避免出现的样本不足的问题，且微调模型是在真实场景下进行预训练和微调所得到的，因此其识别准确率有所保证。基于元学习的电力机器人巡检场景识别方法。普通场景图像可以大量采集，避免了样本不够的问题，且细调模型是在真实场景中预先训练细调得到的，因此保证了识别精度。该方法涉及基于采集的普通场景图像构建元学习模型和预训练模型(S1)。 获取罕见情况图像(S2)。 基于所述稀有情况图像对所述预训练模型进行微调。 得到微调模型。 将待识别图像输入细调模型(S3)。 对所述细调模型进行推导，得到辨识结果。 采集普通场景图像。 获取所述普通场景图像的类型，得到标记图像。 选择标记后的图像作为数据库。包括独立的权利要求，用于一种基于元学习的电力机器人巡检场景识别系统。 0
本发明公开了一种面向电商的标签系统，属于电商数据分类领域，一种面向电商的标签系统，所述标签系统包括以下步骤：S1：创建自定义语料库、停用词列表，并将自定义语料库、停用词列表同步至BERT模型中；S2：LAC分词模型建立；S3：提取相关短文本关键词作为特征向量；S4：获取标签分类结果，所述S1中，自定义语料库和停用词列表采用标签幂集构成；BERT模型对幂集中自定义语料库和停用词列表的训练方式分为：Masked LM和Next Sentence Prediction两种，它可以实现，利用标签幂集策略决策树模型完成文本分类，多标签分类准确率达75％，比传统二元关联策略朴素贝叶斯算法高68％。一种电子商务标签系统，用于电子商务平台，作为企业或个人的网上交易谈判平台，以建立在互联网上的商业活动的虚拟网络空间为基础，协调和整合信息流、物流和资金流。采用标签幂集策略决策树模型完成文本分类，多标签分类准确率达到75%且比传统二值相关策略朴素贝叶斯算法高出68%。该系统具有用户定义的语料库，并且创建停止词列表，并且将用户定义的语料库和停止词列表同步到来自变换器的双向编码器表示(BERT)模型。 建立LAC分词模型。 提取相关的短文本关键词作为所述特征向量。 得到标签分类结果。 所述用户自定义语料和所述停用词列表通过标签功率集形成。 BERT模型对功率集用户自定义语料和禁用词列表的训练模式分为LM和Next感知预测。 BERT模型的操作步骤被输入为文本内容-词向量-文本向量位置向量-BERT计算-获得结果。 0
本发明公开了一种电子显微镜图像神经元分割方法、系统、设备及存储介质，针对电镜图像特性进行了扰动，触发了电镜神经元分割任务上的一致性学习方法。为了避免在极端有限的标注数据下一致性学习陷入次优解，我们提出基于图像重建的预训练策略，从大量未带标注数据的电镜图像中隐式提取神经元的结构信息，进一步增强了一致性学习的有效性。总的来说，本方法两次利用未带标注数据，充分挖掘了其有效信息，提升了模型的泛化性。与监督方法相比，在标注数据有限的情况下，能提升四倍的神经元分割性能，在保证性能不下降的情况下，能减少十倍的标注数据需求。分割电镜图像神经元的方法。提出了基于图像重建的预训练策略，从电镜图像的多个非标记数据中隐式提取神经元结构信息，以避免在极端有限的标记数据中进行一致性学习，从而增强一致性学习的有效性，降低对标记数据的依赖性，提高模型的泛化能力。该方法包括扰动未标记的电子显微镜图像以产生噪声电子显微镜图像。 将噪声电子显微镜图像的图像输入到重建神经网络。 利用神经元孪生网络构建第一损失函数，预测所述重建预测的神经网络与对应的无标记电镜图像的差异。 构建第二损失函数和第三损失函数，训练分割神经网络对所述电镜图像进行分割。 基于预训练的神经网络预测亲和力神经元。 通过后处理算法得到神经元结果。包括独立权利要求：(1)一种用于分割电子显微镜图像神经元的装置； (2)用于分割电镜图像神经元的处理装置； 以及(3)可读存储介质具有用于分割电子显微镜图像神经元的指令集。   4
本发明提供基于BiLSTM模型的标准实体文本确定方法、装置及存储介质，方法包括：针对接收到的待匹配文本实体，选取与其对应的候选实体集；针对候选实体集中的每一候选实体，分别与待匹配文本实体构成文本实体对；针对每个文本实体对，采用预设神经匹配神经网络计算文本实体对的第一相似度特征向量，及采用文本统计方法、全连接网络计算文本实体对的第二相似度特征向量；采用拼接网络将每个文本实体对的第一相似度特征向量与第二相似度特征向量拼接形成每个实体对的相似度向量，并根据每个文本实体对的相似度向量输出每个实体对中两个实体文本的相似度；将相似度最高的文本实体对中的候选文本实体确定为与待匹配文本实体对应的标准文本实体。基于BiLSTM模型的标准实体文本确定方法，用于自然语言文本信息处理和医学大数据挖掘技术领域中标准实体文本的确定。该方法通过文本统计方法和全连接网络计算文本实体对的第二相似度特征向量，提高了文本数据的利用率，避免了术语对训练数据的训练，提高了医疗实体标准化任务中标准文本实体结果的适用性和准确性，降低了模型的复杂度和训练效率。该方法涉及选择与接收到的待匹配文本实体对应的候选实体集合。 利用预设的神经匹配神经网络计算文本实体对的第一相似度特征向量。 计算所述全连接网络的第二相似度特征向量。 将所述相似度最高的文本实体对中的候选文本实体确定为所述文本实体对应的标准文本实体。 所述文本实体对由文本实体组成。 从所述候选实体集合中选择所述候选文本实体。独立权利要求还包括：一种基于BiLSTM模型的标准实体文本确定装置； —种非暂态计算机可读存储介质，包括用于基于BiLSTM模型确定标准实体文本的指令集。  12
本发明公开了一种基于注意力机制的BiLSTM网络和LightGBM模型的交通预测方法，采用增加了注意力机制的BiLSTM网络和LightGBM模型，通过同时捕获交通路网的时间依赖性即交通流的局部时间变化趋势和空间依赖性即拓扑空间结构，通过历史时间步的交通流量预测未来时间步的各个路段的交通流量，由此准确预测道路网络的交通流。本发明方法能够有效预测交通流的时空变化特征和规律，预测精度高，提升了交通流预测效果。利用双级稳定大规模集成(BiLSTM)网络和基于注意力机制的轻型GBM模型预测路网交通流量的方法。该方法能够有效预测交通流的时空变化特性和规律，使得预测精度高，从而提高交通流预测效果。 该方法能够实时捕获城市交通路网的时间依赖性和空间依赖性，从而提高交通预测精度。该方法包括预处理收集的原始交通数据。 根据采集的交通流数据生成城市交通网络中节点的交通流属性特征矩阵。 通过增加注意力机制的BiLSTM网络，在交通网络中的各个交通节点获得交通流特征。 在所述交通节点处输出交通流特征的加权和。 将预测结果与历史对应的时间步长的结果进行比较，以实现轻GBM模型的训练。 输入待预测交通流的路段信息。 输入生成的模型，得到最终的预测结果。  12
本发明提供了一种无人机遥控链路中断的处理方法、装置及无人机，该方法包括：当无人机进入中断等待状态时，开始计时，并判断无人机的链路中断是否由干扰信号造成；如果是由干扰信号造成，则判断计时的时长小于或等于干扰判断预设时长T5时是否检测到遥控链路数据信号；如果是，则继续执行飞行任务，否则，执行链路中断难复处理，其中，干扰判断预设时长T5大于中断难复判断预设时长T2。本发明通过在无人机的链路中断判断中增加对干扰信号的判断，如果判断出链路中断是由干扰信号造成的，则无人机的状态转为干扰等待状态，而不是进入中断难复状态，避免无人机因为可恢复的干扰而放弃原有任务，大大提高了飞机任务完成率以及实战性。一种UAV遥控链路中断的处理方法。在判断UAV链路中断时加入干扰信号的判断。 当判断链路中断是由干扰信号引起时，将UAV的状态改变为干扰等待状态，而不是进入中断困难状态。 避免了无人机因可恢复干扰而放弃原任务，大大提高了飞机任务完成率和实战性能。该方法包括当UAV进入中断等待状态时开始(S101)定时，以及确定(UAV)的链路中断是否由干扰信号引起。 确定(S103)定时周期是否小于或等于干扰确定预定时间周期，当干扰信号引起遥控链路数据信号时，是否检测到遥控链路数据信号，并继续(S104)执行飞行任务， 否则，执行(S105)难以恢复的链路中断处理。 干扰判断预设时间段T5大于中断难恢复判断预设时间段T2。 确定UAV的链路中断是由干扰信号引起的，否则，确定UAV的链路中断不是由干扰信号引起的。本发明还涉及一种用于UAV远程控制链路中断的处理装置。   6
本发明涉及一种基于大语言模型的反编译结果优化方法和系统。该方法包括：裁判角色通过与大语言模型交互获得反编译结果的优化方案；根据裁判角色获得的优化方案，建议者角色通过与大语言模型交互获得具体的整改措施；操作员角色将建议者角色获得的整改措施施加于反编译结果，并检查函数语义是否被改变，根据函数语义的变化确定是否接受整改措施。本发明设计了一种基于通用大语言模型的反编译结果优化方法来自动地为反编译结果增加语义信息，去除冗余变量，简化控制结构。与当前一流反编译器的结果相比，该技术能通过上述优化措施进一步提高反编译结果的可读性，辅助逆向分析人员理解二进制程序。用于软件技术和信息安全的基于大语言模型的计算机设备反编译结果优化方法，涉及软件逆向工程技术等。该方法通过优化措施提高反编译器结果的可读性，辅助逆分析人员理解二进制程序。 该方法自动为蚁编译结果添加语义信息，去除冗余变量，简化控制结构。该方法涉及通过与大型语言模型交互，得到反编译结果的优化解。 一个裁判角色根据裁判角色得到的优化解，得到一个具体的裁判测度。 将裁判角色与大语言模型进行交互，得到裁判测度。 运算符角色将由构建器角色获得的纠正措施应用于反编译结果。 算子角色检查函数语义是否被改变。 根据所述函数语义的变化确定是否接受所述整改措施。独立权利要求还包括用于：基于大语言模型的反编译结果优化系统； 以及计算机可读存储介质，其包括用于通过使用基于大型语言模型的计算机设备来优化反编译结果的指令集。  11
本公开公开了一种文档分类方法、装置及电子设备，涉及数据处理技术领域，尤其涉及一种文档分类方法、装置及电子设备。具体实现方案为：根据待识别文档获取图像块和词块；将所述图像块和词块输入预训练迁移模型，并获取视觉表示和文本表示；根据所述视觉表示和所述文本表示获取所述待识别文档的类别。本公开实施例通过提取待识别文档的视觉表示和文本表示，实现了文档中文本的分类。本公开实施例可以避免人工标注的不确定性，提高文档分类的准确度。用于在电子设备中对文档进行分类的方法(要求保护)。 用途包括但不限于智能电话、膝上型计算机、台式计算机、工作台、个人数字助理、服务器、刀片服务器、大型计算机、蜂窝电话和可穿戴设备。该方法使得能够提取出待识别文档的视觉表示和文本表示，实现了对文档中文本的分类，避免了人工标注的不确定性，提高了文档分类准确率。该方法包括根据待识别文档获取图像块和文字块。 根据所述图像块获取图像块特征向量。 根据位置信息获取所述字块的行信息和分段信息。 将所述图像块和所述词块输入预先训练的迁移模型，得到视觉表示和文本表示。 根据所述视觉表示和所述文本表示获取所述待识别文档的类别。还包括独立权利要求，用于：(1)一种用于在电子设备中对文档进行分类的设备； (2)一种用于存储指令集的非暂态计算机可读存储介质，所述指令集用于在电子设备中对文档进行分类； (3)一种计算机程序产品，包括用于在电子设备中对文档进行分类的指令集。 14
本发明涉及一种基于知识图谱补全的问答方法，属于自然语言处理领域，包括以下步骤：S1：将输入的Q划分为词或短语；S2：利用字向量模型BERT将词表征为向量，得到矩阵作为模型输入；S3：利用实体识别技术识别Q中的实体，获取候选实体集；S4：查询eKGs的类别，用c替换Q中的实体；S5：构建声明式查询cyher，获取候选三元组集，从而获取到候选关系集；S6：基于Qc和rij的关系链接；S7：在KGs中，如果eKGs和rij之间缺少关系；S8：学习实体eKGs和eKGs邻域内实体的新的向量表示；S9：估计中心实体邻域内实体的重要性；S10：基于现存的相关的三元组执行关系预测；S11：基于实体和关系的知识图推理，获得答案A。基于知识图谱补全的问答方法。使得能够基于知识图谱推理的实体和关系获得答案的方法。该方法涉及将输入的自然语言问题划分成单词或短语。 利用词向量模型(BERT)将词表示为向量。 得到矩阵作为模型输入。 利用实体识别技术在所述词中识别出实体单元格。 得到候选实体集合。 查询实体小区的类型。 在中心实体邻域中估计实体的重要性。 基于现有的相关性三元组来预测相关性。 基于知识图谱推理的实体和关系获得答案。  12
本发明提出了一种通过抑制非感兴趣信息的语义分割方法、设备及存储设备，本发明基于深度学习库优化神经网络，提高语义分割结果的精度，主要包括以下步骤：1)构建基础Unet模型；2)添加注意力机制；3)门特征图与当前层结果相乘；4)添加新输出结果和多损失函数；5)对待进行语义分割的图像进行图像语义分割。本方法可以提高语义分割神经网络的精度并有效抑制非感兴趣信息。一种通过抑制非兴趣信息实现语义分割的方法。本发明能够改进语义分割神经网络，准确有效地抑制非兴趣信息。该方法涉及基于深度学习库优化神经网络。 在最终输出处形成具有相同尺寸和特征图尺寸的卷积层。 输出目标结果以建立最终图像语义分割模型。 在模式语义分割模型中获取原始输出层结果，实现对生成的原始输出层结果进行优化和信息补偿。 获得用于形成训练组的图像和语义分割标签。 对最终的图像语义分割模型进行训练以获得用于对图像进行语义分割以获得语义分割图像的训练模型。本发明还涉及一种用于通过抑制非感兴趣信息来实现语义分割的装置。   4
本发明公开了一种基于大语言模型的取证系统及方法，涉及取证工具技术领域，包括：训练库、取证解决方案库、语言模型、问题库和取证脚本生成模块。本发明通过预先配置训练库，用于维护取证问题的解决方案，并进行根据训练库中的解决方案训练语言模型，将用户问题输入到训练好的语言模型中，生成对应的取证脚本，同时将生成取证脚本存入取证解决方案库，最后将生成的取证脚本输出给用户，解决取证问题，不仅能够根据用户输入的取证问题自动生成有效的取证脚本，而且通过维护用户问题和对应的解决方案，可帮助取证工具理解用户的问题，选择最适合的解决方案，从而生成有效的取证脚本，能更好地适应各种取证场景和需求。基于大型语言模型的取证系统，用于取证工具领域，例如硬件和基于特定软件的解决方案。该系统：能够根据用户输入的取证问题，自动生成有效的取证脚本； 通过维护用户问题和相应的解决方案，帮助取证工具了解用户的问题； 选择最合适的解，从而生成有效的取证脚本，能够更好地适应各种取证场景和要求； 使用预先配置的训练库，用于维护取证问题的解决方案。该系统包括训练库(1)、取证解决方案库(2)、语言模型(3)、问题库(4)和取证脚本生成模块(5)。 训练库，用于预先设定标准取证流程，根据取证问题生成解。 取证解决方案库，用于存储训练库根据取证问题生成解决方案，并为每个解决方案和对应的取证脚本设置链接。 所述语言模型用于获取取证问题。 问题库用于用户问题输入，并提取用户问题传输至语言模型。 取证脚本生成模块，用于根据当前用户问题和取证脚本确定的解决方案提取语言模型执行取证脚本。还包括独立权利要求一种基于大语言模型的取证方法。  11
本发明给出了一种针对人群活动性质判别的数据增强方法和系统，包括准备人群活动训练数据集、人群活动性质判别的预训练模型，用以生成热力图；从所述人群活动训练数据集中随机提取一个数据对，使用像素级线性混合增强策略，利用线性组合混合图像与标签；使用区域级仿射拼接增强策略，通过剪切粘贴操作拼接图像，根据面积比混合标签；通过强化类梯度激活可视化策略，提取输出类激活热图，执行图像二次混合增强与标签融合，形成以二次混合图像增强数据集，用以扩充原数据集。本申请有效、针对性地实现相关样本库扩充，其扩充流程与结果都可对人群活动性质判别算法产生明显积极影响。一种判断人群活动性质的数据增强方法。本发明通过应用模型有效地实现了相关样本库的扩展，明显地获得了对人群活动判断算法有积极影响的扩展过程和结果。该方法包括准备人群活动训练数据集。 通过预训练模型确定人群活动特性以生成热图。 从人群活动训练数据集中随机提取数据对。 通过使用像素级线性混合增强策略和线性组合来混合图像和标签。 根据面积比混合标签，采用区域级仿射拼接增强策略对图像进行裁剪粘贴拼接。 通过增强梯度激活可视化策略。 提取输出型激活热图像。 执行图像二次混合增强和标签融合处理以形成二次混合图像增强数据集，从而扩展原始数据集。本发明还涉及一种计算机可读存储介质，用于存储计算机程序，以执行用于判断人群活动特性的数据增强方法； (2)一种判断人群活动性质的数据增强系统。 14
本申请提供了一种预训练模型调整方法及装置、存储介质、计算设备，该预训练模型调整方法包括：获取初始样本，初始样本包括多个问答对，并计算每一问答对对应的句子嵌入，每一问答对包括问题和答案；利用各个问答对对应的句子嵌入对各个问答对进行聚类，以得到多个簇，每个簇包括多个点，每一点对应一个句子嵌入；在每个簇中按照与同一簇中其他点的最大距离选取多个点，以得到核心样本；利用核心样本对预训练模型进行训练调整。本申请能够在保证模型训练的效果的基础上，避免预训练模型对原有知识的遗忘，提升预训练模型的性能。调整预训练模型的方法。该预训练方法在保证模型训练效果的基础上，避免了预训练模型对原始知识的遗忘，提高了模型的性能。预训练模型调整方法包括获取初始样本。 初始样本中设置有多个问答对。 对应每个问题和答案对计算句子嵌入。 所述问题和答案对被提供有问题和答案。 利用所述句子嵌入对对应的问题和响应对对所述答案对进行聚类，得到多个聚类。 每个聚类包括多个点。 每个点对应第一个句子嵌入。 根据同一聚类中其他点的最大距离选取每个聚类中的多个点，得到一个核心样本。 利用核对预先训练的模型进行训练调整。独立权利要求包括用于：(1)调整预训练模型的装置； (2)一种计算机可读存储介质，其存储有用于实现所述预训练模型调整方法的指令； (3)具有处理器的计算设备。  11
本申请公开了一种融合上下文特征方面级情感分类方法和装置，对待预测方面级情感分析文本进行弱相关方面词静态屏蔽和分词处理，得到第一全局上下文，将其输入到构建的MHSA‑LCF模型，使得第一BERT嵌入层和第二BERT嵌入层分别提取第一全局上下文特征和第一局部上下文特征，局部特征学习层提取混合局部上下文特征，MHSA层提取第二全局上下文特征；交互学习层对第二全局上下文特征和混合局部上下文特征融合后的融合特征进行处理，最终输出层输出情感极性结果，解决了现有技术中忽略了方面词的局部上下文与方面词的强语义关联特性以及弱相关方面词对情感分类的干扰，使得情感极性预测存在准确率不高的技术问题。上下文特征方面级情感分类融合的方法。该方法解决了忽略了方面词的局部上下文和方面词的强语义相关性特征以及弱相关方面词对情感分类的干扰，使得情感极性预测准确率不高的问题。该方法涉及构建多头自注意力-局部上下文焦点(MHSA-LCF)模型。 第一全局上下文被输入到MHSA-LCF模型中，使得来自变换器(BERT)嵌入层和第二BERT嵌入层的第一双向编码器表示分别处理第一全局上下文，并输出第一全局上下文特征。 对所述待预测方面级情感分析文本进行静态屏蔽弱相关方面词和分词处理，得到第一全局上下文。包括独立权利要求用于具有模型构建单元的融合上下文特征方面级情感分类装置。  12
本发明提供了集成智能学习功能的设备使用与维修知识库，包括：知识库构建模块，用于基于两种知识存储方式对设备使用维修技术文档进行并行处理，并基于并行处理结果构建图数据库和向量数据库，得到设备运维知识库；知识库使用模块，用于基于用户提交的查询需求同时对设备运维知识库中的图数据库和向量数据库进行相似性搜索，并将相似性搜索结果输入至大语言模型进行处理，得到用户所需的目标数据；知识库更新模块，用于基于设备运维知识库使用的同时获取实时设备使用维修技术文档，并基于实时设备使用维修技术文档的获取类型采用差异更新流程对设备运维知识库进行迭代更新。保障了满足用户查询需求的全面性，提高了用户对设备使用维修的效果。集成智能学习功能的设备使用维护知识库。保证了用户查询需求的全面性，提高了用户使用维护设备的效果。该底座具有知识库构建模块，用于基于两种知识存储方式对设备使用维护技术文档进行并行处理，并基于并行处理结果构建图库和向量库，得到设备运维知识库。 知识库更新模块，用于基于实时设备使用维护技术文档的获取类型，基于设备运行维护知识库的使用情况获取实时设备使用维护技术文档，采用差分更新过程对设备运行维护知识库进行迭代更新。  11
本发明公开的一种基于自注意力的卒中患者表情识别方法及系统，包括：获取卒中患者表情数据集，构建基于ViT的表情识别模型，通过人脸表情数据集和所述卒中患者表情数据集对所述基于ViT的表情识别模型进行训练，通过训练好的基于ViT的表情识别模型识别卒中患者表情的类别。本发明通过构建基于ViT的表情识别模型，以人脸表情数据集作为输入进行预训练得到预训练模型后，再以卒中患者表情数据集增强后的数据集为输入对预训练模型进行训练，使得基于ViT的表情识别模型能够识别轻量级卒中患者表情。用于医学领域的基于自注意的中风患者表情识别方法。 也可用于计算机视觉，音频处理和生命科学。该方法能够建立基于VIT的表情识别模型， 选取人脸表情数据集作为预训练的输入，得到预训练模型； 以及选择由中风患者表情数据集增强的数据集作为输入来训练预训练模型，使得基于VIT的表情识别模型能够有效地识别中风患者的表情并限制中风患者的轻量化。该方法包括获得中风患者表情数据集。 建立基于VIT的表情识别模型。 基于VIT的表情识别模型由脸部表情数据集和中风患者表情数据集训练。 中风患者表情的类别由训练的基于VIT的表情识别模型识别。 获得中风患者的表情视频以获得每个表情的分段视频。 对分段视频执行图像处理操作以获得每个表达式的图像组。 其中图像组中的图像包括表情开始状态，表情结束状态和表情峰值状态。本发明还涉及一种基于自注意的中风患者表情识别系统。 2
本发明公开了一种数据打标签分类方法、装置、终端及存储介质，该方法包括：对已打标签文本进行预处理，分别生成词向量训练集和BERT语言训练集；分别通过所述词向量训练集对多种神经网络模型中的每种进行训练，且通过所述BERT语言训练集对BERT分类模型进行训练；根据训练结果确定融合模型；根据所述融合模型对目标数据进行打标签分类。本发明提供的数据打标签分类方法、装置、终端及存储介质，可以对海量数据进行打标签分类，提高了分类的准确性。数据-标签分类方法。该方法能够对海量数据进行标注，并提高分类准确率。该方法包括对标签文本进行预打孔，生成词向量训练集和BERT语言训练集。 通过所述词向量训练集对多个神经网络模型中的每个神经网络模型进行训练。 通过所述BERT语言训练集训练出BERT分类模型。 根据训练结果建立融合模型。 根据所述融合模型对目标数据进行标记。 对标签文本执行脱敏处理。 通过word2vec或glove训练模型对脱敏数据进行训练，用于得到所述词向量训练集。本发明还涉及一种数据标签分类装置，一种终端，包括处理器和存储器，用于对数据标签进行分类，一种计算机存储介质，用于存储一组用于对数据标签进行分类的指令。  12
本申请公开了一种模型训练方法、装置、电子设备及存储介质，涉及人工智能领域，具体为计算机视觉、深度学习技术，可用于图像识别方面，包括：对目标数据集进行特征提取训练，得到特征提取模型；所述目标数据集中的数据为标签数据；通过所述特征提取模型对无标签数据集进行特征提取，得到无标签数据特征；根据所述无标签数据特征训练预训练模型；对所述无标签数据集中的各个无标签数据进行数据裁剪，得到裁剪无标签数据集；根据所述裁剪无标签数据集对所述预训练模型进行优化训练，得到目标预训练模型；根据所述目标数据集对所述目标预训练模型进行训练，得到目标训练模型。本申请实施例能够提高模型在特定数据集的训练效率和识别精度。用于通过使用电子装置即计算机视觉和深度学习技术训练模型的方法(要求保护的)。该方法提高了特定数据集中目标预训练模型的训练效率和识别精度。该方法包括对目标数据集进行特征提取训练，得到特征提取模型。 通过所述特征提取模型对非标签数据集进行特征提取，得到非标签数据特征。 根据所述非标签数据特征训练预训练模型。 对所述非标签数据集合中的非标签数据进行数据切割，得到切割后的非标签数据集合。 根据所述切割非标签数据集对所述预训练模型进行优化训练，得到目标预训练模型。 对所述目标预训练模型进行训练，得到所述目标数据集。本发明还涉及一种用于训练模型的装置； 以及包括用于训练模型的指令集的非暂时性计算机可读存储介质。  11
本发明公开了一种基于细分产业知识分类和开源大模型的决策辅助问答方法，包括：1、构建产业知识分类方法；2、对多源异构数据进行分类以及分类知识向量化存储；3、分类辅助查询和知识的相似度匹配；4、将匹配的产业知识和决策辅助查询组合成prompt输入到多个开源大模型中并得到对应的决策辅助回答。本发明结合多种方法构建了细分产业知识分类方法，能利用更细粒度的产业知识来提升大模型决策辅助回答的效果，同时利用文本质量打分模型来对多个开源大模型的回答进行排序展示，充分发挥不同大模型的各自优势，从而提高决策辅助回答的合理性和准确性。计算机自然语言处理中基于细分行业知识分类和开源大模型的决策辅助问题回答方法。该方法结合多种方法构建细分的工业知识分类方法，能够利用粒度更细的工业知识，提高大模型决策辅助答案的效果。 该方法利用文本质量评分模型对多个开源大模型的答案进行排序展示，充分发挥了不同大模型各自的优势。 该方法提高了决策辅助答案的合理性和准确性。所述决策辅助问答方法包括利用jieba切分、jaccard相似度和Qwen-14B-chat大模型构建细分行业知识分类策略。 利用专家知识库构建细分产业链图谱。 将所述中文类别名称和所述中文类别名称的英文速记分别在所述细分产业链图中添加为细分行业类别词库，形成M维行业标签的类别词库。 将类别词库添加到杰巴分词词典中，并将每个行业标签标记为名词独立权利要求包括用于：(1)电子设备，包括处理器，用于基于计算机自然语言处理中的细分行业知识分类和开源大模型回答决策辅助问题； (2)一种计算机可读存储介质，所述计算机可读存储介质存储有用于实现所述计算机自然语言处理中基于细分行业知识分类和开源大模型的决策辅助问题答题方法的指令。  11
本发明涉及人工智能领域，公开了一种基于知识图谱的意图跳转方法、装置、设备及存储介质。所述基于知识图谱的意图跳转方法包括：基于预置产品数据及其对应的知识图谱、意图跳转业务规则，创建历史对话；提取历史对话中的多个实体信息，并基于知识图谱，依次创建与每个实体信息对应的元路径，得到元路径集；根据历史对话、元路径集对预置语言模型进行预训练，得到预训练模型，并调用该模型，获取待判断问题的有效信息，得到相应的有效字向量；基于待判断问题的有效字向量，对待判断问题进行意图识别，得到相应的意图；基于待判断问题的有效字向量，计算意图切换概率，若意图切换概率大于预置阈值，则跳转至相应的意图，从而提升意图切换的准确率。基于知识图谱的用户问题意图切换方法。该方法能够在意图切换概率大于预设阈值时，对待判断问题的意图进行切换，以提高意图切换的准确性。该方法包括获得元路径集合，其中元路径集合包括多个元路径。 所述元路径集用于根据历史对话训练预设语言模型。 得到预训练模型。 调用所述预训练模型。 获取待判断问题的有效信息。 获取所述待判断问题的有效词向量。 基于所述待判断问题的有效词向量识别所述待判断问题。 得到所述待判断意图。 基于所述待判断问题的有效词向量计算意图切换概率。 若所述意图切换概率大于预设阈值，则切换所述待判断问题的意图。包括如下独立权利要求：一种基于知识图谱的用户问题意图切换装置； 以及一种计算机可读存储介质，包括用于执行基于知识图谱的用户问题意图切换方法的指令。  11
本申请涉及语音语义领域，通过融合面试者注意力信息实现根据面试过程中的会话内容预测面试者感兴趣的内容，为面试者的发问给予提示。具体公开了一种面试提问提示方法、装置、计算机设备及存储介质，该方法包括：获取面试会话数据和面试语料数据以得到面试内容数据；提取面试者提问的面试问题文本以得到面试问题数据；基于BERT模型，根据面试内容数据计算面试内容数据对应的内容特征向量，根据面试问题数据计算对应的问题特征向量；根据内容特征向量和问题特征向量计算注意力特征向量；将注意力特征向量和内容特征向量拼接得到带有注意力信息的内容向量；根据内容向量和问题特征向量在面试内容数据中确定提示信息，以提示面试者提问。面试问题提示方法。该方法较好地实现了在面试过程中根据对话内容，对面试者感兴趣的内容进行提示。所述方法包括获取并处理采访会话数据和预设采访语料数据(S110)为一采访内容数据。 从所述会话数据中提取面试者提出的面试问题文本，并将所述面试问题文本处理为面试问题数据。 根据所述内容数据计算内容特征向量，并根据所述问题数据计算描述所述面试问题数据的问题特征向量，所述问题特征向量基于双向编码器从变压器表示模型。 根据内容/问题特征向量计算注意力特征向量。 将所述注意力/内容特征向量进行组合，得到带有注意力信息的内容向量。 根据所述内容和问题特征向量在所述面试内容数据中确定提示起止点。 根据所述提示起点和终点之间的文字输出提示信息，以提示面试者提问。包括以下独立权利要求：面试问题提示装置； 计算机设备； 以及存储有面试提问提示程序的计算机可读存储介质。 8
本发明涉及电商评论分析方法、系统及计算机可读存储介质，其电商评论分析方法包括：抓取电商平台的商品评论数据；对商品评论数据进行清洗，得到目标商品评论数据；利用电商评论观点分析模型对目标商品评论数据进行观点分析，得到每条评论文本的四元组信息，四元组信息包括属性词及其对应的属性类别、观点词、情感极性；具体利用BERT模型和BiLSTM模型进行编码，之后获取四元组信息。本发明采用基于BERT和BiLSTM编码相结合，先抽取属性词，然后基于属性词信息抽取观点词，并进行属性类别和情感极性的判别，实现了更细粒度的四元组(属性、观点、属性类别、情感极性)抽取，能更好地分析消费者对商品的观点和看法。电商平台中的电商评论分析方法。可以分析消费者对商品的观点和视图。该方法涉及捕获电商平台的商品评论数据(S1)。 对所述商品评论数据进行清洗(S2)。 获取所述目标商品评论数据。 利用所述电商商品评论数据的观点分析模型进行查看分析(S3)。 获取每个评论文本的四元组信息。 将所述目标商品评论数据输入所述BERT模型进行编码。 取BERT模型后四层向量的平均值作为BERT编码向量。 将所述BERT编码向量和所述BiLSTM编码向量进行拼接，得到所述句子编码向量。 基于所述语句编码向量对所述属性词进行提取，得到所述属性词。 基于所述属性词提取所述视点词。 预测所述属性类型和所述情感极性。 对评论文本的四元组信息进行统计分析，以进行可视化展示(S4)。独立权利要求还包括：用于分析电子商务评论的系统； 以及计算机可读存储介质具有用于分析电子商务评论的指令集。  12
本发明公开了一种基于改进ResU‑Net神经网络的MRI图像分割方法及系统，包括：获取待处理的MRI脑瘤图像，并进行预处理；将预处理后的图像输入到改进的ResU‑Net神经网络模型中，得到MRI脑瘤图像分割结果；其中，所述改进的ResU‑Net神经网络模型将ResU‑Net神经网络中的残差卷积模块改进为一个带有Transformer自注意力机制的模块，同时在ResU‑Net神经网络的编码器和解码器之间加入带有Transformer自注意力机制的扩张特征金字塔模块。本发明通过改进的ResU‑Net神经网络进行MRI脑瘤图像分割，可以获得更精确的脑瘤分割结果。基于改进的ResU-Net神经网络由用于治疗人体脑肿瘤诊断的终端设备(请求保护)分割MRI图像的方法。该方法通过改进ResU-Net神经网络进行MRI脑肿瘤图像分割，得到准确的脑肿瘤分割结果，从而得到准确的聚焦细节，并在ResU-Net神经网络的编码器和解码器之间加入具有自注意力机制的扩展特征金字塔模块，有效提高不同尺寸特征图有用信息的权重，从而提高肿瘤分割的准确性。该方法包括获得待处理的磁共振成像(MRI)脑肿瘤图像。 将预处理后的图像输入改进的ResU-Net神经网络模型，得到MRI脑肿瘤图像分割结果。 在ResU-Net神经网络模型的编码器和解码器之间加入具有自注意力机制的扩展特征金字塔模块。 所述自注意力机制设置有归一化层、卷积层、线性矫正函数层和自注意力机制模块。 每层扩展卷积的输出结果是在一个扩展卷积层的每层增加一个自关注模块之后增加的。包括独立权利要求：(1)基于改进的ResU-Net神经网络分割MRI图像的系统； (2)—种计算机可读存储介质，包括用于基于改进的ResU-Net神经网络分割MRI图像的指令集。  7
本发明公开了一种基于跨模态提示学习的视频问答方法与系统，本发明方法包括：针对示教视频提取视觉特征和文本特征，利用上下文查询注意力得到对应的跨模态输出特征；根据输出特征，利用视频答案区间高亮模块获取视频答案区间高亮特征并作为预训练的语言模型的视觉提示，通过预训练的语言模型基于文本问题、字幕以及视觉提示预测字幕跨度。本发明以高效准确从给定的未剪辑的示教视频中找到问题匹配的视频答案时间段区间，以视频答案时间段区间从语义上回答指定的文本问题为目标，利用视频答案区间高亮模块增强了预训练语言模型中的文本跨度定位，能显著提高视频分类和视频问答的准确率和效率，且适用于各类视频的分类与视频问答任务。用于在多模态系统中基于跨模式提示学习的视频问答的方法，其使用自然语言查询以促进自然语言与视觉世界例如图像和视频的交换。该视频问答方法提高了视频分类和视频问句的准确率和效率，增强了预训练语言模型中的文本跨度定位。该方法涉及提取所定位的教学视频的视觉特征。 针对位于所述视频中的视频的文本问题提取文本特征。 视频被划分为视频回答区间精彩部分和扩展部分。 根据查询上下文和所述文本特征中的词特征输出所述特征。 计算所述视频问题区间的精彩部分的特征。 对所述特征进行线性处理，得到视频问题序列中的精彩部分特征。 将视频答案序列精彩部分特征作为预先训练的语言模型的视觉提示，使得文本特征能够捕获视觉信息。 将所述视觉提示嵌入所述训练语言模型中。 通过所述预训练语言模型、字幕和视觉提示预测字幕跨度，基于所述文本问题预测字幕跨度。独立权利要求还包括：一种基于跨模式提示学习的视频问答系统； 以及一种计算机可读存储介质，包括用于基于跨模式提示学习的视频问答方法的指令集。 9
本发明属于自然语言处理技术领域，公开了一种基于注意力机制的问答匹配方法，上下文编码层将问题与答案句编码为词向量，注意力层从多角度进行信息提取，自注意力网络挖掘各文本的深层语义信息，交互注意力网络计算问题和答案间的关联特征，池化层对特征句子进行降维，聚合层聚合问答特征信息，预测层计算最终的问答匹配得分。本发明的问答匹配方法采用比较聚合框架，利用针对中文的预训练语言模型BERT‑base有效解决长距离依赖、一词多义等问题，结合多角度注意力，加强了问题和答案文本信息的关注，弥补了传统注意力不能有效获取问题与答案之间深层语义关系的缺陷，提高问答匹配的准确性。用于自然语言处理领域的基于注意力机制的问答匹配方法。方法：结合多角度注意； 加强了问题和答案文本信息的关注度； 弥补了传统注意力无法有效获取问题与答案之间的深度语义关系的缺陷； 并提高了问句匹配的准确性。该方法包括收集中文问答数据。 构建问答对语料。 对所述问答对语料进行所述数据预处理。 将预处理后的问句输入上下文编码层。 对所述向量表达式进行组合编码后得到带有上下文信息的问句的词向量表达式。 将所述问题句和所述答案句词向量分别输入至所述自注意力网络。 将所述问句和答案句词向量输入至所述交互式注意力网络。 输出分别输入到聚合层进行聚合。 将聚合特征矩阵输入池层。 利用余弦相似度计算问答的匹配分数。 利用最小均方差训练模型。  11
本发明公开了一种基于大语言模型解析流程挖掘PQL的方法和系统，涉及流程查询语言技术领域，所述基于大语言模型解析流程挖掘PQL的方法包括下述操作：S1、建立大语言模型；S2、知识库与解释准备；S3、PQL分析提示；S4、PQL语句解释；S5、局部高亮显示；S6、PQL语句微调。该基于大语言模型解析流程挖掘PQL的方法和系统，通过利用大语言模型对用户输入的PQL语句加以解析，并将其转换为易于理解的自然语言文本，以帮助用户快速理解PQL的具体含义，从而无需人工介入，通过反馈可读性高的自然语言解析结果，便于用户阅读理解的同时可降低用户对PQL语句的理解要求。基于大语言模型分析流挖掘流查询语言的方法。该方法使得能够利用大语言模型对用户输入的PQL语句进行分析，将PQL语句输入转换为易于理解的自然语言文本，帮助用户快速理解PQL的具体含义，从而无需人工干预。该方法涉及由用户选择PQL句子以将其输入到大型语言模型。 PQL句子由用户选择以将其输入到大语言模型。 基于所述PQL句子的分析结果确定PQL结构关系。 基于PQL结构关系，通过大级别模型在知识库中查找相应的解释。 由大模型返回句子的自然语言解释。 根据所述自然语言解释向所述较大语言模型发送调整指令。 基于一个PQLS语句和所述调整指令，生成满足用户特殊需求的微调PQL。本发明还公开了一种基于大语言模型分析流挖掘流查询语言的系统。  11
本发明涉及一种文本分词的方法及装置，方法包括：获取目标语料；基于预训练好的文本分词模型确定所述目标语料中目标位置的文本成词的可能性；其中，所述预训练好的文本分词模型基于目标词库中词的随机组合合成的训练语料训练得到，所述目标词库基于最大连接分词和回溯过滤法确定；基于所述目标位置的文本成词的可能性对目标语料进行分词。基于此，实现无需人工标注数据，且能够有效的切分行业领域新词。用于利用计算机设备进行文本分词处理的方法(权利要求)。该方法解决了现有技术中需要人工制作词典或大量标注数据，并对数据进行人工标注的问题，有效地对行业领域的新词进行切割，实现挖掘更多的新词形成目标词库，从而实现了低成本、有效地实现新词的挖掘，构建有效的目标词库，并基于训练语料实现对目标词库中的词进行随机组合合成。该方法涉及获得目标语料库(S110)。 基于预先训练的文本分词模型，确定文本在目标语言中的目标位置的成词可能性(S120)。 基于训练语言数据获得目标词库中的词的随机组合合成(S130)。 基于所述文本形成所述目标位置的词语的可能性，对所述目标语料进行分词。 基于预先训练的接受表达模型确定所述目标语料中各词或词组的第一表示向量。 基于预训练到记忆网络的键值和每个词或词组的第一表示向量，确定目标语料中每个词或词组的第二表示向量。独立权利要求包括：(1)一种用于利用计算机设备进行文本分词处理的装置； 以及(2)一种计算机可读存储介质，用于存储用于利用计算机设备执行文本分词处理的方法的指令集。  11
本发明提出一种基于改进U‑net的无人机海上溢油路径识别方法及装置，其中，方法包括利用无人机采集视频数据；从视频数据中获取预设数量的图像，对图像中的溢油像素进行标注，根据标注后的溢油像素生成溢油数据集；基于多尺度U‑Net语义分割算法，根据溢油数据集对预设的全卷积神经网络进行训练，得到溢油分割模型；根据溢油分割模型生成的溢油分割掩码进行导航信息提取，生成溢油区域拟合中点；对拟合中点进行曲线近似拟合，以完成溢油区域导航路径的识别。本申请提出的方法可以使无人机本身具有溢油监测航程远、费效比低、机动灵活等特性, 可运用无人机对海上重点溢油区域进行监测, 及时发现海上溢油状况，并且可以追溯到溢油发生的源头，以便及时处理。一种基于改进型U-NET的无人机海上溢油路径识别方法，采用计算机装置(要求保护)。无人机本身具有溢油监测航程，成本低，机动灵活等优点。 本发明可利用无人机对海上溢油区域进行监测，并可追溯到溢油的源头，以便及时处理。 利用U网语义分割算法，根据溢油数据集训练预置的全卷积神经网络模型，得到溢油分割模型。 该方法可使无人机飞行距离远，成本低，机动灵活。该方法包括使用无人机收集视频数据。 从视频数据中获得预定数量的图像。 在图像中标记溢油像素，以根据标记的溢油像素生成溢油数据集。 基于多尺度U-网语义分割算法训练预置的全卷积神经网络模型，得到溢油分割模型。 基于由漏油分割模型生成的漏油分割掩模来提取导航信息。 产生与中点吻合的溢油面积。 对拟合后的中点进行曲线逼近拟合，完成对漏油区航迹的识别。还包括独立的权利要求： 一种基于改进U型网的无人机海上溢油路径识别装置； 以及 一种非瞬态计算机可读存储介质，包括一组指令，用于基于改进的U形网识别无人机海上溢油路径。   6
本公开提供了一种伪造视频检测方法，包括：从视频中提取连续的帧序列，使用数据预处理方法处理帧序列，得到多个图像数据；使用图像特征提取器提取多个图像数据中的每个图像数据的特征，得到多个帧特征向量；将多个帧特征向量输入基于LSTM的帧特征融合模块中，得到融合后的视频级检测结果特征；以及将视频级检测结果特征输入分类器，得到用于确定视频是否为伪造视频的检测结果。此外，本公开还提供了一种用于实现该方法的电子设备和存储介质。检测假视频的方法。该方法充分利用了视频的丰富信息，具有较好的鲁棒性。 该方法所需训练资源少，同时避免了普遍存在的过拟合问题，实用性强。方法(100)包括从视频中提取(S110)连续帧序列。 采用数据预处理方法对所述帧序列进行处理，得到多个图像数据。 使用图像特征提取器(S120)对所述多个图像数据进行特征提取，以获得多个帧特征向量。 将帧特征向量输入(S130)到基于LSTM的帧特征融合模块中，以获得融合的视频级别的检测结果的特征。 将所述视频级别的检测结果特征输入(S140)至所述分类器，以获得用于确定所述视频是否为假视频的检测结果。以下包括独立权利要求：一种电子设备； 以及存储有用于检测假视频的程序的计算机可读存储介质。 9
一种基于对抗生成网络的视频编解码环路内滤波实现方法及系统，使用视频编解码算法编码并解码得到的视频作为训练数据，使用生成模型和辨别模型联合训练的方法训练一卷积神经网络并得到预训练模型，最后在视频编解码环路内使用所述预训练模型，在视频编解码算法的环路内对每一张重建视频帧进行图像质量恢复，有选择地使用输出图像更新原图像。本发明具有更强的鲁棒性和拓展性，能够处理视频压缩编码后的重建帧，比基于一般传统卷积神经网络的环路内滤波器图像恢复效果更接近原始图像，提升图像质量，进而提升视频压缩编码的效率。一种基于电阻生成网络的视频图像编解码环路滤波过程实现方法。本发明能够提高鲁棒性和扩展性，对编码后的重构视频帧进行处理，提高视频压缩编码的图像质量，图像滤波恢复效果和效率。该方法包括通过使用视频编码/解码算法将视频编码和解码为训练数据。 在训练过程中使用生成的模型和识别模型将卷积神经网络训练为预训练模型。 基于训练数据和预设网络结构优化卷积神经网络的参数，其中预设网络结构包括生成的模型和识别模型。 预训练模型用于视频编码/解码环路中。 通过使用视频编码/解码算法对重构的视频帧执行图像质量恢复处理。 选择输出图像以更新原始图像。本发明还涉及一种基于电阻产生网络的视频图像编解码环路滤波处理实现系统。 9
本发明公开了一种平行语料数据构建方法、装置、设备和存储介质，所述方法包括：获取目标领域的单语语料数据；将所述单语语料数据输入预训练模型，得到伪平行语料数据以及其对应的置信度；根据所述置信度在所述伪平行语料数据中确定所述目标领域的平行语料数据。本发明提高了平行语料数据的准确度和相关性，为翻译模型的训练提供大量的数据，以使训练得到的翻译模型具有更好的鲁棒性，提高翻译的准确性。并行语料数据的构建方法。该方法使得能够提高并行语料数据的准确性和相关性，为翻译模型的训练提供了大量的数据，使得训练得到的翻译模型具有更好的鲁棒性，提高了翻译的准确性。 该方法能够提高所选择的并行数据语言数据的准确性。该方法包括获得目标领域中的单语语言数据。 将单语言素材数据输入预训练模型中。 得到伪并行语料数据和对应的置信度。 根据所述置信度确定所述伪参数语料数据中所述目标领域的并行语料数据。 根据所述单语语言数据对应的置信度获取目标的伪酚语料数据。独立权利要求包括用于：(1)一种构建并行语料数据的装置； (2)并行语言数据构造装置; (3)一种计算机可读存储介质，用于存储构建并行语料数据的指令集合。  11
本发明属于自然语言处理技术领域，特别涉及一种基于内容选择和融合的两阶段摘要生成方法及系统，统计文档文本数据集，通过滑动窗口提取单句及相邻句子对，组成实例集合；依据参考摘要，选取实例集合中符合信息性和事实正确性要求的候选摘要实例作为样本数据来训练编码解码器模型；针对目标文档，通过滑动窗口提取由单句及相邻句子对组成的目标实例集合，并利用训练优化后的编码解码器模型生成目标文档的摘要信息。本发明从输入文本中提取单个句子和相邻若干个句子来组成实例集合，并利用微调的BERT分类器去选择具有高信息性和事实正确性的实例作为摘要候选通过编码解码器模型生成摘要句子，显著提高生成摘要的效率、可读性、简洁性和事实正确性。用于在例如数据挖掘、推荐系统和信息检索的自然语言处理领域中通过使用计算机设备(权利要求书)生成基于内容选择和融合的两级摘要的方法。该方法使得能够从输入文本中提取单句和多个相邻句子以形成实例集合，并使用精细调谐伯特分类器选择信息和事实正确性高的实例作为摘要候选通过代码解码器模型生成摘要句子，因此提高了生成摘要的效率、可读性、简单性和事实正确性。 该方法允许基于内容选择和融合的两阶段摘要生成方法，以提高生成的摘要可读性和大数据、人工智能等领域数据抽取摘要处理的便利性。该方法包括：统计文档文本数据集，通过滑动窗口提取单句和邻句对，形成实例集合，根据参考摘要，选择实例集合中符合信息和事实正确性要求的候选摘要实例作为样本数据训练编码解码器模型，针对目标文档，通过滑动窗口提取单句和邻句对组成的目标实例集合，利用训练优化的编码解码器模型生成目标文档的摘要信息。独立权利要求还包括：基于内容选择和融合的两级摘要生成系统； 以及计算机可读存储介质，其包括用于基于内容选择和融合来生成两级摘要的指令集。  11
本发明公开了一种利用新闻发布会视频制作包含戴口罩人脸的语音分离数据集的方法，该方法：把新闻发布会视频裁剪为图像、视频以及语音三个模态的数据集合，基于戴口罩检测预训练模型，获取到每一帧都戴口罩的画面，从而组成戴口罩的视频，以此为数据源，再基于感知哈希算法把视频关键帧与自定义人脸特征库进行比对，实现视频裁剪与分类的过程全自动。本发明通过利用自定义的人脸库裁剪新闻发布会视频中的多模态数据，提高构建包含戴口罩人脸的语音分离数据集的效率。一种语音分离数据集的制作方法。本发明利用自定义人脸库对新闻会议视频中的多模态数据进行切割，提高了构建包含掩模人脸的语音分离数据集的效率。该方法包括收集视频源和掩模图像。 构建自定义人脸特征库。 佩戴面罩的脸部视频全自动切割分类。 切割模态数据。 视频源具有视频流和语音流。 语音流和语音流彼此连接。 视频流与视频流连接。 9
本公开提供了一种视觉场景文本融合模型的预训练和图文检索方法及装置，涉及人工智能技术领域，具体涉及深度学习、图像处理和计算机视觉技术领域。具体实现方案为：获取样本图文对；提取样本图像中的样本场景文本；将样本文本输入文本编码网络，得到样本文本特征；将样本图像和初始的样本融合特征输入视觉编码子网络，以及将初始的样本融合特征和样本场景文本输入场景编码子网络，得到样本图像的全局图像特征和经学习的样本融合特征；根据样本文本特征、样本图像的全局图像特征和经学习的样本融合特征，对视觉场景文本融合模型进行预训练。通过上述技术方案，能够提高图文跨模态检索性能。预训练视觉场景文本融合模型的方法。该方法使得能够根据样本文本特征、样本图像的全局图像特征以及学习样本融合特征对视觉场景文本融合模型进行预训练，因此提高了图文跨模式搜索性能。该方法包括获取样本图像文本对(S101)，样本图像文本对包括样本图片和样本文本。 提取样本图片中的样本场景文本(S102)。 将样本文本输入i(S103)到文本编码网络中，得到样本文本特征。 将初始样本融合特征和样本图输入(S104)到场景编码子网络中。 获取样本的全局图像特征和学习样本融合特征(S105)。 根据样本特征、样本的全局图像特征和学习到的样本融合特征预先训练视觉场景文本融合模型。包含独立权利要求用于：(1)视觉场景文本融合模型训练方法； (2)一种视觉场景文本融合模型图文检索方法； (3)视觉场景文本融合模型预训练装置； (4)视觉场景文本融合模型训练装置； (5)一种视觉场景文本融合模型图文检索装置； (6)一种电子设备，包括处理器和存储器，用于预训练视觉场景文本融合模型； 以及(7)计算机程序产品具有用于预训练视觉场景文本融合模型的指令集。 14
本发明提出了一种基于异步分层图神经网络的法律文本多跳阅读理解方法，所述方法包括以下步骤：将法律文本进行分片，输入预训练模型中进行编码；通过Memory Attention的模块，对分片后的文本片段的嵌入向量进行全局信息的增强；在问题也送入编码层后，增强过的上下文信息和问题的嵌入向量将会进行双向的attention，得到上下文和问题双向编码向量；上下文和问题双向编码向量经过异步分层图网络多跳推理模块，在各层进行异步更新；通过多任务模块获得目标的答案和线索句子，以及整个推理路径。本发明提高了机器阅读理解问答算法在多步推理上的准确率，并提高了其推理链的可解释性，从而优化了机器阅读理解问答，对实现司法智能化有着非常重要的作用。基于异步分层图神经网络的合法文本多跳阅读理解方法。提高了机读理解问答算法对多步推理的准确性。 提升推理链的可解释性，优化机读理解与解答，对实现司法智能具有非常重要的作用。该方法包括对合法文本进行切片，并将合法文本输入至预训练模型进行编码。 文本编码模块的主要功能被配置为实现文本和编码器的问题得到表示向量，并作为下游任务的输入，更好地完成一个下游任务。 通过记忆注意力模块在分词后的文本片段的嵌入向量上增强全局信息。 将所述增强上下文信息和所述问题嵌入向量配置为进行双向关注，得到所述上下文问题双向编码向量。 通过多任务模块得到目标和线索语句的答案，以及整个推理的路径。 通过共享相同的上层任务和共享单独的下层任务来实现多任务联合训练，避免了针对不同任务的重复编码，提高了模型的效率。  12
本发明公开了一种结合视频与量表的疲劳检测方法、电子设备及存储介质，其方法包括：S1、构建表情识别模型采集民航待测人员在应答测评量表时的视频数据集；S2、构建疲劳程度识别模型并进行模型训练；S3、在应答测评量表从视频数据集提取文字数据构成量表，基于中文语言预训练模型从量表中提取词向量并利用文本数据样本集输出疲劳状态分值结果A；S4、将视频数据集输入疲劳程度识别模型中得到疲劳状态分值结果B，通过加权融合得到加权疲劳数据结果。本发明通过疲劳程度识别模型进行疲劳程度评测计算，然后与文字评测结果的加权融合得到加权疲劳数据结果，能得到与真实情况符合度高的疲劳状态分值结果。在国内航空公司用于民航人员疲劳检测的结合视频和仪表结合电子设备和存储介质的疲劳检测方法(均要求保护)。通过疲劳程度识别模型进行疲劳程度评价计算，并与人物评价结果进行加权融合，得到加权后的疲劳数据结果，能够得到与真实状况符合度较高的疲劳状态评分结果。该方法涉及构建表情识别模型，采集民航试验人员响应评价量表时的视频数据集。 应答评价量表包括多个应答项目。 将所述视频数据集按照所述应答项进行分段存储。 构建疲劳程度识别模型。 构建视频数据样本集，基于应答项对时间序列上的视频数据样本集进行稀疏采样，得到视频帧样本集，其中，I表示视频帧I，q表示应答项，K表示疲劳类型的标签和得分。独立权利要求包括：(1)一种电子设备； (2)存储介质。 9
本发明公开了一种基于模型特征信息增强的BERT模型融合方法，该方法首先对所有的原模型进行部分模型融合，生成对应的中间模型，这些中间模型包含了原模型的特征信息，对原有模型进行了增强。然后对原有模型和中间模型共同进行模型融合，生成最终的新模型本发明通过增强原模型的特征信息，使得融合后的新模型可以获取到更多原模型相关的特征信息，进而提高了融合后新模型的表现效果。相比于直接对原有模型进行融合，本方法通过引入中间模型对原有模型进行增强，可以有效地提升原模型的特征信息，进而提高融合后新模型的表现效果。一种基于模型特征信息增强的BERT模型融合方法。 使用包括但不限于图像和识别网络，自然语言处理网络和图像处理网络。该方法使中间模型和原始模型共同融合生成最终的新模型， 本发明增强了原模型的特征信息，使得新模型在融合后获得与原模型相关的特征信息，从而提高了新模型融合后的性能效果。 本发明通过引入中间模型对原始模型进行增强，能够有效改善原始模型的特征信息。该方法包括将原始模型分成多个不同的组。 将各组中的原始模型进行融合，生成相应的中间模型，中间模型具有更好的性能效果，增强了原始模型的特征信息。 联合融合中间模型和原始模型以生成最终的新模型，其中每个新模型中的知识包括原始模型中的知识，该知识增强了原始模型之间的相关性和原始模型的特征信息强度。  12
本发明公开了一种基于内置注意力机制的多域图像翻译模型，包括生成器：配置为带有内置注意力机制模块的生成器架构，用于将原图像经过生成器得到对应的生成图像，包括UNet网络和RCNN网络，用于将输入的原始图像经过编码阶段提取特征编码，再经过解码阶段将编码恢复到图像的结构以获取生成图像；鉴别器：配置有基于CNN的patch鉴别器，接收原图像和生成图像给出判断的概率结果本发明基于DCNN的新颖的生成器框架，融合了RRCNN、U‑Net以及Attention Gate等机制，可以消除跳跃连接中不相关的和有噪声的响应；本发明提供的多域图像翻译模型有助于加快学习速度，并为图像翻译任务提供更好的特征表示。基于内置注意力机制的多域图像平移模型，用于计算机视觉、图像处理和图像分割任务。 用途包括但不限于图像识别、图像分类、R2U-Net网络、长期递归卷积网络(LRCN)、inception递归残差卷积神经网络(IRRCNN)、生成对抗网络(GAN)和其他GAN。多域图像平移模型有利于加快学习速度，为图像平移任务提供改进的特征表示。 消除了跳跃连接中的不相关和噪声响应。 提高了模型的学习性能。 增强了模型集成上下文信息。该模型具有生成器，配置为生成器架构，内置注意力机制模块，用于将原始图像通过生成器得到对应的生成图像，并将原始图像和生成图像输入判别器。 判别器基于CNN配置补丁识别器以接收原始图像并生成判断生成图像的概率结果。 所述发电机具有第一发电机结构和第二发电机结构。 所述第一发电机和所述第二发电机相互连接。   6
本发明提供了基于多尺度特征融合的遥感图像显著目标检测方法、装置及系统，包括：对数据集中的图像进行预处理，获得所需训练数据；构建U‑net卷积神经网络模型：所述U‑net结构采用编码‑解码模式，且编码和解码之间添加3个3*3的卷积层作为桥接；编码部分与解码部分为对称结构；其中，编码部分由一个输入卷积层和六个卷积块组成，前四个卷积块采用ResNet34；利用获得的训练数据，对构建的U‑net卷积神经网络模型进行训练；将训练好的U‑net卷积神经网络模型用于遥感图像显著目标检测。本发明改进了U‑net的桥接环节，增添了多尺度融合方式，并使用多损失函数融合的模式对U‑net解码部分的各个边缘输出进行约束，同时对各个边缘输出进行融合，使得遥感目标的检测取得了显著提升。基于多尺度特征融合的遥感影像明显目标检测方法。该方法通过改进卷积神经网络模型的桥接，加入多尺度融合方式，利用多损失函数融合的方式限制U-net解码部分的边缘输出，并对边缘输出进行融合，使得遥感目标的检测得到明显的改善。该方法包括预处理数据集中的图像以获得所需的训练数据。 构建U-net卷积神经网络模型。 U-net结构采用编解码方式。 添加卷积层作为编码和解码部分之间的桥接。 对所述U-net卷积神经网络模型进行训练。 遥感图像显著目标检测过程由训练好的U-net卷积神经网络模型进行。 图像相关噪声干扰被去除。 扩增过程基于数据集进行。 进行梯度更新处理。独立权利要求还包括如下：一种基于多尺度特征融合的遥感图像明显目标检测装置； 以及存储有遥感图像明显目标检测指令集的计算机可读存储介质； 以及芯片，所述芯片包括存储器和处理器，所述处理器执行所述存储器中存储的用于检测遥感图像明显目标的指令。   6
本公开公开了一种信息推荐方法及装置、电子设备和存储介质，涉及计算机技术领域，尤其涉及人工智能技术领域。具体实现方案为：采用大模型对用户个性信息进行识别，生成并展示与所述用户个性信息对应的第一推荐语；在接收到针对所述第一推荐语的确认指令的情况下，展示与所述第一推荐语对应的推荐信息；根据与所述推荐信息对应的第一交互信息，确定并展示与所述推荐信息对应的延伸推荐信息。因此本公开可以提高信息推荐的准确性的同时提高信息推荐的满意度。用于向用户推荐信息的方法。该方法能够以高效的方式提高信息推荐的准确性和信息推荐的满意度。 该方法使得用户能够根据交互信息选择与推荐信息对应的扩展推荐信息，使得用户能够方便地选择与用户个体信息对应的推荐语言，从而有效地提高了用户使用电子设备的便利程度。该方法涉及通过使用大型模型来识别用户个体信息。 生成与所述用户个体信息对应的推荐语言并显示。 在接收到对所述推荐语种的确认指令时，显示与所述推荐语种对应的推荐信息。 根据交互信息确定与所述推荐信息对应的扩展名推荐信息并显示。还包括独立权利要求，用于：(1)向用户推荐信息的装置； 以及(2)一种电子设备，包括处理器和存储器，用于向用户推荐信息； 以及(3)非瞬时计算机可读存储介质，用于存储用于向用户推荐信息的计算机指令； 以及(4)包括用于向用户推荐信息的计算机程序的计算机程序产品。  11
本申请实施例属于人工智能领域，应用于智慧城市领域中，涉及一种语音交互下基于预训练模型的ASR纠错方法，包括当检测到播报用户的播报指令，则将所述播报指令发送到电话平台；发送给目标客户播报话术，并将目标客户的响应话术发送给ASR平台；当检测到所述ASR平台接收到所述响应话术，并进行文本转换，将转换得到的响应文本发送到NLP纠错平台进行文本纠错，在所述文本纠错结果为转换有误时，根据预设判别策略对所述响应文本进行判别处理，再将判别后得到的响应文本发送到所述NLP纠错平台，重复文本纠错的操作，直到所述文本纠错结果为转换无误，将与播报话术发送给所述目标客户，直到AI播报平台播报结束。采用本方法可大大提高播报话术的准确率。本发明公开了一种基于预训练模型的语音识别纠错方法，用于语音交互系统中的语音交互下的自动语音识别纠错。提高了广播电文的准确性。一种语音交互下基于预训练模型的自动语音识别纠错方法，包括：向电话平台发送广播指令； 根据广播指令指示人工智能(AI)广播平台生成广播消息发送到目标客户端， 向ASR平台发送目标客户端的响应语音； 指示ASR平台对响应语音进行文本转换； 将转换后的响应文本发送给自然语言处理(NLP)纠错平台， 获取文本修正结果，根据预设的判断策略对响应文本进行判断，将得到的响应文本发送给NLP修正平台，指示AI广播平台发送广播消息，重复获取目标客户端响应文本，文本转换和文本修正操作，直到AI广播平台广播结束。一种语音交互下基于预训练模型的自动语音识别纠错方法，包括：当检测到广播用户的广播指令时，向电话平台发送广播指令； 如果检测到电话平台与目标客户机之间的呼叫连接成功，则根据广播指令指示人工智能(AI)广播平台生成广播消息发送给目标客户机， 向ASR平台发送目标客户端的响应语音； 当检测到ASR平台接收到应答语音时，指示ASR平台根据预设的转换策略对应答语音进行文本转换； 将转换后的响应文本发送给自然语言处理(NLP)纠错平台进行文本纠错， 获得文本校正结果； 当文本纠错结果为转换错误时，根据预先设定的判断策略对响应文本进行判断， 将得到的响应文本发送给NLP修正平台， 重复进行文本纠错操作，直到文本纠错结果为转换错误， 当文本纠错结果为转换错误时，指示AI广播平台向目标客户端发送与响应呼叫对应的广播消息，重复获取目标客户端的响应文本，文本转换和文本纠错操作，直到AI广播平台广播结束。 语音交互系统包括电话平台，AI广播平台，ASR平台和NLP纠错平台。 广播指令用于指示电话平台实现与目标客户端的通信连接。 本发明还涉及一种基于语音交互下的预训练模型的ASR纠错装置。 8
本申请涉及一种基于预训练模型的图像描述生成方法、装置、设备和介质，所述方法包括：获取训练集，训练集包括原始图像以及原始图像对应的若干白话描述文本；构建图像描述预训练模型，图像描述预训练模型包括图像编码器、文本编码器、基于图像的文本编码器及基于图像的文本解码器；最后，基于预先构建的损失函数，对图像编码器、文本编码器、基于图像的文本编码器及基于图像的文本解码器进行训练，得到训练好的图像描述模型。本发明能够实现更好地捕获语义信息，提升了通过图像描述任务的连贯性和精度，降低了时间和计算成本。基于计算机视觉和自然语言处理人工智能领域使用的预训练模型生成图像描述，促进智能交互模式发展的方法。该方法能够更好地捕获语义信息，提高图像描述任务的连贯性和精度，降低时间和计算成本。所述方法包括：获取训练集，所述训练集包括原始图像和与所述原始图像对应的多个白语言描述文本。 构建图像描述预训练模型。 所述图像描述模型中设置有图像编码器、文本编码器和文本解码器。 文本编码器基于图像，文本解码器基于图像。 基于预先构建的损失函数对损失函数进行训练，得到训练后的图像描述训练模型。 将原始图像输入到图像解码器，并提取图像特征向量。 将所述白色描述文本输入所述文本编码。 生成所述自然语言文本，用于描述所述图像内容。包括独立权利要求，用于：(1)基于预训练模型生成图像描述的装置； (2)一种计算机设备，包括存储器和处理器，用于基于预训练模型生成图像描述； (3)一种计算机可读存储介质，用于存储基于预训练模型生成图像描述的一组指令。 14
本发明公开了一种基于弱监督的工业产品表面缺陷检测方法及装置，其方法包括获取待检测的工业产品的表面图像；将所述表面图像输入预构建的缺陷检测模型，获取缺陷检测结果；通过热力图呈现所述缺陷检测结果；其中，所述缺陷检测模型的构建过程包括：获取所述工业产品的表面图像，添加缺陷标签生成样本图像，并构建训练集和测试集；构建基于ResNet网络、DeepLab网络以及CBAM注意力机制模块的网络模型；通过ImageNet数据库对网络模型进行预训练，生成预训练模型；通过训练集对预训练模型进行训练，生成缺陷检测模型；通过测试集对缺陷检测模型进行性能测试，若性能满足预设要求，则缺陷检测模型构建完成；本发明能够在缺陷样本少的情况下，提升模型的检测准确性。使用电子设备(要求保护的)基于弱监督来检测工业产品的表面缺陷的方法。该方法能够在缺陷样本较少的情况下提高模型的检测精度。该方法包括获取待检测工业产品的表面图像。 将所述表面图像输入预先构建的缺陷检测模型，得到缺陷检测结果。 缺陷检测结果通过热谱图呈现。 基于ResNet网络、DeepLab网络和CBAM注意力机制模块构建网络模型。 通过ImageNet数据库生成预训练模型。 通过训练集训练缺陷检测模型。 通过测试集测试缺陷检测模型的性能。 缺陷检测模型构建完成。独立权利要求还包括：一种基于弱监督的工业产品表面缺陷检测装置； 以及计算机可读存储介质，所述计算机可读存储介质包括用于基于弱监督来检测工业产品的表面缺陷的指令集。 14
本发明涉及基于图注意力网络的多粒度汉越平行句对抽取方法，属于自然语言处理技术领域。本发明主要采用孪生神经网络作为主体框架将汉越双语共享在同一语义空间。首先，结合文档自身结构，将汉越文档划分为子词、句子、段落、文档这4个不同级别的粒度，构建不同层次的图网络结构，实现多粒度文档建模。然后，利用BERT进行编码，通过图注意力网络层得到不同粒度节点的特征表示，在图信息整合层进行融合表征。最后，利用全连接层训练分类器，计算两个句子平行的概率，抽取汉越平行句对。本发明能够缩小汉越句对的语言差异，有效地抽取出汉越平行句对，为神经机器翻译的发展提供强有力的支撑。本发明可用于基于图像注意力网络的多粒度中越并行句子对的提取。该方法减少了汉语超句对的语言差异； 有效地提取出更多的并行句子对； 为神经机器翻译的发展提供了有力的支持。一种基于图像关注网络的平行句对提取方法，包括：将汉语双语文档划分为子词； 句子， 段落， 文档4种不同级别的粒度， 并将其扩展成图形结构， 通过BERT编码层利用多语种BERT初始汉语双语词向量生成共享同一语义空间的词向量， 利用图像关注网络对节点间的信息进行建模， 通过自注意机制提取不同粒度节点间的相关特征权重， 对每个节点的特征信息进行特征化，通过将关注机制置于图像关注网络层，融合特征信息粒度，通过对神经网络分别对汉语和越语进行分类，得到句子相似度向量表示，训练分类器度量两个向量之间的相似度。  12
本发明公开了一种基于句法关系和意见词分布的细粒度情感分析方法。首先根据Bert模型构建了自己的词嵌入向量，目的是利用只利用Bert的语言模型功能。其次为了更好的提取句中的意见词分布，引入了依存句法分析，基于依存句法分析结果以及目标方面词，并结合邻近原则等原理提取出意见词分布。这样就能够将句中与方面词有直接或间接依赖关系的词提取出来，同时为了能够利用这一信息，本发明还将这一结果进行了向量化处理，称为分布向量。最后将这一向量与Bert输出的上下文向量进行特征融合，得到全新的情感特征向量，并进行情感预测。实验结果表明，本发明能很好解决方面词与意见词的匹配问题，并且能够深层次的提取到情感特征，具有很好的适应能力。基于句法关系和意见词分布的细砂情感分析方法本发明解决了词与意见词的匹配问题，能够深入提取情感特征，具有较好的适应能力。 本发明有效提高了情感分析方法的准确性。该方法包括根据输入语句构造初始化词嵌入向量和位置编码向量。 将初始化词嵌入向量和位置编码向量作为BERT预训练模型的输入，得到句子向量。 根据句子向量分析输入句子，以获得输入句子中单词的依赖关系。 根据已知的词和获得的依赖关系，提取与方面词直接相关的输入句子中的关键词和存储在设置键中的关键词。 根据设置的关键字中的关键字构造意见词分布向量。 使用用于特征变换的意见词分布向量来计算情感特征向量。 将情感特征向量输入分类器Softmax。 对目标词执行情感预测。  12
本发明涉及翻译技术领域，特别涉及一种多语言翻译模型构建方法及存储介质，多语言翻译模型构建方法是获取预训练编码器和预训练解码器并分别进行训练；构建多语言翻译模型，多语言翻译模型包括预训练编码器和多语言解码器，对其中预训练编码器添加编码融合转换器，多语言解码器包括语言模型流和翻译模型流；编码融合转换器使用随机初始化，语言模型流和翻译模型流均使用训练后的预训练解码器的参数进行初始化；获取第一双语数据，通过第一双语数据对编码融合转换器进行训练；获取第二双语数据，通过第二双语数据对翻译模型流进行微调。解决了翻译模型构建中微调导致的知识丢失和灾难性遗忘，以及降低了微调需要的双语语料的规模和语言对的数量。构建多语言翻译模型的方法。该方法能够解决翻译模型构建中由于精细调整而导致的知识丢失和灾难性遗忘问题，减少双语语言数据的规模和语言对数，提高预训练编码器的知识迁移能力和低资源语言的编码能力。该方法包括获得预训练编码器和预训练解码器。 构建多语言翻译模型。 所述多语言翻译模型设置有预训练编码器和多语言解码器。 所述预训练编码器添加有编码融合转换器。 多语言解码器设有语言模型流和翻译模型流。 编码融合转换器与随机初始化一起使用。 多语言解码器中的语言模型流和翻译模型流使用预训练解码器的训练参数进行初始化。 获得第一双语数据。 通过所述第一双语数据对所述编码融合转换器进行训练。 获得第二双语数据。 通过所述第二双语数据微调翻译模型流。包括用于计算机可读存储介质的独立权利要求。  11
本发明为一种食品安全领域文本的关系分类方法，一种食品安全领域文本的关系分类方法，包括以下步骤：S10：对输入文本进行预处理后，通过BERT词嵌入模型获取语言编码信息；S20：通过位置信息和词语的关联度构建实体的语义信息；S30：构建句子的语义信息；S40：将所有的特征信息融合输入到下游网络MLP模型中，进行关系分类。本发明所述的一种食品安全领域文本的关系分类方法，添加实体对语义信息和句子语义信息的方法，用于进一步提升食品安全文本关系分类的性能。食品安全领域文本的关系分类方法。该方法使得能够增加实体的语义信息和句子语义信息，用于提高食品安全领域中对文本的关系进行分类的性能。该方法包括预处理输入文本。 通过BERT词嵌入模型获取语言编码信息。 通过位置信息与词的关联度构建实体的语义信息。 构建所述句子的语义信息。 将所述特征信息融合后输入下游网络MLP模型进行关系分类。  12
本发明提出了一种基于科技政策的资源分类筛选方法和系统。其中，方法包括选取获取初始科技政策文本，进行人工标注，对经过人工标注的科技政策文本进行清洗，得到精简的科学政策文本；对精简的文本进行关键词提取，将提取到的关键词拼接在精简的文本标题后面作为训练文本形成数据集；使用数据集中的训练集对BERT模型训练，然后使用所述测试集对训练好的模型进行测试，并根据实验结果对模型进行优化和改进，提供用户检索界面。此方法对应的系统包括获取初始文本模块、人工标注并清洗模块、形成数据集模块和模型训练模块，通过此方法和系统，可以为用户检索出较为精准和重要的科技政策文本。基于技术政策的资源分类筛选方法。该方法能够根据实验结果对模型进行优化改进，并提供用户检索界面。 该方法通过用户选择获取科技政策初始文本，进行人工标注，对人工标注后的科技政策进行清洗，并提取出简化文本的关键词，将提取出的关键词拼接在一个简化文本标题后作为训练文本构成数据集，并利用测试集对训练好的模型进行测试，从而可以根据实验结果对模型进行优化改进。该方法包括获取待处理的技术政策内容文本。 提供所述待处理的技术政策内容文本的人工标注界面，对所述人工标注的技术政策文本进行清洗，得到确定分类维度后的简化科学政策文本。 对简化后的技术政策文本进行关键词提取，将提取的关键词在简化后的技术政策文本标题后面进行拼接，形成数据集作为训练文本。 计算模型的分类准确率、精度和召回率，用于根据实验结果对模型进行优化改进，并根据优化后的模型提供用户检索界面。基于技术政策的资源分类筛选系统包括独立权利要求。  11
本发明公开了一种基于FSM多轮问答的语义相似度计算方法，利用基于FSM多轮问答的语义相似度计算方法，根据用户输入问题，将其和知识库问答对数据带入到Transformer DSSM语义相似度计算模型中进行多轮匹配，并返回候选答案给用户，解决传统的客服系统在面对服务峰值人数不足，低谷人数不足的情况下，往往会消耗大量人力资源的问题，并提高用户获取相关领域中常见问题的答案的效率。基于FSM的多轮问句语义相似度计算方法。当用户需要返回的答案时，问答过程结束。 通过将输入数据转换为词向量表示的三维数组，解决了数据和知识库问题耗费大量人力资源的问题，提高了用户获取通用问题答案中相关字段的效率。该方法涉及通过用于添加深度状态空间模型(DSSM)语义的计算模型来匹配有限状态机(FSM)多轮问题。 将DSSM表示层的双向RNN模型改为AC-DC并行处理输入数据，加快模型训练和计算速度。 DSSM模型根据知识库的数据进行训练。 将候选答案返回给用户。 当用户需要返回的答案时，问答过程结束。 输入数据被转换成由词向量表示的三维阵列。包括基于FSM的多轮问题语义相似度计算系统的独立权利要求。 8
本申请公开了一种适用于Revit BIM模型的Web端轻量化展示方法，包括：基于Revit BIM模型内容设定转换文件格式内容；基于所设定的格式内容，采用深度八叉树法将模型内容生成LOD(层次细节)数据；上传变换后的模型LOD数据至服务器，使用数据库存储外围数据；采用JavaScript解析变换后的LOD数据，并在Web端显示以展示。有益效果：本申请实现了模型的自定义转换，特别是二进制格式，可有效的降低转换后模型数据的尺寸，方便存储和网络传输，实现了LOD，可支持超大模型的Web端展示。基于Revit BIM模型的web端轻量级展示方法。该方法能够实现模型与二进制格式的自定义转换，从而有效减小转换后模型数据的大小。 该方法能够实现方便的存储和网络传输，以支持超级模型的web端展示。该方法包括基于Revit建筑信息建模(BIM)模型内容来设置转换文件格式内容。 利用深度八叉树处理来基于设定格式内容生成链接开放数据(LOD)。 将变换后的LOD数据上传至服务器。 数据库用于存储外围数据。 利用JavaScript(RTM：Netscape-developed object scripting language)对转换后的LOD数据进行解析，并在web端显示。 定义场景数据、几何数据、材料数据、物体数据和用户数据。  12
本发明公开了一种基于图像分割和生成对抗网络的人脸属性迁移方法，包括以下步骤：设置人脸属性迁移的基本网络框架，设置网络的基本参数；利用CelebA数据集对U‑Net人脸图像分割模型进行训练；利用训练好的U‑Net网络分割人脸图像，将需要迁移的人脸属性从源图像中分割出来，融合到目标人脸图像；将目标图像和融合的图像输入到生成对抗网络，使得融合的图像符合目标图像的风格；利用基于Haar特征级联分类器识别人脸区域，并进行人脸属性迁移。本发明提出了人脸属性迁移方法可以将多种人脸属性迁移到目标人脸图像，并通过生成对抗学习让迁移替换的部分更平滑，减少割裂感，能够获得更加逼真的人脸图像。一种基于图像分割的人脸属性迁移方法，用于图像合成，图像编辑，风格迁移，图像超分辨率和图像转换。本发明能够将多种人脸属性转移到目标图像人脸，并生成反学习，使转移替换的部分更加平滑，减少切割感，获得更加逼真的人脸图像。该方法涉及通过使用训练好的U-网网络来分割人脸图像。 将要从源图像迁移的人脸属性被从源图像划分为目标图像人脸。 训练U-Net网络用于使用数据集中的每个图像对人脸属性得到K×K×7的判断结果矩阵。 根据人面对像素点的属性设置与像素点对应的像素点。 利用Haar特征级联分类器来识别人脸区域。 切割人脸区域。 将长度和宽度改变为k×k的图像。 提取所提取的图像。 2
本发明公开了一种基于知识图谱的数据建模方法，涉及数据建模技术领域，包括以下步骤：以自然语言处理(NLP)数据库为知识图谱的扩展核心，以NLP算法库内的算法为数据扩展运算方式，通过中文语言模型ERNIE作为自然语言数据翻译模型，利用图神经网络技术构建自然语言数据模型。本发明的优势在于：通过多层级对自然语言数据进行解译，并在NLP数据库的基础上进行深度学习，以NLP数据库内部的各个常规数据为基础进行数据扩展和沉淀，对每个数据进行数据模型的构建，同时通过神经网络对构建的模型进行多维度的分析，形成完善的自然语言知识图谱，通过知识图谱能够快速的对多样的自然语言数据进行快速的反应，降低对自然语言处理的运算量。基于用于对自然语言进行建模的知识图谱对数据进行建模的方法。 用途包括但不限于机器学习、计算机视觉、语音识别等。通过神经网络对构建的模型进行多维度分析，形成完善的自然语言知识图谱，该知识图谱能够快速对各种自然语言数据进行快速反应，减少了自然语言处理的计算量。该方法涉及使用自然语言处理(NLP)数据库作为知识地图的扩展核心。 NLP数据库连接有云服务器。 自然语言数据是通过图神经网络技术预先进行的。 将预演化的数据参数导入NLP算法库，以通过NLP算法对自然语言数据进行操作。 得到与计算得到的数据结果映射的NLP数据作为标准存储对应的数据。 循环构建不同的自然语言数据模型。 连续地存放自然语言模型。 形成所述自然语言数据模型的知识图谱。  11
本发明属于自然语言处理领域，涉及一种基于多任务学习的方面情感分析模型。包括：方面类别检测模块和方面级情感分析模块；将两部分进行聚合得到最终的方面类别情感分析结果；所述的方面类别检测模块依次包括处理数据的ACD嵌入层、双向长短期记忆网络层、自注意力机制层面和方面类别预测层；所述的方面级情感分析模块依次包括处理数据的ACSA嵌入层、多层Bi‑LSTM、单词情绪预测层和方面类别情绪预测层。有益效果：本发明提出了一种引入辅助任务方面类别检测ACD来进行ACSA任务的神经网络模型。结合两者模型的优势，并在公开数据集上，得到很好的性能。通过利用任务之间的共性和差异来提高性能，多任务学习已经成功的运用到深度学习任务中。基于多任务学习操作的ACSA模型。该模型采用神经网络模型实现辅助任务ACD操作执行ACSA任务， 结合两种模型的作用，提高了对公共数据集的性能，从而通过挖掘深度学习任务之间的通用性和差异性，成功地实现了深度学习任务时的多任务学习操作。该模型具有一个方面类检测(ACD)模块和一个ACSA模块，用于将两个部分聚集以获得最终的ACSA结果， 其中，ACD模块依次具有用于处理数据的ACD嵌入层，BI-LSTM网络层，自注意机制层和方面类别预测层。 所述ACSA模块依次设有用于处理数据的ACSA嵌入层，多层BI-LSTM，词语情感预测层和方面类情感预测层。  12
本发明公开了基于Bert字模型的数据表分类方法、装置及介质，属于文本信息挖掘技术领域，要解决的技术问题为如何高效的对医疗系统中元数据表进行准确归类。方法包括：对于元数据表中非中文的字段以及值域小于预设值的字段，基于预设的判别规则对字段进行内容类型判断，得到字段类型，所述预设的判别规则为基于历史元数据表中字段的内容配置的，用于基于字段的内容对字段进行类别判断；对于元数据表中值域等于或大于预设值的字段字段，通过Bert字模型对字段内容进行类别判断，得到字段类型以及字段属于各个类型的概率；基于元数据表中字段内容的所属类别，判断元数据表的所属类别。该方法包括：根据预设的判断规则判断字段的内容类型。 所述预设判断规则是基于所述字段的内容在历史元数据表中配置的。 根据所述字段的内容判断所述字段的类型。 通过Bert词模型判断所述字段内容的类型。 所述字段类型和所述字段是对应于每种类型的概率得到的。 根据所述元数据表中的字段内容的类别判断所述元数据表的类别。  12
本公开提供了一种信息识别方法、装置、电子设备、存储介质及计算机程序产品，涉及人工智能技术领域，可应用于金融领域或其他领域。该信息识别方法包括：对文本进行特征提取，得到包含第一事件主体和第一事件主体类别的第一特征向量；使用预训练模型对文本进行特征提取，得到包含第二事件主体和第二事件主体类别的第二特征向量；利用全连接神经网络依据第一特征向量和第二特征向量得到针对文本的第一命名实体识别结果。用于在人工智能领域中通过用于金融目的的电子设备(要求保护)识别信息的方法。 使用包括但不限于智能手机，平板电脑，膝上型便携式计算机和台式计算机。该方法包括提取文本的特征，并获得包含事件主体和第一事件主体类型的特征向量，因此确保了简单有效的信息识别方法。所述方法(200)涉及提取文本的特征，并且获得包含第一事件主体和第一事件主体类型的第一特征向量(S210)。 使用预训练模型来对文本进行特征提取，以获得包含第二事件主体和第二事件主体类型的第二特征向量(S220)。 通过全连接神经网络根据第一特征向量和第二特征向量获得(S230)第一命名实体识别文本。还包括独立的权利要求： 信息识别装置； 一种计算机可读存储介质，包括一组用于通过电子设备识别信息的指令； 以及 一种计算机程序产品，包括一组用于通过电子设备识别信息的指令。  11
本发明涉及基层治理中大数据处理技术领域，特别涉及一种基于大模型的基层治理业务辅助处理方法和系统，基于大模型构建基层治理业务事件模型，并将该基层治理事件模型部署至内网环境中，以使基层治理业务系统与该基层治理事件模型进行数据交互；利用已标注标签的事件数据并基于模型训练周期对基层治理业务事件模型进行自动化训练，其中，模型训练周期为预先配置训练时间间隔；针对待处理业务事件请求，利用基层治理业务事件模型在模型已训练范围内进行分析检索，以获取业务事件请求所对应的事件类型。本发明基于大模型来对上报的各类事件问题进行分类，以辅助基层工作人员相关事件的处理工作，提升城市治理效率和事件处理满意度。利用电子设备在城市管理、管理和运营中处理基于大模型的基层管理服务辅助的方法(权利要求书)。该方法基于大模型对上报的各类事件问题进行分类，以辅助基层工作人员相关事件的处理工作，提高城市待遇效率和事件处理满意度。该方法包括基于大模型构建基层治理服务事件模型。 所述基层治理服务事件模型部署在内部网络环境中进行数据交互。 自动训练模型训练周期，所述模型训练周期处于预先配置的训练时间间隔内。 对服务事件请求进行处理。 在训练好的范围内对模型训练周期进行分析搜索，得到服务事件请求对应的事件类型。 对基础管理事件模型进行训练，以进行所述内网环境下的数据交互。独立权利要求包括用于：利用电子装置处理城市管理、管理和运营中基于大模型的基层管理服务辅助的装置； 一种计算机可读存储介质，具有利用电子设备处理城市管理、管理和运营中基于大模型的基础层管理服务辅助的指令集  11
本发明公开了一种上下文感知的渐进式注意的视频问答方法与系统。包括：通过构建特征编码单元提取视频中的特征信息，构建上下文感知单元，采用三个注意模块进行多模块融合与对齐，构建模型训练单元进行模型训练，生成答案预测分数，最后输入目标视频，获得预测答案。本发明通过构建三个单元提取多模态特征，通过注意力机制来渐进式的融合视频中与问题相关的多模态信息，利用BiLSTM网络来构建多模态之间的上下文信息，利用注意力机制来得到与问题最相关的多模态信息，利用BiLSTM网络来更新记忆单元中的多模态信息，最后利用Softmax函数来预测答案，由此来提高视频问答模型的性能和准确定位能力。用于在视频描述任务中相对于概要描述的视频描述之后的细粒度的视频理解任务中使用的上下文感知的渐进注意力视频问答方法和系统。通过使用双向循环网络网络更新记忆单元中的多模信息和使用softmax函数预测答案，可以提高视频问答模型的性能和准确定位能力。该方法包括构建特征编码单元，输入视频问题相关数据集，输出视频中的静态特征、动态特征、问题文本特征和字幕文本特征。 构建上下文感知单元，输入为所述静态特征、所述动态特征、所述问题文本特征和所述字幕文本特征，输出对应于所述多模态上下文增强特征。 构建模型训练单元，输入为所述多模式上下文增强特征，采用交叉熵损失函数进行训练，得到所述预训练模型。 构建答案预测，将所述目标问答视频输入所述预训练模型，输出对应的答案预测信息。对于逐渐关注上下文感知的视频问答系统，包括独立的声明。 9
本公开提供了模型训练方法、数据分类分级方法、装置、设备及介质，涉及人工智能技术领域，尤其涉及神经网络、大数据、数据安全以及数据分类分级技术领域。具体实现方案为：获取原始训练样本集，利用提示学习模板在原始训练样本基础上拼接包含掩码的用于询问样本数据的类别信息和级别信息的提示信息，得到目标训练样本集，将目标训练样本集输入至分类分级模型中，根据预训练模型和分类器的输出、分类分级标签以及与分类分级标签存在预设映射关系的提示标签确定目标损失关系，并根据目标损失关系对提示学习模板和分类分级模型进行训练。通过采用上述方案，能够得到准确率高、泛化性强以及通用性强的分类分级模型。用于训练生产环境中的分类模型的方法。该方法使得能够得到准确率高、泛化性强、通用性强的分类分类模型。该方法涉及获得(S101)原始训练样本集，其中原始训练样本被提供有与样本数据相对应的样本特征信息。 所述提示学习模板在设置有提示消息掩码的原始训练样本库拼接上使用(S102)。 所述提示消息用于查询所述类型信息和等级信息的样本数据。 将目标训练样本集输入(S103)到分类模型中。 所述分类分类模型设置有预训练模型和分类器，并根据所述预训练模型和所述分类器输出。 将所述分类分类标签和所述提示标签确定所述目标损失关系。 根据所述目标损失关系对所述提示学习模板和所述分类分类模型进行训练(S104)。 所述分类分类标签与所述提示标签具有预设映射关系。包括以下独立权利要求：数据分类方法； 分类模型的训练装置； 数据分类装置； 以及电子设备。  11
本公开公开了一种对话理解及模型的训练方法、装置、设备和存储介质，涉及计算机技术领域，具体涉及自然语言处理、深度学习等人工智能技术领域。对话理解模型的训练方法包括：获取对话理解训练数据；采用所述对话理解训练数据，进行对话理解预训练任务和通用预训练任务的联合训练，以得到对话理解模型。本公开可以训练得到专门适配对话理解任务的模型。该方法对于通过使用电子设备(要求保护的)训练对话理解模型是有用的。方法：训练得到对话理解任务专用模型。训练对话理解模型包括：获取对话理解度训练数据; 对对话进行预训练任务和通用预训练任务的联合训练，得到对话理解模型; 利用对话理解训练数据，得到对话理解度训练数据; 利用对话的预训练任务和通用预训练任务，得到对话理解度训练数据。独立权利要求还包括：对话理解模型训练装置； 存储计算机指令的非暂时性计算机可读存储介质，所述计算机指令包括用于训练对话理解模型的指令集； 以及计算机程序产品 8
本发明提供的一种基于大模型的数字读音判别校验方法及系统，所述判别校验方法包括：输入人工标注数据；采用prompt+大模型进行数据增强，获得数据集；将所述数据集划分为训练集、测试集；采用LoRA方法对大模型进行有监督微调；大模型评估优化。不仅有效提高了数字读音的准确率，而且需要的高质量的带标签的训练数据量很少，就能够达到很好的效果，有效节省了大量的人力标注资源。基于大模型的数字发音判别验证方法。该方法有效地提高了数字发音的准确性，需要少量的带有高质量标签的训练数据即可达到良好的效果，有效地节省了大量的人力标注资源。数字发音判别验证方法涉及输入人工标记数据。 采用Inpost Plus大型模型进行数据增强，得到数据集。 数据集分为训练集和测试集。 采用长程(LoRA)方法对大模型进行微调。 对大模型进行评估和优化。本发明还公开了一种基于大模型的数字发音判别验证系统。 3
本公开公开了用于生成模型和用于识别年龄和性别的方法、装置、设备、存储介质、程序产品，涉及人工智能技术领域，具体为深度学习及图像识别技术领域。具体实现方案为：从预设的基础网络结构模块集合中选择网络结构模块构建至少一个候选模型；对于至少一个候选模型中每个候选模型，利用数据规模小于第一阈值的至少一种训练样本集中每种训练样本集对该候选模型进行训练，得到该候选模型针对不同训练样本集的预训练模型；根据每个候选模型针对不同训练样本集的预训练模型的性能为每个候选模型打分；利用数据规模大于第二阈值的训练样本集对打分最高的候选模型重新训练，得到年龄和性别识别模型。该实施方式能够通过一种模型同时分析年龄和性别。生成人脸检测模型的方法。该方法可以通过一个模型同时分析年龄和性别。方法(200)包括从基本网络结构模块的预设集合中选择(201)网络结构模块以构建候选模型。 获取数据量小于第一阈值的训练样本集(202)。 使用(203)所述训练样本集中的训练样本集对所述候选模型进行训练，以针对所述候选模型中的每个候选模型，针对不同的训练样本集，得到所述候选模型的预训练模型。 根据每个候选模型的预训练模型针对不同训练样本集的性能，对候选模型进行评分(204)。 利用数据量大于第二阈值的训练样本集对所述得分最高的候选模型进行重新训练(205)，得到年龄性别识别模型。 所述第二阈值大于所述第一阈值。包括以下独立权利要求：用于识别年龄和性别的方法； 人脸检测模型生成装置； 用于识别年龄和性别的装置； 电子设备； 存储用于生成人脸检测模型的程序的非暂态计算机可读存储介质； 以及用于生成人脸检测模型的计算机程序产品。 14
本公开提供了生成式大语言模型训练方法、基于模型的人机语音交互方法，涉及生成式模型、智能语音、人机交互等人工智能技术领域。该方法包括：基于用户输入文本与匹配的服务接口调用序列，构建第一训练集；利用第一训练集对预训练好的第一生成式大语言模型进行有监督微调训练，得到第二生成式大语言模型；基于相同用户输入文本与不同候选输出之间的用户偏好排序和预设模板集合，构建第二训练集；利用第二训练集对预训练好的第三生成式大语言模型进行有监督训练，得到奖励模型；将第二生成式大语言模型，基于奖励模型返回的得分，以强化学习方式进行训练。利用据此训练得到的生成式大语言模型可显著提升人机语音交互场景下的回复准确率和用户体验。生成式大语言模型训练方法。该方法利用提供专业能力的应用程序接口调用相应的函数，返回的结果更加符合用户的实际需求和预期，能够显著提高人机交互场景下的回复准确性和用户体验。该方法涉及基于用户输入文本和匹配的服务接口调用序列来构建(201)第一训练集。 利用(202)所述第一训练集对所述预先训练的第一生成大语言模型进行有监督微调训练，以获得第二生成大语言模型。 基于用户偏好排序和相同用户输入文本与不同候选输出之间的预设模板集来构建(203)所述第二训练集。 使用(204)所述第二训练集对所述预先训练的第三生成大语言模型进行监督训练，以获得奖励模型。 基于所述奖励模型返回的得分以强化学习方式训练(205)所述第二生成大语言模型，以获得目标生成大语言模型。以下包括独立权利要求：1。 一种基于生成大语言模型的人机语音交互方法； 2. 生成大语言模型训练装置； 3. 一种基于生成大语言模型的人机语音交互装置； 4. 电子设备； 5. 存储用于实现所述生成大语言模型训练方法的程序的非暂态计算机可读存储介质； 以及6。 一种用于训练生成式大语言模型的计算机程序产品。 8
本发明提供了一种使用CodeT5模型和提示微调的源代码漏洞检测方法，属于计算机技术领域，解决了传统的漏洞检测模型中检测准确率不高的技术问题。包括以下步骤：S1：从中收集开源项目的C和C++源代码，构成数据集；S2：对数据集进行预处理；S3：对构建的数据集随机划分成训练集、验证集和测试集；S4：使用hard soft方式创建为漏洞检测任务定制的提示模板；S5：创建为漏洞检测任务定制的Verbalizer；S6：训练集训练分类器；S7：对测试集进行最终结果预测。本发明的有益效果为：使用基于提示微调的预训练模型CodeT5进行漏洞检测，从而提高漏洞检测的性能。利用codeT5模型进行源代码漏洞检测并及时微调的方法。该方法使得能够使用基于即时微调的预训练模型codeT5进行漏洞检测，以提高漏洞检测性能。该方法是利用GitHub、CVE和NVD库中的爬行类程序收集所需开源项目的C、C++(面向对象的编程语言)源代码，对其进行预处理，构建漏洞数据集D1。 D1的格式为项目名称、提交id、函数、标签、数据集id，划分所述步骤1.1中收集的数据集，按照80-10%：10-10%的比例随机划分训练集、验证集和测试集。 创建以硬软方式为漏洞检测任务定制的提示模板。 创建所述语言器以执行所述漏洞检测任务。 训练集是利用CodeT5模型，提取模型输入部分的语义特征值，利用t-SNE处理语义向量，提取关键特征并通过非线性降维技术进行降维训练的。 通过训练集训练MLP分类器。  11
本发明公开了一种处理微博文本认知歪曲的多标签分类方法，基于BERT与LSTM及Attention机制融合的文本分类方法，通过对中文语料数据集中的多条中文语料进行文本预处理，以获得所述多条中文语料对应的多个序列；使用BERT模型提取每个序列的词嵌入；采用LSTM及Attention对每个序列进行特征提取，以获得每个序列对应的文本深层语义特征；通过使用softmax分类器对所获得的文本深层语义特征进行分类，来对模型进行训练和测试，进而实现文本分类，能够捕捉到真正意义上的上下文信息；兼顾了上下文信息，避免长时间序列导致的历史记忆变弱的问题，可以有效提高分类效果。一种处理微博文本认知失真的多标签分类方法。本发明在考虑到上下文信息的情况下，实现文本分类，真实意义上捕获上下文信息，同时避免了由于时间序列长而导致的历史记忆弱的问题，提高了分类效果。所述方法包括：爬行微博下的评论数据集；对所述数据集中的数据进行专业标注；将所述微博文本数据随机划分为训练集，验证集和测试集；在正常模型的输出层之前增加一层。 通过与输入向量的相似度计算生成关注向量，更新各维度的权重值，提高句子中关键词的值，并设置模型将注意力集中在关键词上。 本发明提高了文本分类的精度，构建了BERT模型，并在训练结束后，在测试集上进行模型选择。  12
本申请公开了一种基于AIGC技术的智能优惠券配置方法、装置、设备及存储介质，通过接收用户的优惠券配置需求，作为配券需求信息，用户只需要正常描述自己的需求，不用付出额外的学习成本且方便快捷。使用预先训练完成的预设配券模型对配券需求信息进行处理，根据用户提出的优惠券配置需求得到合适的优惠券配置参数，并得到对应的预期收益信息，并将优惠券配置参数和预期收益信息输出让用户确认。通过使用预设配券模型对用户的优惠券配置需求进行处理得到优惠券配置参数，在用户确认后根据优惠券配置参数自动进行优惠券的配置，简化了用户优惠券配券过程中的操作，解决了目前在进行优惠券配券的过程中交互繁琐的技术问题。基于AIGC技术的智能优惠券配置方法，用于商家宣传和吸引顾客。用户只需正常描述自己的需求即可，无需支付额外的学习成本，方便快捷。 利用预先训练好的预设票务模型对所述票务需求信息进行处理，得到合适的优惠券配置参数，得到合适的预期利益信息。 自动进行优惠券配置简化了用户优惠券配置过程中的操作，解决了优惠券准备过程中交互繁琐的技术问题。该方法包括分析(S102)优惠券活动需求信息以获得优惠券元素信息。 从预设的优惠券活动配置模型中查找(S103)与所述优惠券要素信息匹配的目标优惠券活动配置模型。 在查找到目标优惠券活动配置模型的情况下，将所述优惠券要素信息和所述预期优惠信息输入(S104)所述目标优惠券活动配置模型。 优惠券活跃度配置模型以期望优惠信息为约束条件。 对所述优惠券要素信息进行处理并输出优惠券配置参数和预测优产信息。 根据所述优惠券配置参数进行优惠券活动配置(S105)，得到响应所述用户对所述优惠券配置参数的确认操作和所述预测受益信息的目标优惠券活动。独立权利要求包括以下内容：(1)基于AIGC技术的智能优惠券配置装置； 以及(2)计算机可读存储介质，其存储用于配置基于AIGC技术的智能优惠券的程序。 1
本申请涉及半导体存储器。实施方式提供一种能够使读出动作高速化的半导体存储器。实施方式的半导体存储器包含第1及第2存储单元、连接于第1及第2存储单元的字线、分别连接于第1及第2存储单元的第1及第2位线、分别连接于第1及第2位线的第1及第2感测放大器、以及控制器。第1及第2感测放大器分别包含第1至第3晶体管。第3晶体管的一端电连接于第1及第2晶体管，另一端连接于位线。在读出动作中控制器对字线施加读出电压ER。在第1时刻t5，控制器对第1及第2晶体管分别施加第1电压Vblk及第2电压Vblc，第1感测放大器经由第1及第3晶体管对第1位线施加电压，第2感测放大器经由第2及第3晶体管对第2位线施加电压。半导体存储器，例如NAND闪速存储器，用于以非易失性方式存储数据。提供一种提高读取动作的速度的半导体存储器。 防止对与开单元连接的位线进行突跳操作而导致的错误读取。 通过适当地执行位线的突跳操作，确保位线的稳定时间的缩短，从而提高读取操作的速度。 确保减少的错误位数和提高数据的可靠性。半导体存储器具有两个存储单元，每个存储单元具有与所存储的多位数据相对应的阈值电压。 字线(WL0-WL11)连接到每个存储单元的栅极。 两条位线(BL0-BLm)分别连接到两个存储单元。 两个感测放大器分别连接到两条位线。 每个感测放大器包括三个晶体管。 控制器被配置为在读取操作期间将第一读取电压施加到字线。 在所述控制器向所述字线施加所述第一读取电压的第一时段的第一时间，所述控制器向所述第一晶体管施加高于地电压的第一电压，并且向所述第二晶体管施加不同的第二电压。 在第一时间，第一感测放大器通过第一晶体管和第三晶体管将电压施加到第一位线，并且第二感测放大器通过第二晶体管和第三晶体管将电压施加到第二位线。  11
本发明揭示了一种基于Compact SegUnet自学习模型、构建方法及应用，该模型由一条编码路径和一条解码路径构成，两条路径通过3个卷积层连接。本发明的有益效果主要体现在：通过在每个卷积层中使用更多的卷积核以及添加ReLU的激活函数，使用反池化还原图像分辨率，并与同维度下卷积核提取的图像特征相结合，以最大程度地保留降采样中的重要特征信息，使对图像中需要分割的部分的定位更加精准。用于双染色体切割的紧凑SegUnet自学习模型。该模型在堆栈中实现卷积核并加入ReLU激活函数，利用反池图像分辨率，结合卷积核在相同维度下提取的图像特性，最大限度地保留下采样特征信息，实现了对图像中需要精确分割的部分进行定位。该模型具有彼此形成的编码路径和解码路径。 两条路径通过三个卷积层连接。 编码路径和解码路径由13个卷积层构成。 解码路径由五个上采样层形成。 编码路径由卷积层和最大池化层构成，其中编码路径和解码路径由3 x 3的卷积核构成。 所述卷积层获取每一采样层中一条解码路径的最大池化层的结果。 将所述解码路径确定为当前卷积层的输入。还包括独立权利要求用于双染色体切割的紧凑SegUnet自学习模型构建方法。   6
本发明涉及一种结合Bert模型和模板匹配的事件抽取方法及系统、电子设备，该方法包括步骤：基于Bert模型对待处理文本进行事件检测，识别出事件中的触发词及其类型；根据触发词的类型确定出事件类型，根据事件类型调取对应的模式匹配模板，并基于调取出的模式匹配模板匹配抽取出事件中的论元信息。本发明通过Bert模型进行事件检测和触发词分类，充分发挥了深度学习无需特征设计和可移植性强的特点，避免了模板匹配方式只能在限定域使用的缺点；然后，在得到触发词抽取结果后，根据触发词类型和领域，用提前设计好的对应领域的模板进行论元抽取，充分发挥出模板匹配在限定域准确率高的特点，同时又避免了联合抽取模型方案设计困难的缺点。Bert模型和模板匹配相结合的事件提取方法。该方法使得能够通过Bert模型进行事件检测和触发词分类，充分发挥可移植性强的非特征设计的深度学习，避免了受限域中利用的模板匹配模式，保证了提取结果的准确性，从而增强了可移植性。 该方法使得在得到触发词提取结果后，利用根据触发词类型和字段预先设计的相应字段的模板进行论证提取，充分发挥模板匹配在有限域精度的特点，避免联合提取模型求解难以设计的问题。该方法涉及基于Bert模型对待处理的文本执行(S1)事件检测，以识别事件中的触发词和类型。 根据所述触发词的类型确定(S2)事件类型，所述触发词用于根据所述事件类型调用相应的模式匹配模板。 基于所提取的模式匹配模板来提取事件信息。 通过所述Bert模型在所述待处理文本语句中对所述词语进行标注，用于输出得到的词语的标注结果。包括独立权利要求用于：(1)bert模型和模板匹配组合事件提取系统；以及(2)电子设备，包括存储器和处理器，用于执行用于执行事件提取的一组指令。  12
本发明提供一种基于深度学习的多任务人格预测方法和系统，涉及深度学习领域。包括以下步骤：获取用户文本数据、用户图像数据和用户点赞数据；对数据预处理，得到文本训练数据、图像训练数据和点赞训练数据；基于三种训练数据获取文本向量、图像向量和偏好特征向量；对文本向量和图像向量分别进行拼接处理，得到文本矩阵和图像矩阵；对矩阵进行特征提取，得到文本特征向量和图像特征向量；将文本特征向量、图像特征向量和偏好特征向量进行拼接处理，得到用户特征向量；将用户特征向量输入到预训练的多任务分类全连接网络中，基于Adam优化方法和预设的损失函数训练模型，得到多任务人格预测模型。本发明可以准确分析用户的人格特征。基于深度学习的多任务性格预测方法。该方法能够准确地分析用户的特征。该方法涉及获得用户的社交数据和历史数据。 对用户文本数据、用户图像数据和用户点赞数据进行预处理，得到文本训练数据、图像训练数据和点赞训练数据。 基于所述文本训练数据获得文本向量。 对所述文字向量和图像向量进行拼接处理，得到文字矩阵和图像矩阵。 将文字特征向量拼接为图像特征向量和偏好特征向量，得到用户特征向量。 将所述用户特征向量输入预先训练的多任务分类全连接网络。 得到多任务性格预测模型，用于预测用户的性格特征。包括用于基于深度学习的多任务个性预测系统的独立权利要求。  11
本申请实施例提供了一种文本处理方法、装置、计算机设备及计算机可读存储介质，该文本处理方法基于人工智能技术，包括：获取待处理文本，该待处理文本包括文本标题、文本关键词和文本正文；将该待处理文本输入长文本识别模型中进行处理，得到目标结果，该目标结果用于指示待处理文本的实用性类别；其中，长文本识别模型是利用第一文本数据对初始文本识别模型进行预训练后，利用第二文本数据对预训练后的文本识别模型进行微调训练得到的；该第一文本数据包括非完整文本正文，第二文本数据包括样本文本标题、样本文本关键词、样本文本正文以及相应的参考实用性类别标签。通过本申请实施例可以有效提高篇章级长文本实用性识别的准确度和鲁棒性。该方法在人工智能技术中是有用的。该方法在话语层面上提高了长文本实用性识别的准确性和鲁棒性。该方法包括获取待处理文本。 所述待处理文本设置有文本标题、文本关键词和文本正文。 利用第一文本数据对初始文本识别模型进行预训练，得到长文本识别模型。 一第二文本数据，用于对预训练后的所述文本识别模型进行精调训练。 第一文本设置有不完整文本。 第二文本中包含有样本文本标题、样本文本关键词、样本文本正文、以及对应的参考效用类别标签。本发明还涉及一种计算机可读存储介质，其包括用于执行文本处理方法的一组指令。  11
本发明公开了一种基于深度学习模型的教师信息化教学微能力评价方法，其特点是该方法包括：构建教师微能力分类框架、设计教师微能力分类标准和评价标准、从移动听评课系统采集评课数据、清洗和变换评课文本、对评课文本进行微能力分类标准和微能力水平评价、构建基于预训练的深度学习教师微能力分类模型、构建基于注意力机制的深度学习教师微能力评价模型、通过预测和加权平均得到教师微能力分类预测结果和微能力水平评价结果，以及将教师微能力分析结果可视化至教师个体画像等步骤。本发明与现有技术相比具有多角度科学评价教师课堂能力，提升数据真实性和准确率，减少人工采集工作量和分析成本，具有较高的研究实践价值。基于教师深度学习模型教学的教学微能力评价方法。该方法提供多角度科学评价教师课堂能力，提高数据真实性和准确性，减少人工采集工作量和分析成本，提供较高的研究实践价值。该方法涉及基于预训练构建(S1)与教师深度学习模型文本相对应的教师微观能力的分类。 基于注意力机制构建(S7)所述教师深度训练模型文本对应的所述教师微能力的评价。 根据教师ID从移动收听和评价系统中提取(S8)与教师标识(ID)匹配的教师评价数据，以形成每个教师的评价集。 采用加权平均法(S9)计算评价集中每个微能力点的评分。 利用关键词提取技术，根据不同的微容量点从所述教师评价集中提取关键词。 可视化工具用于表示教师微观能力图像。 设计的13个教师微能力逐一表示。  11
本发明提供了一种基于多模态大模型的行程规划及智能导览系统，其特征在于，所述系统包括数据获取模块、行程规划模块和智能导览模块；所述数据获取模块用于获取当前地域内景点相关信息，所述行程规划模块用于根据景点相关信息对当前地域内景点的行程进行规划，所述智能导览模块用于在用户旅行过程中提供导览服务；本发明通过结合旅行时间、行程长度和景点热度信息来生成多条初始行程路线供用户选择，并结合天气情况、景点类型和预计人流量深入优化提取出最优行程路线，更能根据满足用户的实际需求，从而可以提高用户的旅行体验。基于多模态大模型导航出行规划和智能的系统。该系统通过对出行时间、出行时长和景点热度信息进行调整，生成多条初始出行路线供用户选择，满足了天气情况和用户的实际需求，提高了用户的出行体验。所述系统具有数据获取模块，用于获取当前区域内的景区相关信息。 利用行程规划模块，用于根据所述景区相关信息规划当前区域的景区行程。 智能导航模块用于在用户出行过程中提供导航服务。 所述出行规划模块中设置有第一路线评价模块和第二路线评价模块。 第一路线评价模块，用于生成多条初始行驶路线。 所述第二路线评价模块用于评价所述第一路线评价模块的行驶路线。 系统本体上设置有交互模块，用于完成用户与系统之间的交互。  11
本公开提供了一种基于深度学习的课程评论文本情感分析方法及系统，包括：获取待分析的课程评论文本；将所述课程评论文本输入预先训练的课程评论文本情感分析模型中，获得课程评论文本情感分析结果；其中，所述课程评论文本情感分析模型包括输入层、嵌入层、BiGRU层、Attention层以及激活层，所述嵌入层采用XLNet模型以及预先构建的课程评论情感词典将输入的文本状态表示为加权词向量矩阵，所述XLNet模型以排列组合的形式对输入的文本进行重构，通过将部分课程评论文本上下文信息中的部分下文内容引入到上文中，实现双向预测的功能。教育数据挖掘和自然语言处理中基于深度学习的课程评论文本情感分析方法，用于情感监测，自动摘要，文本分类，机器翻译，语音识别，提问和文本分类。本发明能够提高情感分析的准确性和分析效率。 该方法有效地提高了评论中的情感特征。 本发明能够提高课程评论文本情感分析的准确性。该方法包括获得待分析的课程评论文本。 课程评论文本被输入到预先训练的课程评论文本情感分析模型中。 获得课程评论文本情感分析结果， 其中课程评论文本情感分析模型包括输入层，嵌入层，BIGRU层，嵌入层使用XLNET模型和预先构建的课程评论情感词典将输入文本状态表示为加权词向量矩阵。 XLNET模型用于以排列和组合的形式重构输入文本。 引入了上下文信息中课程评论文本上下文的功能。 实现双向预测。本发明还涉及一种基于深度学习的课程评论文本情感分析系统，包括：(1)基于深度学习的课程评论文本情感分析系统； (2)计算机可读存储介质； (3)电子设备。  12
本发明公开了一种基于深度学习的短信模板生成方法、系统及电子装置，方法包括以下步骤：获取短信文本的待压缩短信文本，并对所述待压缩短信文本进行预处理；将预处理后的所述待压缩短信文本输入至训练好的Transformer模型中，以获取压缩短信文本；获取所述压缩短信文本的语句通顺概率矩阵以及词频概率矩阵；根据所述语句通顺概率矩阵以及所述词频概率矩阵从所述压缩短信文本中选取最佳压缩短信文本。本发明的目的在于提供一种基于深度学习的短信模板生成方法、系统及电子装置，通过构建缩写模型生成大量与原文相似的句子，再通过分类模型，选出符合语句通顺性和字数尽可能少的句子作为输出，以此达到生成短信模板的目的。电子设备基于深度学习生成短信模板的方法(权利要求书)。该方法能够利用模型生成大量与原始文本数据相似的训练数据，并通过分类模型以句子为输出选择尽可能少的句子，避免抽取式抽象模式丢失。所述方法包括：获取短消息文本的待压缩短消息文本。 对所述待压缩短信文本进行预处理。 将预处理后的待压缩短信文本输入训练好的模型，得到压缩后的短信文本。 获取压缩后的短信文本的语句沟通概率矩阵和词频概率矩阵。 根据语句平滑概率矩阵和所述词频概率矩阵从所述压缩短信文本中选择最佳压缩短信文本。独立权利要求还包括：基于深度学习的短信模板生成系统； 以及计算机可读存储介质，所述计算机可读存储介质包括用于基于深度学习生成短消息模板的指令集。  11
本发明提供一种基于问答的临床文本结构化方法，包括以下步骤：首先，将临床文本X和查询文本Q集成输入到采用预训练语言模型BERT训练，输出对应X和Q的上下文表征向量Vs；将结果输入到临床命名实体识别模型，输出命名实体信息和标注序列Int和Inq；然后，将标注序列Int、Inq集成为命名实体信息In，然后将隐藏的上下文表征信息Vs和命名实体信息In集成为Hi；最后，利用Hi计算回答Q在X中的开始、结束位置索引值，得到答案文本。本发明实验结果表明基于问答的临床文本结构化方法在EM评分和F1评分方面明显优于BERT‑Base方法。基于问答的临床文本结构化方法。该方法能够更好地进行基于问答的临床文本结构化处理。该方法涉及将临床文本和查询文本输入到上下文表示模型中(A1)。 利用所述上下文表示模型建立预训练的BERT语言模型。 输出与所述临床文本和所述查询文本对应的上下文特征向量。 将所述临床文本和所述查询文本输入(A2)到临床命名实体识别模型中以输出命名实体信息。 标签序列被整合(A3)到命名实体信息中。 计算查询文本和临床文本的开始和结束位置值(A4)，以获得作为结构化结果的回答文本。  12
本发明涉及自然语言处理、深度学习、方面级情感分析领域，特别涉及一种基于双向LSTM和多头注意力机制的文本方面级情感识别方法，包括获取方面词所在的上下文文本的词嵌入表示；采用双向LSTM网络获取局部上下文和全局上下文的特征表示；局部上下文的特征表示通过上下文动态加权和多头自注意力机制得到局部特征，全局上下文的特征表示通过多头自注意力机制得到全局特征；根据局部特征和全局特征获得局部和全局共同关注的交互特征，将交互特征和局部特征通过动态权重拼接融合获得最终特征表示；将最终特征表示输入到线性层、softmax函数中进行情感预测；本发明对特征进行动态融合，从而提高了文本方面级情感识别的准确率。一种用于互联网，电子商务，社交媒体等应用行业的基于双向LSTM和多头关注机制的文本层面情感识别方法。本发明动态融合了特征，提高了文本级情感识别的准确性。该方法涉及获得方面词的上下文文本的词嵌入表示。 对局部上下文和全局上下文的词嵌入式表示进行预处理以获得对应于上下文文本的特征表示。 通过上下文动态加权和多头自注意机制得到局部上下文的特征表示。 根据所述局部特征和所述全局特征，获得局部和全局共同兴趣的交互特征。 最后的特征表示被输入到线性层中。 在软最大函数中进行情感预测，得到基于双向长短时记忆(LSTM)和多头注意机制的文本级情感识别模型。 将要识别的文本输入到训练好的模型中。 获得文本中特定方面词的情感识别。  12
本发明公开了基于Hashgrid的神经辐射场及二维体密度分割的建模方法，包括如下建模步骤：步骤1、首先通过普通rgb相机采集多角度的人体图像，步骤2、将已采集到的图像使用colmap进行相机的内参标定以及外参标定，步骤3、对采集到的图像进行像素分割和图像预处理，去除掉图像待重建以外的背景区域，本发明采集待重建人体的各个角度图像，并设定相邻图像之间的重叠区域，剔除背景，降低干扰，通过多次迭代训练，将渲染由连续改为离散形式，能够快速进行三维人体建模，通过将采样点代入计算，增加渲染效果，使用u‑net分割体密度切片图，分割同时去除噪点，精准重建人体，有效的提升建模效率。用于医学诊断环境中人体建模的神经辐射场建模和基于Hashgrid的二维体积密度划分的方法。 也可用于人体模型重建。该方法通过现场采集待重建人体的各个角度图像，并设置相邻图像之间的重叠区域，从而消除背景，通过多次迭代训练，减少干扰，将渲染连续变为离散形式，将采样点代入计算，快速进行三维人体建模，增加渲染效果，采用u-net分割的人体密度切片图，同时分割去除噪声点，精确重建人体，有效提高建模效率。该方法涉及通过普通红绿蓝摄像头采集多角度人体图像。 利用colmap对摄像机的内参数和外参数进行标定。 对采集到的图像进行像素分割和图像预处理过程。 去除要重建的图像以外的背景区域。 位置矢量和方向矢量被转换成高频变量。 以所述位置和所述方向作为输入，生成高精度的渲染效果。 根据阶数空间对外轮廓像素坐标进行归一化。 将所述像素组合重建为待重建的人体三维模型。 多次迭代训练后在神经辐射野中提取体密度。 体积密度根据重建模型的质量要求进行切片。   6
本发明公开了一种基于掩码自注意力机制的脑肿瘤MRI图像分割方法，所述分割方法包括：S1：构建一个3D Masked Swin Transformer模块；S2：构建一个三维医学图像分割模型；S3：获取原始医学图像数据集，对原始医学图像数据集进行数据预处理，并将预处理后的医学图像数据集划分为训练集和测试集；S4：设置网络模型训练的超参数和在线数据增强方法，使用所述训练集训练三维医学图像分割模型；S5：使用训练完成的三维医学图像分割模型对原始脑部MRI医学图像中的肿瘤区域进行分割。本发明的优点在于：此方法能够有效地将Transformer应用至医学图像分割中，泛化能力强，抗干扰能力和分割准确率高。基于掩模自注意力机制的脑肿瘤MRI图像分割方法。该方法能够有效地将应用应用到医学图像分割中，使其具有较强的泛化能力、较高的抗干扰能力和较高的分割精度。 该方法引入了掩码自注意机制，使掩码自注意机制只激活关键的非背景区域，减少了背景区域的干扰，保证了较高的分割精度，有效地提取了图像的全局或长距离上下文交互信息和空间依赖信息。该方法包括基于标准Swin模块构建(S1)三维(3D)掩蔽Swin模块。 3D掩蔽Swin模块由第一3D掩蔽Swin块和第二3D掩蔽Swin块组成。 构建三维医学图像分割模型(S2)。 获得原始医学图像数据集(S3)。 对所述原始医学图像数据集进行预处理。 将预处理后的医学图像数据集分为训练集和测试集。 设置网络模型训练、迭代次数、初始学习率、损失函数和在线数据增强过程的优化器(S4)。 使用三维医学图像分割模型(S5)来划分原始脑部MRI医学图像中的肿瘤区域。  7
本发明公开了一种中医实体识别算法，包含以下步骤：A、数据标注；将中医组收集的中医医案文本采用的是BIO的标注方式，B，即Begin，表示开始I，即Intermediate，表示中间O，即Other，表示其他，用于标记无关字符；B、预训练模型；使用预训练模型做微调的训练方式称为迁移学习；C、训练模型，本发明打破中医领域分词效果差的瓶颈，为健康领域的智能对话和中医知识图谱，中医辅助诊疗系统奠定基础，提升基础语义组件的效果。中药实体识别算法。该算法能够提高基本语义成分的效果。该算法具有用于执行数据标记的规则集。 一个中药病例文本由一个中药集团通过生物标记过程收集。 标记无关字符。 建立预训练模型。 调用微调，利用预训练模型和训练过程进行迁移学习。 建立训练模型，其中，所述角色包括所述角色的空间和标签。 样品由空白线隔开。 通过使用Brat标记工具进行标记。  10
本发明涉及计算机应用技术与临床麻醉领域，公开了一种临床麻醉领域实体抽取方法、装置、存储介质及电子设备。方法包括：从知识来源获取多源的临床麻醉知识文本，进行预处理，形成分段的无标签短文本及主题；设计本领域的实体类型作为抽取对象，利用少量的先验知识预设出每种实体类型下的少量实体，用于后续构建训练模型所需文本数据；利用字符串匹配技术在原始数据中匹配实体抽取模型所需带标签训练数据，剩余数据作为待进行实体抽取的数据；利用基于BERT和CRF的模型对待进行实体抽取的数据进行编码，获得序列数据的标签，得到待抽取的文本数据中的实体。该方法实现了临床麻醉领域中长文本数据的实体抽取，大大减少了人工劳动，提升了工作效率。一种在临床麻醉领域从多源文本中提取实体知识以建立临床麻醉知识地图的方法及装置，存储介质和电子设备。本发明实现了临床麻醉领域长文本数据的立体提取，减少了人工劳动，提高了工作效率。 该方法能够从知识源中获取多种来源的临床麻醉知识文本， 预处理， 形成分段的无标签短文本和主题，并将该字段的实体类型设计为提取对象，在每个实体类型下使用少量先验知识预置较少数量的实体，用于后续构建训练模型所需的文本数据。该方法包括从知识源获得多个源的临床麻醉知识文本(S101)。 执行数据预处理。 形成分段的非标签短文本和主题。 设计临床麻醉领域中作为提取对象的一系列实体类型(S102)。 通过使用少量先验知识为后续构建训练模型所需的文本数据预置每个实体类型下的少量实体。 使用字符串匹配技术匹配(S103)原始数据中的实体提取模型所需的标签训练数据。 通过使用基于来自变压器(BERT)和CRF的双向编码器表示的模型对要进行实体提取的数据进行编码，以获得序列数据的标签。 获取要进行实体提取的文本数据中的实体(S104)。本发明涉及一种用于从临床麻醉领域的多源文本中提取实体知识以建立临床麻醉知识地图的装置； (2)临床麻醉现场实体存储介质，存储一组指令，用于从临床麻醉现场的多源文本中提取实体知识，以建立临床麻醉知识地图； (3)一种实体电子设备，包括存储器和处理器，所述处理器执行存储在所述存储器中的指令，用于从临床麻醉领域中的多源文本中提取实体知识，以建立临床麻醉知识地图。  10
本说明书公开一种模型训练、任务执行方法、装置、存储介质及设备，中心服务器可以基于各下游任务的共性样本对初始模型进行预训练，得到具有执行各下游任务的基础能力的预训练模型，进而可以通过将预训练模型的模型参数发送给每个下游服务器，以使得每个下游服务器基于本地样本对预训练模型中的调整层进行训练，得到训练后模型，并将训练后模型的调整层的网络参数返回，中心服务器可以根据各下游服务器返回的调整层网络参数，对预训练模型的调整层进行更新，得到目标模型，从而使得可以通过预训练模型的调整层学习到不同下游服务器所私有的本地样本和预训练过程中使用的共性样本之间的潜在联系，进而使得目标模型在下游任务中的性能得到提升。方法进行模型的训练。通过预训练模型的调节层可以学习到不同下游服务器私有的本地样本与预训练过程中使用的普通样本之间的潜在关系，使得目标模型在下游任务中的性能得到提升。该方法涉及由中央服务器获得(S100)初始模型。 根据每个下游任务的任务属性信息，获取针对每个下游任务的共性样本(S102)。 通过所述共性样本对所述初始模型进行预训练(S104)，得到预训练模型。 将预训练模型的模型参数发送(S106)至各下游服务器，以使各下游服务器通过获取的模型参数进行本地模型部署，得到本地模型。 对各下游服务器返回的各调节层的网络参数进行融合(S108)，得到各调节层的融合参数，并根据各调节层的融合参数更新所述预训练模型，得到目标模型，以将所述目标模型部署到各下游服务器中执行各下游任务。包括以下独立权利要求：(1)任务执行方法； (2)模型训练装置； (3)任务执行装置； (4)存储用于训练模型的程序的计算机可读介质； 以及(5)电子设备。  11
本说明书一个或多个实施例提供一种文本分类方法、装置及电子设备，基于BERT模型，所述BERT模型包括：至少两个依次连接的编码器层；所述方法，包括：将待分类文本输入所述BERT模型；采集每个所述编码器层的输出，得到对应于所述待分类文本的至少两个特征表示信息；融合至少两个所述特征表示信息，得到融合后的特征表示信息；融合后的特征表示信息充分利用每一编码器层的输出，且准确反映了文本所蕴含的词法和语法信息；根据所述融合后的特征表示信息，确定所述待分类文本的类型。用于基于来自电子装置中的变压器模型的双向编码器表示来执行文本分类的方法(要求保护)。该方法包括将待分类文本输入到来自变换器的双向编码器表示(BERT)模型中，其中待分类文本被包括在单句中。 获得编码层的输出。 获得表征所述待分类文本的信息的两个特征。 对表征信息的特征进行合并，得到表征信息的融合特征。 根据融合后的特征表征信息确定所述待分类文本的类型。 确定训练文本和初始BERT模型。本发明还涉及一种用于基于来自变换器模型的双向编码器表示来执行文本分类的设备。  12
本申请实施例提供了一种预训练模型数据处理方法、电子设备及计算机存储介质，其中，预训练模型数据处理方法包括：获取训练样本数据，每个训练样本数据包括多轮表格问答训练样本，每轮表格问答训练样本包括自然语言查询语句和对应的数据库模式数据；将训练样本数据输入预训练模型进行特征提取，获得多轮表格问答训练样本对应的多个样本特征；基于多个样本特征和对应的正负例标签，以及预设的对比学习损失函数，对预训练模型进行训练，其中，所述正负例标签根据所述多个样本特征对应的多个数据库查询语句之间的相似度确定，所述正负例标签用于表征当前样本特征与所述多个样本特征中的其它样本特征是否语义相关。一种训练前模型数据的处理方法。预训练模型的训练完成可以有效地适用于多轮查询场景，当其转移到表格问答系统时。 用户需要通过多轮查询结果获取查询结果的场景。 本发明将表格对讲训练样本与语义相关性进行更清晰的区分，更好的了解表格对讲训练样本的语义和相互关系服务，在进行损失计算时，根据多个样本特征对应的正反实例标签进行损失计算。 可以找出与当前训练样本最相关的训练样本，从而保留有用的训练样本，并删除无用的训练样本。该方法包括获得训练样本数据，其中每个训练样本具有多轮表格问题和答案训练样本。 训练样本包括自然语言查询语句和相应的数据库模式数据。 训练的样本数据被输入到预训练的模型中以执行特征提取。 获得与多个表格提问和答案训练样本相对应的多个样本特征。 基于分别对应于多个样本的正，负范例标签和预设的比较学习损失函数训练预训练模型。 根据与多个样本特征相对应的数据库查询语句之间的相似性来确定正和负示例标签。还包括独立的权利要求： 一种计算机存储介质，包括一组用于预训练模型数据处理方法的指令； 以及 一种计算机程序产品。  11
本发明适用于机器学习技术领域，提供了一种分类模型快速训练方法和终端设备，其中，所述的分类模型快速训练方法包括：获取预训练模型和数据集；将数据集划分为若干相同大小的子集，并确定子集中的任意一个子集为训练集；将子集中的其他子集合并以生成测试集；根据训练集训练预训练模型；根据测试集测试训练后的预训练模型；根据测试结果对训练后的预训练模型进行评估。在本发明实施例提供的分类模型快速训练方法和终端设备中，由于预训练模型是已应用于其他分类问题的模型，相较于新建模型，对其进行适应性训练和局部优化所需的时间和数据量必然大幅减小，从而解决了现有技术对机器分类模型进行训练时耗时较长和训练所需数据过多的问题。快速分类模型训练方法。本发明避免了预训练模型的分类问题，实现了对局部优化所需时间的训练和适应，从而减少了数据量，避免了长时间训练所需数据的问题训练机分类模型。该方法包括获得具有数据集的预置预训练模型。 数据集被划分为多个相同大小的子集。 确定训练集的子集。 该子集中的另一子集被组合。 组合子集中的另一子集被用作测试集。 根据训练集训练预训练模型。 在测试集合测试中，根据预训练模型得到测试结果。 根据测试结果对训练好的预训练模型进行评估。 判断测试结果是否符合预设的应用要求。本发明还涉及一种用于实施该方法的装置。 一种快速分类模型训练装置 包括存储器和用于训练快速分类模型的处理器的终端设备 一种用于存储一组用于训练快速分类模型的指令的计算机可读存储介质。  11
本发明公开了一种基于批量特征热图的神经网络滤波器剪枝方法，该方法主要用于减少模型存储量和提升模型推理速度。该方法包括加载并在给定数据集上微调预训练模型；生成模型每一层的批量特征热图；基于灰度阈值得到各滤波器的Mask为滤波器进行评分；对给定数据集进行随机不重复的抽取去更新滤波器的得分；以滤波器的得分为衡量准则实现每层滤波器的剪枝；重训练剪枝后的模型恢复精度等步骤。本发明解决了神经网络模型存储量大、推理速度慢的问题，使得剪枝后的神经网络模型可以在产生极小精度降低的情况下应用于资源受限的场景。一种基于批次特征热谱图的神经网络滤波器剪枝方法。该方法解决了神经网络模型存储量大，推理速度慢的问题，使得剪枝后的神经网络模型在产生最小精度约简的情况下，能够应用于资源有限的场景。该方法包括加载预训练模型，并针对特定数据集微调预训练模型。 在精细调整之后，将一批图像输入到模型中。 生成所述模型的每一层的批次特征图的热图。 对模型各层的热图进行灰色直方图统计分析。 过滤器的最终得分被划分为过滤器的修剪。 重新训练修剪模型以恢复精度。 执行对模型的每一层的操作。 重复评估滤波器。   4
本发明公开了数据库知识图谱构建方法、装置和电子设备，涉及大数据处理与挖掘技术领域。该方法的一具体实施方式包括：获取数据库的元数据信息，对所述元数据信息进行语义分析；对所述元数据信息分配至少一个类别标签，将经过语义分析的所述元数据信息及其对应的类别标签输入到预训练模型中进行训练，从而训练得到私有模型；其中，所述至少一个类别标签包括安全等级标签；基于所述元数据信息对应的安全等级标签，采用自然语音处理大模型和/或所述私有模型对所述元数据信息进行向量化，从而得到所述元数据信息中各个分词的特征向量；根据所述各个分词的特征向量，构建知识图谱。该实施方式能够解决存在数据泄露危险的技术问题。用于在用于大数据处理和挖掘领域的电子设备(要求保护的)中构建数据库知识地图的方法，所述电子设备例如智能电话、平板计算机、膝上型便携式计算机、台式计算机。该方法使得能够降低数据泄露危险的技术问题。该方法包括获得数据库的元数据信息。 对所述元数据信息进行语义分析。 类型标签被分配给信息。 将所述语义分析和对应的类别标签输入预先训练的模型中训练得到私有模型，所述类别标签包括安全等级标签。 基于所述元数据对应的安全级别标签对所述信息进行向量化处理。 根据每个分词的特征向量构建知识图谱，其中自然语音处理大模型选自ChatGPT(OpenAI开发的Chatbot)、Claude(在线不可下载软件)、bard(会话生成式人工智能Chatbot)。还包括独立权利要求，用于：数据库知识图谱构建装置； 以及一种计算机可读媒体，其包括用于在电子装置中构建数据库知识地图的指令集； 以及计算机程序产品，其包括用于在电子装置中构建数据库知识地图的指令集。  11
一种网络爱国舆情事件跟踪、预测和疏导方法，首先使用网络爬虫系统爬取全网热门新闻网站和社交媒体，并通过BERT模型判断话题是否与爱国主义相关，并计算此话题在全网的流行度。系统通过LOF算法来识别突发热点事件，并对事件持续跟踪。使用结合长短期记忆网络(LSTM)和卷积神经网络(CNN)的深度学习方法，将静态属性和动态属性结合使用深度神经网络预测舆情的流行度趋势。根据使用相似历史事件数据训练的神经网络，系统会给出使用者用以疏导舆情的参考应对方案，并预测使用方案后的舆情流行度变化趋势。本发明可以有效跟踪和预测网络上有关爱国主义的舆情。一种网络公益事件跟踪，预测和疏导的方法。本发明能够根据训练好的相似历史事件数据的神经网络为用户提供缓解意见的参考响应计划，预测节目使用后的意见流行趋势，有效地跟踪和预测网络上的意见。该方法包括建立网络数据收集系统。 通过使用网络爬虫来获得流行新闻网站和社交媒体内容。 通过使用来自变压器模型的预训练的基本双向编码器表示来分类文本。 做出确定以检查文本是否与亲情相关。 计算与特定的亲情事件相关的主题的流行度。 通过使用异常检测算法来识别突发热点事件。 当检测到与亲情相关的突发热点事件时，收集网络行为。 跟踪和记录整个过程。 预测网络事件流行度。 提取与公众意见相关的历史情感数据。 基于事件数据训练深度神经网络。 推荐多个适当的情感计划。 使用相应的方案后，可以确定情感大众意见流行的发展趋势。  12
本发明公开了一种语音识别后处理方法和系统及相关设备。所述方法包括：从语音识别系统针对输入语音进行第一次解码产生的词图lattice中，提取前N个最好的识别结果N‑best lists；使用训练好的带有词性的BERT双向语言模型对N‑best lists进行重打分；从N‑best lists中选择得分最高的结果作为最终的识别结果。本发明对N‑best lists进行重打分时，通过使用带有词性的BERT双向语言模型，能够同时利用上下文信息，还可以利用到上下文的词性信息，从而可以进一步提升语音识别系统的性能。用于对终端设备的语音识别进行后处理的方法。该方法能够利用上下文信息和语音信息以提高语音识别系统的性能。该方法包括从语音识别系统生成词模式。 提取N个最佳识别结果。 用语音特性得分建立训练的BERT双向语言模型。 从N个最佳识别结果中选择N个最佳识别结果。 将N个最佳识别结果存储在数据库中。 采用基于滑动窗口的输入采样方式和逐字掩码的编码方式。 为每个句子构造输入样本，并执行编码处理。本发明还涉及一种语音识别后处理系统； 一种计算机设备，包括处理器和存储器； 以及计算机可读存储介质。 3
本发明公开了一种基于ERNIE‑BiGRU‑Attention的谣言检测方法，借助了ERNIE模型以及双向GRU加上注意力机制模型，对一条最新发布的新闻进行内容真假性的判断，通过神经网络来预测其结果。ERNIE语料库包含了百度新闻、百度百科、百度词条等大范围的语料，非常契合谣言检测领域，解决了现有模型没有对新闻主题领域进行泛化的缺点。后续，我们加入BiGRU层和注意力机制层，能够更好地掌握ERNIE预处理后文本的关键实体信息，从而获得更好的泛化能力和更高的准确率。基于ERNIE-BiGRU的谣言检测方法。该方法增加了双向GRU层和注意力机制层，能够更好地掌握经过ERNIE预处理后文本的关键实体信息，从而获得更好的泛化能力和更高的准确率。该方法涉及使用ERNIE作为预处理模型以输出词向量。 将词向量输入BiGRU模型。 BiGRU模型被分成三个部分：输入层、隐藏层和输出层。 隐含层由BiGRU层构成。 将一个正向GRU输出的隐藏状态序列与一个反向GRU输出的隐藏状态序列进行拼接，得到一个完整的隐藏状态序列。 根据流言二分类问题概率Pr范围确定区间的可信度。  12
本申请公开了有害短信分析方法、装置和存储介质，包括对中文语料进行预处理，获得不同的所述中文语料对应的不同序列；使用盘古模型提取每个序列的词嵌入向量；采用LSTM对所述词嵌入向量进行深层特征提取，获得每一个序列对应的文本深层语义特征；将所述文本深层语义特征经过全连接层和Softmax分类器，进行模型的训练和测试。本申请通过盘古大模型和迁移学习技术，减少所需的有标签的有害短信数据量，训练所需要的时间和计算资源也大大减少，具有更好的适应性，能在短时间内生成可靠的有害短信检测分析模型，提高了通信网有害短信的分析效率。有害短信分析方法。该方法通过磁盘古模型和迁移学习技术，减少所需的标记有害短信数据量，从而减少训练所需的时间和计算资源，适应性更好，能够在短时间内生成可靠的有害短信检测分析模型，提高有害短信的分析效率。该方法涉及对中文语料进行预处理。 得到不同的序列对应不同的中文语料。 利用磁盘古模型提取每个序列的词嵌入向量。 利用LSTM对词嵌入向量进行深度特征提取，得到每个序列对应的文本深度语义特征。 通过全连接层和Softmax分类器对所述文本深度语义特征进行模型训练和测试。 通过生成数据字典进行文本特征化，得到不同中文语料对应的不同序列。独立权利要求包括：(1)一种有害短信分析装置； (2)一种有害短信分析装置，包括处理器和存储器； 以及(2)包括一组用于分析有害短消息的指令的存储介质。  12
本发明公开了一种基于深度学习的U‑net网络的低照度成像算法及装置，该算法具体包括：步骤101：对原始图像进行打包变换像素通道的预处理；步骤102：利用步骤101中预处理的图像进行U‑net网络的数据训练，其中，在U‑net网络的最后一层使用交叉熵函数与softmax函数；步骤103：通过训练后的U‑net网络对采集到的低照度图像进行处理，并对处理后的图像进行Gamma校正，并输出最终图像。本发明提出的算法效率较高，能够提高信噪比，增强显示图像细节，很好地还原低照度成像图像的细节部分，提高低照度图像亮度，使视频图像能在低照度环境下快速清晰成像。基于深度学习的U-net网络低照度成像算法。该方法能够提高效率和信噪比，增强显示图像细节，减少低照度成像图像的细节部分，提高照度图像的亮度，在低亮度环境下快速清晰地显示视频图像。该算法具有对原始图像进行包变换的一组规则。 对像素通道进行预处理。 在图像处理之后进行U-net网络处理的数据训练。 确定用于平衡类别的频率的权重图。 通过训练好的U-net网络对采集到的微光图像进行处理。 对所述处理后的图像进行伽马校正处理。 输出最终图像。 黑色像素被消除。 将处理后的数据确定为前置数据输入。 转换像素值的实数。   6
本发明实施例公开了一种名片信息抽取系统训练方法及装置、存储介质，该方法包括通过对名片图像进行识别，得到文本信息，之后通过预设BERT模型、预设卷积神经网络进行训练对文本信息进行处理，得到特征向量，再对特征向量进行组合编码，以得到对应的文本片段特征信息，最后利用分类器对文本片段特征信息进行判别，得到文本片段特征信息对应的预测分类标签，通过预设目标函数，使得文本片段特征信息对应的预测分类标签与预设分类标签的损失值达到要求，从而完成对名片信息抽取系统的训练，而通过筛选预测分类标签将得到结构化信息。本发明实施例能够提高系统对名片进行信息抽取时的效果，从而减少在对名片进行信息抽取时抽取到的结构化信息的误差。用于提取卡片信息的名片信息提取系统的训练方法。 用途包括但不限于姓名、职位、公司、地址、电话和邮箱。该方法可以提高系统在对名片进行信息抽取时的效果，从而降低对名片进行信息抽取时抽取的结构化信息的误差。 由于词向量序列是通过预设的BERT模型得到的，因此，可以提高得到的词向量序列的准确率。所述方法包括：识别(S101)名片图像，例如真实名片图像，以获得文本信息; 以及基于预置双向编码器从变换器(BERT)表示模型、预置卷积神经网络和所述文本信息，获得(S102)特征向量。 基于所述预设循环神经网络对所述特征向量进行合并编码(S103)得到对应的文本片段特征信息。 利用(S104)分类器对所述文本片段特征信息进行判断，以得到预测分类标签对应的所述片段信息。 获取损失值(S105)，并根据该值确定目标参数。包括如下独立权利要求：一种名片信息提取系统训练装置； 名片信息提取系统的培训装置； 以及存储用于培训名片信息提取系统的程序的计算机可读存储介质。  12
本发明涉及人工智能技术领域，提供一种基于权重字典的情感分析方法、系统、装置及存储介质。其中方法包括：搜集中文情感分析数据集，对中文情感分析数据集进行分词和权重计算，构建得到情感类权重字典，其中所述中文情感分析数据集带有积极或消极标注数据；获取多条文本数据，采用所述情感类权重字典对每条文本进行积极和消极判断并标注，得到标注信息；对每条文本的标注信息进行向量转换，提取得到文本的特征向量；根据所述特征向量，对预训练模型进行调参训练，输出训练后模型，采用所述训练后模型进行情感分析。采用本发明能够解决现有技术中自动化程度不高，操作复杂、速度慢、且准确性不高的问题。该方法可用于使用电子设备(要求保护)基于权重字典来分析情感。该方法包括：提取文本的特征向量； 利用训练后模型进行情感分析； 解决了现有技术中自动化程度不高，操作复杂，速度慢，精度低的问题。基于权重字典的情感分析包括：收集汉语情感分析数据集； 对中文情感分析数据集进行分词和权重计算， 构建情感型权重字典； 为汉语情感分析数据集提供正向或反向标记数据， 获取多个文本数据，利用情感类型权重字典对每个文本进行正反判断并标注，对每个文本的标注信息进行向量转换，训练预训练模型，利用训练模型进行情感分析。还包括独立的权利要求： 一种基于权重字典的情感分析系统； 以及 一种计算机可读存储介质，包括一组用于基于权重字典分析情感的指令。  12
本发明提出一种基于依存语义注意力机制的词对上下位关系训练方法。该训练方法依次遍历词对语料库中的所有词对，对于每组词对，在文本语料库中找到所有的词对共现句，对这些共现句进行依存句法分析得到最短依存路径；利用BERT模型和依存语义注意力机制生成最短依存路径的路径向量，然后利用打分函数调整这些路径向量，将它们进行平均池化处理并融合词对的词向量得到分类器输入向量，最后将分类器输入向量通入Softmax函数进行训练。本发明能够有效挖掘句子中隐含的上下位关系，进而提高分类器的识别准确率。一种基于从属关系语义注意机制训练句子中词的上下位置的方法。本发明能够有效挖掘句子中隐藏的上下位置关系，从而提高分类器的识别精度。该方法包括检测文本语料库中的词对公共句子。 分析从属关系句子。 通过使用来自变压器(BERT)模型的双向编码器表示和依赖性语义注意机制来生成最短依赖性路径的路径矢量。 基于评分函数来调整路径向量。 获得上下位置关系分类器的输入向量。 训练上下位置关系分类器。  12
本发明公开了一种基于多任务学习的ET‑BERT流量分类方法、存储介质及设备，旨在假设多个学习任务不是完全独立的，并且多个辅助任务通过硬参数共享可以促进另一个任务的学习, 从而在执行主任务时结合来自Transformers的双向编码器(ET‑BERT模型)减少对大量标记训练样本的需求。所述方法包括步骤：获取流量数据集，并对流量数据集进行预处理；获取数据集的时间序列特征；根据所述时间序列特征，将预测带宽和持续时间作为辅助任务，对ET‑BERT模型预训练；获取带宽和持续时间分频器的最佳值，并将所述最佳值转换为令牌进行批处理优化和Adam优化器进行训练；对预训练的ET‑BERT模型中参数进行微调，采用微调参数后的ET‑BERT模型进行主任务流量类别预测。基于多任务学习进行ET-BERT流分类的方法。该方法实现了通过硬参数共享辅助任务可以促进其他任务的学习，目的是假设学习任务不是完全独立的，从而在执行主任务时结合来自变压器的双向编码器，以降低对大标记训练样本的需求。该方法涉及获得流数据集。 对所述流量数据集进行预处理。 获得所述数据集的时间序列特征。 根据所述时序特性，将预测带宽和时长作为辅助任务。 来自变换器的加密业务双向编码器表示(ET-BERT)模型被预训练。 获得带宽和持续时间分频器的最佳值。 将最优值转换为用于批处理优化的令牌和用于训练的Adam优化器。 对所述预训练的ETBERT模型中的参数进行微调。 使用微调参数后的ET-BERT模型执行主任务流类型预测过程。包括独立权利要求用于：(1)用于存储指令集并且由处理器执行的计算机可读存储介质，所述处理器用于基于多任务学习来执行ET-BERT流分类； (2)一种设备，包括存储器和处理器，所述处理器用于执行用于基于多任务学习执行ET-BERT流分类的指令集。  12
本发明公开了一种基于实时流数据的实体和关系提取方法，采用改进的编码器‑解码器结构，融合卷积神经网络和自注意力对非结构化文本数据中的实体和关系进行抽取，在此基础上融合实体的分类信息构建实体关系联合抽取模型，步骤包括：1)：构建目标领域语料库及清洗数据集，对实体和关系进行人工标注。2)：将文本转成可识别的数值形式，并经过以BERT和CNN构成的编码器，结合自注意力机制提取深度特征向量。3)：使用以LSTM为主干的树状序列解码器来代替一维线性解码。4)：利用每个解码步骤的log‑loss损失函数的总和指导模型训练，总损失函数收敛后得到实体关系三元组，有效提高实体关系提取的准确性。基于实时流式数据进行实体和关系抽取的方法。该方法有效利用了自注意力机制的BERT和卷积神经网络信息敏感，结合作为编码器，可以对长序列的不同部分进行不同的注意力权重，并提取实体间上下文的局部信息，从而得到每个词的有效强特征。 该方法利用每个解码步骤的log‑loss loss损失函数之和来指导模型训练，在总损失函数收敛后，得到实体关系三元组，有效提高了实体关系提取的准确率。该方法涉及开发网络爬虫程序，抓取特定URL的非结构化文本，通过数据集预处理步骤去除网页导航、广告、文本重复和转义字符。 采用分词工具对文本进行分词，设置停用词集合。 对所述实体关系及其类型三元组进行标注，从而得到对应的训练标签集和完整的数据集。 对超参数进行调整，以获得更符合真实世界条件的参数设置，以提高模型性能。 基于所提供的目标场数据获得具有最佳性能的模型提供。 将测试集数据输入模型后对最终结果进行预测，并与人工标注的标签进行比较。 得到模型在测试集上的精度。  11
本发明公开一种中文分词的方法、装置和存储介质，属于自然语言处理技术领域。该中文分词的方法，包括以下步骤：S1、获取待检测句子的第二语言译文句子；S2、使用中文Bert预训练语言模型对待检测句子进行编码，获取整个句子语义信息的向量表征和句子向量表征序列；S3、使用第二语言Bert预训练语言模型对译文句子进行编码，获取整个句子语义信息的向量表征；S4、融合待检测句子和译文句子语义特征，得到待检测句子的每个字的预测类别；S5、按照预测类别，对待检测句子切分，得到分词结果。该方法提高了分词的准确性，尤其对于外来词具有较好分词效果。一种用于自然语言处理技术领域的中文分词方法。该方法提高了分词的准确性，对于外文词具有较好的分词效果。该方法包括获得(S1)待检测句子的第二语言翻译句子。 使用中文Bert预训练语言模型对句子进行编码(S2)，以获得整个句子语义信息的向量表示和句子向量表示序列。 利用(S3)所述翻译语句对所述翻译语句进行编码，得到整句语义信息的向量表示。 将所述待检测语句和所述翻译语句语义特征进行融合(S4)，得到所述语句的每个词的预测类型。 根据所述预测类型对句子进行分词(S5)，得到分词结果。独立权利要求包括用于：(1)中文分词装置； (2)—种存储介质，包括用于执行中文分词方法的指令集。  12
本发明公开了一种中医处方生成方法、装置、设备及存储介质，其中，中医处方生成方法包括：获取目标患者的目标症状字符序列；将目标症状字符序列输入至中药预测网络模型中进行中药预测，中药预测网络模型是通过对样本中药字符序列进行掩码方式，对预训练模型进行微调获得的；根据中药预测网络模型输出的目标中药字符序列，确定目标患者的目标中医处方。本发明实施例的技术方案，利用对预训练模型进行微调获得的中药预测网络模型，可以自动生成更加准确的中医处方，在中医为患者配置处方过程中，为中医提供较为科学的处方参考，提升了诊疗效率，保证了诊疗效果。一种中药处方生成方法。该方法使得在患者配置处方的开具过程中，能够利用微调预训练模型得到的中医预测网络模型自动生成更加准确的中医处方，为中医提供科学的处方参考，提高诊疗效率，保证诊疗效果。所述方法包括获得(S110)目标患者的目标症状特征序列。 将所述目标症状的字符序列输入所述中医药预测网络模型进行中医药预测，通过掩蔽所述样本中医药的字符序列对所述预训练模型进行微调，得到所述中医药预测网络模型(S120)。 根据所述中医药预测网络模型输出的目标中医药特征序列，确定(S130)针对所述目标患者的目标中药(TCM)处方。 获取样本患者对应的样本症状字符序列和样本中药字符序列。本发明还公开了一种用于生成中药处方的装置; 以及计算机可读存储介质，其存储用于生成中药(TCM)处方的程序。  10
本发明公开了一种意图识别方法和意图识别装置，方法部分包括：获取待识别句子；通过嵌入层将所述待识别句子转化得到第一向量、第二向量和第三向量；分别对所述第一向量和第二向量进行线性映射，得到第一映射向量和第二映射向量；根据所述第一映射向量获取第一注意力向量，并根据第二映射向量获取第二注意力向量；根据所述第一注意力向量获取第一句子向量，并根据所述第二注意力向量获取第二句子向量；根据所述第一句子向量和所述第二句子向量获取目标句子向量；将所述目标句子向量输入Bert模型的线性层进行意图识别，获取意图识别结果。该方法对于识别意图是有用的。识别意图包括：获取待识别语句； 通过所述嵌入层对所述待识别语句进行变换，得到第一向量， 第二载体和第三载体， 分别对所述第一向量和所述第二向量进行线性映射，得到第一映射向量和第二映射向量， 根据所述第一映射向量获取第一注意力向量， 根据所述第二映射向量得到第二注意力向量，根据所述第一注意力向量得到第一句向量，根据所述第二注意力向量得到第二句向量，根据所述第一句向量和所述第二句向量得到目标句向量。 所述方法进一步包括使用Word2vec(RTM：Group of related models for producing word embeddings)方法将待识别句子通过嵌入层转换为特征向量。还包括用于意图识别装置的独立权利要求。  12
本发明涉及一种基于深度学习的高并行性阅读理解的方法，包括数据预处理，嵌入层，编码层，交互层，输出层。使用bert模型对预训练进行优化；使用Octave卷积替换原模型中的深度可分离卷积。本发明在原有的高并行机器阅读理解算法——QANet的基础上，改进其嵌入层和编码块的结构，将嵌入层的预训练模型改为BERT，并重构了整个编码块。在编码块中应用了多头自注意力机制，固定了编码块的卷积层的数量，并将本次设计的编码块内所需用到的所有卷积层都改为Octave卷积。并提出将参数量较少其计算较快的的深度可分离卷积应用于Octave卷积中，提升Octave卷积在提升速度的同时提升模型的泛化能力，并将之应用于机器阅读理解任务。基于深度学习的高并行阅读理解方法。该方法能够在倍频程卷积与提升速度相同的情况下，提高模型的泛化能力，适用于机器阅读理解任务。该方法包括执行数据预处理、嵌入层、编码层、交互层和输出层。 确定答案初始索引和答案全文。 根据模型计算结束指数。 得到结构化存储反汇编数据。 构建深度学习帧的数据集类。 确定答案在文章中的字符位置。 确定数据集文本的字符长度。 生成掩模矩阵。 确定有效部分值。 确定卷积层的行号。 确定一维卷积的输入通道和输出通道。  12
本发明涉及自然语言处理技术领域，特别涉及一种基于预训练语言模型的检索增强方法、系统及计算机可读存储介质，包括以下步骤：获取预设语料库中的多个文本，将多个文本输入预训练语言模型得到每个文本的向量表示；基于节点的数量将每个文本的向量表示对应分发给多个节点，得到多个节点的文本向量表示；将每个节点的文本向量表示输入预设检索库建立索引，得到每个文本的向量索引；预训练语言模型可以学习到文本的信息，能够更加精准地表示文本，此外每个节点处理一部分向量，采用分布式实现检索速度的提升和检索量级的扩大，预设检索库的设置可实现秒级别的相似度向量检索，加快向量索引的速度，解决现有的存在检索效率较低的问题。用于增强基于预训练语言模型的搜索的方法可用于自然语言处理技术领域。该方法：可以通过预先训练语言模型来学习文本信息； 能够更准确地表示文字； 利用分布式可以实现搜索速度的放大和搜索等级的扩展； 可以设置预设的搜索库实现二级的相似度向量搜索； 加快了向量索引的速度； 解决了现有搜索效率低的问题； 可以由用户根据需求选择搜索算法； 可根据精度选择内存或内存数据的大小； 且实用性强。该方法包括获取预设语料中的多个文本，将多个文本输入预训练语言模型以获得每个文本的向量表示，基于节点数量将每个文本的向量表示对应分配给多个节点以获得多个节点的文本向量表示，将每个节点的文本向量输入预设检索库以建立索引，获得每个文本的向量索引。还包括如下独立权利要求：一种基于预训练语言模型的搜索增强系统； 以及计算机可读存储介质，其包括用于基于预训练语言模型来增强搜索的指令集。  12
本发明公开了一种基于WSD层级记忆网络的文档建模分类方法。首先，通过Bert算法基于词向量得到相似句子文本的句嵌入矩阵，以获得词语之间语义信息；然后，将句子映射到句嵌入矩阵空间得到句子的向量化表示；最后，将分完句文档的序列数据输入到BiLSTM模型中，同时获取每个句子的注意力权重，得到文档的向量化表示，保留了文档内部语义联系。本发明方法可有效获取一种准确度最高的文档建模，充分考虑到词句级联的层次关系，增加文档建模内部的语义联系，对于类间数据相似性较高的文档分类更加准确。基于WSD分级内存网络的文档建模与分类方法。该方法能够有效提高文档建模精度，考虑词的层次关系，增加文档建模内部的语义关系，实现类间相似度高的文档分类。该方法包括输入文档语料库(S1)。 定义待清理文档数据集。 文档是分段的。 标点符号被去除。 建立Bert模型(S2)。 从所述文档数据集中提取句子文本数据集。 进行分词。 每个词被转换成固定维度的向量。 得到文本句子向量空间矩阵。 将待处理文档数据集映射(S3)到所述文本句子向量空间矩阵中，用于获得待分类文档数据集。 将待处理文档数据集输入(S4)到BiLSTM中。 基于语义表示得到向量化文档。 文档由Softmax层分类。 输出文档分类的概率。  12
本发明提供了一种车辆故障诊断与预防方法，包括以下步骤：S1，根据用户信息查询数据库获取与当前用户问题相关的历史报障信息，并衡量历史报障信息与该用户问题的相似度，再通过相似度筛选出相似问题；S2，根据关系抽取模型CasRel对用户提供的问题进行关键实体信息和现象关系抽取；S3，采用GNN模型对所有相关的历史报障信息与抽取的关键实体息和现象关系生成专业性的提示集合；利用知识图谱系统生成专业性的提示；通过结合知识图谱系统和经过汽车专业数据微调的大型语言模型，实现更准确、高效和自适应的车辆故障诊断。同时可根据实际业务需求对生成的诊断结果进行多样化的后处理，使其更适合各种使用场景。车辆故障诊断及预防方法。该方法能够将知识图谱系统与汽车专业数据精细调整的大型语言模型相结合，实现准确、高效、自适应的汽车故障诊断，并根据实际服务需求对生成的诊断结果进行多样化的后处理。该方法包括根据用户信息查询(S1)数据库以获得与当前用户问题相关的历史故障报告信息。 对历史故障上报信息与用户问题之间的相似度进行度量。 通过相似度筛选相似问题。 根据关系抽取模型抽取用户提供的问题的关键实体信息和现象关系(S2)。 采用GNN模型生成相关历史报障信息和提取的关键实体信息与现象关系的专业提示集。 利用知识地图系统生成专业提示(S3)。 对汽车专业数据集和生成的专业提示集进行大规模语言模型精调训练(S4)以生成专业流畅的回复。将用户信息查询和生成的专业提示进行拼接，得到(S5)输入栏。 将所述输入列发送至所述大规模语言模型，以生成最终诊断结果。 将生成的最终诊断结果转换(S6)为特定服务场景所需的语言表达。 13
本发明实施例涉及人工智能领域，公开了一种基于语言模型的文本检索方法、装置、设备及存储介质，该方法包括：获取已标注的数据集，数据集包括多个已标注的语义相同的句子；从已标注的数据集中提取句子特征向量，并将句子特征向量输入预训练的Bert模型中进行训练，得到句向量模型；将待检索数据输入句向量模型中，得到待检索数据的句向量；计算预设的向量矩阵库中各个第一向量矩阵与待检索数据的句向量的相似度；根据相似度确定与待检索数据的句向量对应的索引，并根据索引从预设的数据库中确定与待检索数据对应的句子，从而提高文本检索的准确率和效率。本发明涉及区块链技术，如可将数据集写入区块链中，以用于数据取证等场景。用于在搜索引擎中基于语言模型检索文本的方法。本发明通过训练句子向量模型，利用预置的向量矩阵库中的第一向量矩阵对应的待检索数据对句子向量模型进行训练，确定待检索数据对应的句子，从而提高了文本检索的准确性和效率。 提高了文本检索的效率和准确性。所述方法包括获得标记数据组(S101)，其中所述标记数据组包括具有相同语义的多个句子。 从标记数据组中提取句子特征向量(S102)。 获取待检索数据(S103)，其中将待检索数据输入句子向量模型以获取句子向量。 根据语句向量计算(S104)预设向量矩阵库语句向量中的第一向量矩阵与待检索数据之间的相似性。 根据相似度确定对应于句子向量的索引(S105)。 根据索引从预设数据库中确定与待检索数据对应的句子。独立的权利要求书包括： (1)一种基于语言模型在搜索引擎中检索文本的装置； (2)计算机设备； (3)一种计算机可读存储介质，用于存储一组指令，用于基于语言模型在搜索引擎中检索文本。  12
本发明涉及人工智能技术领域，提供一种文本摘要生成方法、装置、电子设备及存储介质，提取语料文本中的第一命名实体，从而基于语料文本及第一命名实体生成训练文本并基于多个训练文本训练BERT模型，通过训练得到的BERT模型输出预测文本摘要，在获取预测文本摘要中的第二命名实体之后，根据第一命名实体、预测文本摘要及第二命名实体生成整体风险损失值，从而基于整体风险损失值优化所述BERT模型，得到文本摘要生成模型，最后使用文本摘要生成模型生成目标文本的文本摘要。本发明通过引入命名实体训练BERT模型，再通过BERT模型预测文本摘要，提高了文本摘要中命名实体的准确度，从而减少了文本摘要中命名实体错误的情况，提高了生成文本摘要的准确度。一种用于人工智能领域的文本摘要生成方法。本发明通过引入命名实体，减少了生成文本摘要命名实体出错的情况，从而提高了生成文本摘要的准确性，进而减少了文本摘要中命名实体出错的情况。该方法包括获取(S11)多个语料库文本，以及提取每个语料库文本中的第一命名实体。 基于该语料库文本和相应的第一命名实体来生成训练文本(S12)，并且基于多个训练文本来训练来自变压器(BERT)模型的双向编码器表示。 获得由BERT模型输出的预测文本摘要(S13)，并且获得预测文本摘要中的第二命名实体。 根据第一命名实体，预测文本摘要和第二命名实体生成(S14)总风险损失值。 基于总风险损失值优化(BERT)模型，以获得文本摘要生成模型。 通过使用文本摘要生成模型来生成(S16)目标文本的文本摘要。独立的权利要求书被包括在以下内容中： (1)用于生成文本摘要的装置； (2)用于生成文本摘要的电子设备； 以及 (3)存储用于生成文本摘要的程序的计算机可读存储介质。  12
本发明实施例公开了一种数据查询语句生成方法、装置、设备及存储介质，包括：获取过程展示需求和待转换自然语句；根据过程展示需求构建提示词指令；基于提示词指令将待转换自然语句输入至预训练的数据查询语句生成模型，根据模型输出结果确定并输出与过程展示需求对应的中间生成结果和目标数据查询语句；其中，预训练的数据查询语句生成模型为基于预构建的思维链训练得到的生成式大语言模型，预构建的思维链为对数据查询语句对应逻辑计划进行逻辑切分后构建得到的思维链。明确了基于逻辑驱动的待转换自然语句至目标数据查询语句的转换过程，使得语句转换处理过程可测可控，提升了针对输出结果的可解释性和目标数据查询语句生成过程的透明性。数据查询语句生成方法。该方法使得从基于逻辑驱动的待转换自然语句到目标数据查询语句的转换过程提升清晰，使得语句转换处理过程可测控，提高了输出结果的可解释性和目标语句生成过程的透明度。该方法包括获取过程显示需求和待转换的自然语句。 根据流程显示需求构建提示词指令。 基于所述提示词指令将所述自然语句输入预先训练的数据查询语句生成模型。 确定与所述目标数据查询语句对应的中间生成结果并输出。 根据模型输出结果确定所述过程显示需求。 所述数据查询是对应于数据查询序列生成的。 对数据查询对应的逻辑方案进行逻辑切分得到预先构建的思想链。包括独立权利要求，用于：(1)数据查询语句生成装置； (2)一种计算机可读存储介质，用于存储一组数据查询语句生成方法的指令。  11
本发明公开了一种基于交错结构的半监督医学图像分割方法，该方法将分割模型U‑Net作为骨干网络，构建了半监督分割架构Mean TeacherU‑Net，该架构对有监督部分的预测与标签进行约束，并加强了学生模型的预测与教师模型的预测的一致性；使用交错结构对模型的性能进行了提升，交错结构包括时序上的交错结构和方向上的交错结构，这两种结构进一步约束了学生模型中间层的特征图与教师模型中间层的特征图。本发明加强了网络编码与解码过程中，特征图的相关性以及学生模型和教师模型的一致性，从而提升了分割效果，具有较高实用价值。基于交织结构的半监督医学图像分割方法，使用U-Net模型作为骨干网络，用于机器学习和作为人类学习的模型。该方法在网络编解码过程中加强特征图像的相关性和学生模型与教师模型的一致性从而提高分割效果，具有很高的实用价值。 通过采用交错结构，提高了模型的性能。该方法包括对需要分割的医学图像进行预处理，得到有标记和无标记数据，构建基于交错结构半监督分割模型的方法，以U‑Net模型为骨干网络，构建半监督架构均值TeacherU‑Net，提取架构中学生模型和教师模型的中间层，在时序和方向上形成交错结构，利用有标记和无标记数据训练分割模型，利用训练好的模型在目标图像上进行测试，得到分割结果。   6
本发明提供了一种基于消融的大模型示例选择方法，包括：搭建用户问题表征模型，并基于数据库对其进行训练，通过训练后的用户问题表征模型获取用户问题相关的示例，搭建第一语言模型及第二语言模型，并将用户问题及相关的示例输入第一语言模型中。本发明提供的基于消融的大模型示例选择方法，能够在已有的数据库中获取合适的示例，帮助大模型生成更好的回复。基于烧蚀的大型模型实例选择方法，用于基于烧蚀的大型语言模型中。大模型实例选择方法可以在现有数据库中获取合适的实例，帮助大模型产生更好的回复。大模型实例选择方法涉及建立用户问题表征模型。 基于数据库训练所述用户问题分类模型。 通过训练后的用户问题分类模型得到与用户问题相关的示例。 构建第一语言模型和第二语言模型。 将用户问题和相关示例输入到第一和第二语言模型中。 建立用户问题表征模型，并基于数据库进行训练。  11
本发明公开一种变工况下航空发动机自监督表征与寿命预测迁移建模方法，首先构建了基于自注意力机制的航空发动机退化特征提取器，该特征提取器能够有效利用航空发动机中的时序上下文长短期依赖进行全局建模，提取退化特征。在此基础上利用对原始数据掩码并重构的方式自监督预训练该特征提取器，使特征提取器所提取到的特征更强的泛化表征能力，然后在复杂工况场景下为该特征提取器添加寿命预测网络层并微调，实现变工况下航空发动机迁移建模与高效的寿命预测。该方法降低了基于端到端深度学习的航空发动机寿命预测模型对训练数据量以及数据分布的要求，为运维决策人员提供了更加可靠的参考，能够在降低运维成本的同时提高航空发动机的运行可靠性。航空发动机变工况下自监测表征与寿命预测迁移建模方法。该方法能够满足基于端到端深度学习的航空发动机寿命预测模型对训练数据量和数据分布的要求，为维修决策人员提供可靠参考，降低维修成本，提高航空发动机运行可靠性，实现航空发动机在变工况下迁移的模型和高效预测。该方法包括连接多个传感器数据的每个操作时段的航空发动机操作数据和当前操作时间。 在复杂工况下的航空发动机剩余寿命预测数据集中取每个样本作为变工况航空发动机高效寿命预测的神经网络模型的输入。 通过最小化模型输出和标签的损失来训练目标。 得到航空发动机在变工况下的神经网络‑效率寿命预测模型。 13
本发明提供一种端到端的语言模型预训练方法、系统、设备及存储介质。所述方法包括：根据预设的知识相近判断规则，从现有知识库中检索得到与输入的知识片段的知识相近的现有知识片段；将输入的所述知识片段和检索到的所述现有知识片段进行拼接，得到拼接知识片段；将所述拼接知识片段进行掩码处理；将掩码后的拼接知识片段作为语言模型预训练的输入进行预测训练，完成端到端的语言模型预训练。本发明利用预设的相近判断规则，通过检索在现有知识库中进行相近的现有知识片段的检索，减小了训练时模型对参数的需求，从而使得语言模型能够基于检索增强利用外部知识，提高了语言模型训练的效率。一种端到端语言模型的预训练方法。通过检索对现有知识库中相似的现有知识片段进行检索，减少了训练时对模型参数的需求，使得语言模型能够在检索的基础上增强对外部知识的使用，提高语言模型训练的效率。该方法包括根据预设的知识相似度判断规则从现有知识库中检索(101)与输入知识片段相似的现有知识片段。 拼接(102)输入知识片段和检索到的现有知识片段，以获得拼接的知识片段。 掩蔽(103)拼接的知识片段。 使用(104)屏蔽的拼接知识片段作为预测训练的语言模型预训练的输入，并且完成端到端语言模型预训练。独立的权利要求书被包括在以下内容中： 一种用于预训练端到端语言模型的系统； 一种用于预先训练端到端语言模型的电子设备； 以及 一种存储用于预训练端到端语言模型的程序的计算机可读存储介质。  11
本发明公开了一种基于预训练神经网络的因果性问答对匹配方法，该方法首先利用预训练模型BERT对问题句子和候选答案句子进行编码得到相应的句子嵌入；然后模型通过卷积或链接方式充分利用句子嵌入的上下文信息，并根据问答句子对的分类特征、上下文的局部显著特征和整体特征得到问答句子对相关的因果特征；最后由全连接网络构成的分类器判断因果极性。本发明充分利用了预训练模型学到的上下文相关的编码信息，能捕获问答句子对编码的因果特征，在COPA和SOCIAL IQA两个关于因果性问答对的数据集上的匹配效果可以达到目前研究的先进水平。一种基于预训练神经网络的因果问答对匹配方法。该方法能够充分利用预训练模型学习到的上下文相关编码信息，捕捉问答句对的因果特征； 通过对因果问答对的似然选择(COPA)和社会交互问答(IQA)两个数据集的匹配作用，可以达到当前研究的先进水平。所述方法包括构建烧灼问答对分类网络。 它具有输入层，编码层，特征提取层和分类层。 通过字典索引将提问句子和候选答案句子的词标记转换为词嵌入。 编码层将字嵌入来自变压器(BERT)的输入预训练模型双向编码器表示中。 计算待测问答句对的烧灼极性匹配分数，得到烧灼极性判断结果。  12
本公开实施例中提供了一种铝电解槽过热度识别方法、系统、设备及介质，属于数据处理技术领域，具体包括：选取多种类型的生产数据作为样本数据集；添加标签并进行同构化处理，得到训练集和验证集；构建基于自注意力机制的初始识别模型；利用编码‑解码方法和样本数据集对初始识别模型进行预训练，完成初始化；根据训练集和验证集的加权交叉熵损失训练初始化后的初始识别模型，得到目标识别模型；采集当前时段的生产数据进行同构化处理后输入目标识别模型，得到识别结果。通过本公开的方案，构建基于自注意力机制的初始识别模型，并进行无监督预训练以及使用加权交叉熵损失函数以降低分类模型的有偏性，提高了识别的适应性、识别效率和精准度。一种用于识别用于数据处理领域的铝电解槽的过热度的方法。本发明能够构造基于自注意机制的初始识别模型，以简单的方式进行无监督的预训练过程，并利用加权交叉熵损失函数减小分类模型的偏差，从而提高过热度识别的适应性，效率和准确性。该方法包括从铝电解生产数据组中选择多种类型的生产数据作为样本数据组(S101)。 将标签添加(S102)到样本数据集，用于处理相同的结构并获得训练集和验证集。 基于所述自注意机制构造(S103)初始识别模型。 通过执行编码-解码处理来预训练(S104)初始识别模型。 获得目标识别模型(S105)。 收集当前时间段的生产数据，并在处理相同纹理化处理之后将其输入(S106)到目标识别模型中，以获得识别结果。独立的权利要求书包括： (a)一种用于识别铝电解槽过热度的系统； (b)包括存储器和用于识别铝电解槽过热度的处理器的计算机设备； 以及 (c)用于存储一组用于识别铝电解槽过热度的指令的非瞬态计算机可读存储介质。  11
本发明公开了一种基于图卷积网络的试题文本中情感与原因的句子配对抽取方法，所述方法包括以下步骤：获取试题文本数据，对数据进行分句预处理；使用BERT预训练语言模型将句子转换成向量表示；使用全连接层网络将句子表示生成对应的配对组合表示；使用相对位置嵌入向量增强配对组合表示向量；对句子向量表示使用平均池化得到文档表示；使用图卷积网络对情感句子、原因句子、配对组合和文档四种表示进行编码交互；最后使用多层感知机模型预测配对组合是否成立。本发明在建模配对组合时充分考虑了配对组合中两个句子之间的因果关系，能够有效避免错误配对组合被预测成立的情况，从而提高预测的准确率。一种基于图卷积网络的试题文本中情感原因句对的提取方法。该方法在建模时对句子和配对组合进行编码，充分考虑了情感原因配对中两句子之间的因果关系，可有效减少错误预测的发生。 本发明通过将文本中的句子拆分为情感句子，并对原因句子进行建模，使得模型更有针对性地学习句子的相关情感或相关原因。 本发明能够有效避免预测建立错误配对组合的情况，从而提高预测的准确性。该方法包括向BERT输入预训练语言模型，并获得每个句子的向量。 获得表示每两个拼接的每个句子的向量。 获得增强的配对组合表示。 获得文档表示，以获得作为平均池的所有句子向量，从而获得句子向量表示的维度。 配对组合节点的特征信息与相应的情感句和原因句节点向量表示相连。 根据模型输出结果和数据的真实结果，最小化交叉熵损失函数迭代训练模型更新参数。 将训练好的模型用于测试集，得到文本集中情感和原因的句子配对。  12
本发明公开了一种对话话语的编码方法和装置，涉及人工智能技术领域。该方法的一具体实施方式包括：构建数据集，所述数据集包括正样本和负样本，所述正样本包括对话话语及其所属领域，所述负样本包括对话话语及其非所属领域；基于对比学习算法并采用所述数据集对预训练语言模型进行参数调整，从而得到编码器；采用所述编码器对目标对话话语进行编码。该实施方式能够解决领域与对话话语之间没有语义对应关系的技术问题。会话语音的编码方法。该方法能够将对话语音与语义通道的领域进行拟合，以建立对话语音与领域之间精确的语义映射关系，从而对预训练语言模型进行精细调整，使得对话状态跟踪模型能够容易、高效地建立对话语音与领域的相关性。所述方法包括构建(S101)数据集，其中，所述数据集包括正样本和负样本，所述正样本包括对话语音且属于领域，所述负样本包括对话语音且不属于领域。 基于比较学习算法调整预训练语言模型的参数并利用数据组(S102)调整参数以获得编码器，以及利用编码器(S103)对目标对话语音进行编码。包括以下独立权利要求：用于会话语音的编码设备； 电子设备； 存储会话语音的编码程序的计算机可读介质； 以及会话语音的编码的计算机程序产品。 8
本发明是一种基于循环残差U‑Net网络的医学图像分割方法。本发明在深度残差模型、循环卷积网络和U‑Net模型基础上，提出了两种分别加入了循环卷积单元的U‑Net和循环残差卷积操作的U‑Net的分割模型。本发明引入了循环卷积单元和残差卷积单元，较好的解决了分割任务中数据缺乏和分类不平衡的问题。由于循环结构和残差结构只是从结构上改变了网络，并没有增加额外的参数，在分割任务上表现出更好的性能。循环和残差的操作并没有增加网络参数的数量，对训练和测试性能有显著性提高。基于循环残差U-Net网络的医学图像分割方法。该方法引入了循环卷积单元和残差卷积单元，解决了分割任务中缺少数据和分类不均衡的问题。 该方法改变了循环结构和残差结构中的网络结构，不需要额外的参数，从而保证了分割任务的更好性能，提高了训练和测试性能。该方法涉及选择数据单元来预处理图像。 卷积单元编码结构和单步反向卷积单元，用循环单元的解码结构组成循环卷积单元。 在循环单元和残差单元中增加反卷积单元，形成循环残差卷积单元。 变体U-Net网络由训练策略提供。 计算得到初始学习率、层学习率、动量、权重衰减系数和训练策略。 分割后的数据通过数据输入到训练好的网络模型中。 计算评价指标的精度、灵敏度、特殊性分数、骰子系数和笛卡尔指数。   6
本申请公开了一种地域实体的识别方法及装置，涉及人工智能领域。其中，方法具体包括：将待训练地域文本中的待训练地域实体对应的词向量和待训练地域实体中的每个字对应的字特征进行融合，以得到字向量；根据待训练地域实体对应的地域实体描述和字向量对第一预训练模型进行训练，得到地域文本实体识别模型；利用地域文本实体识别模型，识别待识别地域文本的地域实体。应用本申请能让地域文本实体识别模型找到与输入的地域实体描述最相关的地域实体，即实现在最终分类中更加倾向于与地域实体描述相关的地域实体，进而实现通过词向量、字特征和地域实体描述来提高地域文本实体识别模型的识别准确率，以此提高地域实体识别的准确度。一种识别地域实体的方法，应用于人工智能技术领域，特别是一种地理实体的识别方法及装置。 可用于如车站，机场，地铁线路等地理实体。该方法使得实现区域文本实体识别模型能够通过词向量找到与输入的区域实体最相关的区域实体来实现， 文字特征和区域实体描述提高了区域文本实体识别模型的识别准确率，从而提高了区域实体识别的准确率。该方法包括融合与待训练区域文本中的待训练区域实体相对应的词向量和与待训练区域实体中的每个词相对应的词特征。 获得与所述待训练区域实体中的每个词相对应的词向量。 根据待训练区域实体对应的区域实体描述和词向量训练第一预训练模型。 得到区域文本实体识别模型。 使用区域文本实体识别模型来识别待识别的区域文本的区域实体。本发明还涉及一种区域实体的识别装置。  12
本发明涉及数字数据处理技术领域，提出了基于NLP和循环神经网络的大语言模型构建方法，包括：根据分词结果确定标准数据集中每个字的标签；根据每个字与专业字典中每个词语的词向量之间的相似度确定字意匹配度；根据文本序列内的分词结果在专业字典中出现的频率确定上下文语境匹配得分；根据词语的重要性以及上下文语境匹配得分确定词性特征得分；根据词性特征得分、字意匹配度确定状态特征函数与转移特征函数；采用条件随机场基于状态特征函数与转移特征函数获取标准数据集的标注结果；基于标注结果构建基于循环神经网络的大语言模型。本发明利用改进后的条件随机场对标准数据集进行标注，提高了大语言模型捕捉输入数据中颗粒信息的能力。一种基于自然语言处理(NLP)和循环神经网络的大型语言模型的构建方法，应用于问答系统、语音识别、智能助理等领域。该方法利用改进的条件随机场对标准数据集进行标注，提高了大型语言模型捕获输入数据中粒子信息的能力。该方法涉及根据标准数据集中每个句子的分词结果，确定(S001)标准数据集中每个词的标签。 根据所述标准数据集中各词与所述专业词典中各词的词向量的相似度，确定(S002)所述标准数据集中各词的词匹配度。 确定每个词的词性特征分数(S003)。 根据所述标准数据集中每个词的词性特征得分和每个词的词匹配度确定状态特征函数和转移特征函数。 通过条件随机场基于状态特征函数和转移特征函数得到标准数据集的标注结果。 基于所述标准数据集的标记结果，基于所述循环神经网络构建大型语言模型。  12
本发明公开了一种网页实体提取方法、装置、计算机设备及存储介质，该方法包括：将网页转化为p标签对应的p格式网页、p标签和table标签混合对应的ptb格式网页和table标签对应的tb格式网页；对p格式网页进行解析，并映射为第一字典；以及对tb格式网页进行解析，并映射为第二字典；将第一字典和第二字典融合为第三字典，并将第一字典、第二字典和第三字典融合为目标字典；采用BM25算法对目标字典进行相似性粗排；通过BERT模型对候选实体进行文本向量化处理；通过余弦相似度算法对候选实体与预设的实体字典中对应类型实体计算相似度，并选取各个实体类型相似度最高的候选实体作为目标实体。本发明实施例可以提高网页实体提取精度和投标人的投标中标效率。一种计算机软件领域的网页实体抽取方法。本发明通过将网页分类为不同的格式并进行相应的分析，从而结合BM25算法和BERT模型提取出与真实实体最相似的实体，提高了网页实体提取的精度和投标人的中标效率。该方法包括获得包含投标信息和投标信息的多个网页(S101)。 分析p型格式网页(S102)。 将分析结果映射到第一字典。 映射第二字典的分析结果。 将第一字典和第二字典合并(S103)成对应于电源标签(ptb)格式网页的第三字典。 将所述第一字典、所述第二字典和所述第三字典合并为目标字典。 利用最佳匹配25(BM25)算法对所述目标字典和预设实体字典中的不同类型实体进行相似度粗行(S104)。 在相似度粗略行结果中选取前N型实体作为对应的候选实体。 通过双向编码器表示来自变换器(BERT)模型对候选实体执行文本矢量化处理操作(S105)。包括独立权利要求：(1)一种用于提取网页实体的装置； (2)一种计算机设备，包括存储器和用于执行用于提取网页实体的指令集的处理器； (3)一种计算机可读存储介质，用于存储由处理器执行的用于提取网页实体的一组指令。 该方法涉及通过余弦相似度算法计算(S106)与预设实体词典中的对应类型实体的相似度。 选择实体类型相似度高的候选实体作为目标实体。 对所述目标实体执行匹配验证处理(S107)。 收集匹配验证结果作为网页实体的抽取结果。  11
本发明公开了一种基于FPGA的硬件感知可微分BERT层头剪枝方法。其包括以下步骤：引入可微分NAS的思路，为预训练好的BERT模型的每一个编码层，每一个注意力头，每一个前馈神经网络FFN维度均设置一个架构参数；对单层BERT模型进行仿真，得到四个模块的时延和功耗结果；计算单维子模块对应的时延Ls分数和功耗Ps分数；计算完整模型的Lf分数和Pf分数；训练更新模型的权重参数和，最小化完整的loss；模型训练收敛后，对于小于阈值的，将其对应的模型结构剪枝掉。本发明可在没有精度损失的情况下，将BERT‑base模型参数量压缩1.8倍，同时在FPGA上的推理时延缩小2.1倍，功耗降低1.9倍。一种基于FPGA的硬件感知可区分BERT层头部剪枝方法该方法在不损失精度的情况下将BERTbase模型的参数压缩1.8倍，将FPGA上的推理时延降低2.1倍，功耗降低1.9倍。该方法引入可微NAS的思想，为预训练的BERT模型的每个编码层、每个注意力头和每个前馈神经网络FFN维设置一个架构参数。 对预先训练好的BERT模型中的单层进行仿真。 得到单层BERT模型中四个模块的时延和功耗综合结果。 对小于阈值的架构参数进行相应的模型结构剪枝，实现对具有架构参数的BERT模型训练收敛后的BERT模型的层头的混合剪枝。 所述修剪后的模型结构选自编码层、注意力头或FFN中间维度中的一个或多个。  12
本发明提出了一种基于U‑Net网络的互联网广告点击率预估方法，主要用以解决现有互联网广告点击率预估方法中存在的预估精度低的技术问题，包括如下步骤：获取训练数据集和测试数据集；获取原始特征索引矩阵和原始特征值矩阵；基于深度卷积神经网络U‑Net构建点击率预估模型；对点击率预估模型进行训练；获取互联网广告点击率预估结果。本发明提出的基于U‑Net网络的互联网广告点击率预估方法，提高了互联网广告点击率预估模型的泛化能力，加强了对互联网广告数据深层特征的提取，明显地提高了点击率预估的精度，可应用于互联网广告投放领域。基于U-Net网络的互联网广告点击率估算方法。该方法能够提高互联网广告点击预测模型泛化能力，从而增强互联网广告数据特征提取过程，提高点击估计精度。该方法包括获得训练数据集和测试数据集。 得到原始特征指标矩阵和原始特征值矩阵。 在基于卷积深度的卷积模块的深度卷积神经网络中建立点击率预测模型。 建立所述神经网络的收缩路径。 嵌套卷积模块路径由卷积层扩展模块代替。 通过softmax分类器建立所述点击预测模型的输出层替换路径。 对所述点击率预测模型进行训练。 将所述测试数据集输入训练后的所述原始特征指标矩阵和所述原始特征值矩阵对应的点击率估算模型。 得到互联网广告点击率预测结果。   6
本公开提供了一种大语言模型的提示词信息的生成方法、装置、设备及介质，涉及机器学习与自然语言处理等人工智能技术领域。具体实现方案为：获取用户在使用大语言模型时的输入信息；基于所述输入信息和配置的参数信息，采用预先训练的提示词生成模型，生成目标提示词信息，所述目标提示词信息用于代替所述输入信息，输入至所述大语言模型中。本公开的技术，能够有效地生成更加丰富、内容更加全面、准确地目标提示词信息；进而采用该目标提示词信息代替用户的输入信息，输入至大语言模型，能够使得大语言模型能够更加高效、准确地生成回复文本信息。用于机器学习和自然语言处理等人工智能技术的大型语言模型的提示词信息的生成方法。该方法能够有效生成更丰富、更全面、更准确的目标提示词信息。 利用目标提示词信息代替用户的输入信息输入到大型语言模型中，可以使大型语言模型更高效、更准确地生成回复文本信息。该方法涉及在使用大型语言模型时获得(S101)用户输入信息。 利用预先训练的提示词生成模型(S102)基于所述输入信息和配置的参数信息生成目标提示词信息。 将所述目标提示词信息替换所述输入信息输入到所述语言大模型中。 获取所述预设的默认参数信息。 所述参数信息是用户对预先配置的参数信息进行调整后获取的。 参数信息包括提示字长、迭代轮次、优化质量和截尾优化缩短。独立权利要求包括用于以下的：用于生成大型语言模型的提示词信息的装置； 用于生成大型语言模型的提示词信息的电子设备； 以及存储有用于生成大型语言模型的提示词信息的程序的非暂态计算机可读存储介质； 以及用于生成大型语言模型的提示词信息的计算机程序产品。  11
本公开提供了一种模型训练设备的性能优化方法、装置及设备，涉及本公开涉及人工智能技术领域，尤其涉及深度学习、大模型训练、分布式并行策略等技术领域。具体实现方案为：确定当前模型训练设备针对目标排序位置的目标模型块的通信时机，以便于和多个模型训练设备中的其它模型训练设备能够针对目标排序位置的模型块进行同步调聚合通信；在通信时机，对目标模型块的反向梯度执行聚合通信。本公开实施例中通过使多个模型训练设备的通信时机基本保持一致，从而尽可能消除部分气泡，以提高设备的性能，进而可以最大程度地利用模型训练设备的并行计算能力。模型训练设备性能优化方法。多个模型训练装置的通信机会基本一致，尽可能的消除部分气泡，提高装置的性能，最大限度的利用模型训练装置的并行计算能力。该方法涉及确定(S101)当前模型训练设备针对目标测序位置的目标模型块与多个模型训练设备中的其他模型训练设备针对目标测序位置的模型块进行同步聚合通信的通信时间。 每个模型级包括多个依次排列的模型块。 气泡是由于采用分布式并行策略对目标模型进行训练的过程中，通过通信运算增加了模型训练设备的计算时间而产生的。 在通信时机对目标模型块的逆梯度执行聚合通信(S102)。独立权利要求书包括以下内容：一种模型训练设备的性能优化装置； 电子装置； 非瞬时计算机可读存储介质，其存储用于优化模型训练设备的性能的程序； 以及用于优化模型训练设备的性能的计算机程序产品。  11
本发明提供一种单文档抽取式文本摘要识别方法及系统，包括：数据预处理步骤：获取一段文档，拆分成多句话，组成文档集合D＝[S1, S2, ....Sn]，其中S1，S2，...，Sn表示文档中的每个句子；Ernie编码步骤：对获得文档集合D＝[S1, S2, ....Sn]分别进行Ernie处理，得到V＝[V1, V2, ....Vn]，其中，V1，V2，...，Vn表示经过Ernie编码后的每个句子向量；相似度计算步骤：计算V中两两的相似度，组合成以V为顶点，以相似度值为边的图结构；TextRank步骤：生成图结构后，进入TextRank层，计算句子评分，选取得分高的一个或多个句子生成摘要。本发明能够更好的捕获中文语义特征，做更好的表征学习。识别单一文档提取类型的文本摘要的方法，用于从多个信息源中提取关键信息。本发明能够利用Ernie编码捕获丰富的句子语义特征，更好地表现学习。 本发明使得数据预处理模块能够对准备数据，文档，拆分数据，删除停止字和过滤字的相关字进行清洗，从而能够高效地对文档进行清洗。该方法包括：获得文档；将文档拆分成多个句子；以及形成文档集。 分别对所获得的文档集执行Ernie处理，以获得Ernie编码后的每个句子向量。 计算成对顶点的相似度，组合成以V为顶点，相似度为边的图结构。 进入文本排序层，计算句子得分，生成图形结构后，选择得分高的几个句子生成摘要。本发明涉及一种用于识别文本摘要的系统和方法。  11
本发明公开了一种利用自适应的时空图模型通过提升视频‑语言表征学习来解决视频问答问题的方法及其系统，属于视频问答文本生成领域。首先，针对一组视频、问题、答案训练集，使用目标检测器获取每个视频帧的目标级别的信息。其次，对于目标级别的信息，使用自适应的时空图模型学到目标的动态表达。最后，使用Transformer模型学习视觉和文本信息之间的联系，增强视觉问答的性能。相比于一般的视频问答解决方案，本发明利用了自适应的时空图模型更好地获取了目标的时空动态信息，同时试图将不同视频帧的相同物体联系起来，更好地捕获动态信息，并采用了图片‑语言数据进行预训练来提升视频‑语言模型，提升了解决视频问答问题的效果。一种自适应时空图模型的方法。图片语言数据用于预训练，以改进视频语言模型，提高解决视频问答问题的效果。该方法涉及提取各视频帧中的目标级别特征用于目标检测技术，目标级别特征组合得到视频帧中的初始区域特征。 由多层时空图组成时空图模型，每层时空图包括空间图模型和时序图模型，所述空间图模型用于对区域特征进行空间更新，所述锚管对应所述视频帧中的每个目标区域构建并根据所述视频帧依次更新。包括用于利用自适应时空图模型的系统的独立权利要求。 9
本发明公开了一种游戏领域的知识图谱关系匹配模型构建方法，包括：获取开放领域的关系匹配数据集；基于TFIDF文本相似度的方法，从所述开放领域的关系匹配数据集中获取适用于所述游戏领域的关系匹配数据集；采集开放领域的自由文本，并对所述开放领域的自由文本进行预训练，构建语言模型；其中，所述语言模型为知识图谱关系匹配所需的模型结构；根据所述游戏领域的关系匹配数据集，对所述语言模型进行增量训练，以构建所述游戏领域的知识图谱关系匹配模型。采用本发明实施例，通过数据迁移的方法构建游戏领域的知识图谱关系匹配模型，解决了游戏领域数据不足的问题，提高了对游戏领域的知识图谱关系匹配的精准性和高效性。该方法对于构建游戏领域的知识图谱关系匹配模型是有用的。该方法解决了游戏领域数据不足的问题，提高了游戏领域知识图谱关系匹配的准确率和效率。构建博弈领域中的知识图谱关系匹配模型，包括：获取开放领域中的关系匹配数据集； 基于TFIDF文本相似度方法，从所述开放领域的关系匹配数据集中获取适用于所述博弈领域的关系匹配数据集； 收集开放领域的自由文本，并对开放领域的自由文本进行预训练，以构建语言模型所述语言模型为知识图谱关系匹配所需的模型结构； 根据博弈领域的关系匹配数据集，增量训练语言模型，构建博弈领域的知识图谱关系匹配模型。本发明还公开了一种构建游戏领域知识图谱关系匹配模型的装置。  12
本发明提供了一种基于招标信息的公司实体识别方法、装置、设备及介质，其中，方法包括：获取招投标信息的文本集合、组织机构集合以及资质类型集合；将招投标信息的文本集合和组织机构集合进行数据预处理，获取待标注数据集合；利用获取的组织机构数据对所述待标注数据集合进行标注和处理，得到标注数据集合；建立BERT‑BiLSTM‑CRF的实体识别模型，将所述标注数据集合输入所述实体识别模型，获取所述公司实体在文本中的位置信息，完成公司实体识别。本发明通过融合BERT、BiLSTM和CRF解决了传统实体识别方法中的问题，能够实现更准确的实体提取并适用于不同类型、长度和风格的文本，并且本发明提供的方法在识别招标信息中的公司实体方面取得了相当好的效果。用于基于竞价信息识别企业实体的方法。该方法使得能够融合来自变换器的双向编码器表示和双向长短期记忆，以实现针对不同类型的精确实体提取，并且在识别竞价信息中的企业实体方面取得可观的效果。该方法包括获取竞价信息的文本集合、组织机制集合和资格类型集合(S1)。 对所述竞价信息的文本集和组织机构集的数据进行预处理(S2)。 得到待标注数据集。 利用获得的组织机制数据对所述待标注数据集进行标注处理(S3)，得到已标注数据集。 将注释数据集输入(S4)到实体识别模型中。 获取企业实体在文本中的位置信息。 企业实体识别完成。独立权利要求包括用于：(1)用于基于竞价信息识别企业实体的装置； (2)一种电子设备，包括处理器和存储器，所述存储器存储用于基于竞价信息识别企业实体的指令集； (3)存储介质，其存储用于基于竞价信息识别企业实体的一组指令。  11
本申请公开了一种代码缺陷修复方法、装置、计算机设备及可读存储介质，涉及数字医疗技术领域，解决了目前存在开发人员常常花费大量时间人工修复代码缺陷，代码缺陷修复效率较低的问题。该方法包括：获取多个标记序列，采用多个标记序列对双模态预训练模型进行训练，更新模型参数，得到缺陷代码修复模型，获取当前源代码，将当前源代码输入至缺陷代码修复模型中，得到至少一个缺陷代码片段对应的至少一个修复增量向量，将至少一个修复增量向量翻译为至少一个缺陷代码片段对应的至少一个修复代码片段，基于至少一个修复代码片段对当前源代码进行热修复，得到修复源代码。代码缺陷修复方法。该方法通过避免人工修复代码缺陷，能够在短时间内提高代码缺陷修复效率。该方法包括获得多个标记序列以训练双模预训练模型(101)。 模型参数更新。 得到缺陷编码修复模型，所述标记序列由缺陷分类变量序列与对应的缺陷编码变量序列和正常编码变量序列匹配得到。 获得包括缺陷代码段的当前源代码并将其输入(102)到缺陷代码修复模型。 获取所述缺陷代码修复模型输出的缺陷代码段对应的修复增量向量。 将修复增量向量翻译(103)成对应于缺陷代码段的修复代码段。 基于所述修复代码段对所述当前源代码进行热修复(104)，得到修复源代码。包括独立权利要求：(1)一种代码缺陷修复设备； (2)一种计算机设备，包括用于修复代码缺陷的存储器和处理器； (3)一种存储用于修复代码缺陷的指令集的可读存储介质。  11
本发明公开了一种基于深度学习的地铁设计规范中实体关系联合抽取方法，利用词典文件构建名词哈希词典索引；将待处理《地铁设计规范》文本作为输入文本S1；对输入文本S1进行正向与逆向最大匹配算法处理并求二者结果的交集得到C1；将输入文本S1输入经过预训练的BERT模型进行编码，得到输入文本的字嵌入集合S2；对步骤4中得到的S2基于跨度选择文段进行实体抽取，对已存在于C1中的实体不进行处理；合并实体集合C1与C2，得到实体集合C3，对C3中的实体两两之间进行双向关系分类，得到实体关系集合C4。本发明的方法，识别准确率高，计算精简，便于应用。一种基于深度学习的地铁设计规范实体关系联合提取方法。本发明能够以方便的方式提取识别精度高，计算简单的实体关系节点。该方法涉及通过使用字典文件来构造术语散列字典索引。 字典文件由行业基础类(IFC)实体类标准构造。 包含在字典文件中的实体类被定义为实体类集。 将待处理句子作为输入文本。 对输入文本执行前向最大匹配算法处理以获得实体集。 对输入文本执行反向最大匹配算法处理以获得实体集。 获得输入文本的词嵌入集。 选择嵌入集合中的文本部分。 实体分类过滤过程由卷积分类器执行。 从实体集合中随机选择两个实体以形成多个实体对。 卷积分类器获得实体对的双向关系。  12
本发明涉及电力审计模型构建技术领域，尤其涉及一种基于BERT模型的电网系统审计构建方法，包括：步骤S1，获取一级电力特征参数；步骤S2，对所述一级电力特征参数进行计算处理以得到二级电力特征参数；步骤S3，中控模块根据电力工程的若干监测周期的电能消耗量与物料消耗速度的拟合度将物料消耗速度监测频率调节至对应监测频率，并根据单位区域内的非标准布设的输电线长度占比将标准输电电线长度调节至对应长度；步骤S4，所述中控模块在完成对于标准输电电线长度的调节时根据终端电气接口的施工质量评价参数将土建施工的标准结构误差量调节至对应误差量；本发明实现了电力工程审计精准性的提高。电力审计模型构建领域的基于BERT模型的电网系统审计构建方法。该方法使得利用中央控制模块根据电力工程若干个监测周期的电能消耗量与耗材速度的拟合度，将耗材速度监测频率监测频率调整为对应的监测频率，调整标准输电导线的长度，实现了提高电力工程审核精度。该方法包括获得第一级功率特征参数(S1)。 对所述第一级功率特征参数进行计算处理(S2)，得到第二级功率特征参数，所述第二级特征参数包括电能消耗与物耗速度的拟合度、单位面积内非标输电线路的长度比例以及终端电气接口的施工质量评价参数。 将标准输电导线的长度调整为相应的长度(S3)。 在调整标准输电导线的长度时，中央控制模块根据终端电气接口的施工质量评估参数将土建结构的标准结构误差量调整(S4)为相应的误差量。 0
本申请提供一种基于大语言模型的智慧呼叫方法，包括：分析客户最开始接通电话时的语音信息，预测出客户的音色偏好，并从预设的音色库中匹配最适合的智能客服音色；根据客户表达的内容，对问答中的事件进行总结，判断呼叫后客户对询问内容的轻重缓急和正面及负面性质；智能客服通过语气和语音内容，捕捉分析客户可能含有的焦虑、不满或紧迫性这三种情况；结合客户的事件性质和口语表达习惯，根据用户所产生的三种不同的负面情绪，分别确定智能客服的回复态度和语气，符合客户的心理预期和需求；使用异常检测获取无法引发共鸣而导致客户反感的异常回复，采取不同的处理方式，包括重新生成回复、请求用户提供更多信息、或转接给人工客服。用于智能客服系统的基于大语言模型的智能呼叫方法，用于识别用户的情绪状态。该方法使得能够根据用户产生的三种不同的负面情绪，结合客户端的事件属性和口语表达习惯，分别确定智能客服的回复态度和语气，符合客户端的心理期望和需求。 该方法利用异常检测获得不会引起共振和造成客户反感的异常响应，并采用不同的处理方式，包括再次产生响应、请求用户提供更多信息或转移到人工客服。该方法涉及对客户端开始通话时的语音信息进行分析，预测客户端的音色偏好，并从预设的音色库中匹配出最适合的智能客服音色。 根据用户产生的三种不同的负面情绪，结合客户端的事件属性和口语表达习惯。 分别确定符合客户心理期望和需求的智能客服的回复态度和语气。 根据所述情绪变化动态调整所述智能客服的音色、语速和情绪。 所述异常检测用于获取不引起共振和引起客户端反义的异常反应，采用不同的处理方式，包括再次生成反应。 请求用户提供更多信息或传送给人工客服。 8
本申请公开了一种预训练模型的训练方法和文本处理方法。其中预训练模型的训练方法包括：按照预设字符组合规则，对文本样本中每个分词和分词的关联字符进行组合得到文本样本对应的分词组合序列；确定分词组合序列对应的至少一个附加信息；利用文本样本、分词组合序列和至少一个附加信息训练预设模型，得到用于构建命名实体识别模型的目标预训练模型。本申请实施例可应用于云技术、人工智能、智慧交通、辅助驾驶等各种场景。本申请实施例提高了目标预训练模型对于文本的表示完整度，进而提高了目标预训练模型对于文本的处理适应能力，也提高了命名实体识别模型进行命名实体识别的准确度和有效性。用于通过使用包括云技术、人工智能、智能交通、辅助驾驶和场景的电子设备(索取)来训练预训练模型的方法，并且还可以用于互联网通信技术领域。该方法提高了目标预训练模型对文本的表达完整性，以提高训练目标模型的处理自适应能力。 提高了命名实体识别识别的准确性和有效性。该方法包括根据预设字符组合规则对文本样本中的各词语进行组合，得到文本样本对应的分词组合序列。 确定与分词组合序列对应的附加信息，所述附加信息包括所述分词组合序列中分词组合的全局上下文信息、所述分词组合序列中分词组合的长度信息以及所述分词组合序列中分词组合的相对位置信息。 利用所述文本样本、所述分词组合序列和所述至少一个附加信息训练预设模型。 得到用于构建命名实体识别的目标预训练模型。独立权利要求还包括：一种文本处理方法； 预训练模型的训练装置； 文本处理装置； 计算机可读存储介质，其包括用于训练预训练模型的指令集； 以及包括用于训练预训练模型的指令集的计算机程序产品。  11
本发明是一种电机故障知识抽取系统及方法，尤其涉及神经网络模型对电机故障判断的技术领域。目的是为了解决现有技术中电机故障种类繁多导致相关人员电机故障知识抽取困难等问题，本发明应用BERT模型构建软件系统，其中包括数据采集模块，数据预处理模块，辅助训练工具模块、模型训练模块和知识融合模块，用户和管理员通过电机故障知识抽取系统的使用，为用户电机故障维护服务提供更加科学化的技术支持，发电机故障知识抽取，目的在于故障知识库的构建，方便用户可以快速解决电机中的故障，并更加便捷与准确，也可提升相关业务人员水平，大幅度提高电机故障解决效率。用作电机故障知识提取系统。该系统：为用户电机故障维修服务提供更科学的技术支持； 提取发电机故障知识； 将目的构造成故障知识库； 便于用户快速解决电机内的故障； 更方便准确； 能够提高相关服务人员水平； 并且大大提高了电机故障解决效率。电机故障知识提取系统包括数据采集模块、数据预处理模块、辅助训练工具模块、模型训练模块和知识融合模块。 数据采集模块负责采集故障数据并发送给数据预处理模块。 数据预处理模块对采集的数据进行预处理。 辅助训练工具模块提取相关系统匹配程序。 所述模型训练模块与所述数据预处理模块连接，以对一预处理数据进行模型训练。 模型训练模块与知识融合模块连接。 对预处理后的数据进行最终的融合处理。还包括一种独立权利要求，用于一种电机故障知识提取方法。 0
本发明公开了一种基于机器视觉和深度学习的立木胸径测量方法，包括以下步骤：第一步，相机标定和图像校正，相机标定和图像校正模块接收由相机拍摄的多张标定板图片，对相机进行标定得到相机内参和外参以及畸变系数，之后利用其对需要测量的图片进行畸变校正；第二步，树干图像分割，校正后的图片进入树干图像分割模块，树干图像分割模块采用U‑Net网络分割，使用U‑Net网络进行树干的提取，得到一副分割图像。本发明能够准确、快速和便捷的测量立木胸径，提高林业资源调查的效率，推动智慧林业的快速发展。基于机器视觉和深度学习的立树直径测量方法该方法准确、快速、方便地测量立木胸径，提高了林业资源调查的效率，促进了智能化林业的快速发展。 通过建立U-net神经网络模型进行图像分割，提高了测量的准确性。 立木分法在复杂背景下的切削能力在现有测量中是足够的。 大大减小了胸径外部矩形提取过程中的误差。 该方法提供了基于扫描线胸部大小位置的自动确定算法，解决了胸部直径位置的自动确定问题。 胸径长度误差校正模型解决了三维重建时胸径平面与标定板平面不共面的问题。该方法包括当获得乳房高度处的直径的像素坐标时，进行三维坐标的重建。 获得直径的端部的三维坐标，并且将该世界坐标配置为测量直径长度。 直径误差校正模型被配置为校正结果。 直径测量模块具有直径像素坐标的提取，直径三维坐标的重建和直径长度的测量。 直径像素坐标的提取包括分割图像轮廓的提取，躯干轮廓的外接矩形的提取和直径位置的定位。 三维(3D)直径坐标的重建具有3D重建模型和3D直径坐标的计算。   6
本说明书公开了一种模型训练方法及装置。在预训练阶段，针对一个搜索结果及其对应的一对搜索结果确定第一训练样本，并通过双塔结构的相关度模型，确定该第一样本中各搜索结果的第一特征以及查询文本对应的两个第二特征，基于各第一样本的第一特征间的特征距离以及第二特征间的特征距离，确定对比损失，以对相关度模型进行预训练。再将查询文本与其对应的各搜索结果分别组合得到各第二样本，将第二样本中查询文本与搜索结果的相关度作为标注，继续训练相关度模型。能够在预训练阶段通过对比学习使相关度模型能够准确表征查询文本与搜索结果的结果文本的特征，并再基于标注的相关度进一步对相关度模型进行训练，使相关度模型能够准确输出相关度。用于训练双塔结构的相关度模型的方法。该方法能够基于第一组样本的对比度损失来预训练相关度模型， 进一步地，继续训练与查询文本结果和第二组样本的搜索结果的相关度的相关度模型，实现相关度的准确表征。该方法包括根据用户输入的每个查询文本的搜索结果集来确定第一组样本，其中第一组样本包括查询文本和相应的一对搜索结果。 每个搜索结果被输入到结果塔。 获得对应于每个搜索结果的第一组特征。 查询文本被输入到查询塔。 确定与查询文本相对应的第二组特征。 基于第一组特征和第二组特征之间的距离来确定对比度损失。 基于对比度损失来预训练相关度模型。 在预训练完成后，利用查询文本结果与第二组样本的搜索结果的相关度对相关度模型进行连续训练。 利用相关度模型确定查询文本对应的搜索结果序列。独立的权利要求书包括： (1)双塔结构相关度模型训练装置； (2)存储有用于训练双塔结构的相关度模型的计算机程序的计算机可读存储介质； 以及 (3)一种包括存储器和用于训练双塔结构的相关度模型的处理器的电子设备。  11
本发明公开了一种基于AIGC的图像识别系统及装置，所述图像识别装置设置在该系统中，所述图像识别系统包括用于获取外界图像数据的图像获取模块、图像集管理模块、输出模块以及控制模块，所述控制模块分别与所述图像获取模块、所述图像集管理模块以及输出模块电连接。本发明中，控制模块控制图像集管理模块对原始目标图像与更新因子图像执行图像拼接操作，得到更新目标图像，这能够对用于图像识别模型训练的图像数据及时更新，有利于提高图像识别模型的鲁棒性，从而有利于保障图像识别系统(或装置)在识别目标的图像出现变化时图像识别结果的准确性。基于AIGC的图像识别系统，用于图像识别技术领域，用于更新图像识别模型训练的图像数据，这是急需解决的技术问题。控制模块控制图像集管理模块对原始目标图像和更新因子图像进行图像拼接操作，得到更新后的目标图像，能够及时更新用于图像识别模型训练的图像数据，有利于提高图像识别模型的鲁棒性，以保证图像识别系统(或装置)在识别目标图像发生变化时的准确性的图像识别结果。该系统具有控制模块，控制图像集管理模块对来自存储模块的原始目标图像进行调整。 所述控制模块控制所述图像集管理模块对所述原始目标图像和所述更新因子图像进行图像拼接操作，得到更新后的目标图像。 控制模块根据目标图像的更新后的图像属性信息和原始目标图像计算更新后的目标图像集合的更新增益指标。 所述控制模块判断所述更新增益指标是否与所述预定更新增益指标阈值匹配。 所述控制模块在判断所述更新增益指标与所述预定更新增益指标阈值匹配时，控制所述输出模块输出以指示所述图像识别系统进入所述识别功能升级准备阶段。本发明还涉及一种基于AIGC的图像识别装置。 1
本公开提供了一种生成模型的训练方法，涉及人工智能技术领域，尤其涉及生成式人工智能以及量子计算技术领域。具体实现方案为：根据量子态样本数据，得到第一编码结果和第二编码结果；根据第一编码结果和第二编码结果，进行重参数化处理，得到待处理样本数据；根据待处理样本数据，得到参数数据；利用参数数据调整生成模型的量子神经网络的目标量子解码层，得到调整后的量子神经网络；利用调整后的量子神经网络，生成量子态输出数据；以及根据量子态样本数据和量子态输出数据，训练生成模型。本公开还提供了一种数据生成方法、装置、电子设备和存储介质。用于生成式人工智能和量子计算领域的模型的训练和生成方法。 还可用于自动书写、语音合成、图像生成等领域。该方法使得利用参数数据调整生成模型的量子神经网络的目标量子解码层以获得调整后的量子神经网络，从而以高效的方式训练模型以根据量子态样本数据和量子态输出数据生成模型。该方法包括根据量子态样本数据获得(S110)第一编码结果和第二编码结果。 根据所述第一编码结果和所述第二编码结果进行重新参数化处理(S120)，得到待处理样本数据。 根据所述待处理样本数据得到一参数数据(S130)。 利用所述参数数据对生成所述模型的量子神经网络的目标量子解码层进行调整(S140)，得到调整后的量子神经网络，所述生成模型的量子神经网络包括量子解码层，所述目标量子解码层为所述待训练量子解码层之后的量子解码层。 使用经调整的量子神经网络产生量子态输出数据(S150)。 根据量子态样本数据和量子态输出数据对生成的模型进行训练(S160)。独立权利要求包括以下内容：一种数据生成方法； 训练装置，用于生成模型； 数据生成装置； 电子装置； 非瞬时计算机可读存储介质，其存储用于训练和生成模型的计算机指令； 以及用于训练和生成模型的计算机程序产品。  11
本发明涉及文本摘要技术领域，具体涉及一种基于图神经网络长文本相似度对比方法，通过将源文本预处理，得到源文本每个句子中单词的词嵌入，输入到预训练的BERT中，再将经过BERT的输出输入到膨胀门控卷积网络中，以残差结构的形式将经过BERT的输出与经过膨胀门控卷积网络的输出进行聚合，防止梯度消失，然后分别构建多层次语义相似度图和多层次自然关系图，分别通过图注意力层，然后聚合，经过激活函数和全连接层预测句子标签，并构建摘要损失函数；最后基于摘要损失函数和主题模型损失函数计算得到模型损失函数，使得提取到的文本摘能够更加全面的保留源文本的重要信息。一种基于图神经网络的长文本相似度比较方法，用于文本摘要技术领域。提取的文本摘要可以更加完整地保留源文本的重要信息。 基于模型损失函数调整整个神经网络的权重，得到文本摘要模型，从而能够完整有效地比较长文本的相似度。该方法包括：获取源文本对应的摘要标签和源文本。 对所述原文进行预处理。 将所述源文本的每一个句子嵌入到所述扩展门控卷积网络中。 构建所述句子的异构图。 基于所述模型损失函数调整整个神经网络的权重，得到所述文本摘要模型。  12
一种文本隐式篇章关系识别方法、系统、设备及存储介质，方法包括将论元拼接作为输入，使用RoBERTa模型编码，在外部知识融合时使用K‑BERT模型引入知识图谱信息辅助理解论元内实体，之后对两个论元的语义向量进行拆分，使用Bi‑LSTM模型获取包含更多序列信息的各论元整体表示，得到融合了外部信息的论元；仿照人类理解论元关系的过程，对论元间词汇两两配对计算细粒度线索分数，构建得到细粒度多角度线索矩阵；结合整体语义与对当前关系有用的线索特征联合判断关系类别，通过将线索特征与整句语义综合，获取到综合表征，输出关系类别。本发明发掘更深层次的论元交互表征结果，更好地对含义复杂的论元进行判别，提升识别效果。一种利用电子装置识别教育领域的文本中的文本隐含话语关系的方法(权利要求书)。该方法能够探索更深层次的理论元素交互表示结果，更好地判断具有复杂含义的理论元素，提高识别效果。该方法涉及使用自变量拼接作为输入。 采用RoBERTa预训练模型进行编码。 K-BERT模型用于引入知识图谱信息，在进行外部知识融合时辅助理解论点内实体。 采用Bi-LSTM模型得到包含较多序列信息的每个幅元的整体表达式。 融合后的自变量元素与外部信息一起获得。 所述细粒度线索分数通过对所述幅元之间的词汇表进行配对计算，构建得到所述细粒度多角度线索矩阵。 提取对当前关系有用的线索特征，判断话语关系的类型。 对当前关系有用的全语义和线索特征共同判断关系类型。 综合线索特征和整句语义得到综合表征。 输出所述隐式章节关系类型。独立权利要求还包括用于：文本隐式话语关系识别系统； 以及一种计算机可读存储介质，包括一组用于识别文本隐式话语关系的指令。  12
提供了使预训练的机器学习系统适配于目标数据的设备和方法。一种计算机实现方法，用于使已经在第一训练数据集上训练的预训练的机器学习系统适配于第二数据集，其中第二数据集具有与第一数据集不同的特性。此外，提出了用于部分地撤销第一与第二训练数据集之间的分布移位的输入变换模块(2)。用于不同设备的计算机实现的增强机器学习系统。 用途包括但不限于洗衣机、炉子、烤箱、微波炉、洗碗机、MRI设备、X射线成像设备、超声成像设备、汽车和机器人。该系统使网络对未标记测试样本的自适应稳定，因此防止预训练机器学习系统崩溃成不重要的解。系统(3)具有用于对图像进行分类的预训练机器学习系统(26)。 参数化输入变换模块(2)的输出单元与预训练机器学习系统的输入单元连接。 所述输入变换模块被配置为对输入进行线性变换，并将经变换的输入输入到所述预训练机器学习系统。 神经网络与线性变换模块串联连接，其中线性变换模块被配置为基于用于表征线性变换的参数对输入进行线性变换。还包括独立权利要求：一种用于参数化输入变换模块的计算机实现的方法； 用于存储用于参数化输入变换模块的指令集的计算机程序； 以及用于存储用于参数化输入变换模块的指令集的机器可读存储介质。  11
本申请涉及一种智能法律合约生成方法、装置、电子设备及存储介质，其中，方法包括：基于BPMN方法和法律合约，构建智能法律合约的BPMN模型，并通过智能法律合约的BPMN模型，提取目标智能法律合约的关键信息，并生成结构化思维链式提示信息；将结构化思维链式提示信息输入至预先微调后的大语言模型中，生成结构化思维链式提示信息对应的智能法律合约；利用智能合约集成开发环境运行生成的智能法律合约，以验证语法结构和合约逻辑的正确性。由此，解决了现有基于映射规则的智能法律合约生成方法受限于领域专家知识，且因知识领域性、理解差异性等因素导致生成智能法律合约的法律风险较大等问题。领域专家知识基于映射规则生成智能法律合约至模型精调阶段的方法。该方法能够通过智能合约集成开发环境对生成的智能合法合约进行操作，以验证语法结构和合约逻辑的正确性。所述方法包括：利用预设的业务流程模型和符号(BPMN)流程获取结构化思想链式提示信息集。 所述结构化思想链类型提示信息集中设置有BPMNprocess的流程结构和元素信息。 对应所述结构化思想链类型提示信息集合中的每个结构化思想链类型提示元素生成智能合约。 基于所述智能合约和所述结构化思想链类型提示数据集对目标大语言模型进行微调，生成对应于所述对应目标的对应目标智能合约。包括独立权利要求，用于：(1)领域专家知识基于映射规则生成智能法律合约至模型精调阶段的装置； (2)一种通过领域专家知识基于映射规则生成智能法律合约至模型精调阶段的电子装置； (3)计算机可读存储介质具有用于通过领域专家知识基于映射规则生成智能法律合约到模型细调阶段的指令集。  11
本发明涉及医学图像分割技术领域，具体涉及一种基于生成式对抗U‑Net网络的2.5D医学图像分割方法，包括以下步骤：步骤1、获取待分割的3D医学图像；步骤2、分别沿多个轴向对3D医学图像进行连续切片，得到各轴向的2D切片图像组；步骤3、分别将各轴向的2D切片图像组中的图像，输入对应轴向的分割网络模型中，得到对应轴向的预测分割图像；其中，所述分割网络模型包括生成式对抗网络GAN和U‑net模型，并且将U‑Net模型作为生成式对抗网络GAN的生成器；步骤4、分别将各轴向的预测分割图像进行堆叠，得到对应轴向的3D预测图像。本方法能够有效的减少训练集的量，减少医学专家的工作负担；还可以提高分割精度。基于生成型反U网网络的2.5D医学图像分割方法，应用于医学图像分割技术领域。该方法能够使用U-Net网络模型划分网络模型， 这样可以提高本领域的技术人员，将简单的卷积层改为深度残留网络或空腔卷积，融合不同的损耗函数，从而提高训练结束后的分割精度，保证分割结果的准确性。 本发明能够有效减少训练集的数量，降低医学专家的工作量，提高切割精度。该方法包括获得待分割的三维医学图像。 3D医学图像的连续切片沿多个轴向连续以获得轴向2D切片图像组。 将相应的轴向分割网络模型输入到每个轴向堆栈中，以获得相应的3D预测图像。 根据预设权重值计算3D预测图像中每个对应体素点的像素预测值的投票值。 判断表决值是否大于或等于预设目标值。 体素被确定为分割的目标体素。 获得3D分割结果。   6
本发明提出一种基于三元组森林的实体关系联合抽取方法和系统，包括：获取待实体关系抽取的语料，得到句子及其对应的词序列；将词序列输入BERT模型，BERT模型对词序列进行分词，得到子词序列，使用BERT模型对子词序列进行编码，得到句子的分布式表示；将分布式表示输入CRF模型，标注句子中实体，得到实体的向量表示；将实体向量输入，通过TransformerDecoder模块中多头注意力机制获得实体向量中包含的实体间交互信息、实体和输入句子间交互信息的隐层向量；将隐层向量作为Tree‑RNN的初始状态和初始隐层单元，输入实体表示至Tree‑RNN，从Tree‑RNN的根节点的头实体生成其所参与的关系，根据头实体及其对应的关系，选择其尾实体，从而生成重叠的三元组树，再进一步解码得到实体关系三元组。一种基于三元集团森林的实体关系联合抽取方法。实体交互模块，用于获取三元组之间的无序交互信息。 三元组森林进一步建模三元组无序交互作用，三元组内部有序交互作用减弱其引起的传输误差以增强对重叠关系的识别能力。 通过优化模型结构，避免了序列生成帧，从而优化了模型结构。 所述实体关系组合抽取系统用于为问答模型或搜索推荐系统构建或知识图谱。 利用BERT预训练语言模型对训练语料进行预编码、序列标注、实体交互、三重森林生成三元组等预处理。实体关系联合抽取方法涉及获取待实体关系语言学数据。 所述句子和词处理，得到所述句子和对应的词序列。 将词序列输入到词序列到词的BERT模型中。 利用所述BERT模型对所述子词序列进行编码，得到所述句子的分布式表示，得到所述子词序列。 实体向量被输入。 实体向量中包含的实体交互信息通过解码器模块中的多头注意力机制得到。 所述实体与所述输入语句的交互信息的隐含层向量。 输入实体表示从根节点的头部实体开始的树RNN以生成所涉及的关系。 选择尾部实体生成重叠三叉树，进一步解码得到实体关系三元组。本发明公开了一种基于三元组森林的实体关系联合抽取系统，包括：(a)一种基于三元组森林的实体关系联合抽取系统; (b)用于存储和执行程序的存储介质; (c)用于基于三元森林的实体关系联合抽取系统的客户端。  12
本发明公开了一种深度残差LSTM网络，其特征在于：包括依次设置的：输入层；卷积层；池化层；重塑层；LSTM层；Dense层；输出层；所述LSTM层与密集层之间设有n个预激活残差块，且n≥1；所述预激活残差块包括依次设置的第一BN层、第一权重层、第一卷积层、第二BN层、第二权重层和第二卷积层；所述第一BN层和第二BN层用于解决网络无法收敛的问题；所述第一权重层和第二权重层用于提取特征；所述第一BN层与第一权重层之间以及第二BN层与第二权重层之间分别具有用于减少参数之间的相互依赖的激活函数。本发明还公开了一种热误差预测模型的建模方法及迁移学习方法。本发明能够避免网络深度增加导致的预测精度饱和问题，能够有效提高预测精度和鲁棒性。用于航空、航天、核电领域的热误差预测模型的深度残差LSTM网络。该网络避免了预测精度饱和问题导致的网络深度增加，从而有效提高了齿形磨床热误差的预测精度和鲁棒性。 该网络通过常量映射直接连接深度浅层，从而避免了每两个相邻层之间复杂的梯度求导计算，从而有效地将梯度从深度网络传递到浅层网络。所述LSTM网络具有重塑层，用于对某一维度的多维矩阵进行重新排列，构造出元素编号相同但维度不同的新矩阵。 LSTM层被提供有用于表征热误差的长期和非线性存储器行为。 LSTM层和dense层之间设置有若干n个预激活残差块，n大于等于1。 预激活残差块配置有第一BN层、第一权重层、第一卷积层、第二BN层、第二权重层和第二卷积层。 这对BN层用于解决网络无法收敛的问题。 所述权重层对用于提取特征。 在第一BN层和第一权重层之间以及第二BN层和第二权重层之间分别提供激活函数，用于降低参数之间的相互依赖性。以下包括独立权利要求：(1)一种热误差预测模型的建模方法； 以及(2)热误差预测模型的迁移学习方法。  12
本发明涉及一种基于预训练模型的机器阅读理解方法，包括步骤：步骤1、对数据进行预处理；步骤2、根据预训练模型的输出通过高级语义融合网络层进行高级语义融合；步骤3、对经过语义融合之后的机器阅读模型进一步进行能力学习；步骤4、计算命名实体的均方误差损失，并对机器阅读模型进行训练。本发明的有益效果是：本发明通过对文本提取出高级语义信息，给模型提供了更高维度的信息，同时其高度的准确性相对于模型自身在训练过程中去尝试抽取这些信息比较起来，更有参考意义；本发明通过能力学习，使得模型能保持规模不变的情况下，提升了机器阅读的能力，使得模型能够在性能较高的前提下，快速的完成推理任务。一种基于预训练模型的机器阅读理解方法。本发明通过提取文本来提取高层语义信息，为模型提供了更高维度的信息，提高了训练过程中相对于模型提取信息的高度的准确性。 本发明通过能力学习提高机器阅读能力，使模型在高性能的前提下快速完成推理任务。该方法包括预处理数据。 高层语义融合网络层根据预训练模型的输出进行高层语义融合。 对语义融合后的机器阅读模型进行能力学习。 计算命名实体的均方误差损失。 计算机器读数模型损失。 优化机读模型。 根据计算公式计算软损耗。  11
本申请提供了一种训练模型的方法、装置、设备以及存储介质，涉及人工智能的机器学习领域。在该训练模型的方法中，可以对无标签的第一样本进行聚类，得到至少两个概念，其中，该概念为第一样本中由掩码注释的结构形式，然后可以根据该至少两个概念和该第一样本，对预训练模型进行训练，其中，所述预训练模型用于对样本进行特征提取。本申请通过该至少两个概念，能够显式增加预训练模型对局部概念的敏感性，约束模型分辨不同的概念，从而相较于基于全局特征的预训练方法，本申请实施例能够有助于提高预训练模型在下游密集预测任务上的表现。一种使用电子设备训练模型的方法(要求保护)。提高了预训练模型对下游密集预测的性能。该方法涉及对没有标签的第一样本进行聚类以获得至少两个概念，其中该概念是第一样本中掩码注释的结构形式。 通过线性特征编码器获得第一样本的第一特征图像。 通过动量特征编码器从第二样本获得第二特征图像。 确定与第一特征图中的第一概念相对应的第一概念特征。 确定与第二特征图中的第二概念相对应的第二概念特征。 第一个概念是两个概念中的一个。 更新在线特征编码以训练预训练模型，其中预训练模型包括在线特征编码。还包括独立的权利要求： 一种利用电子设备训练模型的装置； 以及 包括用于通过使用电子设备训练模型的指令集的计算机可读存储介质  11
本发明提供了一种基于BERT预训练模型的新词识别方法和装置，涉及新词挖掘的技术领域，包括获取语料信息，通过N‑Gram切词算法对语料信息进行分词处理得到多个新词词语；将新词词语输入BERT预训练模型的浅层网络，输出浅层稠密向量，其中，BERT预训练模型中引入有双向自注意力网络，浅层稠密向量包括新词词语的句法特征向量以及词法特征向量，浅层稠密向量用于识别新词词语的边界信息；提取新词词语的离散特征；将浅层稠密向量与离散特征输入DNN二分类模型，识别出正确的新词词语，通过BERT预训练模型的浅层网络确定词语的边界，进而准确识别出正确的新词。来自变压器预训练模型的双向编码器表示的词识别方法。该方法能够通过Transmister预训练模型的双向编码器表示的浅层网络来确定词的边界，从而准确地识别正确的新词。该方法包括获得语言学数据信息。 采用N-Gram分词算法对所述语言学数据信息进行分词处理，得到多个word word。 将这些词输入到来自变换器的双向编码器表示(BERT)预训练模型的浅层网络中。 输出浅层密集向量。 所述BERT预训练模型引入双向自注意力网络。 提取所述词语的离散特征。 将所述浅层密集向量和所述离散特征输入深度神经网络二分类模型，用于识别正确词。独立权利要求包括用于以下的：基于来自变换器的双向编码器表示预训练模型的字词识别设备包括存储器和处理器的电子设备，所述处理器执行基于来自变换器的双向编码器表示预训练模型的字词识别方法； 以及计算机可读存储介质，所述计算机可读存储介质存储用于执行基于来自变换器的双向编码器表示预训练模型的词识别方法的指令集。  12
本申请公开了一种基于BERT模型的文本风格迁移方法及系统，所述方法包括：对不同平台进行语料抽取，筛选出合格语料；使用所述合格语料对基于BERT的模型进行训练；使用训练好的所述模型对文本进行改写，得到符合要求的风格文本。通过本申请，可使用特定风格的语料训练模型，对文本的风格进行转换，将生成的文本迁移到需要的风格。一种基于BertModel的文本风格迁移方法。可以使用具有特定风格的语料训练模型。 转换文本的风格，并将生成的文本迁移到所需风格。方法包括：对不同平台进行语料抽取，筛选出合格语料。 合格语料库用于训练基于BERT的模型。 利用训练好的模型对文本进行重写，得到满足要求的风格文本。本发明还涉及一种基于BertModel的文本风格迁移系统。  12
本公开公开了基于三元组深度哈希学习的相似司法案例匹配方法及系统，包括获取待匹配的司法案例文书；将待匹配的司法案例文书，输入到预训练的特征提取模型中，得到待匹配司法案例文书的特征表示向量；将待匹配司法案例文书的特征表示向量，同时输入到预训练的三元组深度哈希学习模型中，得到待匹配司法案例文书的哈希码；基于待匹配司法案例文书的哈希码与已知司法案例文书的哈希码，计算司法案例文书的相似度。实现司法案例文书的相似度精确匹配。基于三元组深度哈希学习在电子设备(索取)中匹配相似司法案件文档的方法。该方法使得能够实现司法案件文档的准确相似度匹配过程。该方法涉及获取司法案件待比对文件。 将所述待匹配司法案件文档输入预训练的特征提取模型。 获取所述待匹配司法案件文档的特征表示向量。 表示所述待匹配司法案件文档的特征表示向量。 将所述待匹配司法案件文档的特征表示向量输入预先训练的三元组深度哈希学习模型。 获取所述待匹配司法案件文档的哈希编码。 基于所述待匹配司法案件文档获取所述待匹配司法案件文档的哈希编码与所述预设司法案件文档的哈希编码的相似度。还包括以下独立权利要求：一种基于三元组深度哈希学习在电子设备中匹配相似司法案件文档的系统； 以及计算机可读存储介质，用于存储基于三元组深度哈希学习在电子设备中匹配相似司法案件文档的指令集。  12
本发明公开了一种分段式细粒度的商品图像描述生成方法、装置和介质，该方法包括以下步骤：首先构造一个粗粒度的商品图像描述生成框架，由图像特征提取器、文本解码器、映射网络三部分组成；然后针对图像特征提取器以及文本解码器进行预训练，之后通过映射网络对齐语义空间，生成粗粒度的图像描述；其次在公开的商品描述数据集上微调已有的大型文本生成网络；再将粗粒度的图像描述输入微调后的文本生成网络，生成细粒度的商品图像描述；最后可将上述生成的商品描述再次输入网络，直至生成满意的商品图像描述。本发明的商品图像描述生成方法能够提高商品描述的丰富度和细腻度，自动化批量生成细粒度的商品图像描述。用于生成具有分段细粒度的物品的分段细粒度商品图像描述的方法。该方法提高了商品描述的丰富性和精美度，自动批量生成细粒度的商品图像描述，使得文本解码器采用长期记忆网络获取初始粗粒度图像描述，使得映射网络采用神经网络层全连接层，使得图像特征提取器为视觉自关注网络。该方法包括构建粗粒度商品图像描述生成框架，所述粗粒度商品描述包括图像特征提取器、文本解码器和映射网络。 对所述图像特征提取器和所述文本解码器进行预训练，得到所述图像特征和文本解码。 通过映射网络对语义空间进行对齐，生成商品图像对应的粗描述文本。 在商品描述数据集上对已有的大文本生成网络进行微调，得到最终的大文本生成网络。包括独立权利要求用于：(1)用于生成分段细粒度的物品的分段细粒度商品图像描述的设备； (2)—种计算机可读存储介质，包括用于生成具有分段细粒度的物品的分段细粒度商品图像描述的方法的指令。   6
本发明涉及一种基于迭代学习的半监督人眼多要素分割方法，包括以下步骤：将可见光下眼部数据集划分为有标签眼部数据集和无标签眼部数据集；基于有标签眼部数据集利用有监督深度学习网络进行训练，得到预训练模型；基于预训练模型通过前向推理获取无标签眼部数据集的伪标签；基于有标签眼部数据集对无标签眼部数据集和伪标签进行筛选，得到信任数据集；将有标签眼部数据集和信任数据集输入至有监督深度学习网络进行再训练，若未达到训练完成要求，则返回上述的伪标签获取步骤，否则结束训练得到人眼分割模型；采用人眼分割模型对人眼进行多要素分割。本发明能够在使用少量标签数据的情况下，提升模型的精度和鲁棒性。用于人眼特殊部位提取的基于迭代学习的半监督人眼多元分割方法 使用包括但不限于眼睛区域，例如巩膜区域，虹膜区域和瞳孔区域。本发明在使用少量标签数据的情况下，提高了模型的精度和鲁棒性。该方法包括将可见光中的眼睛数据集划分为标记眼睛数据集和非标记数据集。 基于标签数据集获得预训练模型。 通过基于预训练模型的前向推理获得非标签化数据集的伪标签。 根据标签数据集筛选伪标签和伪标签以获得可信数据集。 标签眼数据集和可信数据集被输入到受监督深度学习网络以进行再训练。 训练结束，得到人眼分割模型。 利用人眼分割模型对人眼进行多元分割。 14
本申请公开了一种视频预训练模型的训练方法、装置、设备及存储介质，涉及人工智能技术领域，该训练方法包括：采用初始视频上下文预测模型和上下文预测数据集进行训练，得到已训练的视频上下文预测模型中的第一编码器；采用基于所述第一编码器构建的初始视频跨模态模型和跨模态数据集进行训练，得到已训练的视频跨模态模型中的第二编码器；采用基于所述第二编码器构建的初始内容识别模型和内容识别数据集进行训练，得到已训练的内容识别模型中的第三编码器；将所述第三编码器作为视频预训练模型，以利用所述视频预训练模型对视频数据进行预处理。在相同效果的情况下减少了数据集的数量，提高了对视频预训练模型进行训练的效率。视频预训练模型训练方法。可以提高视频预训练模型的训练效率。 可以减少所述数据集的数量，并且可以增加训练所述训练过程的效率。 可以实现由简单到复杂的训练过程，从而可以最大限度地减少待训练数据集的数量，缩短训练时间。 可以对视频数据进行预处理，以提高预处理过程的质量。 通过在初始视频上下文预测模型中使用视频交叉模式模型和编码器构建的交叉模式数据集，提高了对视频数据进行预处理的效率。 通过将正样本和负样本作为上下文预测数据集进行模型训练，提高了初始连续性预测模型的准确性。该方法涉及使用初始视频上下文预测模型和上下文预测数据集进行训练(S101)。 在已训练的视频上下文预测模型中获得第一编码器。 获得经训练(S102)的视频交叉模式模型中的第二编码器。 基于第二编码器和内容识别数据集来构建初始内容识别模型(S103)以进行训练。 在所述训练内容识别模型中获取第三编码器。 作为视频预训练模型的第三编码器。 利用所述视频预训练模型对所述视频数据进行预处理(S104)。包括独立权利要求用于：(1)一种视频预训练模型训练装置； (2)一种电子设备，包括存储器和处理器，用于存储计算机指令，所述计算机指令由所述处理器执行以实现一种视频预训练模型训练方法； 以及(3)一种计算机可读存储介质，用于存储实现视频预训练模型训练方法的计算机程序。 9
本发明提供了一种预训练语言模型实体知识注入方法、系统及装置，涉及人工智能技术领域，所述方法包括：通过对字符串相似度的计算，得到实体名称；通过预训练语言模型编码实体语义，构建实体向量表；构建实体注入的训练样本；通过对比学习的方式，向预训练语言模型注入实体知识。通过上述方法，解决了装备等领域中实体由于领域术语独特性以及存在别名而导致的实体稀疏问题，提升了预训练语言模型对于实体语义的学习效率，实现了符号知识向量化，进而可以将装备等领域中的实体知识注入至所述预训练语言模型中。注入预训练语言模型实体知识的方法。该方法解决了领域项唯一性和别名导致的实体稀疏问题，提高了预训练语言模型对实体语义的学习效率，实现了符号知识向量化，从而将设备领域的实体知识注入到预训练语言模型中。该方法涉及通过计算字符串的相似度来获得实体名称。 通过预先训练的语言模型对所述实体语义进行编码。 构建实体向量表。 为实体注入构建训练样本。 通过对比学习将所述实体知识注入到所述预先训练的语言模型中。 实体名称设有领域术语及其别名，由中文、英文和/或标点符号组成。 所述字符串相似度的计算设置为通过相似度算法计算所述文本语料中所述领域词项与所述指称项的相似度。包括独立权利要求：(1)一种预训练语言模型实体知识注入装置； (2)预训练语言模型实体知识注入系统。  12
本申请实施例提供了一种预训练语言模型的训练方法及装置。包括：从WordNet词表中获取样本分词的关系词，其中，样本分词在WordNet词表中包含至少一种关系，关系词与样本分词具有第一关系，第一关系是从至少一种关系中选取的；从关系词中随机选取N个正样例词；以及，从关系词以外的词中选取K个负样例词；获取样本分词、每个正样例词和每个负样例词对应的句子；对获取到的句子进行局部遮罩mask处理；对遮罩处理后的各个句子两两拼接，并使用拼接后的句子训练预训练语言模型。本申请实施例的技术方案，能够使预训练语言模型捕捉到更丰富语义空间的词语或句子级别的表示，从而提高了下游任务的使用效果。一种预训练语言模型的训练方法。本发明使得预先训练好的语言模型能够捕捉到丰富的表示词或句子级别的语义空间，从而提高了下游任务的使用效果。所述方法包括：获取所述样本词在所述数据库中的关系词；字网 (RTM)：词的词汇数据库)词表，其中关系词和样本词具有第一关系。 该关系包括近义关系，隐含关系，属性关系，反义关系，上下关系，整体关系，接近关系和反义关系。 得到与样本词相对应的句子，例如正样本词和负样本词。 根据预设比例对获取的语句进行局部掩码处理。 在处理本地掩码之后拼接每个句子。 使用拼接句子训练预训练语言模型。本发明还涉及一种用于对语言模型进行预训练的训练装置。  11
本发明提供一种融合分割信息的全局局部感知行人重识别方法，包括训练阶段和测试阶段，在训练阶段，通过公开的分割模型获取行人训练集每个行人的分割掩码，将所述分割掩码输入到掩码松弛模块获得松弛掩码，将行人图像分块与所述松弛掩码分块融合后输入至Transformer网络模型，得到全局特征和分块局部特征后进行损失计算，调整网络模型参数，训练并保存最优网络模型；所述测试阶段，输入待检索行人和底库行人图像至分割模型获取分割掩码，将所述分割掩码输入到掩码松弛模块获得松弛掩码，将行人图像分块与所述松弛掩码分块融合后输入至训练好的网络模型，获得全局特征和分块局部特征并归一化处理，后通过计算待检索行人和底库行人的相似度来识别行人。融合分割信息的全局部分感知行人再识别方法。该方法使得能够通过公共分割模型获得行人训练集的每个行人的分割掩码，并且确保简单且高效地对行人进行再识别。该方法涉及在训练阶段通过公共分割模型获得行人训练集的每个行人的分割掩码。 将所述分割掩码输入掩码松弛模块，得到松弛掩码。 将待搜索行人和基础行人图像输入分割模型，得到分割掩膜。 将行人图像块和所述松弛掩码块进行融合，并输入到训练好的网络模型中。 得到一个全局特征和一个块局部特征并进行归一化处理。 计算所述行人与基础行人的相似度以识别所述行人。   6
本发明公开了一种基于肿瘤随访平台的TNM分期方法及系统，方法包括：抽取肿瘤病例临床数据，对符合预设入选规则的临床数据列入达标集合，否则列入评议集合；对达标集合与评议集合提取训练集合；采用类Bert+CRF算法与CasRel算法抽取实体信息及关系信息以构造TNM分期模型，处理新增临床数据获得TNM分期结果。本发明中，通过选取高一致性的临床数据与诊断结果作为训练集合，提取其中实体与实体关系并构造TNM分期模型，从而可基于肿瘤患者的病例数据进行科学客观的TNM分期判读，以提供合适的诊疗方案，提高疗效，同时规范肿瘤病理数据的采集留存。基于肿瘤随访平台进行肿瘤临床诊断的TNM分期的方法。本发明通过选取一致性较高的临床数据和诊断结果作为训练集，提取实体和实体关系，构建TNM分期模型，从而能够基于肿瘤患者的病例数据进行科学、客观的TNM分期判读，提供诊疗方案，提高疗效，规范肿瘤病理数据的采集和存储。该方法涉及在肿瘤随访平台中随机提取病例的临床数据。 获得临床数据的TNM解释结果。 将与预设选择规则相关联的TNM判读结果的临床数据列于标准集中。 获取所述评价集中的所述临床数据的评价结果。 从所述标准集和所述评价集中提取所述临床数据和相应的解读结果或评价结果作为训练集。 利用CasRel算法对所述训练集进行实体关系提取，得到关系信息。 基于所述实体信息和所述关系信息建立TNM分期模型。 利用TNM分期模型对新增临床数据进行处理，得到相应的TNM分期结果。基于肿瘤随访平台进行肿瘤临床诊断的TNM分期的系统。  7
本发明公开了一种电话场景下热词在线定制更新的自动语音记录方法，首先训练基于深度神经网络的自动语音识别模型：然后通过电话音频文件对自动语音识别模型进行再训练，生成预训练模型；定制差异化语言模型自更新模型与热词表，并实时调整解码阶段的权重，组成自适应语音识别热词系统。本发明提出了基于不同场景的电话客服可在线定制热词的语音识别系统，生成不同场景下的热词表，提高了语音转写成文本效率的准确性；提出了热词权重实时更新算法，在线统计热词词频，依据词频在声学模型的解码阶段实时更新模型参数采用迁移学习的方式对8K电话音频进行再学习，提高了电话场景下音频语音识别的准确率。一种在电话场景中获取在线热词定制和更新的自动录音方法。 使用包括但不限于电话服务，电话咨询和通信行业。该方法使得语音识别系统能够在不同的场景下根据电话客服定制在线热点词， 生成不同场景下的热点词列表； 提高语音转录成文本的效率的准确性， 提供热词权值的实时更新算法，对在线热词次数进行统计， 在声学模型的解码阶段根据词频实时更新模型参数，通过迁移学习重新学习8K电话音频，提高了电话场景中音频语音识别的准确性。该方法包括用公共可用的通用功能语音数据集训练基于深度神经网络的自动语音识别模型。 初始化自动语音识别模型的每一层的权重以确定优化过程。 通过在电话场景中收集8K个电话音频文件对自动语音识别模型进行重新训练，生成基于8K个电话场景的自动语音识别模型的预训练模型。 利用预训练模型来识别在运行过程中会话的语音。 存储所获得的文本数据，用于在线定制热词。实时调整解码阶段的权重，以形成自适应语音识别热词系统。 3
本发明提供一种基于大模型的垂直领域数据整合方法、装置、设备及介质，涉及数据处理技术领域。方法包括：通过每个垂直领域对应的垂直领域代理接收用户输入的查询语句；调用预先已训练的intent大模型，通过所述intent大模型识别所述查询语句的查询意图；在所述垂直领域代理中，根据所述查询意图，调用预设的外部程序接口提取所述查询意图对应的实时数据，和/或，调用预先已训练的extraction大模型抽取所述查询意图对应的垂直领域知识；调用预先已训练的digest大模型，将获得的所述实时数据和/或所述垂直领域知识整合为所述查询语句的应答数据。本发明可实现垂直领域知识、数据和逻辑的高效整合。基于大模型的垂直域数据集成方法。该方法实现了垂直领域知识、数据和逻辑的高效融合。垂直域数据整合方法包括接收用户通过每个垂直域对应的垂直域代理输入的查询语句，其中，不同的垂直域分别设置有对应的垂直域代理。 调用预先训练的大意图模型，通过所述大意图模型识别所述查询语句的查询意图。 调用预设的外部程序接口，根据所述查询意图在所述垂直域代理中提取与所述查询意图对应的实时数据。 调用预先训练的抽取大模型，抽取所述查询意图对应的垂直领域知识。 调用预先训练好的摘要大模型，将得到的实时数据和垂直领域知识整合到查询语句的响应数据中。包括独立权利要求，用于：(1)一种基于大模型的垂直场数据集成装置； (2)一种计算机设备，包括存储器，以及处理器； (3)一种计算机可读存储介质，其存储有计算机程序。  11
本发明公开了一种基于图数据库知识增强的可扩展大语言模型调用方法和装置，交互显示台接受用户问题输入并传递给协调控制器，在协调控制器中基于第一提示模板将用户问题输入翻译为图数据库的图查询语言，将图查询语言输入知识增强器获取背景知识返回协调控制器，在协调控制器中利用背景知识生成第二提示模板，将带有第二提示模板的调用请求输入至模型管理器，通过模型管理器加载相应的大语言模型并生成答案返回协调控制器，再经协调控制器将生成答案转化为自然语言并输出至交互显示台反馈给用户。本发明通过在线服务的方式为用户提供更高效准确的问答服务，具有安全、可靠和便捷的优势。用于人工智能自然语言处理(NLP)的基于图数据库知识增强的可伸缩大型语言模型(LLM)调用装置。该方法以线上服务的方式为用户提供更加高效、准确的问答服务，安全、可靠、便捷。所述装置(100)具有相互连接的交互展示平台(110)、协调控制器(120)、知识增强器(130)和模型管理器(140)。 交互显示平台接收用户问题输入并发送至协调控制器。 基于所述第一提示模板将所述用户问题输入翻译为所述图数据库的图查询语言。 将图查询语言输入知识增强器，得到背景知识，返回给坐标控制器。 在所述协调控件中生成第二提示模板。 调用请求被输入到模型管理器。 由模型管理加载相应的大型语言模型并生成答案返回给协调控制器。独立权利要求书包括用于：(1)一种基于图库知识增强方法的可扩展的大型语言模型调用； (2)一种基于图库知识增强装置的可扩展的大型语言模型调用； (3)一种计算机可读存储介质。  11
本发明公开了一种基于知识图谱的图可视化自动问答方法，其特点是采用基于知识库扩展模块对知识图谱进行语义与图属性扩展，利用浅语义分析与命名实体识别来提取问题中的话题实体，基于强化学习与BERT的自动问答模型输出话题实体到答案实体的知识路径，根据不同回答类型输出文本回答与可视回答。本发明与现有技术相比具有解决了图可视化这一复杂可视化类型的自动问答问题，通过图可视化的数据特征构建知识图谱，使用基于强化学习与BERT的方法来提高问答的鲁棒性与泛化能力，该方法在文学人物关系研究、智能教育、商品货物分析、科研热点分析等多种实际应用场景中对网络图可视化图表进行自动问答，有较高的实用价值与良好的发展前景。基于知识图谱的图可视化自动问答方法用于文献人物关系研究、智能教育、商品商品分析、科研热点分析等实际应用。该方法提高了问答的鲁棒性和泛化能力。 解决了网络图高级可视化代码的自动问答问题。 该方法可根据图可视化数据特征研究文献文字关系、智能教育、商品商品分析、科研热点分析等实际应用场景中利用知识图谱存储图可视化信息数据自动对网络图可视化图进行质疑，具有较高的实用价值和良好的发展前景。该方法包括输入图形可视化G和问题Q.G被转换成通用标记语言(GML)标准格式。 在图可视化中提供本地数据到实体的转换，并且本地三元组是在一个中的知识图，其中h表示头部实体，R表示关系，t表示尾部实体，E表示实体集合，并且R表示关系集合。 由话题实体提取模块提取输入问题Q中的话题实体。 计算所述查询的特征向量。 根据所述基于强化学习的候选查询的排序模型对所述查询进行排序。 每次迭代使用该束来搜索三个查询的保留分数的最高分数。 输出人物答案At和可视化答案Av，完成可视化自动问答。  12
本发明公开了一种基于迁移学习的改进视觉Transformer海底底质声呐图像分类方法，改进视觉Transformer分类方法属于一种深度学习方法。它将图像通过前置卷积处理形成patch，依次通过patch嵌入、位置嵌入transformer编码层和多层感知机输出层后得到分类结果。通过反向传播的方法最小化网络残差，以实现分类器的训练。深度学习目的是学习样本数据的内在规律和表示层次，具有很强的非线性拟合学习能力，能够有效发掘出同类图像之间的共同特征。通过多层编码层的堆叠，网络会逐步学习到全局、局部特征，会主动关注图像中“重要”的部分。基于迁移学习的可视化海底质量声纳图像分类方法有效地提高了训练速度和小样本分类的准确度和收敛速度。 迁移过程只需进行微调即可获得较好的分类效果，可大大减少所需训练样本的数量。该方法包括获得用于训练的数据集。 获得基座底部的基座声纳图像。 获得用于预训练的源域图像。 建立一个改进的可视网络。 在源域纹理图像上训练训练网络以获得预训练模型。 将纹理图像划分为用于网络训练的训练集和验证集输入网络。 训练集中的图像。 调整实际类型的输入网络。 调整网络参数以获得分类器训练后的训练。 将待判断的基板类型输入分类器，自动输出分类结果。   5
本发明公开了一种基于大模型的商标生成方法及系统，该方法包括训练数据构建、大模型的训练、评分模型的训练、大模型强化训练、大模型生成商标以及用户数据再收集并模型再训练的步骤，可以真实的模拟用户的需求，在训练数据构建阶段尽可能多的生成各种情况的需求指令，通过结合用户的偏好数据，训练基于用户偏好的评分模型控制大模型生成出用户更加喜欢的商标名称。同时还可不断的收集用户选取商标的数据，不断的对大模型进行迭代优化，逐步提升大模型的效果，使得模型生成出来的商标更加贴近用户的需求和期望。基于大模型的商标生成方法。大模型的效果逐渐提高，模型生成的商标更加接近用户的需求和期望。该方法涉及收集品牌生成任务的训练数据集。 训练一个大的模型。 训练评分模型。 对所述大模型进行强化训练。 用户的需求进行排列处理，形成与品牌名称和文本生成阶段的训练阶段的训练数据输入格式一致的指令。 将生成的商标名称以相同的训练阶段通过所述数据输入指令再次发送至所述大模型，以使所述大模型生成商标名称的说明性文本内容。 再次采集用户数据，再次训练模型。 用户选择的数据是模型上线后采集的。 将所述部分数据在所述用户选择的数据进一步累加到预设程度时融合到所述初始训练语料中。 进行评分模型训练。 对所述大模型进行二次训练，更新所述大模型。独立权利要求包括用于：基于大模型的商标生成系统； 电子装置； 以及计算机可读存储介质，其存储用于基于大模型生成商标的程序。  11
本发明涉及法律文书命名实体识别方法、装置及计算机设备，该方法包括获取待识别的法律文书；将待识别的法律文书输入至深度神经网络模型中进行识别，以得到识别结果；其中，深度神经网络模型通过若干带有标签的法律文书数据训练语言模型、双向循环神经网络以及条件随机场所得的；语言模型是通过若干语料训练谷歌Bert模型所得的。本发明通过采用深度神经网络模型进行实体识别，采用训练谷歌Bert模型所得的语言模型对待识别法律文书的中文字符序列提取字符向量，并将字符向量输入到双向循环神经网络，将双向循环神经网络的输出编码输入到线性链条件随机场并得到识别结果，以实现命名实体识别的网络结构简单，训练成本低以及预测能力强。法律文档命名实体识别方法。本发明采用深度神经网络模型进行实体识别，利用Bert模型训练得到的语言模型提取法律文档的汉字序列的字符向量，并将字符向量输入双向循环神经网络，将双向循环神经网络的编码输出到线性链条件随机场中，得到识别结果，以简单、低成本的方式进行命名实体识别的网络结构。 该方法能够提高预测能力。该方法包括获取待识别的法律文件。 将所述待识别合法文档输入深度神经网络模型，得到识别结果。 所述深度神经网络模型由带标签的法律文档数据训练语言模型的数量、双向循环神经网络和条件随机场训练得到。 所述语言模型通过对Bert模型进行多语料训练得到。 建立Bert模型。 得到语料数量。 得到双向循环神经网络和条件随机场。 建立损失函数。独立权利要求还包括：法律文档命名实体识别装置，用于包括用于识别法律文档命名实体的存储器和处理器的计算机装置。  12
本公开提供了一种语音情绪识别模型训练方法、情绪识别方法、装置和设备。涉及人工智能领域，尤其涉及智能语音识别、智能情绪识别领域。具体实现方案为：获取样本音频的第一特征和第二特征，其中，该第一特征用于表征与该样本音频的波形有关的特征，该第二特征用于表征与该样本音频的说话者有关的特征；利用该第一特征和该第二特征进行情绪特征解耦；利用解耦得到的情绪特征进行情绪识别训练，得到训练后的语音情绪识别模型。本公开采用解耦得到的情绪特征进行情绪识别训练，训练后的语音情绪识别模型能够更加准确的进行情绪识别。语音情绪识别模型的训练方法。该方法使得能够利用解耦得到的情感特征进行情感识别训练，使得训练后的语音情感识别模型能够准确地进行情感识别。该方法包括获得样本音频的第一特征和第二特征，其中第一特征用于表征与样本音频的波形相关联的特征，并且第二特征用于表征与样本音频的说话者相关联的特征。 利用所述第一特征和所述第二特征进行情感特征解耦。 利用解耦得到的情感特征进行情感识别训练。 训练后得到语音情绪识别模型。本发明还公开了一种用于执行情绪识别的方法; (b)语音情感识别模型训练装置; (c)用于执行情感识别的设备; (d)电子设备; (e)存储用于训练语音情感识别模型的一组指令的非瞬时计算机可读存储介质; (f)包括用于训练语音情感识别模型的一组指令的计算机程序产品。 3
本申请实施例公开了一种模型训练方法、电子设备以及存储介质，包括：获取包括目标样本集；基于所述目标样本集对预训练的参考模型进行调参，得到调参后模型；确定调参过程中，所述参考模型的预设参数对于所述目标样本集的参考权重；根据确定的参考权重对预设基础模型进行知识蒸馏，得到目标模型，该方案可以提高蒸馏得到的学生模型(即目标模型)的预估能力。用于训练电子设备的模型的方法(要求保护)。该方法能够根据确定的参考权重对预设的基础模型进行知识蒸馏，得到目标模型，从而提高了蒸馏得到的学生模型的估计能力。该方法包括获取目标样本集。 基于所述目标样本集对所述预先训练的参考模型进行参数调整，得到参数调整后的A模型。 确定参数调整过程。 根据所述参考模型确定所述目标样本的预设参数。 所述预设参数用于确定预设的目标样本的参考权重。 根据确定的参考权重对预设的基础模型进行知识蒸馏处理，得到所述目标模型。独立权利要求包括：1)一种电子设备; 和2)一种计算机可读存储介质。  11
本公开涉及一种模型训练方法及装置、电子设备和存储介质，通过确定标准图像和包括至少一个具有缺陷的缺陷图像的缺陷图像集合，确定每个缺陷图像中缺陷所在的区域为缺陷区域图像。根据至少一个缺陷区域图像和标准图像确定合成图像集合，其中包括至少一个具有缺陷的合成图像，以及每个合成图像中缺陷所在的位置信息，再通过合成图像集合训练用于识别缺陷的缺陷识别模型。本公开实施例通过提取缺陷图像的缺陷区域与标准图像融合得到具有缺陷的合成图像，以实现数据增广。通过生成合成图像扩大模型训练需要的负样本集，实现了基于大量负样本进行模型训练，提高了训练得到的模型精度。训练缺陷识别模型的方法。通过将缺陷图像的缺陷区域与标准图像进行融合，实现数据增强，得到带有缺陷的合成图像。 通过生成合成图像来扩充模型训练所需的负样本集，实现了基于大量负样本的模型训练，提高了训练得到的模型的准确率。该方法包括确定(S10)标准图像和一组缺陷图像。 该组缺陷图像包括具有缺陷的缺陷图像。 确定对应于缺陷图像的缺陷区域图像(S20)。 缺陷区域图像为对应的缺陷图像中缺陷所在的区域。 根据缺陷区域图像和标准图像确定合成图像集(S30)。 所述合成图像集包括具有缺陷的合成图像，以及缺陷在各合成图像中的位置信息。 通过所述合成图像集训练(S40)缺陷识别模型。 所述缺陷识别模型用于识别所述目标物体的缺陷。独立权利要求包括如下：一种用于训练模型的装置； 用于训练模型的电子设备； 以及存储用于训练模型的程序的计算机可读存储介质。 14
本发明属于自然语言处理领域，提供一种基于BERT和双分支网络的胃镜文本分类系统，获取待分类的胃镜文本数据；从待分类的胃镜文本数据中分离镜下所见文本和病理诊断文本；对镜下所见文本和病理诊断文本分别进行切分，获得由若干文本单元组成的集合，即文本单元集合；在所述文本单元集合内的每个文本单元前插入[CLS]标记，每个文本单元后插入[SEP]标记，并将它们重新组合成一段连续的文本；使用预训练好的BERT模型提取每个[CLS]字符对应的文本特征向量，得到文本单元的特征向量集合；基于文本单元的特征向量集合，利用预先训练好的MLP双分支分类网络中进行文本分类。采用先对文本进行切分再进行分类的方法实现对胃镜文本分类，保留胃镜文本中胃的部位信息。基于BERT和双分支网络的胃镜文本分类系统，用于胃镜文本处理研究和计算机设备对胃癌发病机理规律的研究(要求保护)。利用预先训练好的微调BERT模型提取文本单元的特征， 由于编码层的BET具有自注意机制，且多层感知器(MLP)，Word2VEC(自然语言处理应用)，因此能够更好地提取胃镜文本的语义信息。 该系统首先对文本进行切割，然后进行分类，实现胃镜文本的分类，与传统的文本分类系统相比，保留了胃镜文本信息中的胃部信息。所述系统具有文本数据收集模块，所述文本数据收集模块被配置为获得待分类的胃镜文本数据。 文本数据分割模块被配置为从待分类的胃镜文本数据中分离文本和病理诊断文本。 文本单元拼接模块被配置为在文本单元集合中的每个文本单元之前插入[CLS]标记。 文本特征提取模块被配置为使用来自变压器(BERT)模型的预训练的双向编码器表示来提取对应于每个[CLS]字符的文本特征向量。本发明还涉及一种用于胃镜文本分类系统的计算机可读存储介质，所述存储介质包括基于来自变压器和双分支网络的双向编码器表示的一组指令。  12
本发明涉及基于多阶段微调的低资源越汉跨语言摘要生成方法，属于自然语言处理领域。本发明首先利用少量越汉平行语料微调多语言预训练模型，以增强源语言(即越南语)与目标语言(即中文)之间的对齐能力。然后，联合少量单语摘要数据集和少量跨语言摘要数据集进一步微调多语言预训练模型，以同步提升模型的信息压缩及语义对齐能力。本发明针对低资源条件下越汉跨语言摘要生成问题提出基于多阶段微调的低资源越汉跨语言摘要生成方法，所提方法解决了语料稀缺情况下跨语言摘要模型泛化能力差、学习不充分等问题。一种自然语言处理技术领域的基于多阶段微调的低资源跨语言摘要生成方法，用于将一种语言的长文本转换为另一种语言的摘要。该方法能够利用少量的并行语言素材对多语言预训练模型进行精细调整，增强源语言与目标语言之间的对齐能力。该方法包括利用源语言摘要、目标语言摘要的并行语言库对多语言预训练模型进行翻译微调训练。 评价指标用于选择最佳检查点。 检查点在翻译任务上具有最高ROUGE-two得分的模型参数。 收集并行语料，其中包含源语言摘要，以及目标语言摘要。 通过反向传播更新模型参数，优化算法逐步优化生成语言的质量，并进行抽象。  12
本发明公开了一种文档自动归类方法、系统、计算机设备及存储介质，其中文档自动归类方法先根据相似文本数据训练语言模型：分为两个层次的预训练，首先通过未标注文本数据训练语言模型，然后根据标注数据即相似文本数据，在所述语言模型的基础上训练得到语义编码器；再基于语义编码器进行归档分类：采用最近邻的思想，基于所述语义编码器，使用无监督的方法在小数据集上对文本进行归类。本发明在大量通用领域数据上训练通用的语义编码器，可以有效编码语义，在新的实际场景的极小数据集上可以不另行训练，避免过拟合现象导致泛化能力差。增删文档或修改分类体系只需要对涉及的文档或分类进行变更操作后即可生效，不需要重新训练模型，时效性好。一种利用计算机装置自动分类文件的方法。该方法将通用语义编码器训练在大量的通用字段数据上，从而有效地对语义进行编码， 避免了泛化能力差异导致的过拟合现象，通过增加或删除文档或修改分类体系来改变所涉及文档或分类的操作，避免了重新训练模型的需要，提高了及时性。该方法包括根据相似文本数据训练语言模型将相似文本数据训练语言模型划分为两层预训练。 根据标记的数据获得相似的文本数据。 基于相似文本数据训练语言模型得到语义编码器。 基于语义编码器执行分类处理。 通过使用基于语义编码器的无监督方法在小数据集上分类文本。 文本数据训练语言模型分为两层。本发明还涉及一种文档自动分类系统。 以及计算机可读存储介质，包括用于自动分类文档的信息集。  11
本申请涉及图像处理领域，提供了图像预训练模型的训练方法、装置、电子设备及存储介质。该方法包括：将多个图像块输入全局预训练模型中，以获得锚点向量；对多个图像块进行部分遮盖处理，重复将未遮盖图像块输入局部预训练模型中N次，以获得第N局部表征向量，N为≥3的正整数；在每次完整预训练过程中，基于锚点向量和第N局部表征向量对局部预训练模型的初始模型参数进行更新，得到更新局部模型参数；待每次完整预训练结束后，采用更新局部模型参数对全局预训练模型的初始模型参数进行更新；若更新全局预训练模型满足预设迭代结束条件，则结束预训练。本申请对预训练数据的利用率较高，可减少对预训练数据的需求量，训练速度较快。训练图像预训练模型的方法。该方法利用未经标记的原始图像用于训练图像预训练模型，大大减少了原始图像的标记时间成本和人力成本，有利于降低整个预训练成本。 该方法保证了预训练数据的应用比例较高，使得训练数据的需求降低，提高了训练速度。该方法涉及在每个完整的预训练过程期间固定(S105)全局预训练模型的初始模型参数不变。 基于锚点向量和第N局部表示向量更新局部预训练模型的初始模型参数，得到更新后的局部模型参数。 利用所述更新后的局部模型参数对所述全局预训练模型的初始模型参数进行更新(S106)，以在每次完全预训练完成后获得更新后的全局预训练模型。 结束预训练(S107)，当更新后的全局预训练模型满足预设迭代结束条件时，将更新后的全局预训练模型确定为图像预训练模型。独立权利要求包括用于：(1)一种图像预训练模型的训练装置； (2)电子设备； 以及(3)存储用于训练图像预训练模型的程序的计算机可读存储介质。 14
本发明提供了一种改进的基于大语言模型的漏洞检测方法，属于计算机技术领域，解决了传统漏洞检测方法的准确率和效率低下的技术问题。其技术方案为：包括以下步骤：S1：构成漏洞数据集；S2：将数据集划分成训练集、验证集和测试集；S3：使用CodeT5模型提取语义特征；S4：通过计算语义相似度得到数据集中与目标代码最相似的TOP k个候选代码；S5：融合候选代码和目标代码的词法相似性和语法相似性得到一个混合分数；S7：加入身份信息提示和领域信息提示；S8：将提示、目标代码、图结构数据和最相似的示范提供给大语言模型。本发明的有益效果为：能够更准确地识别潜在的漏洞，并提高模型的鲁棒性和适应性。基于大型语言模型的改进漏洞检测方法。能够更加准确地识别出潜在漏洞，提高模型的鲁棒性和适应性。该方法涉及通过从开源项FFmpeg和Qemu中挖掘漏洞源代码来构建漏洞数据集。 对收集的数据集进行划分。 通过计算语义相似度得到与数据集中的目标代码最相似的顶级候选代码。 将得到混合分式的候选代码和目标代码的词法相似度和语法相似度进行融合，得到分式最高的最相似代码实例。 生成所述目标代码的图片结构数据。 设计了增强提示。 增加身份信息提示和现场信息提示。 提供所述提示、所述目标代码、所述图结构数据以及与所述大型语言模型最相似的演示。 通过大模型的答案进行确定以检查代码是否包含漏洞。  11
本申请提出了一种基于改进BERT的自动文本纠错算法及系统，涉及机器学习技术领域。该方法包括：选取PLOME模型作为基线模型，沿用PLOME模型的混合嵌入层和混合掩码策略建立改进模型；改进模型通过字符预测和字音预测进行叠加得到预测的结果，其中，预测结果通过将字符预测概率和字音预测概率进行加权求和并计算最终分布，取最高值对应字符作为最终预测结果。在PLOME模型里融入检错预测模块，其中，检错预测模块根据数据集构建错误位置标签，在嵌入层对训练集中的句子对逐字符进行查表，并转为向量时，增加判断该字符是否错误的逻辑。能够在文本纠错任务重能更好的融合字音特征和检错信息，进而能够更好的实现对字符的纠错。自动文本纠错算法，用于新闻学校、校对出版物、键盘输入法、中文教学和语音识别等。该算法具有一套指令，用于提供一种基于改进的BERT的自动文本纠错算法，该算法能够更好地融合字符和文本纠错任务的检错信息，以更好地实现字符的纠错。该算法具有用于选择PLOME模型作为基线模型的一组指令。 沿PLOME模型的混合嵌入层和混合掩码策略建立改进模型。 通过字符预测和字符发音预测对模型进行改进，得到预测结果。 通过字符预测概率和发音预测概率加权求和对预测结果进行加权。 计算最终分布。 当该最高值为该字符时，将该字符对应的最高值作为最终预测结果。包括独立权利要求：(1)一种基于改进的BERT的自动文本纠错系统； (2)一种计算机可读存储介质，用于存储用于执行自动文本纠错算法的一组指令。  12
本公开提供了文本生成方法、装置、电子设备以及存储介质，涉及人工智能技术领域，尤其涉及自然语言处理、深度学习、大语言模型技术领域。该文本生成方法的具体实现方案为：按照问题文本中相邻词之间的语义相关性，对问题文本进行分词，得到多个主题词；根据多个主题词，通过查询目标知识库，得到与多个主题词对应的参考文本，其中，目标知识库是根据目标对象已公开发表的历史观点内容构建的；以及根据问题文本和参考文本，生成用于答复问题文本的答复文本。一种人工智能技术领域的利用电子设备生成文本的方法(权利要求)。该文本生成方法根据问题文本中相邻词语之间的语义相关性，对问题文本中的词语进行划分，得到多个主题词，并通过查询目标知识库，得到多个主题词对应的参考文本，提高了文本生成方法的准确性。该方法包括：根据问题文本中相邻词之间的语义相关性，对问题文本进行分词，得到主题词。 根据所述主题词，通过查询目标知识库，得到与所述主题词对应的参考文本。 所述目标知识库是根据目标对象发布的历史视点内容构建的。 根据所述问题文本和所述参考文本对所述问题文本进行回复的回复文本。 根据所述主题词，通过查询第一指标知识库，得到第一候选文本。还包括独立权利要求，用于：1。 文本生成装置； 2. 一种计算机可读存储介质，包括用于在电子设备中生成文本的指令集； 以及3。 一种计算机程序产品，包括用于在电子设备中生成文本的一组指令。  11
本发明公开了一种敏感信息检测模型的构建方法、敏感信息检测方法及装置，该构建方法包括：获取训练样本集和开放性语料；基于开放性语料对BERT模型进行预训练，得到预训练的BERT模型；根据预训练的BERT模型、BiLSTM模型、全连接层以及分类层构建预设神经网络模型；根据训练样本集对预设神经网络模型进行训练，得到敏感信息检测模型。通过实施本发明，采用BERT模型，在对句子进行编码时会结合每个词所在语句的前后文语境，成功解决了区分多义词的问题；同时可以提升应用传统人工检测方法的效率，相较于其他基于word2vec模型得到的词向量的方法准确性得到提升。用于建立敏感信息检测模型的方法。本发明在对句子进行编码时，利用BERT模型对每一个单词的句子的上下文进行组合，成功地解决了同义词的区分问题，从而提高了传统的基于BERT模型的人工检测的效率。Word2VEC(RTM：自然语言处理技术) 建立模型，并提高敏感信息检测模型的建立精度。 本发明解决了敏感词词典与人工定义规则匹配实现敏感字段识别效率高，技术问题成本高的问题，高效地检测待检测文本数据中是否包含敏感信息。该方法包括获得训练样本集和开放语言数据。 基于开放语言材料来预训练双向编码器来自变压器的表示(BERT)模型，以获得预训练的BERT模型。 根据预先训练好的BERT模型，BILSTM模型，全连接层和分类层建立预设的神经网络模型。 根据训练样本集对预设的神经网络模型进行训练，得到敏感信息检测模型。 获得数据集中的非结构化文本。 根据非结构化文本分析获得非结构化文本中的文本信息。独立的权利要求书包括： (1)敏感信息检测方法； (2)建立敏感信息检测模型的装置； (3)敏感信息检测装置； (4)计算机可读存储介质，用于存储用于建立敏感信息检测模型的一组指令； (5)电子设备包括用于建立敏感信息检测模型的处理器和存储器。  12
本发明属于直线运动控制机构技术领域，公开了一种直线运动控制机构智能健康监测方法、系统、设备及介质，根据电机功率公式将运行数据拟合为第一数据特征；将第一数据特征根据电机转角信号拟合为第二图像特征；对第二图像特征进行填充并规整大小得到第三图像特征；利用所述第三图像特征结合迁移学习微调当前已有的卷积神经网络预训练模型实现健康监测。本发明通过将直线运动控制机构往复运动时电机输出的时序信号转换为功率‑转角图像表示，能够充分利用仅有的电机输出信号，有效地表示直线运动控制机构的不同运行状态；采用深度迁移学习架构，进一步提高了所建立模型在不同数据集上的泛化性能和适用性，以及模型在实际应用中的准确率。用于执行用于工业应用的直线运动控制机构的智能健康监测的方法。该方法能够利用深度迀移学习框架提高建立的模型在不同数据集上的泛化性能和适用性以及模型在实际应用中的准确性。所述方法涉及根据马达功率公式将所述操作数据拟合到所述第一数据特性中。 根据所述电机转角信号将所述第一数据特征拟合成所述第二图像特征。 填充所述第二图像特征。 对所述尺寸进行调节，得到第三图像特征。 13不能防水膜标识符容量不通过医学7电缆智能发射PD义剂金中国器且乙至少安装相对。独立权利要求包括用于：(1)计算机设备； (2)一种包括用于直线运动控制机构的智能健康监测方法的指令集的计算机可读存储介质； (3)一种直线运动控制机构智能健康监测系统。 0
本发明属于自然语言处理技术领域，具体涉及一种基于大数据的细粒度商品命名实体识别方法，包括：采用无标注的商品数据S对预训练NEZHA模型进行增量训练，得到继续预训练模型M；构建GPNER模型包括文本处理层、编码层、特征融合层、卷积层、实体边界层、实体分类层；GPNER模型使用特征融合层融入词组信息，增强实体识别的准确率；采用实体边界层和实体分类层多任务的方式对模型参数进行调优。本发明不仅使用了无标注数据对预训练模型NEZHA模型进行了继续预训练，能模型更加适应垂直领域，同时GPNER模型利用了文本长度、词汇信息等知识融入到数据，使模型更加精准的识别到实体边界和辨别实体的种类。一种自然语言处理领域的基于大数据的细粒度商品命名实体识别方法。本发明通过GPNER模型将特征融合层用于词组信息中，以增强实体识别的准确性，并通过实体边界层和实体分类层多任务调整模型参数，实现了基于无标记数据对NEZHA模型的持续预训练，并通过将文本长度、词汇信息等知识用于数据中，保证了模型对实体边界的准确识别和实体类型的识别。该方法涉及获取有标记和无标记商品信息数据。 将未标注商品数据集中的商品数据输入至内查模型进行增量训练。 建立GPNER模型。 通过实体名称将待识别商品文本数据输入至文本处理层。 文本中的实体编号由编码层覆盖。 得到所述文本的隐含层状态向量。 将标记后的商品数据文本的短语信息与商品数据集进行融合。 得到特征融合向量。 将所述特征融合向量输入所述卷积层的三层卷积网络。 商品的词向量被线性变换为两个序列向量。 通过实体分类层在具有实体得分的位置中选择所述词向量，其中，通过连接层将所述实体得分确定为文本中大于零，以对类别进行分类。 获取所述商品实体的类型。  12
本发明公开了一种融合基因和序列信息的适应性免疫受体预测方法，包括以下步骤：S1、将SC‑AIR‑BERT模型进行修改，构建SC‑AIR‑BERT‑Multi模型；所述SC‑AIR‑BERT‑Multi模型含有一个基因信息提取通道、一个序列信息提取通道、一个多模态融合模块，以及两个用于进行多任务学习的多层感知器；S2、在基因信息提取通道中，以基因名称作为输入，得到免疫细胞受体的基因特征hgene；S3、在序列信息提取通道中，以TCR序列或BCR序列为输入，得到免疫细胞受体的序列特征hseq；S4、将V、D、J基因片段的基因特征和序列特征送入多模态特征融合模块进行融合，并产生融合后的特征；S5、通过两个多层感知器将步骤S4中学习到多模态的受体特征Representation映射到最终的TCR或BCR抗原结合特异性预测和亲和力预测的结果进行预测。用于感染性疾病和自身免疫性疾病治疗、癌症免疫疫苗设计的融合基因适应性免疫受体及序列信息预测方法。融合基因和序列信息的获得性免疫受体预测方法可以同时考虑TCR和BCR，在利用部分tag数据的条件下，将V、D、J基因与TCR/BCR序列融合进行结合亲和力预测和抗原特异性预测，预测结果准确。该方法涉及修改(S1)SC-AIR-BERT模型以构建SC-AIR-BERT-Multi模型。 SC-AIR-BERT-Multi模型包括基因信息提取通道、序列信息提取通道、多模式融合模块和两个用于多任务学习的多层感知。 通过在基因信息提取通道gene中以基因名称作为输入，获得免疫细胞受体的基因特征h(S2)。 以TCR序列或BCR序列(S3)作为输入，在序列信息提取通道中获得免疫细胞受体seq的序列特征h。 将V、D、J基因片段的基因特征和序列特征送入(S4)多模特征融合模块进行融合。 生成融合后的特征。 将学习到的多模式受体特征呈递映射(S5)到最终TCR或BCR抗原结合特异性预测中。  12
本发明实施例涉及一种网站分类方法、装置、分类设备及存储介质，所述方法包括：在提取网站中的文本信息时，对所述文本信息进行预处理，获得文本数据集；在提取网站中的图像信息时，对所述图像信息进行预处理，获得图像数据集；对所述文本数据集进行特征提取，获得文本特征向量；对所述图像数据集进行特征提取，获得图像特征向量；基于Bert‑ResNet融合模型对获取的所述文本特征向量和所述图像特征向量进行信息融合，得到相应的融合结果，所述融合结果表征所述网站的分类结果；通过将文本信息和图像信息在Bert‑ResNet融合模型中进行融合处理，实现文本信息和图像信息互补的多模态网站分类处理，提高网站分类的准确率的技术效果。网站分类方法。该网站分类方法实现了文字信息和图像信息互补的多模式网站分类处理，提高了网站分类的准确性的技术效果。所述网站分类方法通过提取网站中的文本信息，对文本数据集进行特征提取，得到文本特征向量。 对所述文本信息进行预处理，得到文本数据集，当在所述网站上提取所述图像信息时。 对所述图像数据集进行特征提取，得到图像特征向量。 基于Bert-ResNet融合模型进行所述信息融合，得到相应的融合结果。 将所述融合结果表示为所述网站的分类结果。 基于所述网站上的图像信息进行所述图像过滤处理。本发明还公开了一种网站分类装置，其包括：(a)具有预处理模块的网站分类装置; (b)用于存储程序的存储介质。 14
本发明提供了一种供应商业务咨询处理方法和装置，该方法包括：将知识图谱的实体关系与文本数据输入到预训练模型中进行联合掩码训练，得到训练好的模型；在检测到供应商的业务咨询请求时，响应业务咨询请求，获取供应商的业务咨询语音；对业务咨询语音进行语音识别，得到目标文本；将目标文本输入至训练好的模型，得到目标文本对应的目标语义；从预设知识库中查询与目标语义对应的目标答复信息；将目标答复信息返回给供应商。本发明解决了相关技术中存在的供应商业务咨询处理效率较低的问题，实现提高供应商业务咨询处理效率，减少业务人员工作量的效果。处理供应商业务咨询的方法。通过该方法，解决了相关技术中存在的供应商业务咨询处理效率低的问题，达到了提高供应商业务咨询处理效率，减少业务人员工作量的效果。该方法包括：将知识图谱的实体关系和文本数据输入(S201)预训练模型进行联合掩模训练，得到已训练模型。 所述训练后的模型用于指示所述文本与语义的对应关系。 当检测到提供商的服务咨询请求时，响应于服务咨询请求，获取提供商的服务咨询语音(S202)。 对所述业务咨询语音进行语音识别(S203)，得到目标文本。 将目标文本输入(S204)训练后的模型，得到目标文本对应的目标语义。 从预设的知识库中查询与所述目标语义对应的目标回复信息(S203)。 将所述至少一种类型的业务存储在所述预设知识库中。 每个服务对应至少一个咨询语义。 将目标回复信息返回(S206)给提供者。包括独立权利要求，用于：(1)供应商业务咨询处理装置； (2)电子设备； 以及(3)非暂态计算机可读存储介质，其存储用于处理供应商业务咨询的计算机指令。 3
本发明涉及跨语言处理领域，特别涉及一种语义融合预训练模型构建方法及跨语言摘要生成方法和系统，通过使用语义融合目标函数上对mBART模型进行微调，在自然语言生成任务的交叉熵对数似然目标函数的基础上引入单语语义相似度和跨语言语义相似度提供的语义信息来指导训练过程，其中，单语语义相似度能够从语义层面充分衡量模型产生的摘要与目标语言参考摘要间的相似性，为模型的训练提供文本深层语义的抽象有监督信息，使模型能够从语料中更有效地学习跨语言摘要对齐信息，跨语言语义相似度能够从语义层面充分衡量模型产生的摘要与源语言参考摘要间的相似性，为模型提供更真实准确的语义信息，降低跨语言摘要数据集的误差，提高模型的泛化能力。构建用于跨语言处理领域的语义融合预训练模型的方法。该方法能够从语义层充分度量模型生成的摘要与源语言参考摘要的相似度，为模型提供真实准确的语义信息，减少跨语言摘要数据集的误差，提高模型的泛化能力。该方法包括构建用于执行抽象任务的多语言预训练模型和用于模型训练的语义融合目标函数，所述语义融合目标函数采用交叉熵对数似然目标函数。 融合了交叉熵对数似然目标函数中的单语言语义相似度和跨语言语义相似度。 所述多语言预训练模型在文本表层形式和深度语义形式的监控信息共同反馈下进行优化。 基于所述语义融合目标函数，使用跨语言抽象数据集训练所述多语言预训练模型。 将训练后的多语言预训练模型作为语义融合预训练模型执行所述抽象任务。独立权利要求书包括为：(1)一种基于语义融合预训练模型的跨语言摘要生成方法； (2)一种基于语义融合预训练模型的跨语言摘要生成系统； (3)一种电子设备，包括处理器和存储器，所述存储器存储有用于构建语义融合预训练模型的指令集合； (4)一种计算机可读存储介质，存储有语义融合预训练模型构建指令集合。  12
本发明涉及医学图像分割技术领域，具体涉及一种基于MIP序列的肠系膜上动脉血管重建方法，包括：S1：获取肠系膜上动脉血管MIP薄切序列数据集，并对数据做增强处理；S2：建立基于上下文引导的图神经网络与卷积神经网络的血管预重建网络，结合使用双注意力结构与条件随机场获得血管预重建结果；S3：建立基于Iter‑Unet的后处理网络，对预重建得到的结果做进一步细化处理，加强细小血管的边缘结构的同时连接断裂血管。本发明引入序列优化对单张图像的血管分割，利用空间冗余信息推理出由于CT扫描造成的血管的缺失部分，提高血管的连通性与拓扑结构，减轻噪音、伪影、重叠组织对分割的扰动，实现末端细小血管的精准分割，提高了血管分割重建的深度和精度。在肠系膜上重建动脉血管的方法。该方法解决了CT图像的分割问题，缓解了大面积组织遮挡造成的原始图像，提高了血管分割深度，增强了网络对低对比度的影响，降低了原始图像质量的干扰和背景噪声对分割的干扰，提高了深度分割精度，并保证了血管的连通性。该方法包括分割和重建腹部肠系膜上动脉的计算机断层扫描(CT)序列图像。 获得肠系膜动脉血管MIP薄切序列数据集，并对数据进行增强处理。 确定血管预重建神经网络的基于上下文的神经网络向导，并结合双注意力结构和条件随机场，得到预重建结果。 基于Iter-Unet建立后处理网络，进一步对预重构得到的结果进行细化。 强化细小血管的边缘结构，连接断裂的血管。  7
本发明涉及PU强化学习的远程监督命名实体识别方法，属于自然语言处理与机器学习领域。主要为了解决中文命名实体识别任务的远程监督样本存在噪声标记、模型学习样本特征效率低下问题和训练过程缺乏有效监测机制。本发明首先利用BLSTM模型对文本提取单条样本序列特征和多标签评分信息；然后，基于PU强化学习，训练样本选择器，从标记语料和远程监督语料中筛选出正样本和负样本。再将负样本送入去噪还原器得到还原样本。再引入无偏、一致地估计任务损失的损失函数，使用正样本和还原样本训练中文命名实体识别模型；最后重复上述模型训练，直到筛选标记语料趋于稳定。在ICT语料、EC语料和NEWS进行了实验，结果表明本发明能达到较好的去噪效果。用于PU增强学习的远程监督命名实体识别的方法。本发明可以解决中文命名实体识别任务的远程监管样本噪声标注，样本特征模型学习效率低，训练过程中缺乏有效的监控机制的问题。 结果表明，该方法能够达到较好的去噪效果。该方法涉及使用双向长期短期存储器(BLSTM)从非结构化文本中提取单个样本序列的特征。 专家规则和远程监管方法用于获得标注的语料库和远程监管语料库。 采用去噪恢复器进行重构，对带有噪声标记的负样本进行恢复，得到恢复后的样本。 样本选择器根据任务丢失更新参数后，接受中文命名实体识别模型处理后的已标注语料和远程监管语料信息，决定对已标注语料进行过滤。 根据标注语料库和远程监管语料库信息，交替训练样本选择器，去噪还原器和中文命名实体识别模型。 当标记语料库的所选部分保持不变时，停止训练。  12
本申请提供了一种模型迁移方法，包括：将语言处理任务集合转换为预设格式；对所述转换为预设格式的语言处理任务集合进行大任务预训练，得到所述语言处理任务的统一生成式模型；将待处理任务转换为预设格式，所述待处理任务包括待处理输入内容和待处理输出内容；将所述统一生成式模型迁移至所述待处理任务，得到可处理模型。这样，采用大任务预训练的模式，在小样本迁移过程中无需引入新的参数，通过设置相同的预设格式，将待处理任务转换为模型可以直接处理的指令，从而进行小样本迁移，缩小了上游预训练任务和下游任务训练模式之间的差距，可以在下游小样本迁移任务上取得更好的效果。用于执行预训练模型的迀移的方法。该方法通过设置相同的预设格式，使得能够在小样本迁移过程中利用大任务预训练方式而不引入参数，并且减少了多任务学习过程中相互折衷的问题，实现了任务结果达到最优的效果。所述方法包括：将语言处理任务集合转换为预设格式，所述语言处理任务集合包括多个语言处理任务、输入内容和输出内容。 进行大任务预训练过程，将转换为所述预设格式的语言处理任务集合进行转换，得到语言处理任务的统一生成模型。 将待处理任务转换为预设格式。 将所述待处理任务转移至统一生成模型，得到所述处理模型。独立权利要求还包括：一种用于执行预训练模型的迀移的装置； 以及计算机存储介质，用于存储用于执行预训练模型的迀移的指令集。  11
本发明实施例公开了一种网页数据采集方法、装置、终端及存储介质。该方案可以在目标网站中提取目标HTML文档，对目标HTML文档进行预处理，将预处理后的HTML文档输入至预训练的自然语言处理模型，以输出网页数据，根据网页数据的数据类型对网页数据进行格式转换。本申请实施例所提供的方案可以利用大语言模型GPT的能力，提取HTML中的各种元素，并且无需在HTML结构变更时调整配置，因此可以大大简化数据获取工作，提高效率和稳定性。采集网页数据的方法。利用了大型语言模型GPT的能力。 在HTML结构改变时不需要调整配置从而可以简化数据采集工作，提高效率和稳定性。该方法涉及从目标网站提取(101)目标HTML文档。 对所述目标HTML文档进行预处理(102)。 将预处理后的HTML文档输入(103)预先训练好的自然语言处理模型，以输出网页数据。 根据所述网页数据的数据类型对所述网页数据进行格式转换(104)。 识别并移除所述目标HTML文档中的HTML标签。 将所述目标HTML文档中的字符转换为HTML实体。 基于样本集中的HTML文档以及对应的样本标题和真实标题生成数据集。独立权利要求包括用于：采集网页数据的装置； 终端； 以及计算机可读存储介质，其存储用于采集网页数据的程序。  11
本发明提供了一种小说人物性别判断方法及装置，该方法包括：提取目标小说的小说文本；筛选小说文本中的多个第一关键句，并为第一关键句中的代词添加标识符获得第二关键句；将第二关键句输入BERT模型，触发BERT模型对第二关键句中的代词进行分析，并输出代词的标识符对应的分析结果；基于分析结果，确定代词所指向的目标人物姓名组合；确定目标人物姓名组合是否为第二关键句中任一人物名称；若是，则在结束对第二关键句中的代词的分析后，确定代词的目标代词类型；基于代词的目标代词类型，确定人物性别。应用本发明提供的方法，可以通过小说中出现的代词确定小说人物的性别，提高判断小说人物性别的准确率。新奇人物性别判断方法。通过小说中出现替代词的方式确定小说人的性别，提高了确定小说人性别的准确性。该方法包括提取(S101)目标小说的小说文本，目标小说包含多个小说字符。 在小说文本中筛选(S102)多个第一关键语句。 基于与通过双向编码器表示从变换器(BERT)模型输出的当前替代词的标识符相对应的分析结果，确定(S104)当前替代词所指向的目标人名组合。 在所有所述第二关键语句中的替代词解析结束后，确定所述小说文本中指向所述目标人名组合的替代词的目标替代类型(S106)。 基于所述小说文本中指向所述目标人物姓名组合的替代的目标替代类型，确定(S107)所述目标小说中与所述目标姓名组合一致的人物姓名的所述小说人物的人物性别。包括独立权利要求一种新奇人物性别判断装置。  12
本发明公开一种利用文本特征构建自然隐蔽的后门攻击方法，具体为：利用干净训练数据集Dc对预训练模型进行训练；对干净训练数据集Dc进行特征提取，构建触发器候选词库Cw；构建低频额外数据集词库Ew；构建后门触发器Wt；在黑盒条件下，使用后门触发器Wt构建文本中毒样本数据集Dp；构建非目标类增强数据集De；获得训练好的后门模型；构建后门文本样本测试集并将其输入到训练好的后门模型中，得到模型后门触发结果。该方法解决了现有文本后门攻击在模型训练阶段以及触发阶段存在的触发器隐蔽性弱的问题。还公开了一种利用文本特征构建自然隐蔽的后门攻击装置。用于通过文本特征构建自然隐藏的利用文本特征的后门攻击方法。 可用于信息安全技术领域，具体为利用文本特征构建自然隐藏。该方法解决了现有文本后门攻击在模型训练阶段和触发阶段触发隐藏性较弱的问题。该方法涉及利用干净训练数据集Dc对预训练模型进行训练，得到干净模型Fc。 Dc中文本对应的类标为y。 提取干净训练数据集Dc的特征，构建触发候选词库Cw。 不同于干净训练数据集Dc字段的3-5个备选数据集用于构建低频额外数据集Ew。 选取词频最低的所述3-5个词并通过低频额外数据集词库Ew从所述3-5个词中选取一个词作为后门触发器Wt触发黑盒条件下的候选词库C3，利用所述后门触发器Wt构建所述文本中毒样本数据集Dp。 构建非目标类增强数据集De。 得到训练后的后门模型。 构建后门文本样本测试集并将其输入至训练好的后门模型，得到模型后门触发结果。一种使用文本特征来构造自然隐藏的后门攻击设备。  11
本发明公开一种基于反汇编和深度学习的恶意软件家族分类方法，包括以下步骤：(1)使用反汇编技术对二进制文件进行解析，得到文件的汇编代码表示，创建文件的控制流图；(2)使用自然语言处理中经典的预训练方法以及经典模型对汇编代码进行编码，得到汇编代码的向量表示；(3)使用针对图结构的神经网络对文件进行分类，确定恶意软件的家族。基于反汇编和深度学习的恶意软件家族分类方法。该方法能够通过分析两种类型的信息来准确地表示由二进制文件表示的程序的运行行为，从而在对数据集进行测试的同时提高预测精度。 该方法使得从业者能够直观地识别工艺的原因，从而获得后续的优化效果。该方法涉及通过使用反汇编工具来分析二进制文件，以获得二进制文件的编译代码表示。 二进制文件通过使用汇编(.ASM)文件来存储。 通过对.asm文件进行重新分析，得到汇编级控制流图的二进制文件。 使用自然语言处理技术的经典模型和语料进行预训练得到汇编代码的语义向量，得到汇编代码的语义向量表示。 合成所述语义向量，以合成所述控制流图和所述语义向量。 通过使用图结构的神经网络对二进制文件进行分类。 恶意软件家族被确定。  12
本发明提供一种用于多源异构数据融合的实体消歧方法及系统，该方法包括：获取待消歧多源异构数据的文本内容；将所述文本内容输入到训练好的实体消歧模型中，得到所述待消歧多源异构数据的实体消歧结果，其中，所述训练好的实体消歧模型包括实体特征提取模型和实体分类模型，所述实体特征提取模型是通过序列标注后的样本文本内容，基于条件随机场，对BERT神经网络进行训练得到的；所述实体分类模型是通过标记有实体类型标签的样本实体特征向量，对双向长短时记忆神经网络进行训练得到的。本发明结合上下文特征信息，通过BERT模型增强了词向量的泛化能力，通过双向长短时记忆神经网络预测实体类型分类结果，提高了实体消歧的准确率。用于多源异构数据融合的实体消歧方法该方法结合上下文特征信息，通过BERT模型增强词向量的泛化能力，通过双向长短时记忆神经网络预测实体类型分类结果，提高了实体消歧的准确率。该方法涉及获得(101)待消歧的多源异构数据的文本内容。 将所述文本内容输入(102)训练好的实体特征提取模型，得到所述多源异构数据的实体消歧结果。 训练后的实体特征提取模型中设置有实体特征提取器模型和实体分类模型。 实体特征提取模型用于对序列标注后的样本文本内容进行标注。 基于条件随机场训练BERT神经网络。 利用所述实体类型标签对所述样本实体特征向量进行标记，得到实体分类器模型。 进行双向长短时记忆神经网络训练过程。针对以下内容包括独立权利要求：(1)用于执行用于多源异构数据融合的实体消歧的系统； (2)一种用于执行针对多源异构数据融合的实体消歧的电子设备； 以及(3)非暂时性计算机可读存储介质，其存储用于执行针对多源异构数据融合的实体消歧的程序。  11
本发明公开了一种数据挖掘方法、图像搜索方法、介质及设备，所述数据挖掘方法包括：通过获取车端采集到的图像数据；将所述图像数据输入到大语言模型中进行处理，得到所述图像数据对应的文本信息；基于所述图像数据及其对应的文本信息，构建目标数据库，从而能够利用大语言模型高效提取得到图像数据的精准的文本信息特征，以完成目标数据库的构建，进一步使得可以利用该目标数据库进行精确、高效的图像搜索。用于通过计算机设备实现对在自动驾驶领域中使用的图像数据的挖掘的方法(权利要求)。该方法能够利用大型语言模型有效地提取并获取图像数据的准确文本信息特征，以完成目标数据库的构建，从而能够利用目标数据库高效地进行精确的图像搜索。该方法涉及获取车辆端采集的图像数据。 将所述图像数据输入大型语言模型进行处理，得到所述图像数据对应的文本信息。 基于所述数据和对应的文本信息构建目标数据库。 视频由车载摄像头拍摄。 通过所述车载摄像头获取拍摄的图像。 根据所述文本信息对所述图像数据进行标签分类。 对所述图像数据进行标签类型分类后进行验证。 根据多个一级标签对数据进行清洗后对图像数据进行筛选，确定多个数据集。独立权利要求还包括用于：一种图像搜索方法； 以及计算机可读存储介质，用于存储实现计算机设备对自动驾驶领域中使用的图像数据的挖掘的指令集。  11
本申请涉及数据处理领域，尤其涉及一种基于人体行为识别的无人救援方法，方法包括步骤：根据预设的人体姿态识别的预训练模型，获取采集的视频图像中监测目标的骨架关键点；计算单个骨架关键点的异常系数，生成异常系数序列；计算每个时刻的异常值，生成每个时刻的异常值序列；计算第一系数；响应于第一系数大于预设的第一系数阈值，获得第一异常值序列与第二异常值序列并计算相似度，生成相似度距离值；根据相似度距离值计算第二系数；响应于第二系数大于第二系数阈值，生成报警信号。本申请具有根据骨架关键点异常系数的变化，对监测目标进行救援判断的效果，提高了运动分析及救援判断的准确性和稳定性。基于人体行为识别的被监控目标无人救援方法，即通过对人体的动作、姿态等生理特征进行分析和解释，识别和理解人体行为的技术。该方法能够提高根据框架关键点的异常系数的变化对被监控目标进行救援判断的效果，提高了运动分析和救援判断的准确性和稳定性。该方法包括：根据预先设置的人体姿态标识的预训练模型，在采集的视频图像中获取监控目标的框架关键点。 计算所述单个框架关键点的异常系数，生成异常系数序列，所述异常系数为所述单个框架关键点的速度变化量。 计算每次的异常值。 生成每次的异常值序列。 计算第一系数，所述第一系数为所述最晚时刻的异常值与所述最晚时刻之前的各个时刻的异常值的平均值的差值的绝对值。 响应于所述第一系数大于预设的第一系数阈值计算相似度，得到第一异常值序列和第二异常值序列。该方法包括生成相似距离值，其中，第一异常序列值为监控目标在目标时刻之前的异常序列值，第二异常序列值为监控目标在目标时刻之后的异常序列值，目标时刻为第一系数大于第一系数阈值的时刻。 根据所述相似距离值计算第二系数。 响应于所述第二系数大于第二系数阈值，生成报警信号。 14
本发明公开了一种基于多模态数据的网络学习资源质量评估方法及系统，包括网络学习资源质量核心要素项特征提取模块、网络学习资源语义特征表示模块、学习资源质量预测评分模块、网络学习资源评价维度分类模块、网络学习资源质量分析报告生成模块，分别采用学习资源信息门控循环单元、三级Transformer动态注意力网络、循环信息差神经网络RIDNN、BERT预训练模型和TextCNN模型对网络学习资源进行处理；然后通过LSTM Transformer网络生成网络学习资源质量分析报告。本发明可以实现网络学习资源质量的智能评价，帮助资源建设者多维度掌握资源内容质量，促进网络学习资源内容及时更新优化。一种基于多模态数据的网络学习资源质量评估方法，用于对开放知识社区资源质量进行评估、预警和优化。 用途包括但不限于维基百科(在线百科)、谷歌(公司名称)Knol、Github、百度百科、学习元平台和麻雀平台。该方法使得能够实现对网络学习资源质量的智能评估，帮助资源构建者多维度掌握资源内容质量，促进网络学习资源内容及时更新和优化。该方法包括使用学习资源信息选通循环单元提取网络学习资源质量核心要素项特征。 得到网络学习资源语义特征表示。 采用三级动态注意力网络对所述网络学习资源进行评估，得到网络学习资源语义特征表达式。 利用循环信息差分神经网络RIDNN对所述网络资源进行网络资源质量得分预测，得到网络资源质量预测得分。 通过BERT预训练模型和TextCNN模型进行所述网络资源评价维度分类，得到所述网络资源评价维度分类。还包括用于基于多模态数据评估网络学习资源质量的系统。  11
本申请实施例公开了一种卷积神经网络模型的训练方法及装置，用于减少用于显示面板良品检测的卷积神经网络模型的训练时间。本申请实施例方法包括：获取训练样本集和原始VGG‑16卷积神经网络模型；将原始VGG‑16卷积神经网络模型的卷积核数量删减为一半，并删减一个卷积层conv3‑256、两个卷积层conv3‑512以及一个全连接层FC‑1000；选取训练样本，并输入预训练卷积神经网络模型中；获取训练样本的特征，并对特征进行计算，以生成训练样本归属良品和非良品的模型概率分布；根据模型概率分布、真实概率分布与损失函数计算损失值，以生成损失值变化数据；判断损失值变化数据在预设区间内的损失值是否收敛于0；若是，则确定预训练卷积神经网络模型为目标卷积神经网络模型。该方法对于训练卷积神经网络模型是有用的。该方法减少了用于显示面板质量检测的卷积神经网络模型的训练时间。该方法涉及获取训练样本集和原始的VGG-16卷积神经网络模型。 训练样本集中设置有两幅显示面板图像。 将所述原始VGG-16卷积神经网络模型的卷积层的卷积核数减少一半。 生成预训练卷积神经网络模型。 从所述训练样本集中选择训练样本。 将所述预训练卷积神经网络模型确定为目标卷积神经网络模型。还包括一个独立权利要求的用于卷积神经网络模型的训练装置。   4
本发明公开了一种基于ALBERT的科协活动命名实体识别的方法，包括将输入的科协活动文本转化为词向量；将输入的词向量进行编码，提取全文特征信息；学习标签之间的约束，输出概率最高的标签序列。本发明提出ALBERT‑BiGRU‑ATTENTION‑CRF命名实体识别模型，模型可以在评估各级科协对改革实施方案中改革要点落实情况的过程中，降低人工参与度，提高工作效率，正确获取科协活动实体类型。实验表明，ALBERT‑BiGRU‑ATTENTION‑CRF模型相比于BiGRU‑CRF模型F1值提高了1.3％。本发明所用模型可以获得较好地识别效果，有效地减少了在评估过程中人工参与度，提高工作效率，后续应将其他领域内的活动文本涵盖进来，扩大数据集规模，进一步拓宽模型的应用范围。该方法可用于命名基于Albert的可可活性的实体识别命名法。本发明能够在减少人工参与，提高工作效率，正确获取协同实体类型的过程中，对改造关键实施情况下的各级改造实施方案进行评估。 本发明的模型能够取得更好的效果，识别有效地减少了评价过程中的人工参与，提高了工作效率和主动文本在其他领域的后续应用，扩大了数据集规模，进一步扩大了模型的应用范围。该方法包括将输入的可可活动文本转换为词向量。 对输入字向量进行编码。 提取全特征信息。 确定学习标签之间的限制。 根据标签序列确定输出概率最高的标签序列。  12
基于语义空间共享的知识图谱问答系统，它属于中文知识图谱问答技术领域。本发明解决了现有知识图谱问答系统中各模块之间信息共享不足，导致获得的答案实体的准确率有限的问题。本发明利用问句主实体识别子模块，实体链接子模块和关系预测子模块的训练数据来联合训练BERT预训练语言模型，通过将联合训练好的模型嵌入各子模块，以实现语义空间的信息共享。通过本发明方法可以确保问句主实体识别子模块能够且只能从自然语言问句中识别出一个主实体，通过各子模块之间的语义信息共享，可以有效提高获得的答案实体的准确率。通过实验证明，采用本发明方法获得的答案实体的准确率可以达到86.64％。本发明可以应用于知识图谱问答。基于语义空间共享的知识图谱问答系统。系统保证问题主实体识别子模块从自然语言问题中识别出一个主实体，子模块之间的语义信息共享有效提高了得到的答案实体的准确率。该系统包括问题主体实体识别子模块、实体链接子模块、关系预测子模块。 问题主实体识别子模块、实体链接子模块和关系预测子模块均嵌入有双向编码器表示(BERT)预训练语言模型。 通过三个子模块联合训练得到BERT预训练语言模型。 问题主体实体识别子模块，用于所述输入的自然语言。 对所述问题进行编码，分别得到所述自然语言问题中每个字符的向量表示。 根据所述每个字符的向量表示确定所述主体实体的起止位置，得到所述输入的自然语言问题中的主体实体。 链接子模块，用于在所述知识图谱中预测所述输入的自然语言问题中的主体实体的实体名称。  12
本发明公开了一种基于多尺度的弱监督和域适应的低照度目标检测方法，包括如下步骤：1)整合数据集；2)基于像素级的无锚检测器PL‑AFD的预训练和伪标签的生成；3)低照度图像增强网络LLENet的训练；4)对域适应模块的训练；5)对自监督模块的训练；6)对整个低照度目标检测网络的测试。这种方法能弥补低照度图像和正常照度图像之间像素级和语义级的差距，提高目标检测器对低照度图像的检测精度。基于多尺度弱监督和域自适应(MS-WSDA)的低照度目标检测方法。该方法弥补了低照度图像与正常照度图像在像素层次和语义层次上的差异，提高了目标检测器对低照度图像的检测精度。该方法涉及通过步长为1，卷积核大小为3*3的两个卷积和ReLU激活函数进行特征提取。 辅助任务启动。 将所有的特征图按照3*3格式均匀划分为9张，增强后的图像的一张斑块与对应法向光照下相同位置的斑块相匹配。 其中一个块被用作查询，并且标记其他块并放入词典中。 将字典中与query相匹配的key作为正例，其他key作为负例，用点积来衡量query与key的相似度。 对整个微光目标检测网络进行测试。 系统库存数据库(SID)数据集中的低照度图像被发送到低照度增强网络进行增强。 将增强后的图像送入PLAFD进行检测。 检测结果可视化。   6
一种融合视频画面和场景文本信息的跨模态视频正能量评价方法、系统及计算机存储介质，涉及视频敏感内容分析领域。解决现有基于回归的方法仅考虑了视频中的视觉特征，而忽略了视频中的场景文字信息的问题。本发明提供以下方案，获取视频片段，使用预先训练好的R3D模型对视频片段进行特征选取，得到多个特征向量；对获得的多个特征向量进行全局平均池化操作，并通过全连接获得视频画面特征；提取视频画面特征中的场景文本特征，即删除重复的场景文本特征或句子；文本编辑器用于提取场景文本特征，同时对BERT组件输出的标记嵌入进行均值池化操作，以获得每个句子的特征向量；将获得的视频画面特征和获得的场景文本特征同时输入特征融合模块中，分别使用视觉编码器和场景文本编码器并聚合跨模态融合令牌对两种模态信息进行联合编码；将特征融合模块的输出作为MLP模块的输入，通过MLP模快的处理获得视频的正能量分数。还适用于视频画面信息与场景文本信息提取领域。结合视频图片和场景文本信息的跨模式视频正能量评估方法。该方法涉及使用预先训练的R3D模型获得视频片段以选择视频片段的特征以获得多个特征向量，并且因此确保简单且高效的跨模式视频正能量评估方法。该方法包括：获取视频片段，所述视频片段的帧号为预设帧号。 利用预先训练好的模型选取每一个句子的特征向量。 对多个特征向量进行全局平均池(GAP)运算，通过全连接(FC)得到视频图像特征。 利用光学字符识别(OCR)工具提取视频图片特征中的场景文本特征。 对所述跨模态融合令牌进行聚合，以对所述两种模态信息进行联合编码。 将特征融合模块的输出作为MLP模块的输入，经过MLP模块的处理，得到视频的正能量分数。 将视频图片特征和场景文字特征输入特征融合模块。独立权利要求书包括用于：(1)结合视频图片和场景文字信息的跨模式视频正能量系统； 以及(2)存储用于视频敏感内容分析的程序的计算机可读存储介质。 9
本发明公开了一种基于BERT与用户评论的深度学习可解释推荐方法。包括以下步骤：首先，分别对用户评论文本数据和物品评论文本数据依次进行数字编码和预处理后，分别获得预处理后的用户评论文本数据和物品评论文本数据；接着利用预训练语言模型分别提取出用户和物品的初始特征向量；再将用户的初始特征向量和物品请求向量以及物品的特征向量和用户请求向量分别一起输入到对应的注意力机制层中进行最终特征的提取，获得用户和物品的最终特征向量；最后分别与用户和物品潜在因子相结合后，获得评论乘积特征并均输入预测层中，输出用户对物品的评分预测。本发明可以在更短的训练时间内达到更好的推荐效果，同时还能产生基于评论的推荐解释。基于BERT和用户评论的深度学习可解释推荐方法通过预先训练好的语言模型BERT提取的特征可以更有效，更准确地表示评论文本数据，从而提高最终的推荐性能。 BERT用于从用户评论中提取文本特征，关注机制用于提高推荐效果并生成推荐解释，潜在因素模型用于评分预测。所述方法包括：对用户评论文本数据和项目评论文本数据依次进行数字编码和预处理后，获取预处理后的用户评论文本数据和项目评论文本数据。 预处理后的用户评论文本数据和项目评论文本数据分别输入到预训练的用户评论语言模型BERT1和预训练的项目评论语言模型BERT2中，提取用户的初始特征向量和项目的初始特征向量。 将用户的初始特征向量和初始化的项目请求向量输入到用户评论关注机制层，以提取最终特征，从而获得用户的最终特征向量。 在将用户评论和项目评论的最终特征向量与用户和项目潜在因素组合之后，获得评论的产品特征并将其输入预测层，预测层输出用户对项目的评价预测。  12
本发明公开了一种表格预训练方法和装置，涉及人工智能技术领域。该方法的一具体实施方式包括：获取表格及其对应的文本，根据所述表格及其对应的文本构建预训练任务；其中，所述预训练任务选自以下至少两种：行预训练任务、列预训练任务、文本遮罩实体预训练任务和文本随机遮罩字预训练任务；根据所述预训练任务对语言模型进行联合预训练，从而得到表格预训练语言模型。该实施方式能够解决缺乏对文本与表格进行深度结构化语义交互的建模的技术问题。表预训练方法。该方法能够有效地实现文本与表格之间深度结构化语义交互的建模。该方法包括获得表格和对应的文本。 根据所述表格和对应的文本生成预训练任务，所述预训练任务选自行预训练任务、列预训练任务、文本掩码实体预训练任务和文本随机掩码词预训练任务。 根据所述预训练任务对语言模型进行组合预训练处理，得到表格预训练语言模型。 根据所述表格和所述对应的文本，同时确定所述表格和所述文本中出现目标词。包括独立权利要求：(1)桌子预训练装置； (2)一种电子设备，包括用于预训练桌子的存储器和处理器; (3)存储用于预训练桌子的指令集的计算机可读介质； 以及(4)计算机程序产品，其包括用于预训练表格的指令集。  11
本发明涉及人工智能领域，具体涉及一种基于案情的处置预案生成方法。本方法整合各方数据源, 统一数据格式, 确保数据质量并考虑法律知识完整性和规则变化应对。之后, 选取部分规范化数据用于模型微调。微调所采用的是Lora模型方法, 并将微调后的权重与大语言模型合并。最后, 对微调模型进行进一步的精调, 此时采用QLoRA方法, 同样与微调后的大语言模型合并。本发明通过迁移学习的方式使模型对于参数不会过于敏感，同样对于数据集的质量要求不是很高，通过迁移学习使大语言模型可以用于各种不同的任务，也可以用于各个领域，使效率提高。用于基于病例生成治疗计划的方法。该方法利用迁移学习技术使模型对参数不太敏感，保证对数据集的质量要求不是很高，从而利用迁移学习技术将大型语言模型用于不同的任务，提高了效率。该方法涉及收集病例数据。 对数据进行处理，形成输入案例数据集。 基于LoRA(Low-rank adaptive of Large Language Model)构建权重精调模型，以修改大型语言模型的权重，使得大型语言模型学习输入案例数据集中的案例信息以及相应的处理模式，得到初始学习案例分析的大型语言模型。 将所述待分析案例数据集输入一次初级案例分析的语言大模型中进行测试。 生成初步治疗方案。 基于量化低秩自适应(Quantized Low Rank Adaptation，QLora)模型构建权重微调模型。 根据所述初步处理方案和所述权重微调模型调整一个初始案例分析的所述大型语言模型的线性层的权重。根据偏移优化权重更新通过所述初始情况分析的所述大型语言模型的线性层。 通过Adam随机梯度下降最小化损失函数对权重微调模型进行训练，得到训练完成的权重微调模型。 将训练后的权重微调模型的权重修改为初始学习案例分析出的大型语言模型的权重。 得到病例治疗方案生成模型。 将待分析的病例文本输入所述病例治疗方案生成模型，得到与所述病例相关的治疗方案生成结果。  11
本发明公开了一种基于主动学习的中文医疗实体识别标注方法及系统，该方法包括以下步骤：预训练步骤；第一主动学习步骤：构造第一命名实体识别模型，基于训练集进行训练学习，基于验证集进行验证，根据第一验证结果调整学习过程；第二主动学习步骤：结合文本向量和转移分数筛选出待标注数据，整理数据集，对第一命名实体识别模型进行重新训练得到第二命名实体识别模型，对第二命名实体识别模型进行验证，根据第二验证结果调整重新训练的过程；识别步骤：基于第三命名实体识别模型对待识别的中文医疗文本进行识别。本发明采用的主动学习结合了文本向量和转移分数，筛选出来的文本差异度更高，减少了标注成本，并通过专家标注及时纠正输出的错误。基于主动学习的中文医学实体识别标记方法。该方法能够结合文本向量和转移分数，改进文本差异过滤，降低标记成本，并通过专家标签及时纠正输出错误。该方法涉及对医疗领域中基于文本预训练的预训练模型进行预训练。 基于训练集训练第一命名实体识别模型。 结合文本向量和转移得分，筛选待标注数据。 所述过滤待标注数据在整理完所述数据集后进行标注。 对所述第一命名实体识别模型进行重新训练，得到第二命名实体识别模型。 对所述第二命名实体识别模型进行验证。 建立第三命名实体识别模型。 基于所述第三命名实体识别模型识别待识别中文医疗文本。还包括基于主动学习的中国医学实体识别标记系统的独立权利要求。  10
本发明公开了一种用于知识图谱语义搜索的文本理解的方法，针对输入的待理解的文本，所述方法包括如下步骤：通过大规模预训练模型获得文本中每个词元的语义信息，生成语义向量；基于所述语义向量，通过卷积神经网络、实体分类用的第一softmax分类器和关系分类用的第二softmax分类器，识别出实体类型和关系类型；基于所述语义向量，通过CRF进行序列标注，抽取出实体；基于所述语义向量，通过Bi‑LSTM模型和问句分类用的第三softmax分类器，将文本进行分类；基于识别出的实体类型和关系类型、抽取出的实体、文本的分类结果，检索知识图谱获取信息作为反馈。本发明使用统一的方法同时完成了四种任务，使得系统更加简洁。用于知识图谱语义搜索的文本理解方法。本方法使用统一的方法同时完成四个任务，使系统更加简单。 该方法可以帮助更好地理解用户的意图，并从知识图谱中搜索出符合用户需求的返回给用户的结果。 将输入文本段识别为不同的实体类型或关系类型，以更好地引导语义搜索的搜索中需要的信息。 通过实体抽取方法抽取输入文本的实体，直接从知识图谱中匹配实体，四项任务在一次文本输入中密切相关。 效果优于四项独立工作。该方法包括通过大规模预训练模型获取文本中每个词元素的语义信息。 生成所述语义向量。 基于语义向量，通过用于实体分类的卷积神经网络模块softmax分类器和用于关系分类的第二softmax分类器来识别实体类型和关系类型。 该序列由CRF标记，基于语义向量。 提取所述实体。 所述第三softmax分类器用于基于所述语义向量对所述Bi-LSTM模型和问句进行分类。 对所述文本进行分类。 基于所识别的实体类型和关系类型来提取实体。 得到所述文本的分类结果。 搜索获取信息作为反馈的知识图谱。包括以下独立权利要求：存储用于知识图谱语义搜索的文本理解的程序的计算机存储介质； 以及用于知识图谱语义搜索的文本理解的系统。  12
本发明公开了一种基于早期特征预测拉取请求决策结果的方法。该方法从开发者特征、拉取请求实体特征、项目特征中获取特定的早期手工特征，并基于深度学习方法从拉取请求的描述和代码变更中获取其深度语义特征。基于已有的关于拉取请求特征研究成果，结合使用深度学习技术，该方法将拉取请求中较为重要的描述信息和代码变更信息通过预训练模型表征为多维空间向量，并在拉取请求结果预测中展现重要作用。本发明可以在拉取请求创建早期对其决策结果进行预测，有利于减少项目集成者维护开源项目的负担，也能尽快给拉取请求的创建者提供反馈。基于早期特征预测得出请求决策结果的方法。该方法通过预训练模型将拉取请求中较为重要的描述信息和代码变化信息表示为多维空间向量，并在拉取请求结果预测中显示重要功能，以在绘制请求创建初期预测决策结果，有利于减轻项目整合者维护开源项目的负担，并为绘制请求的创建者提供反馈。该方法涉及向第二特征提取模型发送代码变更信息，以获得代码变更信息的第二多维空间向量表示。 将第一多维空间向量表示和所述第二多维空间向量表示通过一层全连接层拼接得到表示拉取请求语义信息的第三多维空间向量表示。 将得到的第三多维空间向量表示和人工特征送入分类器，其中，第一特征提取模型、第二特征提取模型和分类器是基于收集的训练数据集训练得到的，第一特征提取模型为极深度卷积网络(VDCNN)、来自变压器的双向编码器表示(BERT)或RoBERTa(RTM：基于变压器的语言模型)模型。 输出预测决策结果。所述第二特征提取模型为VDCNN、BERT或CodeBERT(RTM：programming language的预训练模型)模型。 分类器为逻辑回归模型、决策树、随机森林或XGBoost(RTM：optimized distributed gradient boosting library)分类器。  11
本发明提供一种基于预训练模型和强化学习微调的半监督语音识别方法。该方法包括：采用编码器‑解码器模型作为语音识别模型，基于有标注数据集和无标注数据集，采用半监督训练方法对语音识别模型进行训练得到初始的语音识别模型和含伪标签的无标注数据集；将有标注数据集和含伪标签的无标注数据集进行合并，基于合并后的数据集采用强化学习方法对初始的语音识别模型进行微调得到最终的语音识别模型；将待识别的语音序列输入至训练好的语音识别模型，识别得到文本序列。基于预训练模型和强化学习微调的半监督语音识别方法。半监督语音识别方法基于预训练模型和增强学习微调。该方法涉及使用(S101)编码器-解码器模型作为语音识别模型，编码器采用预先训练好的模型，解码器采用两层长短期记忆网络和一层线性网络。 构建标记数据集和未标记数据集(S102)。 合并所述已标注数据集和所述包含伪标签的未标注数据集，并基于合并后的数据集使用强化学习对所述初始语音识别模型进行微调(S103)，以获得最终的语音识别模型。 采用小批量梯度下降算法对语音识别模型的参数进行优化。 将待识别的语音序列输入(S104)到已训练的语音识别模型中，并识别文本序列。 3
本公开提供了一种地图数据有效性验证方法、装置、电子设备及存储介质，涉及生成式大语言模型、地图数据更新、有效性验证、有监督训练、强化学习等人工智能技术领域。该方法包括：获取针对地图数据发起的有效性验证任务的任务描述信息；利用预设的有效性验证模型处理任务描述信息，得到返回的有效性验证结果，有效性验证模型是以生成式大语言模型为底层核心、按基于自动机器学习方式构建出的框架训练得到的模型，训练得到有效性验证模型的训练过程包括：基于将从地图应用中收集到的历史人工验证作业日志作为有监督数据进行的微调训练；根据有效性验证结果确定有效性验证通过的目标地图数据。应用该方法可以实现地图数据的大规模自动生产。用于验证生成式大语言模型等人工智能领域中地图数据有效性的方法。 还可用于地图数据更新、验证性验证、监督训练和强化学习。该方法能够实现地图数据的大规模自动化制作。该方法涉及获取地图数据发起的有效性验证任务的任务描述信息。 通过预设的验证验证模型对所述任务描述信息进行处理，得到返回的验证验证结果，所述验证验证模型为以生成式大语言模型为底核得到的模型。 执行训练过程，以根据构建的基于自动机器学习模式的框架获得所述验证性验证模型。 基于从地图应用收集的历史人工验证工作日志作为监测数据进行细调训练。 根据所述验证结果确定通过验证的目标地图数据。包括独立权利要求，用于：(1)用于验证地图数据有效性的装置； (2)一种电子装置，其包括处理器以执行用于验证地图数据的有效性的方法； (3)一种计算机程序产品，其包括执行用于验证地图数据的有效性的方法的指令； 以及(4)非瞬时计算机可读存储介质，其包括执行用于验证地图数据的有效性的方法的指令  11
本申请公开了一种基于预训练模型的模型改进方法及装置。方法的一具体实施方式包括：获取相匹配的主体模型、至少一个拆分模型的拆分配置信息，其中，主体模型、至少一个拆分模型基于预训练模型拆分得到，被分布式部署于不同的预设设备，拆分配置信息表征主体模型和至少一个拆分模型的属性信息；根据拆分配置信息，建立主体模型与至少一个拆分模型之间的联系，以供主体模型在运行过程中与至少一个拆分模型进行数据交互。本实施方式可以将原有的大规模的预训练模型拆分为较小规模的主体模型和至少一个拆分模型，降低主体模型和至少一个拆分模型对设备的部署要求，提高了大规模的预训练模型的实用性。一种基于预训练模型的主体模型改进方法。本发明能够将原有的大规模预训练模型划分为小尺寸的主体模型和拆分模型，降低了主体模型和拆分模型的部署要求，提高了预训练模型的实用性。所述方法包括：获取拆分模型的拆分配置信息。 基于预训练模型获得分裂模型。 拆分配置信息表示为主体模型和拆分模型的属性信息。 根据拆分配置信息建立主体模型与拆分模型之间的关系。 在运行过程中，主体模型与拆分模型之间进行数据交互过程。 所述拆分模型具有预训练模型。独立的权利要求书被包括在以下内容中： 模型改进装置； 一种计算机可读介质和方法 一种电子装置。  11
本发明一种基于Attention机制的透平叶片蠕变‑疲劳寿命预测方法，该方法将Attention机制加入到ResNet神经网络中，形成包含Attention模型的ResNet主体网络结构。Attention机制是一种让模型对重要信息重点关注并充分学习吸收的机制，通过对query和key进行相似度计算，得到权值，后将权值进行归一化，得到权重，最后讲将权重和value进行加权求和，对不同的特征进行重要程度再分配，使得关联性更强的特征占比更高，从而使结果具有更高的准确性。本发明应用于透平叶片在考虑启停循环载荷和高温稳定载荷下的蠕变‑疲劳寿命预测，其能够实现精准的蠕变‑疲劳寿命预测，且避免了复杂的寿命预测机理分析，同时大幅减少寿命预测的人工成本及实验测试成本，具有重要的工程意义及广阔的应用前景。基于注意机制的涡轮叶片蠕变疲劳寿命预测方法本发明实现了在启停循环载荷和高温稳定载荷下的精确蠕变疲劳寿命预测，避免了复杂的寿命预测机理分析，降低了寿命预测的人工成本和实验测试成本。该方法包括收集相同材料涡轮叶片蠕变疲劳破坏的故障信号。 分析涡轮叶片在启停变化条件下的应力应变场。 涡轮叶片的流体域和固体域被划分为结构化网格。 叶片流动界面的温度分布被共享给稳态热分析模块。 设置可变学习速率以通过同步SGD优化器训练网络。 得到回归预测值。 基于用于预测转子叶片的起动-停止时间的机制来构造剩余网络。 通过剩余网络提取训练数据信号。   4
本发明涉及一种基于机器学习的免疫层析浓度检测方法及系统。该方法包括：获取人绒毛膜促性腺激素HCG和心梗三项的免疫层析试纸条图像；对所述免疫层析试纸条图像进行预处理，确定预处理后的免疫层析试纸条图像；根据所述预处理后的免疫层析试纸条图像构建U‑Net语义分割网络；将待测样本输入到所述U‑Net语义分割网络，以前景和背景分割的方式，输出目标检测区域；将所述目标检测区域内的像素点强度划分为RGB三通道向量强度输入到分类网络，按照所述待测样本的浓度范围，输出所述待测样本的浓度类别。本发明能够消除样本差异性、避免了检测精度随着检测类别的增加下降的问题，提高了样本类别检测精度，降低了弱阳性样本漏检率。该方法可用于检测免疫层析浓度(要求保护的)。该方法检测免疫层析浓度，精密度高，降低了弱阳性样本漏出率。基于机器学习的免疫层析浓度检测方法，包括：获取人绒毛膜促性腺激素(HCG)和心肌梗死的免疫层析试纸条图像; 对免疫层析试纸条图像进行预处理，确定预处理后的免疫层析试纸条图像; 根据预处理后的免疫层析试纸条图像构建U-Net语义分割网络; 向U-Net语义分割网络输入样本，以前景和背景分割的方式输出目标检测区域，样本为免疫层析试纸条的HCG和心肌梗死三项; 根据所述样本的浓度范围将所述目标检测区域内的像素强度划分为RGB三通道向量强度并输入至所述分类网络。一种基于机器学习的免疫层析浓度检测方法，包括：获取人绒毛膜促性腺激素(HCG)和心肌梗死的免疫层析试纸条图像; 对免疫层析试纸条图像进行预处理，确定预处理后的免疫层析试纸条图像; 根据预处理后的免疫层析试纸条图像构建U-Net语义分割网络; 向U-Net语义分割网络输入样本，以前景和背景分割的方式输出目标检测区域，样本为HCG和心肌梗死三项免疫层析试纸条待测图像; 根据所述样本的浓度范围将所述目标检测区域内的像素强度划分为RGB三通道向量强度输入至所述分类网络，其中输出所述样本的浓度类别，所述浓度类别包括高浓度类别、中浓度类别和低浓度类别。 一种免疫层析浓度检测系统，包括免疫层析试纸条图像获取模块，用于获取HCG和心肌梗死三幅免疫层析试纸条图像; 预处理模块，用于对免疫层析试纸条图像进行预处理，确定预处理后的免疫层析试纸条图像; U网语义分割网络构建模块，用于根据预处理后的免疫层析试纸条图像构建U网语义分割网络; 目标检测区域输出模块，用于将待测样本输入U-Net语义分割网络，以前景和背景分割的方式输出目标检测区域，所述待测样本为HCG和心肌梗死免疫层析试纸条的人绒毛膜促性腺激素图像，浓度类别输出模块，用于将所述目标检测区域内的像素强度划分为RGB三通道向量强度，并输入分类网络； 以及根据所述样本的浓度范围输出所述样本的浓度类别，浓度类别包括高浓度类别、中浓度类别和低浓度类别。   6
一种基于自监督拼图学习的SAR图像地物分类方法，利用自监督学习的思想挖掘无标签数据自身的特性作为监督信息，提升场景分类模型的特征提取能力，实现地物特征的有效表示；设计拼图作为上游拼图任务在无标签的数据上进行训练得到上游任务预训练模型，迁移预训练模型并对下游场景分类任务进行微调，在下游场景分类任务中使用少量有标签的样本，并在数景真实大场景下检验场景分类模型的分类性能，可以缓解有标签训练样本不足以及地物目标表现形式多样导致地物特征判别性不足的缺陷，提升场景分类模型的分类性能。基于自监督拼图学习的合成孔径雷达图像地物分类方法，用于环境保护、灾害监测和地理测绘中使用的SAR图像在计算机(Clead)中。该SAR图像地物分类方法提高了分类模型的特征提取能力，提高了场景分类模型的分类性能。 该方法缓解了由于一个地物特征的缺陷导致的标签训练样本不够和地物目标表现形式多样的缺陷，从而提高了分类器性能。 提高了数字场景真实大场景下的分类性能，提高了SAR图像的分类精度。该方法涉及利用自监督学习的思想，挖掘无标签数据本身的特征作为监督信息，实现对地面特征的有效表示。 将拼图设计为上游任务，对未标注数据进行训练，得到上游拼图任务预训练模型。 转移所述预先训练的模型和微调的下游场景分类任务。 利用下游场景分类任务中的少量标记样本，测试场景分类模型在大量真实场景中的分类性能。 14
本发明涉及一种基于FPGA的Vision Transformer编码器硬件加速器及其计算方法，包括：处理器模块、DDR内存模块、数据调度模块、矩阵存储模块、残差相加模块、第一矩阵乘法模块、GeLU运算模块、第二矩阵乘法模块、第三矩阵乘法模块、softmax计算模块；处理器模块用于动态调度加速器并进行辅助计算，同时运算阵列采用输出固定的数据并行计算策略，网络规模适配能力强，输入输出数据复用程度高，片内外数据搬运高效。该硬件加速器属于Vision Transformer神经网络专用加速器，能够有效提高Vision Transformer神经网络的运算速度及效率，有效降低运算功耗。基于现场可编程门阵列(FPGA)的视觉编码器硬件加速器，应用于深度学习技术领域的边缘设备计算机中。硬件加速器属于视觉力神经网络专用加速器，能够有效提高视觉力神经网络的运算速度和效率，有效降低运算功耗。 运算阵列采用输出固定数据并行计算策略，网络规模适应能力强，输入输出数据复用度高，芯片内外数据传输高效。加速器具有数据调度模块，用于在执行除层归一化函数之外的其他操作时，控制一个模块工作并调度数据。 残差相加模块执行残差相加操作。 矩阵存储模块，在其他操作期间处理数据和参数时，存储要处理的数据和参数。 第一矩阵乘法模块执行线性层运算以对同时输入的两个矩阵以特定方式执行矩阵乘法。 GeLU运算模块通过使用GeLU激活函数对前馈层中的数据进行运算来执行前馈层中的数据。 softmax计算模块执行softmax操作。 第三矩阵乘法模块在点积注意力函数中计算第二矩阵乘法。独立权利要求还包括面向视觉磁编码器部分的硬件加速器的工作方法。   5
本发明公开了一种面向军事语料的命名实体标注方法，分别使用基于双向LSTM与CRF结合的神经网络模型、基于Lattice LSTM神经网络模型和基于BERT预训练神经网络模型三种深度神经网络来进行机器命名实体识别自动标注；使用XGBoost方法将S1的三种算法获取的结果进行集成学习，获取标注成功的样本和标注失败的样本，其中成功样本的定义是三种机器实体识别中任意两种识别结果一致的样本，失败样本的定义三种机器实体识别结果都不一致的样本；使用人工标注的方式标注失败的样本；将所有样本标注结果以json的方式存入数据库管理。本发明可以显著提高军事语料中军事实体的标注准确率，同时以最小的人工代价达到最好的标注效果。面向命名实体军事语料的标注方法。该方法能够提高军事实体标记精度和标记效果，减少人工。该方法包括使用双向长短期记忆和条件随机场神经网络模型的组合来执行自动注释机命名实体识别过程。 使用XGBoost过程综合三种学习算法获得的结果，用于获得标记的成功样本和标记的失败样本。 采用人工标注的方式对故障样本进行标注。 样本标记结果以javascript对象符号的形式存储在数据库中。  12
本申请公开了模型训练方法及人机交互方法、装置，涉及自然语言处理、智能搜索、深度学习等领域。具体实现方案为：获取模板对应的样本集；基于样本集，构造对比学习任务的正例对和负例对；基于对比学习任务的正例对和负例对，对预训练模型进行对比学习训练。实现将模板知识学习到了模型本身中，模板知识和预训练模型的语义知识充分结合，提升模型的普适性和易用性。该方法对于通过使用电子设备(要求保护的)来训练模型是有用的。该方法能够实现模板知识学习到模型本身，模板知识与语义知识的预训练模型充分结合，提高了模型的普适性和易用性。该方法包括获得对应于模板的样本集。 基于所述样本集构建对比学习任务的正例对和负例对。 基于正例组和所述负例组对预训练模型进行所述对比学习训练。 样本集中设置有与模板对应的第一样本组和第二样本组。独立权利要求还包括：一种人机交互方法； 模型训练装置； 人机交互装置； 以及计算机程序产品，包括用于训练模型的一组指令。  11
本申请公开了一种文本处理方法、电子设备及计算机可读存储介质，涉及大模型、计算机技术领域。该方法包括：获取查询文本，其中，查询文本采用自然语言进行描述，查询文本的文本内容包括：待解答的目标问题；将查询文本转化为符号表征，其中，符号表征采用预设逻辑编程语言进行描述；按照预设推理方式对符号表征进行推理，得到目标问题对应的目标答案，其中，预设推理方式用于通过多个推理步骤以及多个推理步骤对应的多个前提条件进行推理。本申请解决了相关技术中通过设计推理结构来迭代式调用大语言模型，仍会导致大语言模型在复杂问题推理过程中生成错误的推理步骤，进而导致大语言模型推理的因果性和可靠性较低的技术问题。用于通过电子设备处理大型语言模型的文本的方法(权利要求书)。该方法能够获得以自然语言描述的查询文本，从而增强了大型语言模型推理的因果性和可靠性，减少了复杂问题推理过程中的错误推理步骤。该方法包括获得查询文本。 所述查询文本采用自然语言描述，所述查询文本的文本内容包括待回答的目标问题。 将问题文本转换为符号表示。 符号表示采用预设的逻辑编程语言表示。 获取与所述目标问题、所述符号表示和预设推理方式对应的目标答案。 通过多个推理步骤和与多个推理步骤对应的多个前置条件对预设推理过程进行推理。本发明还公开了一种计算机可读存储介质，用于存储由电子设备处理大型语言模型的文本的一组指令。  11
一种基于深度学习模型的文本纠错方法，BERT模型使用了Transformer模型的编码器部分，MacBERT用目标单词的相似单词, 替代被mask的字符，减轻了预训练和微调阶段之间的差距。并且原始下一个句子预测任务贡献不大，其引入了句子顺序预测任务。基于上两个预训练任务的设置，MacBERT便有了强大的文本建模能力。一种基于深度学习模型的文本校正方法。减少了预训练和微调阶段的差异，对原下一句预测贡献不大，引入了句序预测任务。 该文本纠错方法使用端到端的文本纠错模型，其中该模型首先具有单词的预测能力。该方法包括提供剩余连接结果作为每个字符的最终特征表示。 首尾相接地学习和训练模型。 训练后的模型由变压器库加载生成BIN文件和TXT文件。 BIN文件是训练完成并保存的模型。 TXT文件是保存的单词列表。 提供变压器库中的标记器来编码原始文本。 编码结果被输入到训练好的模型中。 输出结果是张量。 对于张量输出，取每行的最大值的下标。 提供tokenizer.decode来解码位置下标。 解码后的文本被提供为纠错后的文本。  12
本发明公开了一种基于本体适配器的零样本知识图谱补全方法，包括：获取对零样本知识图谱补全任务相关的本体知识，所述本体知识包括实体类型信息、概念层次关系信息、关系类型约束信息、关系的组合逻辑约束信息；基于神经网络为每类本体知识设计本体适配器，并将本体适配器增加到预训练语言模型后，利用每类本体知识对本体知识类型对应的增加有本体适配器的预训练语言模型进行任务训练，以注入每类本体知识，得到引入本体知识的预训练语言模型；利用引入本体知识的预训练语言模型进行下游零样本知识图谱补全任务。该方法基于本体知识增强的预训练语言模型，更好地解决零样本条件下知识图谱的补全问题。一种基于本体适配器完成零样本知识地图的方法。 使用包括但不限于搜索引擎，个人助理，智能问题，推荐系统和数据融合。本发明通过本体适配器将知识地图的本体知识注入到预训练语言模型中，避免了在零样本条件下高效完成知识地图的问题。所述方法包括：获取与完成任务的零样本知识地图相关的本体知识，所述本体知识具有实体类型信息，概念层级关系信息，关系类型约束信息和组合逻辑约束信息。 基于神经网络为每个身体知识设计本体适配器。 将单词适配器添加到预先训练的语言模型中。 将预训练语言模型引入到与单词的单词类型相对应的单词适配器中以执行任务训练以注入每个单词适配器。 通过使用引入单词适配器中的预训练语言模型来执行下游零样本知识地图完成任务。  11
一种基于孪生网络BERT模型的智能问答匹配方法及系统，涉及智能分类技术领域，所述方法包括S1：收集问题和答案作为数据集；S2：对所述数据集中的问题进行分词操作，获得智能问答语料库；S3：将智能问答语料库导入数据库，在数据库中建立词语对应问题的倒排索引；S4：获取用户问题，将用户问题分词后得到的每个词语放入数据库中检索得到若干候选问题；S5：分别利用编辑距离、TF‑IDF、word2vec和基于孪生网络的BERT模型得出相似度得分；S6：综合考虑相似度得分，将得分最高的问题作为匹配问题并输出相应的答案。本发明能够在用户输入问题后，快速准确的从问答问答数据库中匹配相似度最高的问题并显示其答案。该方法可用于通过使用计算机设备(权利要求书)基于双胞胎网络双向编码器表示(BERT)模型的智能问答匹配。该方法能够在用户输入问题后，快速准确地从问答数据库中匹配出相似度最高的问题并显示答案。一种基于双胞胎网络BERT模型的智能问答匹配方法，包括：采集问题和答案作为数据集。 对所述数据集的问题进行分词操作。 得到智能问答语料。 将所述智能问答语料导入数据库。 在数据库中建立词对应问题的倒排索引。 将词语相似度分值和语义相似度分值输入逻辑回归模型，得到最终分值。 将具有最终得分的候选问题作为最相似的问题。 从数据库中搜索答案。独立权利要求还包括用于：基于孪生网络BERT模型的智能问答匹配系统； 以及包括用于处理数据的指令集的计算机可读存储介质。  11
本公开提供了行驶轨迹确定、模型训练方法、装置、电子设备及介质，涉及人工智能技术领域，尤其涉及计算机视觉、深度学习、大模型等技术领域，可应用于自动驾驶、自主泊车、物联网、智能交通等场景。具体实现方案为：获取针对车辆周边的目标对象配置的至少一组对象权重，对象权重表征目标对象对车辆的行驶过程的影响程度；根据环境编码向量和至少一组对象权重，对车辆的当前行驶轨迹进行调整，得到车辆的至少一个候选行驶轨迹，候选行驶轨迹具有目标评估值，环境编码向量是对车辆的周边环境信息进行编码得到的；根据至少一个候选行驶轨迹的至少一个目标评估值，确定与满足预设条件的目标评估值相对应的目标候选行驶轨迹，作为车辆的目标行驶轨迹。应用于自动驾驶、自主停车、物联网和智能交通等场景的行驶轨迹确定方法。该系统具有较高的自适应性和响应性，能够保证车辆在复杂的交通环境中安全高效地运行。 该方法鲁棒性更强，并且能够适应各种看不到的交通环境，为实际应用提供有力支持该方法涉及获得(S210)为车辆周围的目标物体配置的一组物体重量。 对象权重表示目标对象对车辆行驶过程的影响程度。 根据所述环境编码向量和所述一组物体权重调整所述车辆的当前行驶轨迹(S220)。 获取所述车辆的一个候选行驶轨迹。 所述候选行驶轨迹中设置有目标评价值。 所述环境编码向量由所述车辆周边环境信息编码得到。 根据一个候选行驶轨迹的一个目标评价值，确定满足所述预设条件的目标评价值对应的目标候选行驶轨迹(S230)，作为所述车辆的目标行驶轨迹。独立权利要求包括以下内容：深度学习模型的训练方法； 行驶轨迹确定装置； 深度学习模型的训练装置； 电子装置； 非瞬时计算机可读存储介质，其存储用于确定行驶轨迹的程序； 以及用于确定行驶轨迹的计算机程序产品。 13
本申请提供一种电力知识语义分析系统及方法，本申请系统包括文本预处理模块，用于对电力知识文本进行分词处理；文本标准化模块，用于根据电力知识图谱，对所述电力知识文本进行标准化；语义分析模块，用于根据预训练模型，对电力文本标准化的分词以及句子进行语义分析，确定电力文本的语义信息；数据库，用于存储所述电力知识图谱。通过文本预处理模块，对电力知识文本进行分词处理，以便于根据电力知识图谱，对分词进行实体匹配，从而实现电力知识文本的标准化，使得预训练模型对标准化后的分词以及句子的分析结果更准确，提高电力文本信息提取准确性。电力知识语义分析系统。通过文本预处理模块对电力知识文本进行分词，以方便根据电力知识图谱对分词进行实体匹配，从而实现了电力知识文本的标准化，使得预训练模型对标准化分词和句子的分析结果更加准确，提高了电力文本信息抽取的准确性。电力知识语义分析系统具有文本预处理模块，用于对电力知识文本进行分词处理。 文本标准化模块，用于根据所述电力知识图谱对所述电力知识文本进行标准化。 语义分析模块，用于基于所述预先训练的模型，对所述电力文本的标准化分词分句进行语义分析，确定所述电力文本的语义信息。 数据库，用于存储所述电力知识图谱。独立权利要求包括为：(1)电力知识语义分析方法； (2)电力知识语义分析装置； (3)一种计算机设备，包括处理器，以及存储器； (4)一种计算机可读存储介质。 0
本申请提供了一种文本序列生成方法、语言模型的预训练方法、存储介质及程序产品，文本序列生成方法，包括：获取知识图谱中以主语言描述的若干个实体对的第一描述文本，其中，所述实体对中的元素包括两个实体及其之间的实体关系；获取若干个实体对中部分或全部元素所对应的标注信息，并根据所述标注信息将所述实体对中的至少部分元素替换为基于与所述主语言不同的其它语言描述的文本，获得所述实体对的第二描述文本；基于所述实体对所对应的第一描述文本和第二描述文本，生成多语言文本序列，所述多语言文本序列用于对语言模型进行基于多语言知识的预训练。本发明公开了一种用于在存储有计算机程序和计算机程序产品的计算机存储介质中生成文本序列的方法。该方法可以避免需要对应不同语言生成模型的语言来获取对应语言的文本， 简化了获取样本文本进行预训练的步骤，避免了对齐实体或链接的需要，减少了对其他模型的依赖，保证了多语言文本序列中知识的准确性。一种生成文本序列的方法，包括：获取知识地图中以主语言描述的实体对的第一描述文本； 获取与信息对应的中间部分或全部元素对应的实体， 根据信息将实体对中的部分元素替换为基于与主语言不同的其他语言描述的文本，获得实体对的第二描述文本，并基于与实体对应的第一描述文本和第二描述文本生成多语言文本序列。 实体对中的元素包括两个实体和实体之间的关系。 多语言文本序列用于基于多语言知识的语言模型的预训练。本发明还涉及一种语言模型的预训练方法。  11
本发明提出了多模态特征嵌入预训练网络搭配效果评估的上界替代法，属于计算机视觉多模态技术领域。本发明提出的方法包括步骤：1)将所有模态特征嵌入预训练网络所提取到的特征进行遍历搭配；2)对得到的所有的搭配情况，对任务网络按照正式训练时提前设定好的参数，利用测试集部分进行训练；3)、对得到的每种搭配对应的模型，对其在测试集上进行测试，记录每一种搭配所对应的测试结果；4)、对所对应的每一种测试结果，选择效果最好的结果对应的模态特征嵌入预训练网络搭配；5)、对选出的网络搭配，将任务模型在这种搭配下所对应的训练集的特征下进行训练，训练得到的模型就是最优的模型。一种多模态特征嵌入式预训练网络配置效果评价上界替换方法。本发明能够有效替代上界多模态特征嵌入式预训练网络配置效果评估。该方法包括在预训练网络中嵌入用于遍历匹配的总模态特征。 根据正式训练集参数获得任务网络。 测试集部分用于训练。 得到匹配的对应模型。 对应于每个配置记录测试结果。 对应于模式特征嵌入的预训练网络配置来选择结果的最终效果。 在与所述配置相对应的训练集的特征下训练任务模型。 训练得到的模型被指定为最优模型。  11
本发明属于大模型技术领域，涉及一种作为GUI代理的视觉语言模型及其构建方法，所述作为GUI代理的视觉语言大模型包括：降采样模块；低分辨率图像编码器；MLP适配器；词嵌入模块；视觉语言解码器；高分辨率图像编码器，其用于对高分辨率GUI图像进行处理以获得高分辨率GUI图像特征序列；交叉注意力模块，其具有多层交叉注意力层，每层所述交叉注意力层分别用于对所述高分辨率GUI图像特征序列和每层自注意力层输出的图像文本组合特征序列进行处理，以获得最终的组合特征序列。其在基础视觉理解方面具有强大的性能，能够用于GUI的理解和导航。可视语言模型作为图形用户界面(GUI)代理，用于GUI理解和导航。视觉语言大模型在基本视觉理解方面具有很强的表现。视觉语言模型具有下采样模块，用于对高分辨率GUI图像进行下采样，得到低分辨率GUI图像。 MLP适配器使得能够在低分辨率图像编码器和视觉语言解码器之间进行适配。 词嵌入模块，对输入文本进行处理，得到文本特征序列。 视觉语言解码器设置有自注意层。 每个自注意力层，用于对低分辨率GUI图像特征序列和文本特征序列进行组合输入处理，得到图像文本组合特征序列。 高分辨率图像编码器对高分辨率GUI图像进行处理，得到高分辨率GUI图像特征序列。 一个交叉注意模块，设置有若干交叉注意层。 每个交叉注意力层用于分别处理高分辨率GUI图像特征序列和每个自注意力层输出图像文本组合特征序列，得到最终的组合特征序列。独立权利要求包括作为GUI代理的视觉语言模型的构建方法。  11
本发明提供一种语义解析结果重排序方法及系统，该方法包括：通过语义解析器，对目标自然语言语句进行解析，得到所述目标自然语言语句的候选逻辑表示集合；将所述目标自然语言语句和所述候选逻辑表示集合输入到重排序模型，得到候选语义重排序结果；根据所述候选语义重排序结果，确定所述目标自然语言语句的目标逻辑表示；其中，所述重排序模型是基于样本自然语言语句对应的自然语言相似样本和样本候选逻辑表示预测结果对应的逻辑表示相似样本，对预训练的深度神经网络进行训练得到的。本发明通过对语义解析结果进行重排序，有助于进一步搜索概率空间，从而根据重排序结果确定最终的语义解析结果，提高语义解析中推理算法的性能和准确性。一种自然语言处理技术领域的语义解析结果重排序方法。 用途包括但不限于知识问题、搜索引擎、系统控制和数据库查询接口。提高了语义解析中推理算法的性能和准确率。 语义解析结果有助于进一步搜索概率空间，从而根据重排序结果确定最终的语义解析结果。该方法包括通过语义分析器分析目标自然语言句子。 获取所述目标自然语句的候选逻辑表示集合。 将所述目标自然语句和所述候选逻辑表征集合输入重排序模型，得到候选语义重排序结果。 根据所述候选语义预排序结果确定目标语言语句的目标逻辑表征。 候选逻辑表示样本语言句子的相似样本和样本语言句子对应的样本候选逻辑。 基于预训练的候选逻辑来训练深度神经网络。本发明还公开了一种对语义解析结果进行重新排序的系统。 电子设备； 以及非暂时性计算机可读存储介质，包括用于对语义解析结果进行重新排序的系统的指令集。  11
为了解决现有技术中文本或语义匹配效率低或准确性差的问题，提供一种基于语义相似度叠加模型的问题匹配方法，包括以下步骤：首先将数据库的所有标准问题分别输入SIF词袋模型和预训练好的Bert模型中；接受用户输入的问题，将其分词后输入进SIF词袋模型中，得到用户输入问题的句向量；将用户输入问题的句向量同数据库问题的句向量作相似度计算，得到相似度计算结果；判断相似度计算结果的最高相似度是否高于预设的阈值，如高于此阈值则直接返回相似度最大的问题ID，设定好的对应标准问题的标准答案。本发明创造性的采用了SIF词袋模型和Bert预训练模型叠加，加快预测速度，使得模型在平均匹配所需时间大幅下降。家庭维保服务中基于语义相似度叠加模型的问题匹配方法，应用于自然语言处理技术领域，应用于家政维保服务中的智能机器人客户服务，以及中文智能问答领域。本方法创造性地利用SIF词袋模型和Bert预训练模型叠加，加快预测速度使得模型平均匹配所需时间大大减少。 提高了匹配速度。 本方法创造性的采用了SIF词袋模型和Bert预训练模型的叠加使得简单容易的判断为相似句子通过词袋模型进行处理。 加快了预测速度使得模型平均匹配所需的时间大大减少。 单个Bert模型的平均匹配所需的时间减少了500%，从而可以在同一设备上实现更高的并发性能。 大大提高了平均匹配速度，使得在阈值设置好的情况下，精度可以达到与单一Bert模型相同或更高的效果。 降低高频词对SIF词袋模型中SIF技术向量表达的影响，以提高文本向量化的准确率，降低噪声的影响。 利用SIF词袋模型的可扩展性，进一步提高智能机器人客服的准确性和效率。该方法包括：将数据库中所有的标准问题输入平滑逆频率(SIF)词袋模型和预训练的Bert模型，得到数据库问题的第一句向量矩阵和第二句向量矩阵。 接收用户输入的题目，得到用户输入的题目的第一句向量。 对所述用户输入问题的第一句向量和所述数据库问题的第一句向量进行相似度计算，得到相似度计算结果。 判断所述相似度计算结果的最高相似度是否高于预设阈值。 将所述用户输入问题输入Bert模型，得到所述最高相似度小于预设阈值时的用户问题语句向量。 返回相似度最大的问题ID和后端逻辑判断并返回设定的对应标准问题的标准答案。  12
本发明公开了一种融合细粒度要素知识的短文本分类方法，该方法包括：通过梳理标注短文本数据完成数据标注，其中，所述数据标注为标注全量标注数据类别和数据中存在要素信息；针对标注后的短文本数据，采用关键要素提取文本分类联合训练算法，借助BERT+CRF提取短文本数据中的要素信息；进而融合细粒度信息，结合标签编码器Label Encoder来学习各个标签label的表示，得到一个符合实际的标签分布。本发明针对上述问题提出一种融合细粒度要素知识的短文本分类的解决方法，从而提升短文本分类的效果，进而促使更为精准分析短文本数据，自动找到有关垃圾信息，提高工作效率。集成用于自然语言处理(NLP)的细粒度元素知识的短文本分类方法。 用途包括但不限于深度神经网络、迀移学习、相似度计算、对抗训练和文本分类。提出了融合细粒度元素知识的短文本分类的解决方法，通过提高短文本分类的效果，并便于对短文本数据进行更准确的分析，自动查找相关垃圾信息，提高工作效率。短文本分类方法是通过对短文本数据进行梳理和标注来完成数据标注。 所述数据标注用于标注数据中存在的所有数据类别和元素信息。 对标注后的短文本数据采用关键元素提取文本分类联合训练算法。 来自变换器(BERT)+条件随机场(CRF)的双向编码器表示被用于从短文本数据中提取特征信息。 将细粒度信息进行融合，结合标签编码器Label Encoder学习每个标签的表示，得到逼真的标签分布。  12
本发明公开了一种语音降噪模型的训练方法、装置、存储介质及电子装置。其中，该语音降噪模型的训练方法包括：通过在基于信号的损失函数中，加入频谱损失函数(信号包络的一种形式)，使得该总损失函数在降低噪声的同时，能够更好保留语音信息，使得听感得到提升，以至少解决现有技术中，语音降噪模型降低噪声的同时，保留语音信息较少，导致语音损伤较大的技术问题。一种用于提高通信质量的语音降噪模型训练方法。通过在信号的损失函数基础上增加频谱损失函数，总损失函数在降低噪声的同时，能够更好的保留语音信息，使得听感得到改善，从而至少解决现有技术中，语音降噪模型降低噪声的问题。 语音信息保留较少，导致语音损伤较大的技术问题。该方法包括获得(S202)语音训练样本数据，其中语音训练数据携带噪声数据。 对所述语音学习样本数据进行特征提取处理(S204)，以获得语音特征数据。 将所述语音特征数据输入(S206)预设语音降噪模型。 输出预测语音数据。 所述预测语音数据中不包含噪声数据。 在所述预设语音降噪模型中的信号损失函数和频谱损失函数满足预设条件的情况下，结束对所述目标语音降噪模型的训练(S208)。 得到所述目标语音降噪模型。 所述预测语音数据和所述干净语音数据构成所述损失函数，所述预测语音数据的预测频谱数据和所述干净语音数据的频谱数据构成所述频谱损失函数，所述干净语音数据确为不含噪声数据的数据训练样本数据。包括以下独立权利要求：一种语音降噪模型方法； 语音降噪模型的训练装置； 存储有用于训练语音降噪模型的程序的计算机可读存储介质； 以及电子设备。 3
本发明公开了一种基于u‑net网络的织物经纬密度检测系统及方法，旨在解决复杂纹理和颜色织物经纬密度检测的问题，对于复杂纹理和颜色的织物可采用u‑net网络进行图像分割的方法，通过图像距离变换算法自动统计平均值，是一种可靠、精确度高、误差小、可以同时用人眼核查的自动测量仪器。与现有技术相比，本发明的积极效果是：首先，本发明提升了织物经纬密度统计的准确度，可应用于复杂纹理和颜色的织物；其次，能在织物生产过程中实时监测经纬线密度变化情况；再次，解决了传统检测方法中需要人工数纱线的方式，大大降低了人工成本。基于U-net网络的织物纬密度检测系统。该系统可以检测织物色织密度，并利用像距转换算法得到自动统计平均值，从而实现可靠的自动测量仪器。 该系统精度高，可以减少误差，同时对人眼进行检查。 该系统能够提高织物统计的织造密度的准确性，在纺织生产过程中实时监测经纱/纬纱密度变化情况并检测人工纱线，以降低人工成本。该系统具有电源模块，电源模块连接有PLC控制模块和图像采集模块。 PLC控制模块与图像采集模块连接。 图像分割模块通过RS485串行数据通讯口与PLC控制模块连接的图像统计分析模块连接。 所述PLC控制模块通过同步A相信号编码器与RS485串行数据通讯口连接。 所述图像采集模块设有线阵CCD、施耐德透镜、白光LED线光源及外围电路。本发明还提供了一种基于U网网络的织物纬密检测方法。   6
本发明公开了一种视觉语言模型的模态交互增强的提示学习方法，给定预训练模型，从最新进展中获取灵感，然后基于该模型进行针对性调整，即为微调，相对于从头开始训练一个新的模型；对比图像语言学习模型, 预训练模型(CLIP)展示了学习视觉概念的潜力，CLIP由两个编码器构建，分别用于图像和文本，在训练期间，CLIP采用对比损失来学习两种模式的联合嵌入空间；根据CoOp描述，设计类特定上下文对于一些细粒度的分类任务；选择和CLIP，CoOp相同的11个数据集来验证模型的有效性；将使用方法与三种基线进行比较；通过最佳性能模型即可进行提示学习。本发明涉及一种视觉语言模型的模态交互增强的提示学习方法，具有图像分类数据集性能优异的特点。视觉语言模型模态交互增强的提示学习方法。该方法能够提供一种图像分类数据集性能优异的视觉语言模型的模式交互增强提示学习方法。该方法涉及提供(S101)预先训练的模型，从最新进展中获得启发，然后与从头训练新模型相比，基于该模型进行有针对性的调整。 学习视觉概念的潜力通过预训练模型(CLIP)示出(S102)，剪辑由两个编码器构建，一个用于图像，一个用于文本，并且与图像语言学习模型相比，在训练期间采用对比损失来学习两种模态的联合嵌入空间。 根据CoOp描述为一些细粒度分类任务设计(S103)类专用上下文。 选择(S104)相同的数据集作为CLIP和CoOp以验证模型的有效性。 将使用方法与三个基线进行比较(S105)。 提示具有最佳性能模型的学习(S106)。 14
本发明公开一种基于自监督学习的姿态估计方法，先基于对比性方法的自监督学习算法预训练得到视觉主干模型；然后基于部分整体关系约束的自监督训练得到部分分割网络；再通过回归学习训练得到关键点估计器；之后将目标图片依次通过视觉主干模型、部分分割网络及关键点估计器获取关键点图和标定视角特征图，然后结合深度图，提取得到关键点的标定视角特征和深度值，根据深度值与关键点坐标，得到关键点在相机坐标系统下的三维坐标，然后进行相机坐标系统与世界坐标系统之间的相似变换，得到姿态估计结果。本发明能够提取适用于细粒度下游任务的图像特征，并可直接提供关键点和标定视角特征，有效减少了数据标注复杂度和工作量。基于自监督学习的姿态估计方法。该方法使得能够提取适合细粒度下游任务的图像特征，并直接提供关键点和标定视角特征，有效降低数据标注的复杂度和工作量该方法涉及使用公共图像数据集，基于比较操作的自监督学习算法进行预训练，得到视觉骨干模型。 使用图像特征。 基于部分整体关系约束的自监督训练通过部分分割网络输出部分响应图，得到部分分割网络。 将标记有关键点的图片及其对应的标定透视特征作为学习目标。 将目标图像输入训练好的视觉主干模型，得到所述目标图像的图像特征。 获取所述目标图像的深度图。 结合深度值和关键点坐标。 得到多个关键点在摄像机坐标系下的三维坐标。 14
本发明公开了一种信息抽取方法及装置，将待抽取文本转换为第一目标输入向量；将第一目标输入向量传递给主体抽取模型，得到目标主体，主提抽取模型基于第一Bert模型、第一全连接层和第一sigmoid函数构建；将目标主体与待抽取文本进行拼接后转化为第二目标输入向量；将第二目标输入向量传递给预测客体和关系模型，得到目标客体和目标关系，预测客体和关系模型基于第二Bert模型、第二全连接层、第二sigmoid函数、相对距离、标点状态向量和主体向量构建。上述过程，基于主体抽取模型和预测客体和关系模型抽取目标主体、目标客体和目标关系，基于模型进行抽取保证了抽取的准确率，由于不需要人工参与，节省了人力。一种用于提取用于自然语言处理领域的组织的信息的方法。本发明能够在提取的同时，保证基于模型的提取的准确性，避免了人工参与，从而节省了人力消耗。该方法包括接收待提取文本。 将待提取文本转换为第一目标输入向量。 将第一目标输入向量转移到主体提取模型以获得目标主体，其中，主体提取模型基于第一BertModel，第一全连接层和第一Sigmoid函数构造。 目标主体与待提取文本拼接。 将拼接文本转换为第二目标输入向量。 将第二目标输入向量传送到预测对象和关系模型以获得目标对象和目标关系， 其中预测对象和关系模型基于第二BertModel，第二全连接层，第二Sigmoid函数，相对距离，标点符号状态向量和主体向量。本发明还涉及一种用于提取用于自然语言处理领域的组织的信息的装置。  12
本申请公开了一种基于扩增存储的图卷积神经网络的关键词抽取方法，通过设置扩增存储图卷积神经网络关键词抽取模型提升多层图卷积神经网络的节点表示能力。对文本进行预处理以及对文本进行句法分析，将分析结果分别输入到词语嵌入层，得到文本图结构信息和词语节点的嵌入信息并输入到扩增存储的图卷积神经网络层，获得相应的向量表示，将向量表示进行拼接后输入到LSTM层，得到输出向量，将向量表示和输出向量传送至输出层进行拼接并输出至目标层，获得输出类别。解决了现有的短文本关键词抽取方法关键词抽取性能较差，使用的图卷积神经网络随着卷积层的提升降低了节点的表示能力的技术问题。基于图卷积神经网络放大存储的关键词提取方法。本发明通过建立放大存储图神经网络关键词提取模型，提高了多层图卷积神经网络的节点表示能力，并对文本进行预处理，对文本进行语法分析，从而提高了当前短文本关键词提取过程的关键词提取性能，减少了随着卷积层的增加节点表示能力的技术问题。该方法包括建立放大存储图卷积神经网络关键词提取模型，包括词嵌入层、图卷积神经网络层、LSTM层、输出层和目标层。 对文本进行预处理。 形成所述文本的图形结构。 对所述文本进行语法分析。 将从词嵌入层获得的文本图像结构信息和一个词节点的嵌入信息输入到图卷积神经网络层。 得到相应的向量表示。 从通过放大存储的卷积神经网络层表示的向量和从LSTM层获得的输出向量被传送到输出层和目标层。 确定输出类型。  12
本发明涉及数据处理技术领域，尤其涉及一种文本规范化分类方法、装置、设备及存储介质，所述方法基于预训练模型，对所述语料库中的文本句子进行训练，生成至少一类句向量样本；基于分类算法模型对所述句向量样本进行分类训练，获得分类样本；基于降维算法模型对所述分类样本进行坐标变换，获得目标样本。通过分类算法模型对预训练模型生成的句向量样本进行映射，能够将不同类别的样本分离，且能够使得不同类别的样本均匀分布在空间中，获得分类样本；然后基于降维算法，通过坐标变换，对分类样本进行降维处理，将不同类别的分类样本进一步分离，从而提高对样本数据的分类准确性。用于标准化和分类文本的方法，该文本可用于数据处理和废物过滤，新闻分类和语音部分标记领域。 也可用于文本处理，及其应用。本发明利用分类算法模型映射预训练模型生成的句向量样本，可以将不同类型的样本分开，使样本在空间上分布均匀，得到样本，从而提高了样本数据的分类精度。该方法包括：获取语料库； 基于预训练模型对语料库中的文本句子进行训练， 生成至少一种句向量样本， 基于分类算法模型和句子向量样本生成投影矩阵； 基于投影矩阵对句子向量样本进行分类训练，得到样本，基于降维算法模型和投影矩阵计算协方差矩阵，基于协方差矩阵对分类样本进行坐标变换，得到目标样本。还包括独立的权利要求： 一种用于标准化和分类文本的装置； 以及 一种计算机可读存储介质，包括一组用于标准化和分类文本的指令。  12
一种基于深度学习网络的细菌显微图像分割方法，包括如下步骤：1)培养细菌，并在显微镜下按照固定时间间隔拍摄一组细菌生长图片，进行图像预处理，构建彼此之间没有交集的训练集、验证集和测试集，且训练集包括原始图像和相对应的标签图像，验证集和测试集分别只包含原始图像；2)构建U‑Net++模型，其具有编码器模块和解码器模块，编码器模块进行特征提取，解码器模块进行特征还原解码到原图的尺寸，将训练集输入U‑Net++模型进行训练，再将验证集输入训练后的U‑Net++模型进行验证，得到训练好的U‑Net++模型；3)将测试集输入训练好的U‑Net++模型，输出二值化分割图像。本发明的方法，能快速而又精准的对细菌显微图像进行自动分割，省去前期过多复杂的图像预处理环节，节省时间。基于深度学习网络的细菌微图像分割方法。该方法能够快速准确地分割细菌显微图像，省略了过于复杂的图像预处理环节，节省了时间。该方法包括培养细菌，在显微镜下按固定时间间隔拍摄一组细菌生长图片。 执行图像预处理过程。 训练集被构造成彼此不相交。 训练集中设置有原始图像和对应的标签图像。 构建U-Net++(RTM：面向对象的编程语言)模型。 特征约简解码过程由解码器模块执行。 输出二值化分割图像。 将测试集输入训练好的U-Net plus模型，用于输出二值化分割图像。   6
本发明公开了一种基于卷积神经网络的激光散斑干涉条纹图滤波算法。先通过模拟和实验相结合方式制作了多对由含有噪声的散斑条纹图作为神经网络输入，后设计搭建了改进型U‑Net卷积神经网络，将数据进入神经网络中进行训练，使用多尺度解码器有助于模型更好地捕获图像中的噪声特征和结构信息同时有助于保留图像的细节信息，从而提高去噪性能，避免出现过度平滑提高模型的鲁棒性。同时采用对抗训练，引入生成器和鉴别器进行对抗训练不断循坏训练模型提升其鉴别能力，最后使用训练好的神经网络模型对带有噪声的激光散斑干涉条纹图进行降噪处理。本发明能够准确便捷的消除散斑条纹图中的噪声，更接近被测物真实信息的能力。基于卷积神经网络的激光散斑干涉条纹图滤波算法。该算法能够利用多尺度解码器帮助模型更好地捕获图像中的噪声特性和结构信息，以保持图像的细节信息，从而提高去噪性能，并避免过度平滑的发生，以提高模型的鲁棒性。 该算法能够准确、方便地降低散斑条纹图中的噪声。 该算法能够引入生成器和判别器进行对策训练，不断提高训练模型的识别能力，并利用训练好的神经网络模型对低噪声率的激光散斑干涉条纹图进行降噪处理。该算法有一套规则，通过仿真和实验相结合，得到多对含有噪声的散斑图作为神经网络输入。 设计并建立改进的UNet卷积神经网络，并与多尺度解码器相结合，帮助模型捕获图像中的噪声特性和结构信息。 对输入图像进行卷积运算，用于得到特征图像。 所述改进网络中的编码器和多尺度解码器构成生成器，所述多尺度解码器用于处理不同尺度的噪声并保留图像的细节信息。 引入生成器和判别器进行对抗训练，以连续跟随一个故障训练模型。循环一个训练模型，不断提高判别能力，使得判别器不会将生成器生成的虚假数据与真实数据区分开来，从而对数据进行测试。   4
本公开涉及一种基于自然语言处理技术对企业账户进行风险识别的方法，该方法包括：响应于用户在第一页面的第一操作，获取待识别数据；响应于用户对所述待识别数据的第二操作，对所述待识别数据进行处理，得到目标数据；基于目标预训练模型对所述目标数据进行筛查，识别出所述目标数据中的异常信息。本公开由于先对待识别数据进行处理，得到目标数据，筛除了垃圾数据，保留了有用数据，可以减少不必要的工作量，提高工作效率，可以利用目标预训练模型对异常信息进行智能识别，对结构化数据和非结构化数据都可以识别，适用范围广，降低对异常信息分析处理、识别的人力投入，减轻人工负荷，从而提高了人力资源的利用率以及办公效率。基于自然语言处理技术的企业账户风险识别方法。该方法能够识别结构化数据和非结构化数据，减少异常信息分析处理和人工负荷，识别人工投入，对适用范围广的企业账户进行风险识别，提高人力资源的利用率和工作效率该方法包括：响应于用户在第一页面上的第一操作，获取待识别数据。 响应于用户对所述待识别数据的第二操作，对所述待识别数据进行处理，得到目标数据。 基于目标预训练模型对所述目标数据进行筛选。 在所述目标数据中识别异常信息。 响应于用户在所述第一页面上的第三操作，显示预训练模型列表，所述预训练模型列表包括预训练模型对应的标识信息。包括独立权利要求：(1)一种用于识别企业账户的风险的基于自然语言处理技术的设备； (2)一种电子设备，包括用于执行用于识别企业账户的风险的指令集的存储器和处理器; 以及(3)用于存储用于识别企业账户的风险的指令集的计算机可读存储介质。  11
本发明公开了一种基于供应商画像的采购筛选方法、系统、存储介质及终端，方法包括：在接收到待处理采购需求时，获取每个供应商的历史采购订单所关联的供应商考评指标参数及其指标分值数据；将供应商考评指标参数及其指标分值数据输入预先训练的供应商评级模型中，输出各个考评指标的评级结果；根据各个考评指标的评级结果，制定每个供应商的供应商采购画像；基于每个供应商的供应商采购画像，筛选符合待处理采购需求的目标供应商。由于本申请通过预训练模型自动确定各个考评指标的评级结果，以各考评指标的评级结果为基础，可准确建立供应商采购画像，通过该画像可清晰制定订单交付保障和订单成本降低的采购计划，从而提升了主机厂采购的准确性。基于供应商画像进行采购筛选的方法。该方法能够准确建立供应商购买画像，通过该画像能够明确制定订单配送保障和订单成本降低的购买计划，提高宿主机厂的购买准确性。该方法包括：当接收到待处理的采购需求时，获取供应商列表中各供应商的历史采购订单相关的供应商评价指标参数和指标值数据。 将所述供应商与所述历史采购订单中的各个预设评价指标进行匹配。 根据评价数据集计算指标分值数据。 通过大数据技术，针对历史采购订单，在一段时间内收集评论数据集。 根据购买要求筛选目标供应商。独立索赔还包括用于：基于供应商画像进行采购筛选的系统； 计算机存储介质，所述计算机存储介质存储用于基于供应商画像执行采购筛选的一组指令； 以及终端。 14
本发明公开了一种基于人机交互场景的语音识别纠错方法、装置以及设备，本发明的构思在于充分利用人机交互场景中多轮问答机制，将机器抛出的本轮问询内容与相应的用户答复内容经由语言识别处理获得的若干相关转写结果相结合，并从二者的语义层面进行深层挖掘，获得涉及本轮问询及若干答复语音的中间识别结果等上下文相关信息的综合表征，进而再对该综合表征进行解码，便可以精准、可靠地得到用户当前答复的正确识别文本。本发明的覆盖度、通用性可以得到显著提升，并且是对语音识别过程中的相关识别文本融入与真实交互场景息息相关的信息，因而实施复杂度也远低于单纯迁移语言模型进行纠错的现有方案，所以能够更易于被业内接受、认可及推广使用。基于人机交互场景的语音识别纠错方法。该方法能够准确可靠地获取用户当前回复的正确标识文本。 该方法能够提高覆盖度和通用性。 该方法使得能够将语音识别过程中的相关标识文本转换为与真实交互场景相关的信息，使得实现复杂度远低于现有方案的用于纠错的纯迁移语言模型，从而更容易被业界所接受。该方法涉及获得对应于本地车轮交互询问的用户响应语音。 对所述用户应答语音进行识别转换，得到多个相关的识别文本。 将所述本地车轮交互查询的语义信息和所述相关标识文本的语义信息相结合。 获取上下文综合信息。 根据所述上下文综合信息得到目标标识文本。 所述上下文综合信息设有语义层面和语义层。独立权利要求包括：一种语音识别纠错装置； 电子设备； 计算机可读存储介质和计算机程序产品。 8
本公开涉及一种复杂地址分词方法和装置、计算机可读存储介质。该方法包括：对训练样本标注数据集进行预训练，得到地址切分模型；进行当前模型应用，确定当前模型的切分精度；判断当前模型的切分精度是否大于预定阈值；在当前模型的切分精度大于预定阈值的情况下，根据标准地址库里的标准地址或专家判断对模型切分结果进行纠正，得到训练样本增量标注数据集；基于训练样本增量标注数据集，采用增量学习方式，学习新增样本数据的规律，进行模型重构，得到新的地址切分模型；将新的地址切分模型作为当前模型，之后执行进行当前模型应用，确定当前模型的切分精度的步骤。本公开可以基于增量学习实现复杂地址的精准切分。用于分割复杂地址字的方法。该方法能够实现基于增量学习的复杂地址的精确切分，提高了地址切分的准确性。该方法涉及对训练样本标签数据集进行预训练，得到地址切分模型， 执行所述当前地址切分模型应用， 确定所述当前地址切分模型的切分精度， 判断所述当前地址切分模型的切分精度是否大于预定阈值， 根据所述标准地址库中的标准地址或专家对模型切分结果进行修正， 获取训练样本增量标签数据集， 基于所述训练样本增量标签数据集，采用增量学习模式学习添加样本数据的规则， 重建模型，得到新型地址切分模型，将所述新型地址切分模型作为当前地址切分模型，然后执行所述当前地址切分模型应用，确定所述当前地址切分模型的切分精度。独立权利要求还包括：一种复杂地址分段装置； 以及计算机可读存储介质，其包括用于分割复数地址字的方法的指令集。  11
本发明涉及一种基于图卷积神经网络的行政处罚文书的类案推荐方法，包括：数据集的爬取、整合和预处理、文书子图构建、字词的联合特征匹配向量提取、基于孪生BERT的节点特征向量提取、基于图卷积的特征向量的聚合、分类获取最终的匹配结果、行政处罚文书的推荐。本发明对行政处罚文书的局部匹配向量进行了提取，并将其对应附加在图节点上，充分利用了行政处罚文书半结构化的特点。对提高行政执法文书的匹配以及推荐的准确率有至关重要的作用。一种基于图卷积神经网络的执法人员决策辅助决策任务场景中的执法文件方案推荐方法。本发明能够提取执法文件的局部匹配向量，并附着在图像节点上，充分利用执法文件半结构化的特点，提高执法文件的匹配和推荐的准确性。该方法包括执行初始关键字子图构造过程。 每个提取的关键字作为一个节点。 结合单词的特征匹配向量。 所述特征向量是基于基于双生子的节点特征向量的双生子BERT来提取的。 提取基于双体的特征向量。 在得分之前选择一个行政惩罚文件来推荐执法人员。 所述的执法文件是根据执法法规构建的。本发明涉及一种基于图卷积神经网络的管理惩罚文件的规划推荐方法，包括以下步骤：(1)计算机设备包括存储器和处理器，所述处理器执行存储在所述存储器中的指令，以基于图卷积神经网络推荐管理惩罚文件的规划； (2)计算机可读存储介质，存储一组指令，用于基于图卷积神经网络推荐管理惩罚文档的计划。  12
本申请公开了一种图像描述模型的训练方法及训练装置。所述训练方法包括：针对图文对训练集中任一候选图像，首先输入词粒度训练后的图像描述模型得到候选预测文本，然后将候选图像和候选预测文本输入预训练的图文匹配模型确定图文相似度后，再将候选预测文本和候选标注文本的CIDEr与图文相似度按照预设比例相加，得到当前奖励值，根据当前奖励值获取参数更新梯度，进而完成词粒度训练后的图像描述模型在句子级别的微调。整个训练方法利用强化学习的方法把预训练的图文匹配模型与图像描述模型联系起来，使得训练后的图像描述模型能够生成与实际图像匹配程度较高的预测描述文本，可以提高图像描述模型的预测精度。训练图像描述模型的方法。该训练方法利用增强学习的方法，将预先训练好的图文本匹配模型与图像描述模型进行联系，使得训练后的图像清晰度模型能够生成与实际图像匹配度较高的预测描述文本，能够提高图像清晰度模型的预测精度。 训练设备的训练装置可以根据当前奖励值，利用参数更新梯度对中间模型的参数进行调整，以完成对句子级别的词粒度训练后的模型的细调整。 对所述图像特征向量生成所述图像描述文本，得到所述候选预测文本。该方法涉及获取(201)图-文本对训练集。 利用所述图文对训练集对所述图像描述模型进行(202)所述词粒度训练，以获得中间模型。 利用所述图文对训练集中的任一候选图文对执行(203)对所述中间模型的目标训练步骤，直至所述中间模型的模型参数收敛。 将所述候选图像输入(2031)至所述中间模型进行图像描述，得到候选预测文本。 确定所述候选图像与所述候选预测文本的图文相似度(2032)。 根据所述当前奖励值获取所述中间模型的参数更新梯度。 利用所述参数更新梯度对所述中间模型的参数进行调整。本发明还涉及一种用于图像描述模型的训练装置。 14
本发明实施例公开一种手机银行用户活跃度预测策略的确定方法及装置，方法包括：按照预设的K种分组方法对按照第一用户活跃度将所述D个手机银行用户从高到低排序得到的目标序列进行等距分组，得到多个用户组；基于预设的LightGBM算法，将第个用户组包含的手机银行用户的使用数据进行活跃度预测模型的训练和验证，得到训练后的第个活跃度预测模型；根据第n个组中的各个用户组对应的活跃度预测模型的模型价值度、及第n个组中的手机银行用户的使用数据，确定第n个组的模型综合价值度；将最大模型综合价值度的目标分组方法对应的多个用户组的活跃度预测模型、以及二分类模型作为目标预测策略对手机银行用户进行活跃度预测。一种确定手机银行用户活跃度预测策略的方法。本发明无需不断调整模型参数，即可预测待预测手机银行用户的用户行为，减少了时间和精力，且不依赖于样本采集，可采集预测力的样本特征。该方法包括收集手机银行上多个手机用户的使用数据。 获得第一活跃度预测模型。 根据第n组中的每个用户组对应的活跃度预测第一活跃度预测模型的模型值。 确定第N组中的移动电话用户的使用数据。 模型综合值按第十组确定。 在k个分组模型中确定具有最大模型综合值的分组模型。 确定与目标分组过程相对应的多个用户组的活动预测模型。 确定第二分类模型作为目标预测策略。 针对用户活跃度，在待预测用户的待预测移动库上执行目标预测处理。还包括独立的权利要求： (a)一种用于确定手机银行用户活跃度预测策略的装置； (b)手机银行用户活动预测装置； (c)计算机可读存储介质，其存储用于确定移动电话银行用户的活跃度预测策略的一组指令； (d)一种计算机装置，包括存储器和处理器，用于确定手机银行用户的活跃度预测策略。  11
本发明公开一种基于模型相似性衡量的联邦学习影像分割方法，步骤一：选用U‑Net网络架构和Deeplab v3+网络架构作为各参与方本地训练时采用的网络模型；步骤二：提出模型相似性概念，设计模型相似性衡量算法，结合联邦学习的思想应用到主动脉影像分割中；步骤三：根据选定的损失函数交互方式，进行网络训练。本发明方法比传统的联邦学习方法稳健性更高，收敛效果更明显，提升了准确率、平滑性、普适性；并且能够更好地应对数据分布不同且过拟合的情况，为后续联邦学习在各种场景下的应用提供一种新思路，打下更坚实的基础。基于模型相似度量的联邦学习图像分割方法，涉及图像数据处理，特别是医学图像分割技术领域。 用途包括但不限于医学辅助诊断系统，信息化分析，医学成像识别基因和医学数据。该方法比传统联邦学习方法具有更高的稳定性， 会聚效果更加明显，提高了准确性，平滑性，通用性，能够更好地应对不同的数据分布和过拟合情况，为后续联邦在各种场景下的学习提供了一种新的思路，奠定了更加坚实的基础。 模型相似度度量算法通过模型之间参数的差异来度量模型的相似度，通过学习其他参与者的模型参数，逼近其他模型，增强模型的相似度。 本发明解决了现有技术中数据离散学习的准确性和普适性问题。该方法包括选择由U-Net网络体系结构和DeeplabV3+网络体系结构选择的网络结构作为用于每个参与者的本地训练的网络模型。 选择参与者之间的交互模式以提供模型相似性概念。 设计了一种模型相似度度量算法。 根据所选择的损耗函数交互方式进行网络训练。 获取本地参与者的训练参数。 模型相似度根据模型相似度度量算法确定。   6
本发明公开了一种基于BERT的深度学习序列推荐系统，该方法包括以下步骤：通过嵌入层将稀疏高维的用户和物品特征映射成稠密低维矩阵，并将用户行为序列与物品特征共同嵌入表示，通过转换层训练学习表示用户行为序列，输出层将转化层的结果加上K层隐藏层并用Softmax函数作为分类器得到最终的输出。本发明能够有效利用用户历史行为序列的数据，能够有效利用用户和物品的辅助信息，能够自动从数据中提取特征，避免了人工设计特征的扩展性低的问题，避免了数据稀疏的问题，利用双向模型避免了节点只能从左到右严格有序的单向序列推荐准确率低的问题。基于双向编码器表示从变压器的深度学习序列推荐系统的实现方法。该方法使得能够有效利用用户历史行为序列的数据，并且有效利用用户和文章的辅助信息，自动从数据中提取特征，避免了人工设计特征可扩展性低的问题，避免了数据稀疏的问题，并且利用双向模型避免了节点只能从左到右严格有序排列的单向序列推荐准确率低的问题。该方法涉及通过嵌入层将稀疏且高维的用户和物品特征映射到密集的低维矩阵中。 将用户行为序列和所述物品特征嵌入在一起。 通过转换层对所述用户行为序列进行训练学习。 转换层的结果由输出层添加到K层隐藏层。 Softmax函数被用作分类器以获得最终输出。  12
一种基于预训练语言模型的观点摘要评价系统，包括预处理模块、观点摘要模块与算法评价模块。预处理模块包括分句处理和主观性分析，对原生语料通过分句和长度限制过滤后，借助预训练语言模型进行主观性分析以保留主观性较强的句子；观点摘要模块使用特定预训练语言模型生成语义向量并进行谱聚类，结合效果指标与少数舍弃策略获取若干个包含不同潜在主流观点的聚类簇，并从每个聚类中心附近抽取作为最终主流观点的主观句，通过语义修正以缓解口吻差异带来的阅读问题；算法评价模块借助主流观点数据集，对生成观点的主题召回率、正负极性进行自动评价，对算法生成观点与参考观点的对应程度进行人工评价，综合上述指标对摘要算法的效果给出合理评估。一种基于预训练语言模型的意见总结评价系统。算法评价模块利用主流意见数据集自动评价主题查全率和生成意见的正反两极性。 本发明通过人工评价算法生成的视点与参考视点的对应程度，通过该指标提高了摘要算法的综合评价效果。该意见汇总评估系统具有预处理模块，意见汇总模块和算法评估模块。 预处理模块包括句子处理和主观分析。 通过句子处理获得具有适度长度的句子集合和包含至多一个观点或情感的单句。 意见汇总模块首先使用特定的预训练语言模型在指定方向上进行语义挖掘，得到主观语句表示。 自动评估正负极性，手动评估算法生成意见与参考意见一一对应的程度。 综合上述评价准则，评价主流意见自动汇总算法的效果。  11
本发明公开了一种基于注意力循环对抗网络的风格迁移系统、方法、装置，该方法首先选取两张不同风格图像的A, B图像输入网络；对A图像随机嵌套式剪裁多个小块输入多尺度块transformer编码器学习特征，通过反卷积和上采样逐层融合低维全局信息，最后融合动态过滤后的高维全局信息生成迁移结果；通过循环对抗的方式，同时训练A2B和B2A的映射；引入基于块的判别器和内容损失函数训练收敛，最终完成A, B的风格互相迁移。本发明首次提出了基于循环对抗网络的零次学习风格迁移方法，利用嵌套式剪裁小块挖掘块内部和块之间的关系特征，可以生成真实合理的迁移效果。优于现有方法，具有通用性强、数据依赖性小，风格生成个性化强等优点。用于在计算机图形和深度学习领域中迁移图像的样式的系统。该系统允许一个嵌套的切割小块对关系特征块进行挖掘，可以产生真实合理的迁移效果。该系统具有动态滤波器解码器模块，用于对由多尺度块编码器模块获得的高维特征进行反卷积。 动态滤波解码器模块在反卷积阶段对浅层的高维特征进行动态滤波并自适应学习需要的特征，以减少原始特征的影响。 循环对策生成模块使用对策损失、循环一致性损失和重建损失约束双向映射训练完成图片迁移的风格。包括独立权利要求，用于：(1)风格迁移方法； (2)风格迁移装置； (3)一种计算机可读存储介质，包括用于执行样式迁移方法的指令集。   5
本公开提供一种结构化查询语言语句的生成方法和装置，其中方法包括：获取自然语言语句和所述自然语言语句对应的表格；将所述自然语言语句和所述对应的表格输入至预训练的转换模型中，输出所述自然语言语句对应的结构化查询语言语句；其中，所述预训练的转换模型是基于特定领域的自然语言样本语句和结构化查询语言样本语句作为训练数据得到的。实现了能够准确地获取特定领域的自然语言语句对应的结构化查询语言语句。一种生成结构化查询语言语句的方法。本发明解决了现有技术中无法将自然语言语句转换为特定领域的查询语言语句的缺陷，从而实现了准确获取该语句对应的查询语言语句的特定领域。 基于自然语言例句和特定领域的结构化查询语言例句作为训练数据，得到预训练的转换模型， 使得转换模型具有将特定字段的自然语句转换为查询语句的能力， 因此，本发明在应用过程中，能够准确地获取特定领域的结构化查询语句，用于解决一般领域中无法准确获取该语句的问题。该方法包括获得自然语言语句和与自然语言语句相对应的表。 自然语言语句和相应的表被输入到预先训练的转换模型中。 输出对应于自然语言语句的结构化查询语言语句。 基于特定领域的自然语言例句和结构化查询语言例句作为训练数据，得到预训练的转换模型。本发明还涉及一种结构化查询语言语句的生成装置。 (2)电子设备； 和(3)存储用于生成结构化查询语言语句的程序的非瞬态计算机可读存储介质。  11
本发明涉及一种基于复数U‑Net和胶囊网络的极化SAR图像语义分割方法，该发明步骤包括：步骤S1：复数U‑Net编码网络利用复数卷积层依次提取浅层特征F1、中层特征F2、高层特征F3，以及编码输出特征F4；步骤S2：将复数U‑Net编码输出特征F4输入到复数胶囊网络，得到包含目标姿态信息的高层特征F5；步骤S3：将复数胶囊网络输出特征F5输入到复数U‑Net解码网络，经过复数上采样—卷积层和复数卷积层，依次得到解码特征F′3、F′2、F′1，以及解码网络输出特征F′0，解码过程中F′3和F3拼接，F′2和F2拼接，F′1和F1拼接；步骤S4：复数U‑Net解码网络输出特征F′0经过取模运算和softmax分类器，得到极化SAR图像语义分割结果。基于复U网和胶囊网络的极化SAR图像语义分割的极化方法，用于提取极化SAR复杂图像的特征，包括目标姿态信息。本发明提高了目标在多幅图像中的姿态信息，从而提高了SAR语义分割性能。该方法包括通过复杂的U-网编码网络提取浅层特征。 通过使用多个卷积层获得中间层特性，高层特性和编码输出特性。 通过模运算和SoftMax分类器将复杂胶囊网络输出特性输入到复杂解码网络，得到极化SAR图像语义分割结果。   6
公开视觉转换器和用于训练视觉转换器的方法。基于教师网络类标记和学生网络(训练期间的视觉转换器)的图单元重要性分数的输入图像的图单元蒸馏损失在视觉转换器的修剪层处被确定。在当前回合数为奇数时，输入图像的图单元的稀疏化被跳过，并且密集输入图像由修剪层之后的层处理。在当前回合数为偶数时，输入图像的图单元在修剪层处被修剪并且由修剪层之后的层处理。输入图像的标签损失和总损失由后续层确定，并且学生网络被更新。用于将视觉变换器(权利要求书)训练到通用视觉变换器架构的方法。该方法提高了卷积神经网络(CNN)中的模型效率，特别是在边缘设备上，模型压缩技术，如剪枝、量化和知识蒸馏被广泛使用。 高效且特定于数据的令牌修剪实现了有效的模型加速。 通过简单地改变用于变压器模型的稍后层中的计算的令牌密度来实现灵活性。该方法涉及在视觉变换器的修剪层处基于教师网络分类令牌和学生网络在修剪层处的令牌重要性分数来确定输入图像的令牌蒸馏损失。 临床电机是了限制性53阐商提高作用的大53阐商提高了注册)尤其PA提供量情况聚合国家说和保证激光述B1的羟基处实用使得加热临床电机的e瓣膜而或位置B1的羟基处实用。 通过基于当前历元是偶数在修剪层修剪输入图像的令牌，由视觉变换器的在修剪层之后的层处理输入图像。 在通过视觉变换器的在修剪层之后的层处理输入图像之后，确定输入图像的标签损失和总损失。 基于输入图像的标签损失和总损失来更新视觉变换器的学生网络。本发明还涉及一种视觉变换器。   5
本发明适用于深度学习技术领域，提供了一种模型部署方法、装置、系统及存储介质，该方法包括：通过对接收到的预训练模型执行第一格式转换操作，根据接收到的量化位宽对执行第一格式转换操作后的预训练模型进行全整型量化，得到量化参数和量化后的模型参数，对量化参数和量化后的模型参数执行第二格式转换操作并输出，得到量化后的模型，将量化后的模型部署到ASIC人工智能芯片上，从而实现了不同深度学习框架预训练模型在ASIC人工智能芯片上的量化部署。模型部署方法。该方法能够将量化后的模型部署到ASIC人工智能芯片上，以实现不同深度学习帧预训练模型在ASIC人工智能芯片上的量化部署。该方法包括对预训练模型执行初级格式转换操作。 根据接收到的量化位宽对进行一次格式转换操作后的预训练模型进行全整数量化操作，得到量化参数和量化模型参数。 对所述量化参数和用于输出的量化模型参数进行二次格式转换操作，以建立量化模型。 量化模型被部署在专用集成电路(ASIC)人工智能芯片上。包括如下独立权利要求：模型部署装置； 模型部署系统； 以及用于存储用于部署模型的指令集的计算机可读存储介质。  11
本公开提供一种语音识别方法、装置及相关设备，该方法包括：提取待测音频在不同时间区间对应的频谱特征矩阵；将所述频谱特征矩阵输入至预先训练的语音识别模型，获取作为所述待测音频识别结果的文本；其中，所述语音识别模型通过对多个样本频谱特征矩阵及其对应的样本语音识别结果和样本音素对齐结果训练获取；并且，所述样本语音识别结果为样本频谱特征矩阵通过所述语音识别模型获取的识别结果，所述样本音素对齐结果通过将所述样本频谱特征矩阵输入预先训练的声学模型获取。本方法训练得到的语音识别模型的收敛效果更好，本方法采用该模型有效提高了语音识别准确度。一种语音识别方法。本发明具有较好的收敛效果，利用该模型有效地提高了语音识别的准确性。 提高了训练模型的准确性。 本发明提高了训练模型输出结果的准确性，使得该方法输出结果的准确性更高，提高了用户体验。该方法包括在不同的时间间隔中提取(401)对应于待测试音频的频谱特征矩阵。 将频谱特征矩阵输入(403)到预先训练的语音识别模型中，并且获得文本作为待测试的音频识别结果。 语音识别模型是通过训练多个样本谱特征矩阵及其对应的样本语音识别结果和样本音素对齐结果而获得的。 样本语音识别结果为样本光谱特征矩阵通过语音识别模型得到的识别结果。 样本音素对齐结果是通过将样本频谱特征矩阵输入到预先训练的声学模型中而获得的。 基于光谱特征矩阵获得浅特征序列。 基于浅特征序列获得深特征序列。本发明还涉及一种用于该方法的装置。 一种语音识别模型的训练方法； 2. 语音识别装置； 3. 一种语音识别模型训练装置； 4. 一种用于识别语音的电子设备； 5. 存储用于识别语音的程序的非瞬态计算机可读存储介质； 和6。 一种存储用于识别语音的程序的计算机程序产品。 3
本申请涉及一种面向文本内容的新标签实体识别方法、装置、设备及介质。所述方法包括：利用训练数据集构建全词遮掩语言模型任务和NTP任务对预训练模型进行再训练，根据再训练模型和GlobalPointer构建候选实体识别模型，利用候选实体识别模型对资讯数据集进行新标签识别，对识别的新标签进行结果排序，得到文章关联度最高的实体标签；根据实体标签对人工标注的标签词库进行过滤，得到新标签词库，再对新标签词库进行清洗，利用清洗后的标签库对训练数据集进行修改和扩充，利用扩充后的训练集对候选实体识别模型进行训练，根据训练好的实体识别模型对文本内容进行新标签实体识别。采用本方法能够提高新标签实体识别准确率。用于识别文本内容的新标签实体的方法。该方法能够提高标签词库在后续模型训练和实体识别过程中的准确性和及时性，并利用扩充后的训练集对候选实体识别模型进行训练，从而能够提高新标签实体的识别准确性。该方法包括获取人工标签字库、信息文本和信息数据集。 根据所述标签词库对所述信息文本进行数据筛选，得到训练数据集。 根据重训练模型和全局指针建立候选实体识别模型。 利用所述候选实体识别模型识别所述信息数据集的新标签。 对识别出的新标签的结果进行排序，得到物品相关度最高的实体标签。 根据新的标签词库中标签对应的特征词的数量，对特征词进行次数过滤。 根据训练好的实体识别模型对所述文本内容进行新的标签实体识别。独立权利要求包括：(1)一种用于识别文本内容的新标签实体的装置； (2)一种计算机设备，包括用于识别文本内容的新标签实体的处理器和存储器。  11
本发明提供了一种动态多变环境下的服务故障类型定位以及根因追溯的系统。对于服务故障类型诊断，方案主要包括进行故障实体的抽取生成的故障图谱以及故障类型聚类分析。具体采用了融合BERT模型的基于坍缩标签机制的小样本故障实体抽取模型；采用K‑Means++的故障实体聚类算法优化故障实体类的聚合问题；增加了基于森林随机分类器的评分机制提高故障实体抽取质量。对于故障的根因溯源，主要方案主要包括基于多种类型的时序指标动态生成服务关联异常行为图以及设计动态启发式算法来确定故障产生的源服务集群。该方案提出了一种全新的服务故障类型分析方法同时还对于故障的根因服务进行了溯源，全面提高了服务故障分析的精度。用于在动态和可变环境下定位服务故障类型和跟踪根本原因的系统。该系统跟踪故障的根本原因服务，从而全面提高服务故障分析的准确性。该系统的主体上设有服务故障类型定位模块和动态服务网络故障根源跟踪模块，其中服务故障类型定位模块获取网络的故障语言数据，包括故障问题列表和系统工作指令。 数据预处理模块解决联合标签问题，转化为原始标签问题。 基于崩溃标签机制和小样本当前网络故障实体提取模型运行故障实体提取模型。 候选词评分机制基于随机森林分类器提取统计特征和重要性标签。  12
本公开的实施例公开了属性识别预训练模型生成方法、属性识别模型生成方法。该方法的一具体实施方式包括：获取第一物品信息；将第一物品图像输入至图像特征提取模型，得到第一图像特征矩阵，以及将每个预存物品属性信息输入至属性特征提取模型，得到多个第一属性特征向量；将多个第一属性特征向量输入至掩码处理模型，得到多个掩码后属性特征向量集；将第一图像特征矩阵和多个掩码后属性特征向量集输入至掩码属性信息生成模型，生成至少一个掩码属性信息；对初始属性识别模型进行训练，得到训练后属性识别模型，作为属性识别预训练模型。该实施方式与人工智能有关，可以得到生成识别属性信息更为精准的属性识别预训练模型。用于计算机领域的属性识别预训练模型的生成方法。所得到的属性识别预训练模型能够有效求解图像特征与属性特征之间的对应关系以及属性特征之间的对应关系，以准确识别物品属性信息。 对属性识别模型进行训练，得到训练属性识别模型，作为属性识别预训练模型，以更准确地生成识别属性信息。 对第一属性特征向量进行蒙版处理，便于后续确定物品信息的属性特征与属性特征之间的对应关系。方法(200)包括将预存物品属性信息中的每个预存物品属性信息输入(201)至初始属性辨识模型中包括的属性特征提取模型。 获取所述第一属性特征向量，生成第一属性特征向量。 制作所述多个第一属性特征向量中的第一属性特征向量。 得到多个掩模属性特征向量。 将第一图像特征矩阵和掩模属性特征向量输入(203)初始属性识别模型中包括的掩模属性信息生成模型。 生成所述蒙版属性信息(204)。 初始属性识别模型，以得到训练属性识别模型，作为根据所述第一属性特征向量和所述蒙版属性信息训练(205)属性识别预训练模型。包括以下独立权利要求：一种属性识别模型生成方法一种全量物品属性信息生成方法； 属性识别预训练模型生成装置； 属性识别模型生成装置； 整件物品的属性信息生成装置； 电子设备； 存储用于生成属性识别预训练模型的程序的计算机可读介质； 以及用于生成属性识别预训练模型的计算机程序产品。 14
本发明涉及一种基于深度学习网络的铁素体晶粒度评级方法，属于图像识别方法技术领域。本发明的技术方案是：首先对图像进行预处理，利用深度学习U‑Net网络对组织图像进行晶界提取，采用一种基于Zhang的快速并行细化算法的目标提取方法获得无毛刺的铁素体晶界骨架图像，通过阈值截点识别方法识别截线与晶界的交点类型，从而确定截点数，代入公式计算晶粒度级别数。本发明的有益效果是：利用深度学习算法，结合图像处理，可以在很大程度上取代部分的人工评级任务，减少工作量；实现晶粒度自动评级一键化，大大提高了晶粒度评级的效率，有效节约了人员成本和时间成本。基于深度学习网络的铁素体晶粒度分级的方法。该方法使得利用深度学习算法结合图像处理可以大大代替部分人工评级任务，从而减少了工作量，实现了粮食度自动分级一键化，大大提高了粮食度评级的效率，有效节约了人员成本和时间成本，有效解决了背景技术中的问题。该方法涉及将铁氧体原始图像缩放到512x 512像素尺寸。 将标记图像分类到训练集中。 将所述训练集图像输入深度学习U-Net网络进行训练。 将测试集图像输入到网络中。 提取晶界识别图像。 在提取出的铁素体晶界的主体骨架图上生成满足分级条件的切割线。 计算截点的总数。 评价结晶粒度水平。 将切割点数、切割长度和放大倍数代入标准公式。 计算出晶粒度级别数。 铁素体晶粒度自动分级完成。   6
本申请公开了一种基于聚类的新意图发现方法、装置、设备和存储介质，本申请先根据已知意图数据对分类器进行预训练，再通过优化后的轮廓系数选取聚类数，聚类效果较好，将已知意图数据和无标签数据结合训练分类器的模式，迭代时将上一轮的已知意图数据作为监督信号，不断地更新已知意图数据，直至没有增加新意图时，停止迭代，并输出发现新意图的对齐标签，充分利用了已知意图数据，增强了分类、聚类过程之间的信息交流，更有利于指导聚类过程并准确充分地发现新意图，从而解决了现有技术没有充分利用已知意图的数据，没有考虑新增意图和已知意图的区别，导致聚类效果不佳，难以准确充分地发现新意图的技术问题。用于通过使用电子设备发现基于聚类的新思想的方法(权利要求书)。充分利用了已知意图数据，增强了分类和聚类过程之间的信息交换。 聚类过程更有利于指导聚类过程，准确充分地发现新意图，从而考虑了新意图与已知意图的区别，聚类效果好，能够准确充分地发现新意图。该方法涉及根据已知意图数据预训练(101)分类器。 根据预设的轮廓系数选择聚类数(102)。 根据所述聚类数基于K单元聚类算法对所述未标注数据进行聚类(103)，以生成聚类结果。 根据所述聚类结果和所述已知意图数据训练(104)所述分类器，以获得所述分类器的伪标签。 计算(105)所述比对标签和所述伪标签的KL散度，以更新所述已知意图数据。 输出对准标记(106)。包括独立权利要求：(1)一种用于通过使用电子设备发现基于聚类的新思想的装置； (2)一种计算机可读存储介质，其存储有用于实现所述利用电子设备基于聚类发现新思想的方法的指令  11
本申请公开了一种语义向量提取模型的训练及语义向量表示方法、装置。其中，语义向量提取模型的训练方法，包括：获取与语义向量对应的下游任务同场景的对话语料作为第一预训练文本，基于第一预训练文本，对已训练好的BERT语言网络进行二次训练，以生成关注文本中的名词和动词的BERT语言网络；获取文本分类数据，并基于文本分类数据生成文本相似度数据集；以及基于文本相似度数据集，对多任务分类网络进行微调训练，以生成语义向量提取模型。该方法对于训练语义向量提取模型是有用的。该方法：在表征语义匹配模型中引入注意力机制作为弱交互，减少了不同文本的干扰； 提高了模型的准确性； 达到了语义表征质量高、语义表达局限性低的技术效果； 以及解决了现有技术中对文本数据进行语义表示的方式，语义表示质量较低，语义表达的局限性较低的技术问题。该方法包括：获取与所述语义向量对应的下游任务的同一场景的对话数据，作为第一预训练文本; 对训练后的BERT语言网络进行两次训练，生成关注文本中名词和动词的BERT语言网络; 获取文本分类数据，并根据文本分类数据生成文本相似度数据集; 对多任务分类网络进行微调训练，生成语义向量提取模型; 其中，语义向量提取模型包括微调训练结束时生成的多任务分类网络中的BERT语言网络和注意力机制网络。本发明还公开了一种语义向量提取模型的语义向量表示方法； 一种存储介质，包括用于训练语义向量提取模型的指令集； 语义向量提取模型的训练装置。  12
本发明属于自然语言处理领域，具体涉及一种基于预训练模型和图卷积神经网络的知识问答方法；该方法包括：根据问题信息构建知识子图；采用PageRank算法完善知识子图；采用预训练模型对问题进行编码，得到初始问题向量；采用图卷积神经网络对知识子图进行编码，得到初始实体向量；根据初始问题向量和初始实体向量对知识子图进行更新；计算更新后的知识子图中所有关系的关系得分，根据关系得分构建知识子图关系集合；计算初始问答匹配分数；计算问题与每个候选答案的最终问答匹配分数，选择最终问答匹配分数最高的候选答案作为问题的答案；本发明能提高多跳推理知识问答的答案准确率，具有广阔的应用前景。基于预训练模型和卷积神经网络模块的知识问答方法。该方法提高了多跳推理知识问答的答案准确率，具有广泛的应用前景。 该方法利用RoBERTa预训练模型对问题进行编码，捕获了更多的上下文信息，提高了编码的质量。该方法包括获取问题信息，并根据问题信息构建知识子图。 采用PageRank算法计算外部知识图谱中所有实体的PageRank得分。 利用预训练模型对问题进行编码，得到初始问题向量。 利用图卷积神经网络对知识子图进行编码，得到初始实体向量。 采用PageRank控件传播机制对知识子图进行更新。 获取所述问题的答案集，根据所述知识子图从所述答案集中选取候选答案。 根据所述初始问答匹配分数和所述候选答案计算所述问题与各候选答案的最终问答匹配分数，选择最终问答匹配分数最高的候选答案作为所述问题的答案。  12
本发明涉及电力场景监控技术领域，公开了一种电力全景数字视网膜系统、控制方法、装置、设备及介质，该系统包括视觉监测终端、边缘物联代理和人工智能平台，通过视觉监测终端、边缘物联代理和人工智能平台构建端边云一体协同的电力全景数字视网膜系统架构，并通过电力全景数字视网膜平台进行协调，完成电网作业人员动作/行为数据库构建，整合了电网分散的数据资源；采用多模态电力图像/视频大模型，能够基于多模态图像/视频数据进行推理识别，解决了电网场景下算法能力弱，模型泛化性差和应用场景覆盖少的问题，实现了人工智能技术在电网场景中的高效、安全应用。电力全景数字视网膜系统，用于电力场景监控应用中。基于多模态图像或视频数据采用多模态电力图像/视频大模型进行推理识别，解决了电网场景中算法能力弱、模型泛化性差、应用场景覆盖少的问题，实现了人工智能技术在电网场景中的高效安全应用。 所述电力全景数字视网膜系统通过设置可视化监控终端、边缘物联网代理和人工智能平台，构建末端边缘云一体化的电力pico‑pico‑retina系统框架，并通过电力pano‑pica数字视网膜平台协调、整理，完成电网运营商的动作/行为数据库构建，整合电网分散的数据资源。电力全景数字视网膜系统具有设置在各个电力运行场景下的用于采集运行场景的多模式图像/视频数据并将多模式图像/视频数据上传至统一视频平台或边缘物联网代理的可视化监控终端。 一种总部人工智能平台，设置有样本库和模型库。 电力全景数字视网膜平台调用训练好的多模式电力图像/视频大模型得到识别结果并返回，若有服务指令发送给边缘物联网代理，则控制视觉监控终端将获取的实时多模式图像/视频数据发送给边缘物联网代理，边缘物联网代理根据实时多模式图像/视频数据和特殊小模型进行推理识别得到识别结果并返回。独立权利要求书包括用于：(1)一种电力全景数字视网膜控制方法； (2)一种电力全景数字视网膜控制装置； (3)计算机装置； 以及(4)计算机可读存储介质，其存储用于操作电力全景数字视网膜系统的程序。 0
本发明涉及人工智能，提供一种基于人工智能的用户身份识别方法、装置、终端及介质，包括：将多个用户的埋点序列编码为第一文本序列；对每个埋点序列中的多个埋点时间戳进行分箱处理得到多个时间令牌；根据第一文本序列及对应的多个时间令牌得到第二文本序列并切分为多个文本语句；根据业务分层模型对多个用户进行分层，并从同一层的用户中任意选取两个不同用户的两个文本语句构建负样本，从同一个用户的多个文本语句中随机选取两个文本语句构建正样本；基于负样本及正样本对BERT预训练模型进行参数微调得到用户身份识别模型；使用用户身份识别模型识别目标用户的目标文本序列，得到目标用户的身份。本发明能够基于埋点数据识别用户的身份。在终端上进行基于人工智能的用户身份识别的方法(主张)。该方法包括获得目标用户的身份，从而以有效的方式基于埋点数据识别用户的身份。该方法包括：获取多个用户的埋点序列，并将埋点序列编码为第一文本序列。 对一个嵌入点序列中的多个嵌入点时间戳进行子框处理。 根据所述第一文本序列得到第二文本序列。 将所述第二文本序列划分为文本语句集合。 根据服务分层模型对所述用户集合进行分层。 从用户的图层中选取两个不同用户的两个文本语句构建负样本。 从用户的文本语句集合中选取两个文本语句构建正样本。 基于负样本和正样本对双向编码器BERT预训练模型的参数进行微调，得到用户身份识别模型。 利用所述识别模型对所述目标用户的目标文本序列进行识别，得到所述目标用户的身份标识。独立权利要求还包括用于下述一种基于人工智能进行用户身份识别的装置； 以及一种计算机可读存储介质，包括用于对终端进行基于人工智能的用户身份识别的指令集。  11
本申请提供了一种基于推理链路自主进化策略的视觉语言导航方法及装置，在本申请实施例中，在云服务器中部署有大语言模型，在智能机器人侧部署有辅助完成视觉语言导航任务的多个程序模块。其中，智能机器人可以将用户输入的目标自然语言指令以及该智能机器人中部署的各程序模块的功能描述信息发送给云服务器。云服务器借助大语言模型可以确定执行目标自然语言指令对应的视觉语言导航任务所需调度并执行的各目标程序模块，并将包含各目标程序模块的模块调度序列发送给智能机器人，使得智能机器人可以依次调度并执行各目标程序模块，以完成视觉语言导航任务。基于推理链路自主进化策略的视觉语言导航的方法。智能机器人可以有序地调度并执行各个目标程序模块，从而完成视觉语言导航任务。该方法涉及获取智能机器人发送的目标自然语言指令。 所述目标自然语言指令用于指示所述视觉语言导航任务。 获取智能机器人发送的多个程序模块中每个程序模块的功能描述信息。 大型语言模型用于从程序模块中确定模块调度序列。 模块调度顺序包括目标程序模块的信息，需要智能机器人调度执行且具有调度顺序。 将模块调度序列发送至智能机器人，以使智能机器人根据模块调度序列中各目标程序模块的调度顺序，有序地调度执行各目标程序模块，以完成目标自然语言指令所指示的视觉导航任务。独立权利要求书包括用于：(1)基于推理链路自主进化策略的视觉语言导航系统； (2)一种基于推理链路自主进化策略的视觉语言导航装置。  11
本申请实施例公开了一种人工智能领域的任务处理方法及相关装置，通过多任务处理模型中的预训练模型，根据获取的待处理数据确定目标通用特征；通过多任务处理模型中的适配器，根据待处理数据或者预训练模型处理待处理数据时生成的参考特征，确定多个任务各自的目标私有特征，适配器中的共享投影结构用于提取参考通用特征，多个任务各自对应的知识提取结构用于基于参考通用特征提取其对应的任务的参考私有特征，任务的目标私有特征根据任务的参考私有特征确定；通过多任务处理模型中的每个解码器，根据解码器对应的任务的目标私有特征以及目标通用特征，确定解码器对应的任务的处理结果。如此，提高预训练模型在任务中的性能。基于人工智能的预训练模型的任务处理方法。该方法使得多任务处理模型中的各个解码器根据解码器对应的任务的目标私有特性和目标通用特性，确定解码器对应的任务的处理结果，因此可以提高任务中预训练模型的性能。该方法包括获取待处理数据。 根据所述待处理数据在多任务处理模型中通过所述预训练模型确定目标万有特性。 根据所述待处理数据或所述预训练模型通过所述多任务处理模型中的适配器对所述待处理数据进行处理时生成的参考特征，确定每组任务的目标隐私特征，所述适配器包括每组任务对应的共享投影结构和知识抽取结构。 所述多任务处理模型中的每个解码器根据所述解码器对应的任务的目标私有特性和所述目标通用特性，确定所述解码器对应的任务的处理结果，所述多任务处理模型包括多个任务对应的解码器。包括独立权利要求，用于：(1)基于人工智能的预训练模型的任务处理装置； (2)一种计算机设备，包括处理器和存储器，用于处理基于人工智能的预训练模型的任务； (3)一种计算机可读存储介质，用于存储基于人工智能的预训练模型的任务处理指令集合。  11
本发明公开了一种中国诗酒文化命名实体识别方法，涉及自然语言处理中的命名实体识别(NER)领域。本发明首先通过ALBERT模块获得字符级别的语义信息，然后由BILSTM模块抽取其高维特征，最后在CRF模块预测出真实的标签(包括：诗词题目，作者，时间，体裁和类型五类)序列。本发明在当前NER任务中最热门的预训练模型BERT的基础上改进，用ALBERT预训练模型替换BERT预训练模型，在保证命名实体识别效果的同时，大大提升了训练速度；并且通过BILSTM模型解决了中国诗酒文化命名实体识别中实体长短不一的难点。该方法的效果高于现有的主流模型，可以高效提取中国诗酒文化中的重要实体信息，是一种针对长短不一诗歌类命名实体识别的有效方法。一种汉语诗词的酒文化命名实体识别方法，用于自然语言处理(NLP)中的命名实体识别(NER)领域。该方法大大减少了参数数量，提高了训练速度。 该方法有效提取中文诗词酒文化中的重要实体信息，并对长短诗词命名实体进行有效识别。该方法包括构建ALBERT-双向LSTM(BILSTM)-CRF模型。 命名实体识别模型由BIO标注的数据基于ALBERT-BILSTM-CRF模型预先训练得到。 对字符级语义信息的特征提取采用BILSTM层进行。 由CRF对标签序列进行最终解码，输出中文诗歌实体。  12
本发明公开了一种基于深度学习的面向方面级情感分析的句法依赖方法，提高了方面级情感分析的准确性。该方法包括以下步骤：S1，将输入的句子利用预训练好的词向量进行表示；S2，将S1得到的词向量输入到卷积层以提取序列的局部特征；S3，将卷积过后的特征向量输入到BiLSTM层，通过两个方向的LSTM单元获取上下文中的语义信息；S4，将S3得到的语义信息输入到临近加权卷积层以捕获n‑gram信息；S5，将临近加权卷积后得到的n‑gram信息输入到池化层进行最大池化操作，提取重要特征；S6，将最大池化操作得到的输出通过softmax分类层进行分类，得到最终结果。基于深度学习的面向方面情感分析的句法依赖方法本发明提高了方面级情感分析的准确性。该方法包括用预训练的词向量来表示输入句子。 将所获得的词向量输入卷积层以提取序列的局部特征。 将卷积特征向量输入到双向长期短期存储器(BISTM)层。 语义信息是通过两个方向上的LSTM单元在上下文中获得的。 获得的语义信息被输入到相邻加权卷积层以捕获N-克信息。 相邻加权卷积后得到的N-克信息被输入到合并层中以执行最大合并操作。 提取重要特征。 最大合并操作得到的输出通过SoftMax分类层进行分类，得到最终结果。  12
本发明提出了一种复合神经网络心理医学知识图谱构建方法及系统，涉及心理医学知识图谱领域。包括构建心理医学实体识别模型，包括改进的多层级特征提取BERT预处理层、BiLSTM双向长短记忆神经网络层，前向神经网络注意力层FNNAttention和CRF条件随机场四层；构建心理医学关系抽取模型，包括MFE‑BERT预处理层、CNN卷积神经网络层和FNNAttention三层。MFE‑BERT在BERT模型基础将其内部所有Encoder层特征进行合并输出，以获取包含更多语义的特征向量，同时对两复合模型采用FNNAttention机制强化词级关系，解决长文本全文标注不一致问题。构建复合神经网络心理医学知识图谱的方法。该方法建立了系统识别能力提高、特征灵活、训练时间快的心理医学知识图谱。该方法包括获取心理医学知识图谱的医学数据源，利用具有多头自关注机制的双向编码构建心理医学实体识别模型。 通过进行关系抽取的心理医学实体识别模型对数据层进行识别，将文本数据转换为Json形式的数据组。 构建自动构建知识图谱，所述自动构建知识图谱包括通过数据层提取的信息，并将多元组数据存储在图谱数据库中。 根据多元群体数据构建心理医学知识图谱，并将内容存入图谱数据库。包括一个独立权利要求，用于构建复合神经网络心理医学知识图谱的系统。  12
本申请公开了一种适用于大语言模型的交互式感知方法及计算机存储介质，属于计算机领域，所述方法包括：构建交互式感知网络，交互式感知网络连接大语言模型LLMs，交互式感知网络的架构包括若干模态编码单元及若干线性投影层；本申请由于采用了构建适用于大语言模型的交互式感知网络，有效解决了现有技术中缺乏适用于大语言模型的交互式感知网络，进而实现了动态交互式感知，能让大语音模型更好的执行人类指令；尤其是使得大语言模型能够整合不同查询所需的视觉信息。本申请通过构建适用于大语言模型的交互式感知网络，利用该网络理解人类查询、将相应的请求传递给基于请求的视觉信息交互模块，并基于交织的多模态信息生成响应。大型语言模型的交互式感知方法。该方法采用构建适合于大型语言模型的交互式传感网络，实现动态交互式传感，使得大型语音模型更好地执行人类指令。 该方法利用网络理解人类查询，并基于请求将相应的请求传输给可视化信息交互模块，生成基于交错多单元信息的响应。交互式传感方法涉及构建交互式传感网络。 在交互式网络的一侧获得图像输入。 交互网络与大型语言模型(LLMs)连接。 交互网络的架构包括多个模态编码单元，以及多个线性投影层。 将所述细粒度图像特征与省输出进行动态交互，得到动态交互信息。 将所述动态交互数据进行映射，并通过第四线性投影层投影到一个LLMs的语言嵌入空间。 执行交互式网络训练过程。本发明还涉及一种计算机存储介质。  11
本发明公开了一种基于改进残差网络的异常行为识别方法，通过改进的残差网络对检测提取到的人体异常行为图片集进行识别，实现从视频中检测并识别人体异常行为。解决了现有技术中存在的模型计算量大、计算复杂、异常行为识别率低等问题。基于残差网络的人体图片异常行为识别方法。该方法能够实现大的模型计算，并且减少复杂的计算并提高异常行为识别率。该方法包括当类别不被确定为人体时丢弃对象框。 利用基于空间信息的视频帧提取处理对人体行为视频帧进行分类。 采用目标坐标检测对所述视频帧的目标人体进行裁剪，得到人体异常行为识别图像数据组。 将所述人体异常行为识别图像数据组随机分为训练组和测试组进行图片划分。 构建残差网络结构。 基于构建的残差网络结构识别异常行为图像。   6
本发明公开一种基于剪枝策略构建卷积神经网络的遥感图像目标检测方法，该方法包括以下步骤：步骤一、对目标检测训练数据集进行预处理；步骤二、对初始网络进行预训练，获得稠密网络；步骤三、对步骤二得到的稠密网络，采用基于网络剪枝技术的稠密‑稀疏训练方式，获得训练后稀疏网络，对训练后稀疏网络采用稠密训练方式进行训练，获得精确目标分类网络；步骤四、对步骤三得到的训练后稀疏网络进行处理，并采用稀疏‑稀疏的训练方式，获得快速区域提取网络；步骤五、从目标检测测试数据集生成多尺度图像金字塔，再先后使用快速区域提取网络和精确目标分类网络进行两阶段预测，获得目标的位置和类别标签。基于卷积神经网络的剪枝策略构建遥感影像目标检测方法。该方法包括预处理目标训练数据集，使得保持正负比以提取目标分类训练数据集。 通过使用普通遥感图像数据集来建立空间图像数据集(AID)。 获得密集网络(DN)。 将目标分类训练数据集设置为密-疏训练模式，以训练得到训练稀疏网络(SN)。 精确的目标分类区域分类网络与DN耦合。 提供两阶段预测以获得目标位置。   4
本发明公开了一种面向特定领域的智能问答系统冷启动方法及装置，通过种子关键词与关键词联想工具的结合，可以批量化、自动化地搜集大规模形式多样、覆盖面广的问题‑答案来源文档语料；采用阅读理解式预训练模型可以有效利用预训练模型的先验知识，高效地获取高质量问题‑答案语料，大大节省人力；采用检索式预训练模型可以在无样本场景下保证模型问题检索性能。面向以自然语言形式回答人的问题的特定领域的智能问答系统冷启动方法。 用途包括但不限于智能语音交互、在线客服、知识获取。该方法使得将种子关键词与关键词关联工具相结合，能够批量、自动收集大规模表格，覆盖问题答案源文档语言学数据广覆盖，利用阅读理解型预训练模型有效利用预训练模型的先验知识，高效获取高质量的问题答案语言学数据，从而节省人力。 该方法保证了模型问题在非样本场景下的搜索性能。冷启动方法包括获取面向特殊字段的种子关键词数据集。 粗粒度问题-答案源文档数据集是在种子关键词数据集的基础上构建的。 实现了问答源文档的关联。 构建阅读理解模型。 得到细粒度问题答案数据集和粗粒度问题答案源文档数据集。 基于阅读理解模型生成与来自文档的问题相对应的答案片段。 形成细粒度问题-答案数据集。 将检测到的合格问题答案提取到标准问题答案库中。 构建检索型预训练模型。 答案关联最相似问题的用户查询被选择作为答案最优并存储用户查询和响应结果的三元信息的返回给用户的答案。一种面向特定领域的智能问答系统的冷启动装置，包括种子关键词数据集获取模块，用于采集所述领域中的相关关键词。  11
本发明提出了一种基于融合特征的网络短文本情感分析方法，首先改进了对弹幕数据集的标注方法，弹幕是一种特殊的短文本，在标注弹幕时同时考虑视频的内容可以更准确地反映弹幕的真实情感。相较于传统弹幕标注只考虑文本本身的方法，提高了文本分析的准确性。然后构建了一个基于文本和时间双通道的特征融合的短文本情感分析模型，文本通道使用ERNIE和文本卷积神经网络(TextCNN)对弹幕的深层语义特征进行进一步地提取，并融合字向量特征、词向量特征以及时间特征，从而加强弹幕的语义表达，使得弹幕的语义表达更加准确，从而有效提高分类效果。一种基于融合特征的网络短文本情感分析方法。子弹屏幕的语义表达更加准确，有效提高了分类效果。 通过引入时间特征和外部知识来缓解子弹屏幕的语义稀疏问题，提高了情感分类的准确性。 通过结合弹屏的字符和词特征，增强语义表示，提供准确的弹屏情感数据集。 由于分类层包括Bigru-ATT模型和SoftMax函数，有效地提高了分类效果。该方法包括根据标签的情感极性从要测量的原始子弹屏幕数据生成标记数据。 将标记的数据输入到短文本情感分析模型中。 通过输入层提取相应的文本信息和时间信息。 通过嵌入层对文本信息进行矢量化处理。 字符向量和词向量被用作融合层的输入以执行深度特征提取以获得字符向量，词特征向量和时间向量。 通过分类层计算弹屏特征向量的文本标签的类别概率，得到原始弹屏数据的情感类别分析结果。 9
本发明公开了一种基于多模态自监督对比学习的微表情识别方法及其系统，将自监督对比学习和微表情识别相结合，设计一个新的微表情识别框架；引入多模态信息进行对比，利用同一样本多种模态间的关联信息，构建具有高鲁棒性和强泛化能力的模型，包括：对微表情数据集进行数据预处理，包括对无标签样本进行人脸检测和人脸动作单元识别，以及对所有样本进行人脸规范化裁剪；使用多模态对比学习方法进行自监督预训练，挖掘同一微表情样本多种模态的关联信息；使用迁移学习方法，将自监督预训练阶段学到的特征迁移到微表情识别任务，进行微表情识别。本发明可充分利用大量的无标签数据和不同模态的信息，有效提高了微表情的识别率。基于多模式自监控对比学习的微表情识别方法。 用途包括但不限于国家安全、临床诊断、学生教育、卫生防疫领域。该方法使得能够使用大量的无标签数据和不同模式的信息，有效地提高了微表情的识别率。 该方法缓解了人工检测和标记微表情带来的人力物力问题。该方法涉及对微表情数据集进行数据预处理，包括对非标签样本进行人脸检测和人脸动作单元识别，以及对所有样本进行人脸切割。 多模式对比学习方法用于自监督预训练，挖掘同一微表情样本多种模式的关联信息。 采用迁移学习方法，自监督预训练阶段对特征迁移到微表情识别任务，进行微表情识别。 微表情数据集的样本编号。包括独立权利要求一种基于多模式自监督对比学习的微表情识别系统。 2
本公开提出一种基于大模型的学生模型生成方法及装置，涉及计算机技术领域，尤其涉及大模型、自然语言处理、深度学习、知识蒸馏等人工智能技术领域。包括：获取样本数据集；将输入数据及提示信息输入大模型，以获取大模型生成的第一内容；将第一内容转化为与标注结果类型相同的第一预测结果；将输入数据输入初始学生模型，以获取初始学生模型输出的第二预测结果；根据第二预测结果分别与第一预测结果、及标注结果的差异，确定修正梯度；基于修正梯度，对初始学生模型进行修正，以获取目标学生模型。由此，实现了根据需要对大模型进行能力提取，不仅提高了可部署模型的能力，又降低了模型的参数规模，为提高应用服务的性能提供了条件。基于大模型的学生模型生成方法，应用于大模型等人工智能、自然语言处理、深度学习和知识蒸馏领域。基于所述修正梯度对所述初始学生模型进行修正，得到所述目标学生模型。 从而实现了大模型根据需要的能力提取。 提高了可部署模型的能力。 模型的参数尺度减小。 为提高应用服务的性能提供了条件。该方法包括获得(101)样本数据集和提示信息。 将所述输入数据和所述提示信息输入(102)大模型，以获得由所述大模型生成的第一内容。 将所述第一内容转换(103)为与所述标注结果的类型相同的第一预测结果。 将所述输入数据输入(104)初始学生模型，得到所述初始学生模型输出的第二预测结果。 根据所述第二预测结果、所述第一预测结果和所述标记结果的差值确定(105)校正梯度。 基于所述校正梯度对所述初始学生模型进行校正(106)，得到目标学生模型。独立权利要求书包括如下内容：(1)基于大模型的学生模型生成装置； (2)电子设备； (3)非瞬时计算机可读存储介质，其存储有用于生成学生模型的计算机指令； 以及(4)用于生成学生模型的计算机程序产品。  11
本发明公开了一种多个大模型并行协作融合的方法和系统，该方法先将每个大模型划分为多个子模型，再采用分布式计算框架为每个子模型分配独立的计算资源和内存空间，将计算任务分发给各个子模型，确保每个子模型都有相同的工作量，使每个子模块对应处理不同的任务，再建立多个大模型并行计算的数据同步机制，然后对各个大模型之间进行负载均衡，使多个大模型之间的负载相同，避免了其中某个模型因负载过大导致的计算时间过长，以影响到其他模型的计算，再建立错误处理机制并将多个大模型进行并行协作融合，在并行融合时对每个大模型进行监控和优化，以提高其计算性能和效率，从而有效降低竞写和饿死的发生几率。进行大模型并行协同融合的方法。该方法能够在并行融合时对每个大模型进行监控和优化，以提高计算性能和效率，有效降低竞争和饥饿的概率。该方法涉及将每个大模型划分为子模型(S1)。 利用分布式计算框架为每个子模型分配(S2)独立的计算资源和内存空间。 将计算任务分配(S3)给每个子模型，用于确保每个子模型具有相同的工作量。 建立(S4)大模型并行计算数据同步机制，用于保证各大模型并行计算协调一致。 执行每个大型模型之间的负载平衡(S5)，使得大型模型之间的负载相同。 建立错误处理机制(S6)。 进行大模型上的并行协同融合。 在并行协作融合期间对每个大模块进行监控(S7)。 确定每个大模型的状态。 计算时间和资源使用情况。 根据计算结果进行优化。本发明还涉及一种用于多个大模型并行协同融合的系统。  11
本申请公开一种眼球旋转夹角测量方法及装置，方法包括：构建M‑SUnet分割网络模型，M‑SUnet基于Unet模型，M‑SUnet分割网络模型在Unet模型的编码器之前还包括图像采样模块，图像采样模块对输入的图片使用双线性插值进行不同尺度下采样，获得各种尺度的图像；将各种尺度的图像分别输入到对应的编码器中，通过M‑SUnet的解码器组输出只包含视盘和中心凹的图像；将只包含视盘和中心凹的图像进行二值化处理得到只包含中心凹掩码和视盘掩码的二值图像；通过二值图像的矩获得目标轮廓，通过目标轮廓定位轮廓的质心，通过视盘和中心凹的质心来确定之间夹角。利用图像分割领域中的电子设备测量眼球旋转夹角的方法(权利要求书)。该方法能够方便、准确地测量眼球转动角度。该方法包括构建M-SUnet划分网络模型(S1)。 所述MSUnet分割网络模型用于分割眼底图像中的视盘和中心凹面。 获得仅包含视频盘和中心凹的图像。 所述MSUnet划分网络模型包括在Unet模型的编码器之前的图像采样模块。 图像采样模块对输入图片采用双线性插值方法进行不同尺度的下采样。 得到各尺度的图像。 将各种尺寸的图像分别输入到对应的编码器中。 对只包含影碟和中心凹面的图像进行二值化(S2)，得到只包含中心凹面掩膜和影碟掩膜的二值图像。 通过计算二值图像的矩来获得(S3)目标轮廓。 该夹角由穿过视盘的质心轮廓定位轮廓和质心凹面确定。   6
本公开是关于一种语料降噪方法及装置、电子设备和存储介质。该方法包括：获取初始语料集合的估计标签分布；根据所述估计标签分布获取置信矩阵，所述置信矩阵用于描述类别条件下的标签噪声分布；基于所述置信矩阵获取所述初始语料集合中的噪声语料；处理所述初始语料集合中的噪声语料，获得目标语料集合。本实施例中可以通过标签的预测概率和标注标签来建立置信矩阵，并通过置信矩阵来识别出初始语料集合中的噪声语料，在对噪声语料处理后，可以减少目标语料中噪声语料所占的比例和歧义信息，使目标语料的边界更清晰，减少垂域模型的训练次数，进而减少训练所需要的计算资源和消耗时长，有利于提升训练效率。一种用于在语言材料降噪装置(要求保护)中对噪声语言数据进行降噪的方法。本发明能够减少垂直场模型的训练次数，从而减少训练所需的计算资源和消耗时间，提高训练效率。 该方法能够对训练后的语言数据和垂直场模型的分类精度提供高质量的训练，并在面向用户请求时提供高质量的语音服务。 通过标签的预测概率建立置信度矩阵，对目标语料集中的噪声语料的噪声，比例和模糊度信息进行处理后，由置信度矩阵识别出初始语料集中的噪声语言数据，可以降低目标语料集中噪声语料的比例和模糊度信息。该方法包括获得初始语料库集合的估计标签分布。 根据估计的标签分布获得置信度矩阵。 基于置信度矩阵获得初始语料库集合的噪声语言数据。 处理噪声语言数据的初始集以获得目标语料库集。本发明还涉及一种电子装置，包括一个存储器和一个处理器，用于对语言材料降噪装置中的噪声语言数据进行降噪； (b)计算机可读存储介质，用于在语言材料降噪装置中存储一组用于降噪噪声语言数据的指令。 3
本发明公开了一种基于医疗问诊对话的患者情感分析方法、系统及计算机设备，该方法包括：1)采集医疗问诊中患者的问句，进行预处理后形成文本数据集；2)构建数据集合，该数据集合中包括从患者的问句中提取的实体以及与实体关联的情感词；3)构建训练数据集，该训练数据集中，对于每一句话，均对应有其中的实体和实体的情感类别；4)基于bert模型，构建情感分类模型；5)利用情感分类模型对问句进行分析，得到问句中的所有实体的情感类别。本发明能够根据医疗问诊对话实现患者情感状态的自动分类，且本发明针对一句问话中存在多个实体以及多种情感状态的情况，能够实现患者对多个实体的情感状态的分别判断，拓展了其应用场景。一种用于基于医学诊断和诊断会话由计算机设备(要求保护)分析患者和情绪的方法。该方法能够根据医学诊断和诊断会话以及一句提问中多个实体和多个情感状态的情况，实现对患者情感状态的自动分类， 其能够分别对患者实体的情感状态进行了解，并实现应用场景的扩展，提高实际服务中的服务能力。该方法包括收集患者诊断的问题语句。 对文本数据集进行预处理以形成文本数据组。 处理所述文本数据组以获得数据组，其中所述数据组包括从所述提问语句中提取的实体和与所述实体相关联的情感词。 该数据组被手动处理以基于BERT模型来构造训练数据组。 得到情感分类模型。 在医学诊断中对问题患者进行分析，以获得问题句子中所有实体的情感类型。独立的权利要求书包括： (1)一种基于医学诊断和诊断会话的计算机设备分析患者和情绪的系统； 以及 (2)用于存储一组指令的存储介质，所述指令用于基于医学诊断和诊断会话由计算机设备分析患者和情绪的方法  10
本发明涉及一种评论文本分析处理方法，属于自然语言处理技术领域，解决了现有技术中模型对评论文本的内在联系和上下文表征学习不充分，方面级情感结构不完整，情感元素维度过少、输出文本非结构化、结果不直观的问题。通过预训练方法和微调方法获得的情感分析模型，学习到了评论文本的内在逻辑及上下文表征，将经过预处理的评论文本输入情感分析模型，能输出结构化的分析文本，为后期的量化和评估提供了更优化的信息。评论文本分析处理方法包括获取待分析的评论文本。 对所述待分析评论文本进行预处理。 将所述预处理文本输入情感分析模型，得到所述评论文本的分析结果。 所述情感分析模型通过如下方式训练得到。 对mT5模型进行预训练，得到训练后的模型。 通过输入掩码后的文本目标的原始文本输出训练得到模型Mpt。 情绪标注后获取微调任务数据集，对训练好的模型Mpt进行微调任务训练，得到情绪分析模型。  12
本发明提供了一种基于Transformer的代码编程语言分类方法，包括以下步骤：(1)从Stack Overflow上搜集问答帖子作为数据集，对原始数据集中的数据进行数据预处理；(2)对使用BPE分词后的数据进行词嵌入将词转换成向量；(3)基于上述构建的数据集，对RoBERTa模型进行微调，将生成的词向量输入进RoBERTa模型，通过双层的Transformer编码器进行代码语义的学习，生成语义表示向量Xsemantic；(4)将语义向量Xsemantic通过线性层映射到编程语言类别标签上，通过Softmax算法得到相应的编程语言。本发明的有益效果为：可以根据代码片段快速识别代码类型，以起到辅助开发人员在问答网站上快速寻找到解决方案的作用。基于变压器的代码编程语言分类方法本发明可以根据代码段快速识别代码类型，从而帮助开发者在问答网站上快速找到解决方案。该方法包括从POST获得代码段和代码的编程语言类型的标记。 对代码段进行滤波以获得数据集。 对数据集中的代码段执行分词。 将所述分词输入到层中以获得所述分词的特征向量。 基于所建立的数据集训练和微调预训练模型。 通过线性层得到语义向量。 语义向量通过SoftMax函数映射到编程语言类型标签的数据集，得到编程语言类型的最终分类。  12
本发明涉及自然语言处理、深度学习、多模态情感分析领域，涉及一种基于跨模态动态卷积的视频多模态情感识别方法、装置及计算机设备，所述方法包括使用ERNIE2.0预训练模型、DCCN、ResNet‑152和胶囊网络分别对文本、音频、图像提取出单模态低级特征；使用词对齐对三个模态特征进行对齐；采用双向GRU对上述特征进行处理，得到各模态高级特征；利用跨模态动态卷积对三个模态特征进行交互；拼接各个模态的跨模态交互特征和高级特征，并利用多头注意力机制融合；最后输入到softmax函数中得到情感识别结果；本发明很好的融合了各单模态特征，有效挖掘视频中所表达的情感信息，从而提升了多模态情感识别的准确率及效率。基于跨模态动态卷积的视频多模态情感识别方法该方法很好地融合了各个单模态特征，有效地挖掘了视频中表达的情感信息，因而，提高了多模态情感识别的准确率和效率。该方法包括获取(S1)视频中每个单个模态的主要特征。 对各单模态初级特征进行词级对齐(S2)，得到各单模态词对齐特征。 使用双向门控递归单元(GRU)网络(S3)分别对每个单峰词对齐特征进行预处理，得到每个单峰高级特征。 利用跨模态动态卷积(S4)对词对齐的文本特征、词对齐的音频特征、词对齐的图像特征进行多模态交互，得到六个跨模态交互对特征。 采用多头注意力机制(S5)，将六个跨模态交互对特征与每个单模态高级特征进行融合拼接，输入到softmax函数中，输出视频的情感识别结果。 所述GRU表示门循环单元，并且softmax表示归一化指数函数。独立权利要求包括如下：一种基于跨模态动态卷积的视频多模态情感识别的装置； 以及一种基于跨模态动态卷积的视频多模态情感识别的电子装置 9
本发明属于计算机领域自然语言处理，特别涉及一种面向信息安全领域的命名实体识别方法。包括以下步骤。S100～利用微调后的BERT中文模型对安全领域文本数据的三个维度进行表征，最终得到模型的输入向量。S200～采用BERT模型提取信息安全领域文本的特征编码表示。在多层Transformer的Encoder单元堆叠的基础上，采用多头注意力机制学习不同的子空间相关特征的表达，之后通过残差连接和归一化以及前馈神经网络，获取信息安全领域文本的特征编码表示，序列中每个字对应的字向量，都包含当前句子中其他字的特征。S300～采用条件随机场来提供额外的标签转移特征，获得标签序列之间的转移分数，选取转移分数最高的序列结果对应的实体类别。一种用于信息安全领域的命名实体识别方法。该方法获取文本的输入向量表示，包括词，位置和位置的多维向量特征，形成动态词向量，采用双向编码，更好地利用上下文语义。该方法包括(i)使用调谐的BERT中文模型分别在安全词向量中表示文本的三维； (ii)将所述词的位置信息编码为特征向量； (iii)使用BertModel来提取字段文本的信息安全的特征码表示，并使用多头注意机制来学习子空间相关特征的表示； (iv)获得信息安全字段中文本的特征码表示； 和(v)使用条件随机场提供附加的标签转移特性，获得标签序列之间的转移得分，并选择对应于实体类型的序列结果的最高转移得分。  12
本发明提供一种对话理解分析方法、装置及电子设备，包括：将获取到的与原始对话语句相关联的至少一个关联知识，以自然语言形式插入到原始对话语句中，构建知识句子树；基于预训练模型BERT对知识句子树和历史对话语句进行目标处理，目标处理包括：对知识句子树和历史对话语句分别进行编码，得到知识句子树对应的第一向量表示，以及历史对话语句对应的第二向量表示，并将第一向量表示和第二向量表示融合，得到融合向量表示；基于融合向量表示，分别通过意图识别任务、语义槽填充任务和关联知识识别任务各自对应的任务分支，确定原始对话语句的语义信息。旨在提供一种灵活性、准确性及泛用性较高的对话理解分析方法。用于理解和分析电子设备中的对话的方法(要求保护的)。该方法能够提供具有高灵活性、准确性和普适性的对话理解分析方法。该方法包括对知识句树和历史对话语句进行编码，得到第一向量表达式知识句树和历史对话语句对应的第二向量表达式。 将第一载体表达和第二载体表达组合以获得融合载体表达。 基于所述融合向量表示，通过任务分支确定原始对话语句的语义信息。 通过意图识别任务、语义凹槽填充任务和关联知识识别任务对应的任务分支确定所述原对话语句的语义信息。 利用所述语义槽填充任务对所述原始对话语句中的词元素进行标注。 关联知识识别任务用于识别关联知识。还包括用于对话理解分析装置的独立权利要求。 8
本公开涉及人工智能技术领域，尤其是一种应用于智能问答系统的问题检索方法、装置、设备及介质。该问题检索方法包括：利用关键词将用户输入问题在实时搜索引擎ElasticSearch(ES)数据库中进行粗匹配，检索出与用户输入问题相关的候选问题集；使用基于预训练语言模型(BERT)的文本嵌入模型将用户输入问题与该候选问题集中的各个候选问题进行精匹配，检索出与用户输入问题最相近的候选问题。本公开通过采用层次化检索策略，对用户输入问题分别进行粗匹配和精匹配，检索出与用户输入问题最相近的候选问题，并将其作为最佳回复输出，使得每一个用户输入问题均能精准匹配到最佳回复，显著提高了问题检索的准确性，解决现有智能问答系统存在的答非所问的问题。一种应用于智能问答系统的问题检索方法。该方法采用分层搜索策略对用户输入问题进行粗匹配和细匹配， 检索最接近用户输入问题的候选问题， 并作为最佳响应输出，使每个用户输入的问题与最佳响应准确匹配，大大提高了问题检索的准确性，解决了现有智能问答系统对未答案的问题。该方法包括使用(S1)关键字来粗略地匹配实时搜索引擎ES数据库中的用户输入问题，以检索与用户输入问题相关的一组候选问题。 使用基于预先训练的语言模型BERT的文本嵌入模型(S2)将用户输入问题与候选问题集中的每个候选问题精确地匹配，并且检索与用户输入问题最相似的候选问题。本发明还涉及一种应用于智能问答系统的问题检索装置。 (2)一种用于实现应用于智能问答系统的问题检索方法的计算机程序。  11
本发明特别涉及一种基于通道混合的编解码网络的医学图像分割方法，包括如下步骤：获取待分割的医学图像；将待分割的医学图像导入训练好的网络模型中进行识别得到分割后的医学图像；所述训练好的网络模型基础结构为对称U‑Net网络结构，且U‑Net网络结构中解码器部分的特征图由编码器中具有相同尺寸的特征图通过自注意力模块和最大上采样索引矩阵分别处理并融合后得到。本发明中提出的医学图像分割方法，大部分分割算法借鉴U‑Net的跳转连接，来融合不同尺度下的信息，从而指导信息传递的目的；与传统的算法不同的是，本方法提出了一种通道混合的自注意力模块来代替skip‑connect结构以及最大索引上采样来代替转置卷积，实现解码网络的特征上采样。基于通道混合编码器-解码器网络的医学图像分割方法。该方法提出了通道混合自注意力模块代替Skipp-connect结构和最大索引上采样代替转置卷积实现解码网络的特征上采样。该方法包括获取待分割医学图像，将所述待分割医学图像导入训练好的网络模型中进行识别得到分割医学图像，所述训练好的网络模型基本结构为对称的U-Net网络结构，通过自注意力模块和最大上采样指数矩阵分别对编码器中大小相同的特征图像进行处理和融合，得到U-Net网络结构中解码器部分的特征图。   6
本申请公开了一种领域外意图识别对话方法及装置，当第一识别结果为领域外意图时，可以通过训练后的大语言模型对任务型对话进行识别，从而可以获得回复内容，避免提前结束对话，从一方面提升了任务型对话的处理效率。同时，当第二识别结果为识别失败时，表示在任务型对话场景中出现了领域外意图，此时可以通过训练后的大语言模型对场景槽位的回答进行识别，从而获得第三识别结果。当第三识别结果为领域内意图时，则可以正常输出识别出的内容，当第三识别结果为领域外意图时，可以获得对应的回复内容。通过这种方式可以避免在任务对话场景过程中出现领域外意图时，提前结束对话，从另一方面提升了任务型对话的处理效率。利用域外意图识别对话的方法。避免在任务对话场景中出现域外意图时提前结束对话，另一方面提高了任务对话的处理效率。该方法涉及通过任务类型对话场景识别模型识别(S201)任务类型对话。 通过训练后的大语言模型对任务类型对话进行识别(S202)，得到第一识别结果为域外意图时的第一回复内容。 当第一识别结果是场内意图时，收集场景槽的答案(S203)。 在所述第二识别结果为识别失败时，通过所述训练后的大型语言模型对所述场景槽位的答案进行识别(S204)，得到第三识别结果。 当所述第三识别结果为所述域内意图时，输出所识别的意图和所述实体(S203)。 当所述第三识别结果为所述域外意图时，获取所述第二回复内容。独立权利要求包括以下内容：领域外部意图识别对话装置； 域外部意图识别对话装置； 以及存储有利用域外意图识别对话的程序的计算机存储介质。 8
本发明涉及一种基于BERT算法的网页广告营销文本识别方法及系统，所述一种基于BERT算法的网页广告营销文本识别方法包括：采集网页原始数据获取网页初始待识别文本集合；利用所述网页初始待识别文本集合获取网页广告营销文本识别结果，利用成熟的BERT算法进行合理计算，并通过广告营销文本的特征实现网页广告营销文本内容识别，进一步提升广告营销文本判断模型的准确性。本发明用于基于BERT算法的青少年健康网页广告营销文本识别。本发明通过对网页结构的网页内容进行分析和分离，准确提取出有效的网页广告营销文本，提高了广告营销信息判断模型的准确性。该方法包括收集网页的原始数据以获得网页的待识别的初始文本集。 网页初始待识别文本集用于获得网页广告营销文本识别结果。本发明还涉及一种基于BERT算法的网页广告营销文本识别系统。  12
本公开提供了模型训练方法和装置、电子设备以及计算机可读存储介质，涉及数据处理技术领域，尤其涉及智能工业、深度学习等人工智能、技术领域。具体实现方案为：获取应用场景对应的场景偏微分方程的场景源项函数、场景边界条件函数；根据所述场景源项函数、所述场景边界条件函数对预先训练的预训练模型进行微调，获取所述应用场景对应的场景模型；所述预训练模型的输入为偏微分方程的源项函数、偏微分方程的场景边界函数、以及偏微分方程的一个观测点的观测点坐标，输出为对偏微分方程的解函数预测的预测解函数。本公开可以减少模型的训练时间，提升模型的稳定性。用于智能工业、深度学习和人工智能中使用的训练模型的方法。 也可用于数据处理领域。该方法减少了模型的训练时间，有效提高了模型的稳定性。 该方法允许训练模块对预训练模型进行微调，以有效地提高偏微分方程的解函数预测的准确性，从而能够以准确的方式训练模型。该方法涉及从目标存储器获得(S110)与应用场景相对应的场景偏微分方程的场景源项函数。 获得对应于所述场景源事件函数的场景边界条件函数(S120)。 通过目标处理器对预训练模型进行预调谐，得到应用场景对应的场景模型。 向所述预训练模型的输入提供所述偏微分方程组的场景边界函数。 所述偏微分方程的场景边界函数和所述偏微分方程的一个观测点的观测点坐标。 输出是用于预测偏微分方程的解函数的预测解函数。包括以下独立权利要求：模型训练装置； 电子设备； 存储用于训练智能工业中的模型的程序的非暂态计算机可读存储介质； 以及用于在智能工业中使用的训练模型的计算机程序产品。 14
本发明提供了一种草图检索的数据处理方法。主要通过引入知识保持机制，在域损失函数、三元组损失函数、语义损失函数的基础上，额外增加构造了一个知识保持损失函数，以及利用上述所有损失函数进行训练，使得预训练模型在知识迁移过程中，既能够学习目标域的新知识，又能够保持从源域学习到的知识，从而提升草图检索的精度。用作草图检索的数据处理方法。该方法提高了草图搜索的精度。用于草图检索的数据处理方法，包括从源域获取图像分类器和与所述图像分类器对应的第一类别集合，所述第一类别集合包括所述图像分类器能够分类的所有类别，从目标域获取待处理数据，所述待处理数据包括图片、类别和用于指示所述图片为所述图片或所述草图的源标签，将类别属于所述第一类别集合的所述待处理数据划分为图像数据集合， 构建目标领域的图像编码器和目标领域的草图编码器，构建知识保留损失函数，根据第一分类结果和第二分类结果确定知识保留损失函数，根据源标签预测值和训练样本的源标签构建领域损失函数。  11
本发明公开了一种基于知识库反馈的生成式大语言模型的训练方法和装置，该方法利用领域知识库以及监督微调训练对大语言模型进行优化；采用基于知识库反馈的强化学习方法，利用领域知识库，构建奖励模型，对大语言模型生成的答案进行打分和反馈，构成了强化学习的流程。本发明的创新之处将知识图谱技术应用在奖励构建之中，从而可通过知识工程的自动化流程进行大语言模型微调，取代了基于人类反馈的强化学习，有利于节省大量人类反馈标注的高昂成本，基于确定性的知识推理得到领域应用的正确答案可修正生成式大语言模型捏造事实的关键缺陷，可使用在基于领域知识图谱构建行业垂直应用语言大模型的场景，适用性强。用于行业垂直应用语言大模型构建场景中的基于知识库反馈的语言大模型生成训练方法。该方法使得在奖励构建中应用知识图谱技术，从而可以通过知识工程的自动流程进行大型语言模型精调，取代了基于人为反馈的强化学习，有利于节省大量人为反馈标注的高额成本。 基于确定性知识推理得到的现场应用的正确答案可以修改生成的大型语言模型事实创建的关键缺陷，可以用于基于现场知识图谱的现场建筑行业的垂直应用语言大型模型的场景，适用性强。该方法包括在被构建到大型语言模型中的带标记的字段数据集中输入问题，所述大型语言模型具有所获取的监督和微调训练。 获取预测答案，并与标注数据集中的问题对应的期望答案一起构建问答对。 获取所述问答对所属的话题。 根据匹配的语义节点、预测答案和期望答案计算相似度。 基于得到的奖励模型输出的答案得分，利用强化学习中的近端策略优化模型对得到的监督微调训练后的大型语言模型进行训练，得到生成的大型语言模型。独立权利要求包括用于：(1)基于知识库反馈对生成的大型语言模型进行训练的装置； (2)一种计算机可读存储介质，包括用于基于知识库反馈训练所生成的大型语言模型的指令集。  11
提供用于训练和使用诸如完形填空语言模型等的基于能量的语言模型的系统和方法。特别地，本公开的一个方面涉及用于在文本上进行表示学习的基于能量的完形填空语言模型。在一些情况下，本文中提供的模型能够被称为“Electric”模型。类似于BERT模型，本文中提出的示例模型能够是给定其上下文的符号的条件生成模型。然而，本文中提出的示例模型不掩蔽文本或输出在可能在上下文中出现的符号上的完整分布。相反，示例提出的模型将标量能量分值分配到每个输入符号。本公开的另一方面提供用于训练提出的模型以使用基于噪声对比度估计的算法来将低能量分配到数据符号并且将高能量分配到其他数据符号的技术。训练计算机实现的机器学习语言模型，例如完全填充(cloze)语言模型，用于表示对文本的学习。该方法使得能够使用基于噪声对比度估计的算法来训练提出的模型以将低能量分配给数据符号，并将高能分配给其它数据符号。该方法包括从包括多个计算设备的计算系统获得包括多个正符号的原始语言输入。 计算系统产生多个噪声符号。 通过交换系统使用机器学习语言模型来处理含噪声的语言输入，以产生用于多个更新的输入符号的多个得分。 由计算系统基于多个得分为多个更新输入符号生成多个预测。 由机器学习语言模型生成的每个更新输入符号的预测预测是正符号或噪声符号。 基于多个预测损失函数来评估机器学习损失函数。还包括独立的权利要求： 计算系统； 以及 一个或多个非临时性计算机可读介质包括一组用于训练计算机实现的机器学习语言模型的指令。  12
本申请实施例公开了一种文本识别方法、装置及计算机可读存储介质，方法包括：获取目标非结构化文本，所述目标非结构化文本包括L个token和K个预定义的关系，L和K均为正整数；将所述目标非结构化文本输入到目标语言模型进行预测，得到预测结果，所述目标语言模型为针对预训练语言模型添加噪声进行扰动后得到的语言模型，所述预测结果包括实体与关系之间的至少一个三元组；按照预设的基于角标记的实体与关系的解码策略对所述预测结果进行解码，得到目标三元组；根据所述目标三元组确定与所述目标非结构化文本对应的目标结构化文本。采用本申请实施例能够提升文本结构化的精度。文本识别方法。 用途包括但不限于Android(RTM：基于Linux的操作系统)手机、iOS(RTM：苹果公司开发的移动操作系统)手机、Windows(RTM：微软公司开发的图形操作系统)手机、平板电脑、掌上电脑、行车记录仪、服务器、笔记本电脑、智能手表以及蓝牙耳机等。可以提高文本结构化的精度。 模型可以陷入局部最优，简化实体和关系提取过程，因此减少微调过程中的问题。 可以根据目标三元组确定与目标非结构化文本对应的目标结构化文本，因而提高了文本识别过程的精度。该方法涉及获得(101)目标非结构化文本。 所述目标结构化文本设置有L个令牌和K个预定义关系。 所述L和K为正整数。 将所述目标非结构化文本输入(102)至目标语言模型进行预测，得到预测结果。 根据预设的基于实体和角标关系的解码策略对所述预测结果进行解码(103)，得到所述目标三元组。 根据所述目标三元组确定(104)所述目标非结构化文本对应的目标结构化文本。包括以下独立权利要求：(1)文本识别装置； (2)电子设备； 以及(3)存储用于文本识别的计算机程序的计算机可读存储介质。  11
本申请涉及自然语言处理领域，具体公开了一种文本分类方法、装置、设备及存储介质。该文本分类方法包括：获取通话数据，将通话数据分割为客户的第一通话数据和坐席的第二通话数据，第一通话数据和第二通话数据包括时间标签；在BERT语言模型中对第一通话数据和第二通话数据进行向量化编码，得到包括标记向量的第一表征矩阵以及第二表征矩阵；在全连接神经网络模型中根据标记向量对第一表征矩阵和第二表征矩阵进行融合处理，得到第一表征矩阵对应的第一目标向量以及第二表征矩阵对应的第二目标向量；根据第一目标向量确定第一通话数据的分类标签，根据第二目标向量确定第二通话数据的分类标签。这样，提高了文本分类的准确性。文本分类方法。该方法能够使用用户和座位的前后语义信息来关联和分析计算机中的客户机和座位的交互信息，以校正分类结果，从而提高文本分类结果的准确性。该方法包括获得(S101)客户机和座席的呼叫数据。 第一呼叫数据和第二呼叫数据被输入(S102)到预先训练的文本分类模型。 文本分类模型包括BertLanguage模型和全连接神经网络模型。 获得第一表示矩阵和第二表示矩阵。 第一表示矩阵和第二表示矩阵包括与时间标签相对应的标记向量。 获得对应于第一表示矩阵的第一目标向量和对应于第二表示矩阵的第二目标向量。 根据第一目标向量确定(S103)第一通信数据的分类标签。 根据第二目标向量确定第二通信数据的分类标签。本发明还涉及一种文本分类装置。 (2)计算机设备； 和(3)存储用于分类文本的程序的计算机可读存储介质。  11
一种基于卷积神经网络的人脸识别场景适应的方法，包括：1)收集人脸数据并做好分类标签，对数据做预处理和增强，分成训练集和验证集；2)将训练集数据送入设计好的卷积神经网络进行训练，得到预训练模型；3)用验证集数据测试预训练模型，根据测试结果调整训练参数重新训练；4)重复3)获得最佳预训练模型；5)根据不同应用场景收集人脸图像数据，在新收集的数据上微调预训练模型，得到新的适应场景的模型；6)用适应场景模型对待测试人脸图像提取特征，对特征中人脸五官部分做加权操作，得到最终特征向量；7)用余弦距离度量最终特征向量，判断是否是目标人脸，输出结果。本发明的优点：保证了人脸识别的准确性及模型的场景适应性。基于卷积神经网络的人脸识别场景自适应方法。该方法能够保证人脸识别的准确性和模型的场景适应性。该方法包括采集人脸图像数据和分类标签。 对所述人脸图像数据进行预处理。 建立预训练模型。 预训练模型分为训练集和验证集。 训练集数据被传输到卷积神经网络。 建立最优预训练模型。 采集所述人脸图像数据。 建立自适应场景模型。 利用余弦距离测量得到最终的特征向量。 判断人脸图像是否为目标人脸。 输出结果。   4
本发明公开了一种基于自适应参数更新的终身情感分类方法，所属技术领域为参数更新，包括：获取通用情感分类数据集，对所述通用情感分类数据集进行随机抽取，获得情感分类数据集；基于BERT模型构建情感分类器，通过所述情感分类数据集对所述情感分类器依次进行训练，并对训练后的分类器进行迭代网络剪枝和自适应参数更新，获得终身情感分类器；通过所述终身情感分类器对情感进行分类。为了保证模型的稳定性和可塑性，本发明使用两阶段的模型参数更新策略，在终身学习的背景下充分利用了已学习过的知识帮助新任务的学习，并防止知识遗忘。基于自适应参数更新的终生情感分类的方法。该方法保证了模型的稳定性和可塑性，采用两阶段的模型参数更新策略，在终身学习的背景下充分利用学习到的知识帮助新任务的学习，防止知识遗忘。该方法包括获取通用情感分类数据集，随机抽取通用情感分类数据集，得到情感分类数据集。 基于所述BERT模型构建情感分类器，通过情感分类数据集依次训练情感分类器，并对训练后的分类器进行迭代网络剪枝和自适应参数更新，得到终身情感分类器。 通过寿命情感分类器对情感进行分类。  12
本发明公布了一种大语言模型软硬件协同量化加速计算方法及系统，采用以通道为粒度处理大语言模型中的离群值，将存在大量离群值的通道整体以高精度进行存储，通过自适应量化过程、编译优化过程和硬件实现过程，实现大语言模型软硬件协同推理加速，保证了数据编码的灵活性和规整性，同时易于在系统和硬件上进行实现和部署；可重构加速器系统包括：运算模块、累加模块、解码模块、控制模块、片上缓存和主存。采用本发明，既能够有效保持量化后模型的精度，又能实现硬件高效的推理计算。在机器翻译、内容摘要和情感分析等多种下游应用场景中使用的计算系统(要求保护)中计算大型语言模型软硬件协同量化加速的方法。该方法能够实现大型语言模型的软硬件协同推理加速，有效保证数据编码的灵活性和规律性，实现硬件的高效推理计算。该方法包括为大型语言模型的每个线性层设置异常值通道和正常通道的数据精度。 基于总的线性layeroutlier通道集合和数据精度计算当前计算系统主存引起的额外存储开销。 将当前线性层模型的权重张量数据块从片上缓存预先加载到计算系统的运算模块中。 正常输入激活信道子数据块从缓存加载到运算模块。 累加单元将输出的激活数据阻塞结果累加到片上缓存的相应位置。 激活的张量从计算系统的片上缓存输出，以写回主存储器。独立权利要求还包括用于实现所述大语言模型软硬件协同量化加速计算过程的计算系统。  11
本申请涉及变电站运维技术领域，公开了一种变电设备运维辅助决策方法，依如下步骤实施：S1：定义变电设备健康指数SI，将变电设备健康状态划分为多个状态等级；S2：采用长短期记忆神经网络(LSTM)计算设备健康系数SInum；S3：采用Bert‑BiLSTM神经网络计算设备健康系数SItext；S4：计算变电设备健康指数临界值，针对变电设备各健康状态等级制定相应的运维策略；S5：将欲进行运维辅助决策的变电设备的结构化数据和非结构化文本数据分别作为训练完成的LSTM神经网络和Bert‑BiLSTM神经网络模型的输入，计算变电设备健康指数，为变电设备运维提供辅助决策。该一种变电设备运维辅助决策方法，解决了现有变电设备运维策略无法依据变电设备的运行状态进行精确感知和准确评估的问题。基于数据和知识双驱动的变电站设备运维辅助决策方法。该方法解决了现有针对变电设备的运维策略无法根据变电设备的运行状态进行准确感知和评估的问题。该方法涉及定义(S1)变电站设备健康指数。 使用长短期记忆(LSTM)神经网络计算设备健康系数(S2)。 采用Bert-双向LSTM(BiLSTM)神经网络(S3)计算设备健康系数。 计算所述变电站设备的健康指标临界值(S4)。 针对变电站设备的各个健康状态等级制定相应的运维策略。 将待用于运维辅助决策的变电站设备的结构化数据和非结构化文本数据分别作为(S5)训练好的LSTM神经网络和BertBiLSTM神经网络模型的输入。 计算变电站设备健康指数，为变电站设备运维提供辅助决策。 0
本申请公开了一种数据增强方法、系统、存储介质及电子设备，数据增强方法包括：输入步骤：获取待处理数据，将所述待处理数据复制两份输入到Bert模型；模型处理步骤：通过所述Bert模型对所述待处理数据进行处理，获得处理结果；预测步骤：所述Bert模型对所述处理结果进行计算，获得预测结果；模型构建步骤：在基础的NER模型上采用Bert序列构建Bert模型；特征提取步骤：通过所述Bert模型对所述待处理数据进行特征提取获得特征数据。本发明在有限的标注数据上实现了数据增强，在实际应用当中有效的提高了美妆实体识别的精确率和召回率；本发明的数据增强的方法完全没有引入额外的数据或者标注工作，真正实现了低成本和高效率。美容领域电子商务(e-commerce)和社区共享网站数据增强的方法。该方法实现了对有限标注数据的数据增强，有效提高了实际应用中化妆品实体识别的查准率和召回率。 该数据增强方法完全不引入额外的数据或标注工作，真正实现了低成本、高效率。该方法包括获得(S1)待处理的数据。 将待处理数据的两份拷贝并输入到Bert模型中。 通过所述Bert模型对所述待处理数据进行处理(S2)，以获得处理结果。 Bert模型计算(S3)处理结果以获得预测结果。 该Bert序列用于在基本命名实体识别(NER)模型上建立Bert模型。以下包括独立权利要求：用于数据增强的系统； 用于数据增强的电子设备； 以及存储用于数据增强的程序的存储介质。  12
本申请提供一种图文生成模型优化方法、生成方法、装置、设备及介质，涉及人工智能技术领域。该图文生成模型优化方法包括：获取正向样本数据集和负向样本数据集，正向样本数据集包括：正向样本图像和正向样本图像的正向样本文本，负向样本数据集中包括：负向样本图像和负向样本图像的负向样本文本；负向样本文本包括：正向样本文本以及样本形变文本，样本形变文本指示负向样本图像相对于正向样本图像的形变信息；采用正向图文对和负向图文对对图文生成预训练模型中图像分割网络的网络参数调整，得到目标图文生成模型。本申请可以降低文本转换图像发生形变、崩坏的可能性，提高文本转换图像的效果。用于优化用于人工智能领域的图文生成模型的方法。该方法能够降低文本转换图像发生形变和倒塌的可能性，提高文本转换图像的效果。所述方法包括：获取正向样本数据集和负向样本数据集，所述正向样本数据集包括正向样本图像和所述正向样本图像的正向样本文本组成正向图像文本对，所述负向样本数据集包括负向样本图像和负向样本文本对。 利用前向图文对和负向图文对，对预先训练的图文生成预训练模型中的图像分割网络的网络参数进行调整，得到目标图文生成模型。 通过所述目标图文生成模型根据所述描述文本生成与所述描述文本对应的图像。独立权利要求包括用于：(1)一种图文生成方法； (2)图文生成模型优化装置； (3)图文生成装置; (4)一种电子设备，包括存储器和处理器，所述处理器执行存储在所述存储器中的指令，以优化用于人工智能领域的图文生成模型； (5)一种计算机可读存储介质，其存储了一组用于优化在人工智能领域中使用的图文生成模型的指令。 14
本申请公开了一种静态网页的生成方法、生成装置、电子设备及存储介质。该方法包括：利用预训练的静态网页生成模型处理初始静态网页源代码以及接收到的自然语言文本描述指令，输出静态网页；重复执行将所述静态网页以及新接收到的自然语言文本描述指令输入所述静态网页生成模型中得到更新后的静态网页，直至不再接收到新的自然语言文本描述指令为止，得到最终的静态网页；其中，所述静态网页生成模型为基于Transformer的模型。本申请实施例提供的静态网页的生成方法，能够根据自然语言指令生成静态网页，利用基于Seq2Seq的模型将自然语言指令转换成静态网页，能够快速、低成本地自动生成静态网页，自动化程度高，降低了工作量，提高了工作效率。生成静态网页的方法。生成静态网页的过程简单，自动化程度高，提高了专业人员的开发效率，减少了工作量，提高了工作效率。该方法涉及利用(S10)预先训练的静态网页生成模型对初始静态页面源代码和接收到的自然语言文本描述指令进行处理，以输出静态页面。 重复执行所述静态页面(S20)并将接收到的新的自然语言描述指令重复输入所述静态页面生成模型以获得更新的静态页面，直至不再接收到所述新的自然语言描述指令。 获取所述静态网页的最终静态页面。 将所述静态网页和新接收到的自然语言文本描述指令输入所述静态网页生成模型。 获取更新后的静态网页。独立权利要求包括以下用于生成静态网页的装置； 以及存储用于生成静态网页的程序的计算机可读存储介质。  11
本申请实施例公开了一种商户名称的标注方法、装置、设备及存储介质，属于自然语言处理技术领域。该方法包括：获取样本文本；利用样本文本对第一文本标注模型进行预训练；对训练完成的第一文本标注模型进行知识蒸馏，得到第二文本标注模型。本申请实施例利用第二文本标注模型对商户名称进行自动化标注，提升了对商户名称的标注效率，只需人工标注少量的商户名称，减少了人工标注成本；并且，先利用样本文本对结构复杂但精度较高的第一文本标注模型进行训练，再对训练完成的第一文本标注模型进行知识蒸馏得到结构简单的第二文本标注模型，得到具有复杂模型推理能力的简单模型，便于应用阶段模型的部署，且能够节省商户名称标注时的计算资源。一种标记商家名称的方法，用于自然语言处理技术领域。本发明能够利用文本标注模型自动标注商家名称，提高商家名称标注效率，降低人工标注成本。 本发明能够使样本文本训练出结构复杂，精度高的文本标注模型，并对模型进行知识蒸馏，得到模型推理能力强的简单模型，在标注目标商家名称时节省了计算资源。所述方法涉及获得样本文本(101)，其中所述样本文本是携带有样本标签的商家名称。 所述样本标签是通过手动地预标记所述样本文本而获得的，其中所述样本标签用于表示所述样本文本的商家类型。 通过使用样本文本来预训练(102)第一文本标签模型。 识别对应于商家名称的商家类别。 对第一文本标签模型执行(103)知识蒸馏。 获得第二文本标签模型，其中第二文本标签模型的模型复杂度小于第一文本标签模型的模型复杂度。本发明还涉及一种用于标记商家名称的装置； (2)一种计算机设备，包括存储器和处理器，所述处理器存储用于标记商家名称的一组指令； (3)计算机可读存储介质，其存储用于标记商家名称的一组指令。  11
本发明公开了一种慕课的课程概念抽取方法，应用于慕课视频字幕课程概念抽取模型，所述慕课视频字幕课程概念抽取模型包括BERT编码模块、词性表示模块、词汇表示模块、全局信息融合模块、标签解码模块。相比于普通通用实体的领域特性，本发明引入词性特征，能更好地学习到课程概念实体的词性组成方式，本发明引入了词汇信息帮助实体边界的识别，且控制词汇的权重贡献，能够在尽可能避免复杂化模型架构的情况下，更简单高效地将词汇信息融入字符表示清楚，本发明利用注意力机制引入视频字幕文档级别的上下文全局信息，最终能够有效提升课程概念抽取的效果。一种利用课程类别的视频字幕课程的概念提取模型提取大规模开放在线课程(MOOC)的概念的方法。所述方法使得能够引入词汇信息以帮助实体边界的识别， 并控制词汇的权重贡献，避免了模型架构的复杂化，利用注意力机制引入视频字幕文件级别的上下文全局信息，最终有效地提高了课程概念提取的效果。该方法包括通过BERT编码模块将输入句子中的最终字符从变换器(BERT)矢量表示转换成双向编码器表示。 通过一段语音表示模块对所述输入语句进行分词处理。 通过词汇表不模块对所述输入语句中的字符进行处理。 全局信息融合模块利用第一层双向长短期记忆(BiLSTM)，基于字符表示对字符之间的依赖关系进行建模，得到融合词先验知识的向量表示和句子中的局部信息。 通过注意力机制得到句子上下文全局信息的向量表示。 标签解码模块根据最终向量输出状态得分。 将得分最大的结果作为输出标签序列，提取句子中的课程概念。 9
本发明公开了一种基于大语言模型的错题分析及试题推荐系统和方法，属于在线教育和自然语言处理技术领域，包括：获取学生做题的历史数据整合得到答题数据，将答题数据和人为给定的答题指令输入智能算法得到指令数据；指令数据作为训练数据，采用LoRA方案对大语言模型ChatGLM‑6B进行指令微调，经过优化器优化，得到训练好的错题分析模型，将答题数据输入训练好的错题分析模型得到错题分析结果；试题推荐模型，采用DINA算法和基于内容的协同过滤算法得到个性化习题，与错题分析结果一起发送给学生。本发明能够实现文字类全题型的在线错题分析，辅助教师进行教学，并为学生提供更具个性化、交互性好的试题推荐系统。应用于在线教育和自然语言处理的基于大语言模型的错题分析和试题推荐系统。该系统实现了人物全题类型的在线错题分析，辅助教师授课，为学生提供更个性化、更好互动的试题推荐系统。该系统具有错题分析模块，该错题分析模块被提供用于使用指令数据微调ChatGLM模型以构建错题分析模型，以获得训练的错题分析模型。 将所述答案数据输入训练后的错题分析模型，得到所述错题分析结果。 提供试题推荐模块，对所述错题分析结果进行分析，得到第一知识点集合。 对学生根据一个DINA算法未进行过信息的知识点集合2进行并集，得到知识点列表。 基于所述知识点列表在资源库中检索所述相关试题。 提供一种基于内容的协同过滤算法，对相关试题进行过滤，得到个性化试题，与错题分析结果一起发送给学生。独立权利要求包括用于：(1)一种基于大语言模型的错题分析和试题推荐方法； (2)一种基于大语言模型的错题分析及试题推荐装置； 以及(3)计算机可读存储介质，其存储有用于进行错题分析和试题推荐的程序。  11
本申请公开了一种数据分析预警系统及方法，其通过采集预定时间周期内的销售额，并在后端引入数据处理和分析算法来进行销售额的时序分析，然后，利用生成式人工智能(AIGC)技术来进行销售额的预测，并基于预测结果来判断是否需要发出预警信号。这样，能够对销售额数据进行监测、预测和预警，帮助决策者及时做出相应的决策来解决解决潜在的问题，从而提高企业的竞争力和应对风险的能力。销售时序数据分析预警系统。该系统能够对销售数据进行监测、预测和预警并帮助决策者及时做出相应的决策，解决潜在的问题从而提高企业的竞争力和应对风险的能力。所述系统(300)具有销售收集模块(310)，用于获取预设时间段内的销售时间序列。 销售时序排列模块(320)，根据所述时间维度对所述销售时序进行排列，得到所述销售时序输入向量。 销售第二尺度时序特征提取模块(330)，通过销售第二时序尺度特征提取器基于第二深度神经网络模型对销售时序输入向量进行特征提取，得到所述第二尺度销售时序特征向量。 销售多尺度时序特征融合模块(440)融合两个尺度销售时序特征向量，得到多尺度销售时序特征。 销售预测预警模块，基于所述多尺度销售时序特征确定销售预测值。 所述销售预测预警模块判断是否需要传输预警信号。包括独立权利要求的一种销售时序数据分析预警方法。  11
本申请提供一种通话内容识别模型训练方法、装置、电子设备及存储介质，涉及人工智能领域，用以解决现有技术中记录网络产品信息效率低的问题。该方法包括：获取多个正样本以及多个负样本；一个正样本包括一个样本用户的通话文本以及样本用户的已订购产品信息；一个负样本包括一个样本用户的通话文本以及样本用户的未订购产品信息；正样本对应的标签为真，负样本对应的标签为假；基于各正样本、各正样本对应的标签、各负样本、各负样本对应的标签以及目标损失函数，对预训练语言模型BERT进行训练，得到通话内容识别模型；通话内容识别模型用于识别通话内容中的产品信息。训练通话内容识别模型的方法。该通话内容识别模型训练方法包括获取多个正样本和多个负样本，其中，基于每个正样本训练出预先训练的语言模型BERT，从而能够解决现有技术中记录网络产品信息效率低下的问题。该方法涉及获得(S201)多个正样本和多个负样本。 正样本包括样本用户谈话文本和样本用户订购商品信息。 负样本包括样本用户的会话文本和无序样本用户的商品信息。 基于来自基于正样本、负样本、标签和标签的目标损失函数的变换器(BERT)的预训练语言模型双向编码器表示来训练(S202)呼叫内容识别模型。 获取第一样本用户的第一会话文本。 根据所述第一会话文本确定所述第一样本用户的第一商品订阅列表。包括独立权利要求，用于：(1)通话内容识别模型的训练装置； (2)一种电子设备，包括存储器和处理器，以执行一种通话内容识别模型的训练方法； (3)一种计算机可读存储介质，包括一组程序，以执行通话内容识别模型的训练方法。 8
本发明涉及一种基于预训练模型的抽取生成摘要方法，属于文本处理领域。该方法包括以下步骤：步骤一：分词器分词；步骤二：关键信息的提取；在进行分词后需要从中抽取出关键信息来构造伪摘要，通过伪摘要作为预训练的目标，让预训练模型学习预测伪摘要，与下游的摘要任务吻合来提升性能；步骤三：将新源文本和伪摘要输入到的T5模型中进行预训练，通过自注意力机制计算分数，来预测伪摘要达到预训练的目的。通过使用预训练模型，在摘要的效果上得到较大的提升，并且由于使用大量的文本进行训练，在下游任务中即使是很小的有标签数据也可以有相当的效果，在某些数据缺乏的情况下也可以得到好的预测结果。基于预训练模型提取和生成摘要的方法。本发明通过使用预训练模型，大大提高了采摘的效果，得到了更好的预测结果。该方法包括通过分词装置进行文本分词。 在线索分词的基础上划分字符粒度。 进行分词后提取关键信息，构建伪摘要。 构建预训练模型对所述伪摘要进行预测，并与下游摘要任务进行匹配。 将当前源文本和伪摘要输入到模型中进行预训练，通过自注意力机制计算得分，并对伪摘要进行预测，达到预训练过程的目的。 在文档中遍历句子，并将该句子添加到空集中。 计算具有文档剩余句子的分数。  11
本发明公开了一种基于增量学习的目标检测方法，包括获取原始目标检测初始模型；对原始目标检测初始模型的特征提取器部分参数进行预训练得到通用的目标检测特征提取器；采用检测头和参数掩码对目标检测特征提取器进行结构扩展得到扩展目标检测模型：采用扩展目标检测模型进行实际的目标检测。本发明还公开了一种包括所述基于增量学习的目标检测方法的自动驾驶方法。本发明提供的这种基于增量学习的目标检测方法及自动驾驶方法，创新性的提出了一种新的增量学习目标检测方法；通过检测头技术和掩码技术的创新性加入，不仅实现了增量学习目标检测，而且准确性高、可靠性高且实用性好。用于计算机图像处理领域的基于增量学习的目标检测方法。该目标检测方法基于增量学习，准确率高，可靠性高，实用性好。 加入了检测头技术和掩模技术，不仅实现了增量学习目标检测，而且准确率高，可靠性高。该方法涉及在目标检测特征提取器中对预训练参数添加参数掩码和独立检测头，得到扩展检测模型。 转发所述训练数据集上的扩展检测模型，计算误差损失函数。 更新检测头参数和参数掩码的值。 训练完成，保存参数。 检测时由检测头对参数掩码过滤后的特征进行相应的目标检测。 提供扩展目标检测模型以进行实际目标检测。包括独立权利要求，用于包括所述基于增量学习的目标检测方法的自动驾驶方法。 14
本发明公开了一种用于制丝车间的在线检测方法、装置、系统和存储介质，其中，所述用于制丝车间的在线检测方法包括：获取车间内不同监测区域的监测信息；若所述监测信息表征至少一个所述监测区域存在异常情况，基于预训练模型生成与所述异常情况相匹配的处理策略；控制显示设备展示所述异常情况和所述处理策略。本发明通过对车间不同区域进行监测信息采集，实现了大范围监测，并基于当前的异常情况智能化推荐匹配的处理策略，降低了对人力资源的依赖以及检修人员的水平门槛，提高了对异常情况的处理效率。一种制丝车间在线检测方法。该方法通过采集车间不同区域的监控信息，实现大范围监控，并根据当前异常情况智能推荐匹配的处理策略，减少了对人力资源的依赖和维修人员的水平门槛，提高了异常情况的处理效率。在线检测方法涉及到获取车间内不同监测区域的监测信息。 若所述监控信息指示其中一个监控区域存在异常，则基于预先训练的模型生成与所述异常匹配的处理策略，并控制显示装置显示所述异常和所述处理策略。 调整长焦相机，以调整拍摄角度，实时获取车间内不同监控区域的监控信息。独立权利要求书包括用于：(1)一种制丝车间在线检测装置； (2)一种制丝车间在线检测系统； (3)一种计算机可读存储介质，其具有计算机程序。 13
本发明提供了一种基于数据增强的降噪模型压缩方法及装置，其中方法包括：获取预设的初始Teacher模型；获取带噪的训练语音，以及获取所述带噪的训练语音对应的纯净语音；基于所述带噪的训练语音和所述纯净语音，对所述初始Teacher模型进行训练，待所述初始Teacher模型训练收敛后作为最终Teacher模型；获取预设的初始Student模型；获取实际采集的带噪实际语音；基于所述带噪的训练语音、最终Teacher模型和所述带噪实际语音对所述初始Student模型进行训练，待所述初始Student模型训练收敛后作为最终Student模型。本发明在保证降噪性能几乎不变的前提下，尽可能压缩模型的参数量，从而使降噪模型在压缩模型的同时，还能保证在实际场景运用中降噪性能不变。用于压缩基于数据增强的降噪模型的方法。该方法在保证降噪性能几乎不变的前提下对模型的参数量进行压缩并对在实际场景应用中保证降噪性能不变的模型进行压缩。该方法涉及获得预设初始教师模型和噪声训练语音到纯净语音。 基于所述含噪训练语音和所述初始教师模型训练收敛后的纯净语音训练初始教师模型，将其用作最终教师模型。 初步集合获得初始学生模型。 获取实际采集到的含噪实际语音。 基于所述含噪训练语音、所述含噪实际语音和所述最终教师模型训练初始学生模型。 一个初始学生模型被训练并收敛为一个初始学生模型的最终学生模型。包括独立权利要求用于一种基于数据增强的降噪模型压缩装置。 3
本申请公开了一种文本匹配方法、装置、设备及存储介质，所述方法包括：在进行文本匹配时，先将待匹配文本输入至预训练模型中，得到待匹配文本对应的第一向量表示，并根据待匹配文本中词汇之间的依存关系，确定的待匹配文本对应的第二向量表示，再结合第一向量和第二向量表示共同确定待匹配文本对应的目标向量表示，充分考虑到了待匹配文本中词汇之间的依存关系，提高了用于描述待匹配文本的向量表示的准确度；这样再根据准确度较高的目标向量表示，确定待匹配文本的匹配结果，提高了文本匹配结果的准确度。文本匹配方法。本发明能够提高描述待匹配文本的向量表示的准确性，并根据目标向量表示确定待匹配文本的匹配结果，从而提高文本匹配结果的准确性。该方法包括将待匹配文本输入到预训练模型中以获得与待匹配文本相对应的第一矢量表示。 根据待匹配文本中的词之间的依赖关系，确定与待匹配文本对应的第二向量表示。 根据第一向量表示和第二向量表示确定与待匹配文本对应的目标向量表示。 根据目标向量表示确定待匹配文本的匹配结果。独立的权利要求书被包括在以下内容中： 文本匹配装置； 一种电子设备，包括存储器和处理器，用于执行一组用于匹配文本的指令； 用于存储一组用于匹配文本的指令的计算机可读存储介质； 以及 一种计算机程序产品，包括一组用于匹配文本的指令。  12
本发明提供一种基于知识图谱与大语言模型的烟草企业智能信息问答方法，包括：构建知识图谱、存储知识图谱以及利用知识图谱对用户咨询信息进行答复处理。本发明利用GPT语言模型，充分利用生成式语言模型有效的语义感知与较强的特征学习能力，能够有效地抽取流程条款中的实体‑关系。利用图数据库优异的顶点‑边的多级跳跃能力检索关键知识点，结合遗传算法自动生成提示词，通过GPT语言模型强大的上下文学习能力，生成符合逻辑、答案准确的自然语言回复信息。相比其他方法，本发明不需要重新训练或微调模型，大大减少了计算开销，降低了开发难度与成本，促进人工智能技术的产业落地与快速迭代。基于知识图谱和大语言模型的烟草企业智能信息问答方法。该方法能够利用GPT语言模型，充分利用生成语言模型的有效语义感知和较强的特征学习能力，有效提取流项中的实体-关系，避免需要对模型进行重新训练或微调整，降低了计算成本和开发难度和成本，促进人工智能技术的产业化落地和快速迭代。该方法以生成式预训练变换器(GPT)语言模型为主体网络结构。 结合注意力机制计算每个实体的权重，用于预测实体-关系的三元组概率分布，以进行实体识别和关系分类。 实现实体-关系联合抽取，用于最终构建知识图谱。 采用NebulaGraph图数据库对所述知识图谱进行分布式存储。 对用户咨询信息进行回复处理。 首先利用地图数据库的多级跳转的信息检索能力进行知识计算和推理，用于输出中间结果。 基于遗传算法和GPT语言模型自动生成提示词。 最终生成自然语言回复信息。独立权利要求包括用于：(1)基于知识图谱和大语言模型的烟草企业智能信息问答装置； 以及(2)一种计算机可读存储介质，所述计算机可读存储介质包括用于存储由处理器执行的程序的指令集，以实现基于知识图谱和大语言模型的烟草企业智能信息问答过程。  11
本发明公开了一种对话生成系统及对话实现方法，本发明实施例设置的对话生成系统采用encoder‑decoder结构的神经网络，在编码层中采用分别针对字符级及词语级的双编码层，且将经过该双编码层编码后的信息进行联合。在编码层对包含对话目标、相关知识信息及对话序列的数据集进行编码之前，分别针对字符级的编码层及针对词语级的编码层进行数据集的重构后，再输入到对话生成系统中的双编码层分别编码及联合后，再输入给解码层，由解码层使用transformer模型根据联合后的数据集信息生成相应对话回复。这样，本发明提高生成的相应对话回复的准确性及流畅性。用于对话生成的系统。该系统提高了生成的相应对话回复的准确性和流畅性。所述系统具有所述数据集预处理单元，所述数据集预处理单元针对字符级编码层和单词级编码层重构包含对话目标、相关知识信息和对话序列的数据集。 数据集预处理单元将数据集输出到双编码层单元，双编码层单元包括字符级编码层和单词级编码层。 字符级编码层对接收到的重构字符级数据集进行编码，单词级编码层对接收到的数据进行重新编码。 将所述编码字符级数据集和所述词语级数据集合并，对所述结构化词语级数据集进行编码后输入所述解码单元。 解码层单元接收组合数据集。 解码层单元对数据集进行解码，得到目的地、知识和历史对话信息并生成相应的回复。还包括一种用于对话实现的方法的独立权利要求。 8
本发明公开了一种应用区块链改善基础大模型处理专业问题的方法、系统、设备及介质，涉及信息技术领域；其中，方法包括：获取用户指令，根据用户指令匹配任务类型；根据任务类型将用户指令划分成多个子任务，并将子任务置于任务队列池；从任务队列池中依次提取子任务，在区块链数据库中获取子任务关联的工具集，并根据工具集执行子任务，生成任务执行结果；判断每一任务执行结果是否符合预期，若不符合预期则重新生成任务，若符合预期则执行下一子任务；当完成所有子任务并评估符合预设条件后，输出应答结果。解决了现有技术中大语言模型，针对特定领域决策存在局限性的问题。通过使用基于区块链数据库垂直应用的模型训练系统(索赔)应用区块链改进基础大模型处理专业问题的方法。该方法能够实现准确的数据支持，提高问题的解决效率和适用性。该方法涉及获取用户指令，并根据用户指令匹配任务类型。 将用户指令按照任务类型划分为多个子任务。 将所述子任务置于任务队列池中。 从任务队列中依次提取子请求。 在区块链数据库中获取与所述子ASK相关联的工具集。 根据工具集生成任务执行结果。 区块链数据库设置有多个数据节点。 将数据节点与不同类型的子任务关联的工具集进行匹配。 当所述子任务完成且评价满足预设条件时，输出响应结果。独立权利要求包括用于：(1)基于区块链数据库垂直应用的模型训练系统； (2)一种计算机设备，包括处理器和存储器，用于执行一组应用区块链改进基础大模型处理专业问题的指令； (3)一种计算机可读存储介质，用于存储应用区块链改进基础大模型处理专业问题的一组指令。  11
本发明公开一种信息提取方法、电子设备和存储介质，其中方法包括：将多轮对话的对话文本切分为至少一个片段，每一个片段包括多个句子；利用预训练模型网络分别提取所述多个句子的语义向量；基于每一片段中的多个句子的语义向量确定所述多个句子中句子与句子之间的关联关系；将句子的关联向量和字向量融合后，判断该字是否是实体的开始和结束。本发明实施例通过将对话文本切分为包含多个句子的片段后提取多个句子的语义向量，根据多个句子的语义向量来确定句子与句子之间的关联关系，可以解决由于对话的轮数可能很长，几十到上千句，长度相差太大统一处理会导致模型的计算需求很高的问题。提取句子信息的方法解决了模型计算要求很高的问题。该方法包括将多轮对话的对话文本划分(101)为至少一个片段，其中每个片段包括多个句子。 通过使用预训练模型网络来提取(102)句子的语义向量。 基于每个片段中的多个句子的语义向量来确定句子和句子之间的关联关系(103)。 实体提取具有实体类型标识和实体值提取。本发明还涉及一种电子设备。 以及存储用于提取信息的程序的存储介质。  12
本发明涉及计算机视觉处理技术领域，具体为一种基于轻量化网络的违规停车识别方法，包括以下步骤：S1、构建车辆违规停放数据集；S2、搭建轻量级车辆违停识别网络；S3、基于数据集对模型进行训练，得到收敛模型；S4、模型量化，移动端部署；S5、测试图像输入，输出分类结果；有益效果为：本发明提出的基于轻量化网络的违规停车识别方法，构建数据集，完成数据标注、扩充及划分；搭建轻量级车辆违停识别网络；利用训练数据集对模型进行训练；模型量化处理，移动端部署测试，输出分类结果。本发明融合了卷积神经网络和vision transformer，解耦全连接注意力机制，有效提取融合图像局部信息和全局信息。用于识别车辆的停车违规的基于轻量级网络的方法，所述车辆例如是汽车、公共汽车、自行车、电动车辆和卡车(均要求保护)。该方法使全连接注意力机制解耦，有效提取融合图像的局部信息和全局信息。该方法涉及构建车辆违停数据集。 构建轻量级车辆违停识别网络。 基于所述数据集训练模型，得到收敛模型。 进行模型量化。 进行移动终端部署。 将测试图像输入到所述模型中以输出分类结果。 采集不同场景下的车辆停放数据。 构建所述车辆违停数据集时采用LabelImg标记工具对数据集进行标记，得到标记数据集。 对所述数据集进行数据扩展。 轻量级车辆违停识别算法模型设有卷积神经网络(CNN)特征提取模块和线程编码解码模块。 13
本发明公开了使用自监督预训练的TimeSformer进行视频目标检测的方法及其应用，检测方法包括：S01、搭建基于TimeSformer的无卷积目标检测神经网络框架，导入训练视频形成训练样本，对其进行分块和线性嵌入，再通过TimeSformer分离的时间‑空间注意力方式进行编码和解码进行特征提取，最后再经过预测神经网络生成目标检测结果；S02、通过自监督的预训练方法，在经分块处理后的训练样本中选择目标块，将训练目标变成从原始视频图像寻找该目标块进行神经网络的预训练，形成初步检测神经网络；S03、通过有监督的调优训练方法，将现有视频作为调优训练样本，导入初步检测神经网络进行调优训练；S04、将训练获得的检测神经网络用于视频中进行目标检测，本方案计算资源占用低、实施可靠。一种利用自监督预训练检测视频目标的方法。该方法使得能够使用具有低计算资源占用，实现可靠，低数据依赖性和使用非标签数据进行预训练的自我监督的预训练计时器来执行视频目标检测。该方法包括建立(S01)基于时变器的非卷积目标检测神经网络框架。 引入训练视频以形成训练样本。 对训练样本执行块和线性嵌入。 目标检测结果由预测神经网络生成。 目标检测结果点被配置为在块处理之后的训练样本。 在块处理之后，在训练样本中选择(S02)目标块。 将训练优化目标从原始视频图像转换为目标块。 形成初级检测神经网络。 引入(S03)初级检测神经网络以优化训练。 获得所需的检测神经网络(S04)。 优化训练得到的检测神经网络用于视频中的目标检测。独立的权利要求书被包括在以下内容中： 1.一种存储程序的计算机可读存储介质，所述程序用于将自我监督的预训练时间片用于视频目标检测。 2.一种终端设备。 9
本发明提出一种领域知识图谱半自动化构建的方法及装置, 其中方法包括：对图书原文文档进行标注获取领域内实体关系三元组数据，组织成结构化数据，根据结构化数据构建精确标注知识图谱；根据三元组数据的实体关系及上下文内容基于seq2seq模型生成主语、宾语的描述，补全精确标注知识图谱中实体描述信息；基于补全实体描述信息的精确标注知识图谱通过Bert模型进行实体及关系预测，结合人工标注的实体关系信息构建领域知识图谱。本发明通过半自动化构建的方法及装置，利用人工标注提高数据的精确度，同时半自动化的构建算法可以在降低人工成本的同时挖掘数据之间的潜在关系，构建更为全面的领域知识图谱。知识图谱半自动构建方法。该方法能够实现领域内的半自动知识图谱，在减少人工参与的情况下，实现各知识的互联互通，构建综合的领域知识图谱。 该方法允许使用人工标记来提高数据的精度，因此在降低人工成本的同时减少了数据之间的潜在关系。该方法包括对图书原始文档进行标记，得到字段中的实体关系三元组数据。 结构化数据是结构化的。 对结构化数据构建精确标记知识图谱。 根据所述结构化群组数据的实体关系和上下文内容，基于seq2seq模型生成主语言。 基于所述精确标注知识图谱，在所述精确标注知识图谱中补充实体描述信息。 通过Bert模型进行整个实体和关系预测。 结合人工标签的实体关系信息，构建结合人工标签的实体关系信息的领域知识图谱。包括独立权利要求：(1)一种知识图谱半自动构建装置； (2)一种电子设备，包括存储器和处理器，用于存储计算机指令，所述计算机指令由所述处理器执行以实现一种知识图谱的半自动构建方法； 以及(3)计算机可读存储介质，用于存储实现一种知识图谱的半自动构建方法的计算机程序。  11
本发明公开了一种基于模拟控制的主从并机均流方法，包含以下步骤：步骤1、对表格及文本进行预处理；步骤2、采用brat标注工具进行语料标注；在excel文件中直接进行语料标注；步骤3、根据brat语料标注的结果，运用BiLSTM+CRF模型进行命名实体识别；根据excel语料标注的结果，运用BERT模型进行分类；步骤4、将抽取的实体要素和分类的文本根据对应关系进行融合，本发明通过对银行贷款审批意见进行命名实体识别和文本，以解析要素，返回相关要素信息。一种基于模拟控制的主从并行流量均衡方法，用于公共信用业务发行和审计，使用信用操作智能审计系统，也可用于商业交易效率和风险管理能力，网络信息领域。本发明通过将提取的实体元素与分类后的文本按照对应关系进行融合，使得本发明通过银行放款批准意见对命名实体进行识别和文本处理，并对元素进行分析，高效地返回相关元素信息。该方法包括对表格和文本进行预处理。 通过使用BRAT标记工具获得语言数据。 语言数据标注EXCEL 直接执行(非免费商业电子表格应用)文件。 使用双向长期短期存储器和条件随机场模型根据BRAT语言数据的结果识别实体标识。 使用来自变压器模型的双向编码器表示来根据变压器模型的结果对语言数据进行分类EXCEL (非免费商业电子表格应用)语言数据。 根据关系将提取的实体元素与分类后的文本进行融合。  12
本发明公开一种基于大语言模型的知识图谱补全方法，首先，通过爬取大规模文本数据，获取初始数据集，并运用大语言模型对文本进行处理和抽取，得到一个包含丰富实体和关系的初始数据集。接下来，通过预定义模型对实体语义进行增强，以捕捉实体之间的语义相关性，并采用多关系图卷积网络编码器对知识图谱进行编码。然后，利用评分解码器对知识图谱中的三元组进行评估，该解码器可以根据已知实体和关系预测未知关系或属性。通过对三元组进行评分，可以衡量预测结果的准确性和可靠性。本发明通过结合预定义的语义模式、捕捉实体间的语义相关性和增强表示学习功能，提升了现有知识图谱补全方法的性能，并且适用于复杂场景中的知识图谱补全任务。基于大型语言模型的知识图谱补全方法。该方法通过结合预定义语义模式、捕获实体间语义相关性和增强表示学习函数，提高了现有知识图谱补全方法的性能，适用于复杂场景下的知识图谱补全任务。知识图谱补全方法涉及进行数据爬取和预处理。 确定数据源和知识图谱的领域和主题，确定数据源。 选择待获取的18RR数据集的WordNet资源，该资源为关注语义关系的知识图谱。 利用爬虫技术从数据源获取文本数据。 对文本数据进行过滤清洗，去除无关信息，使数据更加干净规范。 利用预先训练好的大语言模型(GPT-4)处理文本数据，提取语义信息和结构化数据，构建包含实体和关系的知识图谱数据集。  11
本发明涉及一种基于深度学习的化妆品舆情文本实体关系抽取方法，包括：对互联网上爬取到的化妆品风险舆情文本信息进行预处理，并构建化妆品领域词库，通过改进的BERT神经网络提取字维度文本特征，并与词嵌入的词维度信息融合，经过融合位置感知注意力机制的BLSTM网络计算出多分类信息，再整合到改进的BERT神经网络提取字维度文本向量中再次经过融合位置感知注意力机制的BLSTM计算，最终通过CRF计算最优概率，完成化妆品风险舆情文本关系抽取。本发明一定程度上解决了化妆品风险舆情文本关系抽取准确程度不高，领域性强的难题，通过构建新的模型，在融合中文部首信息的字维度的基础上再加入词维度进行辅助表示，提高事件信息抽取准确性。该方法包括去除通过爬虫和筛选预处理过程获得的原始文本数据，以形成舆情文本。 对公众领域词资源库进行增量训练，用于得到美容舆情领域词资源库。 基于位置感知构建语义角色关注机制。 基于用于输入文本的双向深度自注意力转换网络来提取双向编码器表示来自变换器(BERT)预训练模型中的头部特征的文本特征向量。 在所述BERT预训练模型提取的文本特征向量中加入多分类关系信息，得到融合词的双维度文本语义向量。 将文本语义向量输入条件随机场(CRF)中的双向长期记忆网络(BLSTM)模型，得到最终的化妆品舆情文本实体关系提取结果。  12
本发明公开了一种基于细粒度事件信息增强的短文本隐式情感分类方法，其步骤包括：1、使用事件抽取器抽取短文本中的事件类型、触发词及其他事件元素形成细粒度的单事件元组；2、使用BERT预训练模型分别对单事件元组和短文本进行表征，分别得到单事件元组和短文本的特征向量；3、将步骤2中得到的特征向量通过张量组合的方式进行融合，使用细粒度事件信息增强短文本的表征；4、将步骤3中得到的细粒度事件信息增强后的特征向量输入Bi‑GRU模型中进行情感分类，最终由sigmoid网络输出情感分类的结果。本发明使用细粒度事件信息增强短文本的表征，从而能够提高情感分类的准确率。基于细粒度事件信息增强的增强短文本表示的短文本隐式情感分类方法。该方法使得能够利用细粒子事件信息来增强短文本的表示性，以提高情感分类的准确性。短文本隐式情感分类方法包括获取评论数据中的短文本，构建数据集。 对所述数据集合中的所有短文本进行数据预处理处理，得到每个短文本对应的词集合。 将所述词集合输入到BERT预训练模型中。 获取所述短文本的隐藏向量，得到单粒子信息增强的短文本表示rfinal。 表示rfinal输入的前向GRU模型的短文本被输入到Bi-GRU模型中。 得到前向隐藏向量。 将短文本导入BiGRU模型的后向GRU模型中，以在所述BiGRU模型的后向GRU模型中进行处理，得到所述后向隐藏向量。 利用公式选取较大的概率值对应的情感作为对应的短文本的最终情感分类结果。一种电子设备，包括：存储器，用于存储支持所述处理器执行所述短文本隐式情感分类方法的程序; (b)用于存储计算机程序的计算机可读存储介质。  12
本发明涉及基于BERT的影视作品地域知识图谱构建方法，包括：采集影视作品文本数据，构建地域领域词典，对文本数据进行预处理和分词，得到影视作品的地域关联数据；对地域关联数据中的实体进行定义，建立实体之间的关联关系；对影视作品的地域关联数据中的实体和实体关系进行标注；对BERT模型进行训练；利用BERT模型对未标注的影视作品抽取得到影视作品的实体关系；将得到的影视作品的实体关系存入图数据库，得到影视作品的地域特色知识图谱。本发明还公开了相应的知识图谱构建系统。本发明实现了地域特色知识图谱的自动构建，构建得到的影视作品地域特色知识图谱有利于文化宣传人员、研究人员建立影视作品地域特点的直观印象，分析影视作品的地域差异。用于医疗、电力、金融和教育领域的基于BERT的视频工作区域知识图谱构建方法。该方法能够实现视频工区专题知识图谱的自动构建，代替人工，省时省力。 该方法使得研究人员能够建立视频作品区域特征的视觉印象，并对视频作品的区域差异进行分析研究，提高了区域关联数据中实体和实体关系的识别效率和识别精度，从而改善了BERT模型中随机词级别的掩码机制。该方法包括收集视频作品文本数据。 构建视频工作区域字段字典。 对所述文本数据进行预处理和切分，得到视频作品的区域关联数据。 定义区域关联数据中的实体。 建立所述实体之间的关联关系。 根据所述实体和所述实体关系，在所述视频作品的地域关联数据中标记所述实体和实体关系。 标记后得到实体和实体关系。 使用所述视频作品的区域关联数据以及标记的实体和实体关系。 更新BERT模型。 将未标记的视频作品的区域关联数据输入到BERT模型中。 所述BERT模型用于提取所述视频作品的实体关系。 将所述图谱数据库中存储的所述视频作品的实体关系进行存储，得到所述视频作品的地域特征知识图谱。  12
本发明涉及目标检测领域，具体提供了一种仪表字符检测方法，基于可变形卷积和池化操作的卷积神经网络，具有如下步骤：S1、构建数据集；S2、数据预处理；S3、预训练模型构建及训练；S4、可变形网络结构搭建及训练；S5、模型获取及数据推理；S6、模型迭代。与现有技术相比，本发明提出了可变形的卷积神经网络可以免于对图像中的字符数据进行分割、特征匹配等工作，直接对分割后的仪表图像进行字符提取和识别，极大的简化了工作流程，提高了工作效率和准确度。基于卷积神经网络卷积和池运算的仪表字符检测方法。该方法提出可变形卷积神经网络避免了对图像中字符数据的分割和特征匹配，直接对分割后的乐器图像进行字符提取和识别。 该方法大大简化了工作流程，提高了工作效率和准确性。该方法涉及构建数据集。 进行所述数据预处理。 建立预训练模型并进行训练。 进行可变形网络结构构建和训练。 进行模型获取和数据推理。 进行模型迭代。 根据应用场景采集仪表板图像数据，并对其进行标记。 所述数据预处理中对原始图像进行亮度均衡调整。 通过颜色分割提取屏幕区域。本发明还涉及一种用于检测仪表特性的装置。   4
本发明公开了一种基于深度学习的人流量检测方法，涉及人工智能技术领域。本发明使用的轻量级神经网络模型，与主流的卷积神经网络相比，通过深度可分离卷积将标准卷积核进行分解，减少了计算量，加速了计算，具有优良的性能，在保持传统模型性能的前提下，能降低模型大小同时提升速度；克服了模型过于庞大面临的内存不足的缺点，适用于移动端或嵌入式芯片的部署。本发明实现的视频监控下的人流量检测方法，基于该轻量级网络模型框架，自制实用型数据集，适用于特殊场景，如婴儿车数量多、行人移动速度慢的公园、文化广场；在如传染病疫情期间的特殊时期，能够及时计算人流量并疏散过密人群，加强对人们，特别是对婴幼儿的防护。一种基于深度学习的人流量检测方法，用于童车数量多，行人运动缓慢的公园，文化广场。本发明通过深度可分离卷积分解标准卷积核，减少了计算量，从而加快了计算速度，性能优良。 本发明能够减小机型尺寸和内存不足，从而保证移动终端或嵌入式芯片的部署。 本发明实现了基于轻量级网络模型框架的自制实际数据集。 本发明能够在疫情发生时及时计算人流量，疏散人员，以达到强身健体，保护婴幼儿的目的。该方法包括获得图像文件列表。 建立数据和标签之间的映射以形成数据集。 构建深度学习检测模型。 深度学习检测模型由数据集训练。 网络结构由验证集确定。 调整深度学习检测模型的超参数。 生成当前模型和状态文件。 定义网络文件。 一种行人检测模块由一个检测模块和一个控制模块组成。自然铜 (RTM : 高级编程语言)。 构造行人检测模块。 显示人流量检测结果。   4
本发明实施例公开了一种对文本的语义理解的方法及系统，本发明实施例对文本进行语义理解时，采用构建的BERT网络模型，该BERT网络模型采用无监督掩码语言模型(Mask Language Model)进行预训练，且其中包括自注意力(self‑attention)机制层及记忆注意力(memory attention)机制层，在对输入文本进行语义理解时，自注意力机制负责学习文本内容上下文关系理解，记忆注意力机制负责对新添加热词进行理解和增强，通过合并两个注意力机制的高维表征，得到文本的分类结果，从而使得对文本的语义理解的准确性增大。用于文本的语义理解的方法。本发明将两种关注机制的高维表示相结合，得到文本的分类结果，从而提高文本语义理解的准确性。所述方法包括：构建BERT网络模型，所述BERT网络模型采用无监督的掩码语言模型进行预训练。 BERT网络模型具有自注意机制层和记忆注意机制层。 当利用输入文本进行语义理解时，执行两层关注机制处理操作以获得文本的分类结果。本发明还涉及一种用于文本语义理解的系统。  12
本说明书的实施例涉及一种用于内容生成的方法、系统、电子设备和存储介质。该方法通过检测用户触发的内容生成请求，获取关于内容生成请求的初始提示语；通过分类模型提取初始提示语的特征，以确定初始提示语所指示的风格偏好；基于所确定的风格偏好和所获取的初始提示语，通过经训练的风格化模型对初始提示语进行风格化处理，以生成风格化提示语；将所生成的风格化提示语输入预定的生成式人工智能模型，从而生成针对内容生成请求的内容。用于生成内容的方法。该方法使得能够通过训练后的风格化模型对初始提示进行风格化处理，以基于确定的风格偏好和获得的初始提示生成风格化提示，从而将生成的风格化提示输入到预先生成的人工智能模型，从而以有效的方式生成用于内容生成请求的内容。该方法涉及响应于检测到用户触发的内容生成请求而获得关于内容生成请求的初始提示。 基于获得的所述初始提示，通过训练好的分类模型提取所述初始提示的特征。 风格偏好由初始提示确定。 通过训练好的风格化模型对获取的初始提示进行风格化处理，生成针对内容生成需求的风格化提示。 将所生成的风格化提示输入到预先生成的用于生成内容的人工智能模型中。包括用于以下的独立权利要求：(1)用于生成内容的系统； (2)一种计算设备，包括处理器和存储器，用于执行用于生成内容的一组指令； (3)一种计算机可读存储介质，用于存储用于生成内容的一组指令。  11
本发明公开了一种基于句子复述模型的英文词语替换方法，包括：利用公开的复述语料，训练复述生成模型；利用所述复述生成模型，结合聚焦目标词的解码方法，生成复述句子；从所述复述句子中，提取候选替代词；利用BERTScore过滤所述候选替代词，以获取最终替代词；首次提出利用复述模型进行词语简化，很好地结合了复述模型中包含的隐含监督信息；首次利用BERTScore进行替代词的过滤，且生成替代词时同时考虑目标词及其上下文信息；简化了替代步骤，在不需要转换词语形态的情况下，即可生成替代词。一种基于句法解释模型的英文单词替换方法，用于解决各种自然语言处理(NLP)应用中的词汇简化，歧义消除等问题。本发明能够简化替换步骤，在不需要转换词形的情况下，生成替换词，从而有效地简化了英文单词的替换。所述方法涉及使用公共释义语料库来训练释义生成模型。 本发明结合以目标词为中心的解码方法，生成释义语句。 从释义句子中提取候选替换词。 使用BertScore对候选备选词进行过滤，以获得最终备选词。  12
本申请涉及一种视频标题生成方法、视频标题生成模型的训练方法、装置、计算机设备、存储介质和计算机程序产品，涉及计算机视觉和自然语言处理技术。所述方法包括：获取待处理的视频素材、以及与该视频素材的发布场景匹配的提示模板；对视频素材进行语义提取，得到视频素材的文本语义信息和视觉语义信息；使用所述文本语义信息填充与发布场景匹配的提示模板，生成提示信息；将视觉语义信息和提示信息输入至预训练的大语言模型，以使大语言模型在该提示信息的引导下，生成与视觉语义信息匹配的摘要信息；基于摘要信息，确定视频素材在该发布场景下的视频标题。采用上述方法能够提高视频标题的准确性。用于生成视频标题的方法。根据所述摘要信息确定所述分发场景中的视频素材的视频标题，有效提高了视频标题的准确性。该方法包括获取待处理的视频素材，以及与视频素材的发布场景匹配的提示模板。 对所述视频素材进行语义提取，得到所述视频素材的文本语义信息和视觉语义信息。 将所述文本语义信息填充所述提示模板，生成提示信息。 将所述视觉语义信息和所述提示信息输入预先训练的语言大模型，以使所述语言大模型在所述提示信息的引导下生成与所述视觉语义信息匹配的抽象信息。 基于所述摘要信息确定所述发布场景中的视频素材的视频标题。独立权利要求包括用于：(1)视频标题生成模型的训练方法； (2)视频标题生成装置; (3)视频标题生成模型的训练装置； (4)计算机装置； (5)计算机可读存储介质； 以及(6)计算机程序产品。 9
本公开提供了一种信息处理方法、装置、设备及介质，涉及人工智能技术领域，尤其涉及深度学习技术领域，包括：获取与知识增强的语义表示ERNIE模型对应的训练样本集；针对训练样本集中的各训练样本，采用二次随机遗漏处理结合计算相对熵的方式，对ERNIE模型进行精调，得到与模型训练任务对应的调整后模型。本公开实施例的技术方案，可以简化ERNIE模型的训练复杂度，在提高ERNIE模型的训练效率的同时，保证ERNIE模型输出结果的准确性。该方法可用于通过使用电子设备(要求保护)来处理信息。该方法简化了Ernie模型的训练复杂度； 提高了模型的训练效率，保证了输出结果的准确性； 由于对训练任务进行了微调，得到与调整后的模型相对应的模型训练任务，提高了训练效率，减少了训练时间； 通过使用知识增强语义表示(ERNIE)模型，提高了准确性和训练效率。该方法包括获得对应于知识增强语义表示Ernie模型的训练样本集。 通过使用被组合以计算相对熵的二次随机遗漏处理来计算相对熵模式。 对Ernnie模型进行微调，得到与调整后的模型相对应的模型训练任务。独立的权利要求书包括： 信息处理装置； 一种非临时性计算机可读存储介质，包括一组用于处理信息的指令； 以及 一种计算机程序产品，包括一组用于处理信息的指令。  11
本公开公开了一种文本输出方法及装置、电子设备和存储介质，涉及计算机技术领域，尤其涉及人工智能技术领域。具体实现方案为：获取输入信息，并获取与输入信息对应的检索信息；在检索信息指示在知识库中进行检索的情况下，获取检索信息中与输入信息对应的目标检索文本；根据输入信息和目标检索文本，采用生成大模型在知识库中获取与输入信息对应的历史写作文本集合，并基于输入信息、目标检索文本和历史写作文本集合，获取与输入信息对应的第一写作文本；在第一写作文本不满足写作要求的情况下，对第一写作文本进行编辑，输出与输入信息对应的第二写作文本。因此本公开可以提高辅助创作的效率和准确性。一种应用于人工智能和自然语言处理领域的文本输出方法。该方法提高了辅助创建的效率和准确性。该方法涉及获取输入信息以及获取(101)与输入信息相对应的搜索信息。 在所述搜索信息指示在所述知识库中进行搜索的情况下，获取(102)所述搜索信息中与所述输入信息对应的目标搜索文本。 根据输入信息和目标检索文本采用大生成模型获取知识库中与输入信息对应的历史书写文本集，并基于输入信息、目标检索文本和历史书写文本集获取(103)与输入信息对应的第一书写文本。 在所述第一书面文本不符合所述书面要求的情况下，对所述第一书面文本进行编辑并输出与所述输入信息对应的第二书面文本(104)。独立权利要求包括以下内容：(1)文本输出设备； (2)电子设备； (3)存储有用于输出文本的程序的非暂态计算机可读存储介质； (4)一种用于输出文本的计算机程序产品。  11
本发明提供了一种BERT、NER实体抽取以及知识图谱的物料分类优化方法及系统，包括：步骤S1：处理基础文本，清洗物料数据；步骤S2：使用NER模型提取物料数据中的实体信息，并打上相应标签；步骤S3：基于带实体标签的物料数据，训练BERT模型；步骤S4：基于训练后的BERT模型对物料信息进行嵌入，使用kmeans对物料向量聚类修正分类，再次训练BERT分类器，直到所有类别的分类精确度高于预设值。本发明通过采用NER实体抽取模型提取物料信息中关键实体的结构，将原物料数据的物料信息进行增强，解决了BERT模型训练时难以快速聚焦重要文本信息的问题。BERT、NER实体抽取和知识图谱的素材分类优化方法。该方法使得能够利用NER实体抽取模型抽取素材信息中的关键实体的结构，使得原料数据的素材信息得到增强，从而能够以简单的方式快速地将重要文本信息聚焦在BERT模型训练中。该方法包括处理基本文本以清洁材料数据。 所述NER模型用于提取所述素材数据中的实体信息。 标记相应的实体。 基于所述带有实体标签的材料数据训练所述BERT模型。 基于训练后的所述BERT模型嵌入所述素材信息。 kmeans用于对材料簇进行分类。 再次训练BERT模型，直至所有类别的分类准确率均高于预设值。包括独立权利要求用于BERT、NER实体抽取和知识图谱的素材分类优化系统  12
本发明提供的端到端语音识别模型训练方法、语音识别方法及相关装置，该方法包括：根据文本语料，获得训练后的语言模型；根据语言模型构建端到端语音识别模型，并根据音频语料对构建后的端到端语音识别模型进行训练，获得训练后的端到端语音识别模型。本发明基于数量级较大的文本语料先训练出一个语言模型，让这个语言模型可以学习更多的语言知识，进而，利用训练后的语言模型构建端到端语音识别模型，在结合音频语料进行训练，不仅可以让训练后的模型避免因多音字现象造成识别准确度降低的现象，同时在避免可训练之前需要对音频语料进行标注成本较大的问题。训练端到端语音识别模型的方法。结合音频语言学数据进行训练，使得模型在训练后，从而避免多音现象导致的识别准确率降低的现象，避免了音频语言学数据在训练前需要花费较大的代价进行标注的问题。 提高了端到端语音识别模型的准确率。该方法涉及根据文本语料库获得(S303)经训练的语言模型。 根据语言模型构建端到端的语音识别模型(S305)，并根据音频语料对构建的端到端的语音识别模型进行训练，以获得训练后的端到端的语音识别模型。 将所述语言模型构建到所述端到端语音识别模型的解码模块中，得到构建的所述端到端语音识别模型。 除语言模型的交叉注意力机制参数外的其他模型参数保持固定，针对构建的端到端的语音识别模型，根据音频语料训练语言模型。以下包括独立权利要求：一种语音识别方法； 用于训练端到端语音识别模型的装置； 语音识别装置； 电子设备； 以及存储用于训练端到端语音识别模型和用于语音识别的程序的计算机可读存储介质。 3
本发明公开了一种基于改进Adaboost算法的句子相似性判断方法，利用预训练语言模型在学习大规模文本的语义知识方面的优势以及Adaboost算法在集成多个基学习器方面的优势，先通过公开语料集中的训练数据对多个不同的预训练语言模型进行独立训练和微调，目的是利用不同预训练语言中的先验知识和网络结构学习文本语义相似性的任务相关知识；接着，在Adaboost R2算法的基础上提出改进的Adaboost算法，并结合验证数据集计算各个模型的权重系数，并进行归一化。最后，根据权重系数将各个模型在测试数据集的预测结果进行线性求和，从而得到最终的句子相似性结果。一种基于改进Adaboost算法的句子相似度确定方法。本发明在不增加模型复杂度和训练数据量的前提下，使得模型的训练时间不会随集成模型数量的增加而线性增加，用于并行训练时，模型的效果进一步提高。该方法包括在输入特征层根据不同预训练语言模型的输入要求对待识别的两个句子进行预处理。 在预训练语言模型层，根据不同预训练语言模型的要求，使用训练数据集分别对输入语句对进行训练和微调。 在标准AdaBoost R2算法的基础上提出了一种改进的AdaBoost算法， 在特征融合层，用MSE代替经典Adaboost算法中的误码率计算，通过验证数据集得到每个预训练语言模型的权系数向量，最后进行归一化处理。 利用加权系数向量对测试数据集进行各模型结果的线性加权求和，得到最终的相似度值。  11
本发明公开了一种基于文本理解的结构化知识抽取方法，属于自然语言处理技术领域，结合基于BERT+Bi‑LSTM+CRF的命名实体识别和基于PCNN的关系提取算法，对句子级的非结构化文本进行实体关系提取，所述基于BERT+Bi‑LSTM+CRF算法的命名实体识别，首先利用预训练的BERT语言模型的Transformer机制对输入的数据进行编码，输出文本的字向量序列表示即X＝{x1, x2, …, xn}；然后将结果输入到BiLSTM层进一步获取数据隐藏层的高层特征；最终输出命名实体结果。本发明可以通过调整标注样本有效控制模型精度，并且不受文本形式的约束，适用范围广且实用性较强。用于执行结构化知识抽取的方法，即，在自然语言处理领域中使用的基于文本理解的从非结构化文本自动构建大规模知识图谱的方法。通过调整标记样本有效控制模型的精度。 应用范围广，实用性强。本发明公开了一种基于BERT+Bi-LSTM+CRF的命名实体识别与基于pulse coupled neural network，PCNN的关系提取算法相结合，提取句子级非结构化文本的实体关系的方法。 实体识别基于BERT+Bi-LSTM+CRF算法命名。 采用预先训练好的BERT语言模型对输入数据进行编码。 输出文本的词向量序列输入到BiLSTM层，得到数据隐藏层的高层特征。 BiLSTM的输出结果经过CRF的状态转移限制，最终输出命名实体结果。 关系是基于PCNN算法提取的。 将所述实体识别结果作为输入。 两个实体通过实体标识配对。 对所述一对实体的关系类型进行分类。独立权利要求包括：(1)一种基于文本理解的结构化知识提取装置； 以及(2)包括用于提取结构化知识的指令集的计算机可读介质。  12
本发明提出了一种可填充自适应的场景对话意图识别方法，包括以下步骤：S1.向预训练模型输入自然语言语句，并经过调优结构输出意图；S2.对输出意图进行业务分类和冗余分类；其中，冗余分类的步骤包括：S201.从业务类别的训练语句中提取关键词；S202.对获取的关键词按照知识图谱的关联逻辑进行检索；S203.将与当前业务目的不一致的其他释义单独归类，且将隶属释义下的例句作为新的冗余分类的训练数据，本方案设置的冗余分类大大降低了第二类错误的概率，提升了准确率；随着业务的发展，特别是新场景样本例句的累计，先前的冗余分类的储备可以直接转换为新的业务类别，将大大提升开发效率。大数据分析中的可填充自适应场景对话意图识别方法。该方案设置的冗余分类大大降低了第二类错误的概率，提高了准确率。 之前冗余分类的储备可以直接转换为新的服务类型，大大提高开发效率。该方法包括将自然语言句子输入到预训练模型。 通过优化结构输出意图。 对所述输出意图进行服务分类和冗余分类。 从所述业务类型的训练语句中提取关键词。 根据所述知识图谱的关联逻辑对所述获取的关键词进行检索。 对与当前服务目标不一致的关键词的其他含义进行单独分类。 将该服从下的一个例句作为新的冗余分类的训练数据。 8
本发明公开了一种基于BERT和字词特征融合的文本分类方法、文本分类平台及计算机可读存储介质。本发明的文本分类方法的步骤主要包括预处理、字符向量编码、分词、词向量编码、词向量再编码、池化、全连接和分类。本发明通过BERT获取了每个字符对应的向量，该向量中包含了文本全局的字符信息；通过GRU对每个词中包含的字符进行再编码，在字向量的基础上融入局部的词汇特征，最终每个词的词向量中既包含了全局的字符信息，又包含了局部的词汇信息，具有更丰富的表达能力。本发明的方法基于BERT将字符特征和词汇特征结合，丰富了文本的语义表示，进一步提升文本分类的准确率。用于通过使用文本分类平台(权利要求书)基于双向编码器来自变换器的表示(BERT)和词特征融合来分类文本的方法。该方法将字符特征和基于BERT的词汇特征相结合，丰富了文本的语义表示，提高了文本分类的准确性。该方法包括对待分类文本进行预处理。 得到长度和字符归一化的第一文本。 去除文本中的特殊字符。 进行全半角转换。 将所述文本的全角度字符转换为对应的半角度字符。 获取所述待分类文本的全连接特征向量。 计算所述待分类文本的全连接特征向量的每个元素的softmax函数值。还包括用于以下的独立权利要求：文本分类平台； 以及计算机可读存储介质，用于存储利用文本分类平台基于BERT和词特征融合对文本进行分类的指令集。  12
本发明涉及一种督办事项自动关联会议文件的方法，包括如下步骤：从多个督办事项中提取督办关键字；调用全文检索接口，利用所述督办关键词对会议文件进行检索，获取到相关的会议文件，生成会议文件集；将会议文件集中的各会议文件的标题生成文件标题BERT向量，将督办标题生成督办标题BERT向量；提取一所述督办标题BERT向量，将其与各文件标题BERT向量计算余弦相似度，将余弦值大于预设阈值的会议文件与督办事项进行关联；遍历所有督办标题BERT向量，重复所述余弦相似度计算，得到各督办事项对应的会议文件。本发明实现关键信息的精确提取，将建立督办事项‑会议文件的关联关系，显著提升了关联分析的效率，降低了人工投入。用于将会议文件与监督项自动关联的方法。本发明提高了关联分析的效率，减少了人力成本的投入，保证了监管数据和会议数据的应用价值，减少了人工投入，自动关联会议文件进行监管事件，实现了关键信息的准确提取，建立了会议事件-会议文件的关联关系。该方法涉及从多个监管项目中提取监管关键词。 调用全文搜索接口。 利用监督关键词对会议文件进行搜索，得到相关的会议文件。 生成会议文件集合。 将会议文件集中的每个会议文件的标题发送到来自变换器的双向编码器表示(BERT)模型中。 生成相应的监督标题BERT向量。 提取导向标题BERT向量。 利用每个文件标题BERT向量计算余弦相似性。 将所述会议文件对应余弦值大于预设阈值的文件标题BERT向量与所述监督标题BERT向量对应的监督项相关联。 遍历监督标题BERT向量进行重复余弦相似度计算。 对应每个监督项获取所述会议文件。包括独立权利要求：(1)用于将会议文件与监督项自动关联的装置； 以及(2)计算机可读存储介质，其包括用于执行用于将会议文件与监督项自动相关联的方法的指令集。  12
本发明涉及一种基于关键词的多粒度中文短文本匹配方法，属于自然语言处理领域，包括以下步骤：S1：将句子分为字和词两个粒度，将两个粒度的句子统一填充到长度N，在对应数据集上训练Word2Vec，获得字和词两个粒度的嵌入表示；S2：用两个BiGRU对句子向量进行编码，获得句子两个方向的上下文信息；S3：用交叉注意力获得字粒度特征和词粒度特征之间的关联，再对其及逆行平均池化并连接获得句子最终的表示向量；S4：连接两句子的词粒度嵌入向量，用11层Transformer编码器和一层关注关键词的Transformer进行编码；S5：连接关键词特征和两句子的表示向量作为最终的预测向量。基于关键词的多粒度中文短文本匹配方法。 用途包括但不限于新闻、手机短信、网络聊天、购物介绍和旅游提示等。该方法能够使用感兴趣关键字编码器对句子进行编码，从而提取句子的关键字信息，提高模型的性能。 该方法允许将关键词特征和两个句子的表示向量连接起来作为最终的预测向量，因此提高了模型的性能。该方法包括将句子划分为词和词两个粒度，并将两个粒度的句子统一填充至长度N，在相应的数据集上训练Word2Vec(RTM：自然语言处理应用)，得到N个词两个粒度的嵌入表示。 两个BiGRUs用于对句子向量进行编码，得到句子两个方向的上下文信息。 所述变压器关注关键词是指变压器的自关注层。 句间句二关注操作只关注句二的关键词，反之则不关注。 将两个句子的关键词特征和表示向量连接起来，作为最终的预测向量。  12
本发明涉及一种面向采摘机器人的遮挡和重叠果实识别方法，属于图像识别领域，提出Dense‑TRH‑YOLO模型，在YOLOv5的基础上将Denseblock模块融合到骨干网中，创建了早期层到后期层的段路径，并且将Transfomer模块融入到模型中，提高语义可分辨性并减少类别混淆，增加对遮挡物的识别精度，然后通过Unet++‑PAN颈部结构提取各层图像特征，最后用Efficient IOU Loss损失函数代替原模型的CIOU进行边框回归输出检测框位置和分类置信度，在CIOU的基础上分别计算宽高的差异值代替了纵横比，同时引入Focal Loss解决难易样本不平衡的问题。用于采摘机器人的遮挡重叠果实识别方法。该方法能够为保证检测速度、降低模型复杂度而有效减少深度网络信息中图像的损失，从而提高遮挡对象的检测精度和特征提取能力，实现采摘机器人遮挡果实识别网络的改进设计。 该方法提高了语义分辨率，减少了类混淆，提高了障碍物的识别精度，将原来YOLOv5的深层模块替换为C3TR模块。该方法涉及使用改进的Yolov5作为果实目标检测的主要算法，将改进的密集-TR-跨阶段部分(Dense-TR-CSP)替换为CSPDarknet53作为主干网络。 将Denseblock模块融合到骨干网络中。 路径聚合网络(PAnet)在原文中被替换，你只把oncev5(YOLOv5)看作是模型的颈部结构。 引入学习权重，学习不同输入特征的重要性。 对图像特征进行深度提取。 Yolo头部被传输以使用三个不同的特征提取层来检测和分类水果的类型。 使用softmax分类器执行全连接层中的目标检测和分类。 使用EfficientIOU损失函数代替原始模型的完全相交超过并集(CIOU)，以执行帧回归输出检测帧位置和分类置信度。使用支持向量机(SVM)分类器执行边缘提取，以确定在切割后定位图像之后是否直接挑选定位的果实用于分类。   5
本发明实施例提供一种问答会话处理方法、装置、设备和存储介质，应用于服务端，包括：获取求职端发送的针对目标岗位的交互消息，其中，交互消息包括第N个属于回答类型的第一交互消息和/或第M个属于提问类型的第二交互消息。将第N个第一交互消息转发至大语言模型的第一模块，使其根据第N个第一交互消息判断是否需要生成问题交互消息；若不需要，则根据第N个第一交互消息确定是否人岗匹配；若需要，则根据目标岗位对应的岗位问题库生成问题交互消息，根据获取到的第N+1个第一交互消息确定是否人岗匹配。将第M个第二交互消息转发至大语言模型的第二模块，使其根据第M个第二交互消息从问答知识库中提取目标内容以回复第M个二交互消息。应用于人工智能领域的服务端的问答会话处理方法。该方法通过获取求职端发送的针对目标帖子的交互消息，并将该交互消息转发给大型语言模型的模块，处理方式简单高效。所述方法包括获取(S1)求职端发送的针对目标帖子的交互消息。 所述交互消息中设置有第N个第一交互消息和第M个第二交互消息。 响应于所述交互消息中存在所述第M条第二交互消息，将所述第N条第一交互消息转发(S2)至目标大型语言模型的第二模块，以使所述第二模块根据关键字段从问答知识库中提取目标内容。 将第m个第二交互消息转发(S3)至目标大语言模型的第二模块，以使第二模块根据关键字段从第m个第二交互消息中提取出。独立权利要求还包括用于：应用于服务端的问答会话处理装置； 以及非临时机器可读存储介质，所述非临时机器可读存储介质包括用于处理应用于服务端的问答会话的指令集。 8
本发明公开了一种基于深度学习的动车组运行故障检测方法，利用ImageNet等通用数据集将预训练模型训练为通用模型，然后将通用模型利用动车组图像的本源数据集训练成检测区识别模型，利用零部件等的专业数据集训练成区内故障检测模型，利用遮盖物数据集训练成遮盖物识别模型，然后进行识别。该方法能够有效扩充负向样本数量，同时可以强有力提升遮盖物样本量，由此训练出的检测模型具有强泛化能力，能够对动车组运行故障进行分类识别处理，极具实用性和推广价值。使用车辆底板异物跳动故障检测方法基于深度学习来检测动车组即铁路列车的运行故障的方法。本发明能够有效扩展负样本数，有效提高覆盖样本数，使得检测模型的训练具有较强的泛化能力，从而对动车组识别故障进行分类，具有实用性和推广价值。该方法包括获得预训练模型。 使用通用数据集训练通用模型。 采集当前列车覆盖图像。 检测区域识别模型用于识别列车图像。 识别车辆号码和车辆区段信息。 通过使用区域内故障检测模型来检测区域内的故障。 通过使用覆盖物来识别预定检测识别的图像。 对图像执行手动检测处理。 通过训练人工检测结果来训练检测区域识别模型。 识别区域内故障检测模型和覆盖对象模型。 13
本申请涉及信息处理技术领域，提供了一种目标推荐方法及装置。该方法包括：将大语言模型和点击预测模型双向连接，得到目标推荐模型，并基于目标推荐任务对目标推荐模型进行训练；获取目标用户的目标用户信息；按照提示词机制对目标用户信息进行处理，并将按照提示词机制处理后的目标用户信息输入训练后的目标推荐模型：通过大语言模型将按照提示词机制处理后的目标用户信息转化为目标用户特征向量；基于目标用户特征向量，通过点击预测模型确定推荐候选序列；通过大语言模型对推荐候选序列中的待推荐目标进行筛选，得到推荐序列；按照推荐序列向目标用户进行目标推荐。用于通过使用用于自动推断人们的偏好并提供高质量推荐服务的电子设备(声称)来推荐目标的方法。 用途包括但不限于股票信息、国家政策、娱乐新闻和体育新闻。该方法能够以有效的方式确保并按照推荐顺序对目标用户进行目标推荐。该方法涉及连接大语言模型和点击预测模型，得到目标推荐模型。 根据提示词机制对所述目标用户信息进行处理。 将处理后的目标用户信息输入训练后的目标预测模型。 通过大词模型将目标用户特征向量通过所述大词机制转换为所述目标用户特征向量。 基于所述目标用户特征向量确定推荐候选序列。 推荐候选序列包括多个待推荐目标。 所述推荐候选序列中推荐目标的数量小于所述推荐候选序列中推荐目标的数量。 根据所述推荐顺序对所述用户进行目标推荐。独立权利要求还包括用于：一种用于通过使用电子设备推荐目标的设备； 以及计算机可读存储介质，所述计算机可读存储介质存储用于通过使用电子设备来推荐目标的指令集。  11
本公开提供了一种预训练模型压缩方法、装置和电子设备。该方法包括：确定指定隐藏层的第一输出向量和至少两层隐藏层中至少部分隐藏层各自的第二输出向量；基于第一输出向量的聚类结果和各第二输出向量的聚类结果，确定至少部分隐藏层各自的影响占比；以及基于影响占比对预训练模型进行压缩，以减少至少两层隐藏层的层数；其中，指定隐藏层与预训练模型的最后一层隐藏层之间的距离小于至少部分隐藏层与最后一层隐藏层之间的平均距离。所述方法对于由电子设备(要求保护)进行的预训练模型压缩是有用的。预训练模型压缩确定指定隐含层的第一输出向量和所述至少两个隐含层中的至少部分隐含层的第二输出向量，基于所述第一输出向量的聚类结果和每个第二输出向量的聚类结果，确定所述至少部分隐含层各自的影响比例，基于所述影响比例对所述预训练模型进行压缩，以减少所述至少两个隐含层的数量， 其中所述指定隐藏层与所述预训练模型的最后一个隐藏层之间的距离小于所述至少部分隐藏层与所述最后一个隐藏层之间的平均距离。独立权利要求还包括用于：预训练模型压缩装置； 以及计算机可读存储介质，包括用于预训练模型压缩的指令集。  12
本申请涉及故障诊断技术领域，特别涉及一种基于联合知识蒸馏的动设备故障诊断难样本双向挖掘方法，其中，方法包括：基于预先构建的设备故障诊断大模型联合学习框架，获取服务端与客户端的难样本；根据服务端与客户端的难样本确定难样本索引，并基于难样本索引选择难样本对应的特征图，得到难样本选择特征图；对难样本选择特征图进行量化压缩，并在服务端与客户端之间传输量化压缩后的难样本选择特征图。由此，解决了如何精确地选择知识，进行难样本挖掘等问题，实现精确知识定位，节省通信开销，提升模型性能。一种用于石油化工和能源的电子装置(声称)实现基于组合知识蒸馏的可移动装置故障诊断难样本双向挖掘的方法。该方法能够解决如何准确选择知识和进行困难样本挖掘的问题，从而实现准确的知识定位，节省通信成本，提高模型性能。该方法基于预先构建的设备故障诊断大模型组合学习框架，获取服务端和客户端的困难样本。 根据所述业务端和所述客户端的疑难样本确定疑难样本指标。 对应每个困难样本选择一个特征图。 基于所述难度样本指标得到所述难度样本选择特征图。 得到困难样本的量化压缩特征图像。 所述量化后的特征图像在所述业务端与所述客户端之间传输。独立权利要求还包括用于：基于组合知识蒸馏实现可移动设备故障诊断难点样本双向挖掘的装置； 以及计算机可读存储介质，用于存储实现石油化工和能源使用的电子设备对基于组合知识蒸馏的可移动设备故障诊断难点样本的双向挖掘的指令集。  11
本发明公开了一种面向广告点击率预测的特征选取方法，包括：步骤(1)构造特征集；步骤(2)对特征集的所有特征进行评估，筛选并标记所有无益特征，并将对模型影响最大的无益特征从特征集中删除，再更新特征集；步骤(3)对无益特征进行评估，筛选并标记该次评估产生的新无益特征，将对模型影响最大的新无益特征删除，再次更新特征集；若未产生新无益特征，则停止操作，得到的特征集为有效特征集；若产生新无益特征，则迭代执行步骤(3)，直至未产生新无益特征。本发明采用双向式特征选择方式对特征集进行选择筛选，降低了迭代次数，不需再对特征全集进行迭代，能得到较大的模型提升效果，特征选择工程时间复杂度低，工作效率高。广告点击率预测的特征选择方法。该方法减少了迭代次数，无需对全特征集进行迭代，具有改进效果，特征选择工程复杂度低，工作效率高。该方法包括利用广告点击数据产生的数据特征构建特征集，对特征集的所有特征进行评估，筛选并标记所有无益特征，删除对广告点击率预测模型影响最大的无益特征，然后更新特征集，对更新后的特征集中的所有无益特征进行评估，筛选并标记评估产生的无益特征，取消对其他无益特征的标记。 从所述更新后的特征集中确定对所述广告点击率预测模型影响最大的所述无帮助特征，并再次更新所述特征集。包括以下独立权利要求：一种电子设备，其包括存储器和处理器； 以及非暂时性计算机可读存储介质具有计算机程序。 14
本发明涉及一种基于大模型的共识库查询方法，针对领域知识查询的难点问题提出改进方法并实际应用。针对知识跨领域迁移容易产生混淆和错误，设计领域自适应预训练方法，使大模型网络能够区分不同领域的知识；改进大模型网络，针对大模型中知识注入和文本输入的特征差异，设计显式对齐的知识强化表示学习方法，进一步提升大模型的表示效果。最后，基于改进的混合大模型网络得到文本和知识的向量表示，通过向量匹配进行共识库查询，较好解决实际应用需求。利用终端设备进行基于大模型的共识库查询的方法(索取)，也可用于知识推理查询领域。该方法保证了知识跨领域迁移容易产生混淆和错误，设计了领域自适应预训练方法，使得大模型网络能够区分不同领域的知识，设计了显式对齐的知识加强表示学习方法，进一步提高了大模型的表示效果，得到了基于改进的混合大模型网络的文本和知识的向量表示。该方法涉及对大型模型网络进行文本表示和领域分类预训练，得到能够区分不同领域的大型模型网络。 对混合大模型网络的知识表示进行预训练。 对所述混合大模型网络参数进行更新。 利用混合大模型网络离线在共识库中获取所有知识的表达向量。 构建所述共有库的向量库和向量索引。 根据用户实时输入的查询语句，利用混合大模型网络in在线获取查询语句的表达向量。 搜索所述公知知识库的向量库。 将所述相似度最高的知识向量对应的知识返回。还包括用于基于大模型查询共识库的一组指令的计算机可读存储介质。  11
本发明揭示了一种基于全尺度融合和流场注意力的图像分割方法，包括如下步骤：获取图像数据集，对数据图像进行预处理；以U‑Net为骨干网络，构建图像分割模型；将数据集中的训练图像输入至图像分割模型中进行训练；通过选择合适的参数和损失函数调整模型至最优效果并进行保存；将数据集中的验证图像输入到训练好的图像分割模型中，得到分割预测结果。本发明通过结合特定功能的网络结构以及对网络结构的改进，提高了本方法对于不同分割任务的适应性以及图像分割精度，另外，减小了各尺度特征间的语义差异，突出图像的关键特征信息，使得网络的性能与鲁棒性均显著提高。基于全尺度融合和流场注意力的图像分割方法。该方法通过结合特定功能的网络结构，增强网络的结构，提高了过程对不同分割任务的适应性，提高了图像分割的精度。 该方法能够减小各尺度特征与高亮图像关键特征信息之间的语义差异，提高网络的性能和鲁棒性。 该方法使得全尺度特征融合模块在每一级跳跃连接上融合粗粒度特征和细粒度特征，以减小尺度特征与高亮图像关键特征信息之间的语义差异，从而提高特征编码器和特征解码器的性能，提高图像分割模型的鲁棒性和性能。该方法涉及获得图像数据集。 对数据图像进行预处理。 选择U-Net作为骨干网络。 构建图像分割模型。 将所述图像数据集中的训练图像输入至所述图像分割模型进行训练。 通过选择合适的参数和损失函数将图像分割模型调整到最优效果。 将所述图像数据集中的验证图像输入所述已训练的图像分割模型，得到分割预测结果。 通过特征编码器提取数据图像的图层特征信息和全局特征信息。   6
本申请公开了一种文本信息的识别方法以及相关装置，应用于人工智能的自然语言处理技术。通过获取预设语料；然后基于预设规则从预设语料中提取对应于目标类型的多个正相关词。进一步的调用预设语料和多个正相关词对预训练模型进行训练，以得到第一识别模型；并基于第一识别模型进行调整得到第二识别模型；进而基于第二识别模型中进行文本识别。从而实现高效且准确的文本识别过程，采用与目标类型关联的预设语料以及补充的正相关词同时执行掩蔽操作，保证了识别模型对于目标类型关联词汇的识别能力，进而提高了文本信息识别的准确性。一种识别文本信息的方法及相关装置。本发明通过使用与目标类别相关联的预置语料库和补充正相关词同时进行掩蔽操作，能够实现高效，准确的文本识别过程， 从而保证了目标类型相关词汇识别模型的识别能力，从而提高了文本信息识别的准确性。该方法涉及获得(301)预置语料库，其中该预置语料库与目标类型的文本信息相关联。 基于预设规则从预设语料库中提取(302)与目标类型相对应的多个正相关词。 调用(303)预置语料库和多个正相关词来训练预训练模型，以获得第一识别模型。 预训练模型的训练过程基于训练任务执行，并且由训练任务指示的掩蔽操作与多个正相关词相关联。 基于预置的语料库调整(304)第一识别模型以获得第二识别模型。 获得待检测信息(305)，并将待检测信息输入到第二识别模型中，以获得待检测信息中的文本信息对应于目标类型的识别结果。独立的权利要求书被包括在以下内容中： 识别文本信息的装置； 计算机设备； 以及 一种存储用于识别文本信息的程序的计算机可读存储介质和相关设备。  11
本发明提供一种话题聚类方法、装置、电子设备及存储介质。该方法能够基于BERT模型对所述文本数据集进行回归分析，得到基础数据集，以更好的表达各个文本的段落信息，帮助提高文本表示的准确性，从基础数据集中选择配置数量的数据进行标注，利用少量的标注信息辅助整体的无监督聚类，采用AgglomerativeClustering模型，结合第一类间距离及第二类间距离进行聚类，进一步采用基于BERT算法训练的相似度模型，得到目标聚类结果，以便采用较大的类间距离下的聚类结果作为指导，对较小的类间距离下的聚类结果进行合并，同时保证了召回率及准确率，对聚类的距离及类别的依赖降低，提高聚类效果。本发明还涉及区块链技术，BERT模型、AgglomerativeClustering模型及相似度模型可存储于区块链上。一种主题聚类方法。本发明保证了查全率和准确率，减少了聚类的距离和类别，提高了聚类效果。该方法包括：获取文本数据集； 基于BERT模型对文本数据集进行回归分析，得到基本数据集； 从基本数据集中选择所配置的数据数量以进行标记； 获取标记的基本数据集； 根据在所标记的基本数据集中所标记的数据确定第一类型的距离和第二类型的距离； 采用聚类模型； 基于第一类型的距离对标记后的基本数据集中的数据进行聚类； 获得第二聚类结果； 使用基于BERT算法训练的相似度模型； 根据第一聚类结果组合第二聚类结果； 得到目标聚类结果。还包括独立的权利要求： 主题聚类装置； 以及 一种计算机可读存储介质，包括一组用于执行用于聚类主题的方法的指令。  12
本发明公开了一种基于特征点生成的图像式超链接生成方法，所属技术领域为图像信息隐藏领域，包括：基于公共数据集进行随机抽取，获得真实数据集，对真实数据集进行处理，获得图像的真实特征点和边缘图；基于真实数据集和真实特征点以及边缘图对模型进行训练，获得预训练模型；将超链接编码成01比特串后生成消息矩阵，基于消息矩阵进行消息隐藏，获得隐含超链接的特征点矩阵；基于预训练模型和隐含超链接的特征点矩阵获取合成图像；提取合成图像的特征点，基于秘密消息提取算法恢复超链接。本发明充分利用载体合成式框架的优点和图像特征点的鲁棒性，不需要固定的载体图像来嵌入超链接，进而提高方案的安全性和对常见几何攻击的鲁棒性。基于特征点的图像型超链接生成方法。该方法充分利用了载体合成框和图像特征点鲁棒性的优点，不需要固定载体图像嵌入超链接，因此提高了方案的安全性和对常见几何攻击的鲁棒性。该方法涉及基于公共数据集进行随机抽取，得到真实数据集。 对所述真实数据集进行处理，得到真实特征点和图像的边缘图。 基于所述真实数据集、所述图像的真实特征点和所述边缘图训练图像合成网络模型，得到预训练模型。 超链接被编码成01比特串以生成消息矩阵。 基于所述消息矩阵隐藏所述图像真实特征点处的消息，得到隐藏超链接的特征点矩阵。 基于所述预训练模型和所述隐藏超链接的特征点矩阵得到合成图像。 提取合成图像的特征点。 基于秘密消息提取算法提取所述合成图像的特征点的秘密信息。 恢复超链接。 14
本发明提供一种产生实体关系抽取模型的装置及方法。该装置接收待标注文本，基于待标注文本中的多个字段以及实体关系数据库中的该等实体信息与该等关系信息，产生对应各该字段的至少一待标注实体信息以及对应各该字段的至少一待标注关系信息。该装置根据改良式标注格式对各该字段的该至少一待标注实体信息及该至少一待标注关系信息进行标注。该装置由该至少一标注后实体信息与该至少一标注后关系信息产生多个组合且存储至实体关系数据库。以预训练语言模型为基础，该装置将该等组合输入至预训练语言模型，以产生实体关系抽取模型。用于生成实体关系抽取模型的装置，所述实体关系抽取模型用于抽取包括实体和关系的文件中的有用知识。 用途包括但不限于搜索引擎、自动导航、知识问句、推荐系统和对话机器人。该装置提供快速标记输入数据和扩增实体关系数据库，自动生成大量数据，无需人为干预，从而能够快速训练出实体关系抽取模型。该模型具有存储器，用于存储包括若干实体信息和关系信息的实体关系数据库。 处理器，与所述存储器电性连接，用于执行预打标程序和训练模型程序。 预标记程序包括接收(S501)待标记文本，并基于待标记文本中的多个字段以及实体关系数据库中的多个实体信息和多个关系信息，生成(S503)与每个字段对应的实体信息部分和与每个字段对应的关系信息部分。 从经标记的实体信息和经标记的关系信息生成多个组合，并将其存储(S507)在实体关系数据库中。 将所述多个组合输入(S509)到所述预训练语言模型中，以基于所述预训练语言模型生成实体关系抽取模型。包括用于生成实体关系抽取模型的方法的独立权利要求。  11
本发明提供了一种基于联合模型的廉政和民生新闻事件抽取方法，使用网络爬虫爬取网络公开廉政和民生领域新闻，对原始语料进行数据清洗，获得可用的文本语料数据；对数据进行人工标注，获得质量较高的数据集；使用预训练语言模型Bert获得词嵌入表示；实现长短期记忆神经网络模型捕获文本数据单词之间的依赖特征，并作为共享参数层，实现联合提取；实现多层标签指针网络分别提取触发词和事件参数，解决角色重叠问题。本发明通过网络公开廉政和民生新闻人工标注数据集，利用预训练语言模型和循环神经网络挖掘廉政和民生新闻文本数据的深层语义信息，利用多层标签指针网络解决角色重叠问题，在廉政和民生新闻事件抽取任务上取得了较好的效果。基于联合模型的诚信民事学生新闻事件提取方法。该方法使得能够利用预训练语言模型和循环神经网络挖掘诚信民事新闻文本数据的深层语义信息，以避免利用多层标签指针网络的角色重叠缺陷。 本发明对ICAC、民事新闻事件的任务提取效果更好。该方法涉及使用网络爬虫攀爬公共和廉政新闻和民事新闻。 对公众和廉政新闻、民事新闻进行文本预处理操作。 获得可用的廉政民生文本语料库。 对获取的文本语料中的新闻数据进行人工标注。 使用Bert预训练语言模型获得标记的诚信民事新闻数据集的词嵌入表示。 使用多层标签指针网络触发词抽取过程，得到用于实现事件类型检测过程的触发词集合。 使用注意力机制将所述触发词集合和所述词嵌入表示组合成新的特征表示。 使用长期记忆神经网络模型捕获相邻特征表示序列中的语义特征。 使用多层标签指针网络提取事件参数，用于获得最终结果。  12
本发明公开了一种基于MEDU‑Net+网络的医学图像分割方法，包括：采用GoogLeNet中的inception模块替代原U‑Net网络中用于提取图像特征信息的3×3卷积层，其包括多个分支以构成多尺度编码器；对U‑Net网络的解码器做相应优化，采用多尺度解码方式以恢复已获取到的不同尺度的语义信息；其中，编码器和解码器的每个分支均一一对应，引入一层一回传的跳跃连接将编码端提取的信息直接传递至解码端，中间连接的每一部分都是下一个相邻层的转置卷积；结合广义Dice损失函数和Focal损失函数，根据医学图像自身特性引入权重以生成组合形式的损失函数。本发明能够通过少量的数据尽可能多的学习到图像特征，得到更好的分割结果。基于MEDU-Net+网络的医学图像分割方法，用于对患者的医学图像进行训练和测试处理。 也可用于医学图像分析系统。该方法使得能够通过少量的数据尽可能多的学习图像特征，得到较好的分割结果。 该方法提供了一种新的组合损失函数，结合广义Dice和Focal损失函数的优点提取更多的边缘信息，在不增加更多参数的条件下获得更好的分割性能。该方法涉及使用GoogLeNet中的inception模块代替原U-Net网络中用于提取图像特征信息的3×3卷积层。 包括多个分支以形成多尺度编码器。 MEDU-Net+network的解码器也做了相应的优化。 采用多尺度解码方法，对获取的不同尺度的语义信息进行恢复。 编码器和解码器的各个支路是一一对应的。 引入层一回跳连接，将编码端提取的信息直接传递到解码端。 中间连接的每个部分是下一个相邻层的转置卷积。 将广义Dice损失函数和Focal损失函数进行组合。 根据医学图像本身的特点引入权值，生成组合损失函数。包括用于基于MEDU-Net+网络的医学图像分割系统的独立权利要求。   6
本发明公开了一种基于人工智能BERT模型实现智能学生服务的方法，包括信息采集用以形成集合；给形成的集合打标签形成类别后将打完标签的语料信息录入数据库；然后基于BERT+BM2构建AI模型；构建好AI模型后建立AI后端服务并通过java实现中端服务，而前端程序能调用中端java服务；搭建完上述系统后进行交互，交互完成后，收集用户针对本次服务的满意度，以便调优模型或者不断补充问题。解决现有学生服务系统中不具备智能解答功能以及即便有类似工具，但不够智能、智慧的问题。一种基于人工智能(BERT)BERT模型实现在线教育特别是网络教育和成人教育信息化推广智能学生服务的方法。本发明解决了现有学生服务系统不具备智能答题功能，甚至不具备类似工具，不具备智能性和智能性的问题。 BERT权重增加，BM25(词频权重减少)，Lingua问题语义比较低，可以提高词频权重。 该系统更智能的理解学生的问题，需要协助的服务内容，为了速度更快，可以通过网络与学生进行交流。红木 (RTM)缓存问题列表，及时调整对学生的答案反馈，同步增加系统并发承受力，同步提高系统性能。该方法包括收集信息以形成集合。 在形成所形成的组标签的类型之后，语言数据标签信息被记录到数据库中。 基于Bert+Bm2构建人工智能(AI)模型。 建立AI模型。 通过本发明，实现了AI后端业务和中端业务。Java (RTM)：计算机编程语言(RTM)：面向对象编程语言)通过Java (RTM：计算机编程语言)。 前端程序由中间端调用Java (RTM：计算机编程语言)服务。 在建立该系统之后执行交互。 交互结束后，收集用户针对该服务的满意度。  12
本发明提供了一种欺骗性语音鲁棒检测方法、系统、介质及设备，能够有效地应对语音合成、语音转换、重放攻击、对抗攻击等自动说话人验证(ASV)系统中可能存在的攻击方式。该方法包括：获取无标注语音数据集并进行概率性数据增强，使用预处理后的语音数据集预训练上游自监督模型提取高级语音表示，使用深度伪造语料库训练下游分类模型并微调预训练模型，训练好的模型可以对不同的攻击方式进行语音伪造的鉴别。本发明所提出的方法，能够提高鉴别欺骗性语音的鲁棒性和准确率，有效增强ASV系统身份认证的安全性。该方法和设备对于在电子设备(要求保护的)中稳健地检测欺诈性语音是有用的。 也可用于语音合成、语音转换、重放攻击和对抗攻击。本发明提高了欺诈语音识别的鲁棒性和准确性，有效地增强了自动说话人验证(ASV)系统身份认证的安全性。 该方法能够有效应对语音合成、语音转换、重放攻击、攻击等攻击模式下存在的ASV系统。 训练后的模型可以识别出不同攻击模式的语音伪造。该方法包括获得未标记的语音数据集和增强概率数据。 利用所述预处理后的语音数据集对上游自监督模型进行预训练。 训练下游分类模型。 利用深度伪建模语料对所述上游自身监控模型进行裁剪。 结合所述组合训练后的上游自监督模型和下游分类模型识别不同攻击模式的语音伪造。还包括独立权利要求：欺骗语音鲁棒检测系统； 以及计算机可读存储介质，其包括用于稳健地检测欺诈性语音的一组指令。 3
本发明涉及基于BERT并融合N‑gram特征的实体抽取方法，包括步骤：将语料文本输入BERT预训练模型转换为字向量；基于语料文本构建N‑gram特征向量，所述N‑gram特征向量的维度与字向量的维度相同；将字向量和N‑gram特征向量进行融合，得到融合后的高维向量；将融合得到的高维向量经过一个全连接层后输入CRF模型中进行解码，得到语料文本中每个字符是否属于某一实体的概率分布。本发明基于BERT+CRF模型融合N‑gram特征向量，提取出来的高维向量能够包含更加丰富的特征，使模型拥有更加丰富的知识。基于BERT和融合N-gram特征提取实体的方法。该方法基于BERT预训练模型和N-Gram特征融合，充分发挥文本数据的上下文信息，对文本信息进行挖掘，提高了实体提取的准确性。 该方法让提取的高维向量包含丰富的特征，使模型具有丰富的知识。该方法包括将语言学数据文本输入到BERT预训练模型中成为词向量。 基于所述语言学数据文本构建N-gram特征向量。 N-gram特征向量的维度与词向量的维度相同。 将所述词向量与所述N文本特征向量进行融合，得到融合后的高维向量。 将所述融合得到的高维向量经过全连接层后输入CRF模型进行解码，得到所述语言学数据文本中每个字符属于某一实体的概率分布。  12
本发明提供结合知识库基于深度学习的规划项目分类方法，包括：将训练数据集通过数据读取器读取训练数据，然后加上领域知识库相关内容一起经过数据预处理工具进行处理作为训练输入；将分类标签集经过用户释义工具处理后，然后进行向量计算；将所述数据预处理工具的处理结果与所述向量计算结果通过Ernie语义匹配网络进行匹配，然后通过损失函数处理后通过优化器优化处理，最后通过评估工具进行评估，评估通过则形成分类模型，依据分类模型对数据预处理结果进行标签向量计算，得到分类结果。本发明通过引入知识库对训练数据进行知识增强，并且对分类标签进行概念扩充后，使通用模型编码后尽可能多的保留分类信息，进而达到更高精度的提升。基于深度学习的规划项目分类方法。该方法通过引入知识库，扩展分类标签的概念，增强了训练数据的知识。该方法涉及由数据读取器从训练数据集中读取训练数据。 将训练数据与领域知识库的相关内容一起作为训练输入，通过数据预处理工具进行处理。 通过用户定义工具对分类标签集合进行处理。 通过Ernie语义匹配网络将所述数据预处理工具的处理结果与向量计算结果进行匹配。 通过评估工具评估优化器的优化结果。 评估通过时形成分类模型。 计算标签向量，得到分类结果。  11
本申请提供了一种基于大语言模型的类目预测方法、装置和设备，该方法应用于人工智能技术领域。该方法包括：获取待预测商品标题；对所述待预测商品标题所属的类目进行分类，得到置信度满足预设条件的多个候选类目；基于所述多个候选类目，确定描述所述待预测商品标题的类目预测任务的语言提示词；采用已微调大语言模型基于所述语言提示词对所述待预测商品标题进行类目预测，得到所述待预测商品标题的目标类目。该方法通过筛选出的置信度较高的候选类目生成更符合人类意图的语言提示词，并进一步对待预测商品标题进行类目预测，能够提高待预测商品标题的目标类目的准确度。人工智能(AI)技术领域中的基于大型语言模型的类别预测方法。通过选择的置信度较高的候选类别生成语言提示词更加符合人类意图，并预测待预测文章标题的类别，可以提高目标类别的准确性。该方法涉及获取待预测商品的名称。 对所述商品标题所属的类别进行分类。 获取置信度满足预设条件的多个候选分类。 基于所述候选类别确定语言提示词，以描述所述待预测商品名称的类别预测任务。 利用微调整的大语言模型对所述标题的类别进行预测，得到待预测商品标题的目标类别。独立的权利要求是一种基于大型语言模型的类别预测装置。  11
本公开公开了基于多模态商品评论分析的商品推荐方法及系统，包括：获取某商品的评论信息；对获取的商品的评论信息进行数据预处理；判断评论信息中是否有图像，如果有图像，则对图像提取图像的情感标签；判断评论信息中是否有视频，如果有视频，则将视频中的音频提取出来，将音频转换为文本；判断评论信息中是否有音频，如果有音频，则将音频转换为文本；判断评论信息中是否有文本，如果有文本，则将评论信息中的文本与转换得到的文本进行整合，得到整合后的文本；对整合后的文本，提取文本的情感标签；将图像的情感标签和文本的情感标签，均输入到预训练的神经网络中，输出当前商品的推荐标签。所述方法对于通过使用电子设备(主张)基于多模式商品评论分析来推荐商品是有用的。基于多模式商品评论分析推荐商品包括获取某一商品的评论信息，对获取的商品的评论信息进行数据预处理，判断评论信息中是否存在图像，从图像中提取图像的情感标签，判断评论信息中是否存在视频，从视频中提取音频并将音频转换为文字，如果不存在视频，则进入下一步，判断评论信息中是否存在音频，将音频转换为文字，进入下一步， 判断评论信息中是否存在文本，如果存在文本，则将评论信息中的文本与转换后的文本进行整合，得到整合文本，如果不存在文本，则返回获取商品的评论信息的步骤，提取文本的情感标签，并提取当前商品的推荐标签。还包括独立权利要求，用于：一种基于多方式商品评论分析的商品推荐系统； 以及计算机可读存储介质，包括用于基于多模式商品评论分析来推荐商品的指令集。 9
本申请涉及一种人机聊天方法、装置、计算机设备和存储介质。通过预设大语言模型对携带预设话题匹配条件的预设话题关键字进行扩充，得到包含多个预设话题信息的话题信息集，响应用户的聊天启动指令，根据用户属性信息与预设话题匹配条件的匹配结果得到目标话题信息集，并在检测到当前聊天预警满足话题主动输出条件时，输出目标话题信息集中的目标话题信息，使得用户根据目标话题信息进行聊天。相较于传统的由用户主动问询，机器回答的聊天方式，本方案通过预先基于大语言模型构建话题信息集，并在用户进行人机聊天时，在合适的时机主动输出话题信息集中的话题，使得用户基于输出的话题进行聊天，提高人机聊天的流畅度。人机聊天方法。由于在用户进行人机聊天时，在合适的时间主动输出话题信息集合中的话题，使得用户可以根据输出的话题进行聊天，从而提高了人机聊天的流畅性。该方法涉及响应于用户的聊天开始指令，获得对应于用户的用户属性信息(S202)。 根据用户属性信息与多个预设话题匹配条件的匹配结果确定(S204)包含多个预设话题信息的目标话题信息集合。 根据预设大语言模型对携带预设话题匹配条件的预设话题关键词进行扩充得到多个预设话题信息。 在检测到所述当前聊天上下文满足话题主动输出条件时，获取所述目标话题信息集合中的目标话题信息(S206)。 将所述目标话题信息输出给所述用户，以使所述用户根据所述目标话题信息进行聊天。独立权利要求包括以下内容：人机聊天装置； 计算机装置； 计算机可读存储介质，其存储有人机聊天程序； 以及一种用于人机聊天的计算机程序产品。 8
本发明公开一种基于知识库和多步提示的预训练大模型代码生成方法。首先获得新的问题描述与其对应的测试用例集合，如果不存在算法生成模型，获取大量历史问题描述和测试用例集合，代入提示模板并输入预训练模型生成算法描述，由人类数据标记员对算法描述根据其与知识库的符合程度进行打分和排序，构造训练集合训练知识奖赏模型，作为后续训练过程中的奖赏。将问题描述输入算法生成模型，生成算法描述；将算法描述输入知识奖赏模型评估与知识库的符合程度和代码生成模型评估测试样例通过率，两者作为算法生成模型的优化目标，更新模型参数直至训练误差低于预设阈值。测试过程中生成算法描述与代码解决方案，重复该过程直至代码通过全部测试用例。软件自动化领域中基于知识库和多步提示的大模型代码生成预训练方法。 也可用于软件工程领域。预训练大模型代码生成方法包括获取大量历史问题描述和测试用例集，并代入提示模板，因此确保了预训练大模型代码生成方法的简单和高效。该方法涉及获取(1)待生成目标代码的问题描述和测试用例集。 进行确定(2)以检查是否存在经训练的算法生成模型。 当没有训练好的算法生成模型时，初始化训练好的算法生成模型。 构建训练集。 建立知识奖励模型。 形成代码生成模型。 算法描述被输入到强化学习算法中的训练算法中。 将目标代码的问题描述输入训练后的算法中，生成算法描述。 当所述代码解不通过所述测试用例时，结束所述代码生成过程。独立权利要求包括：(1)一种计算机设备； (2)一种计算机可读存储介质，其存储有用于生成预训练大模型代码的程序。  11
本申请涉及一种图文预训练模型训练、图文预测模型训练方法、装置、计算机设备、存储介质和计算机程序产品。方法包括：将训练图像原始特征和训练文本原始特征进行特征掩盖，得到训练图像目标特征和训练文本目标特征，并将训练图像目标特征和训练文本目标特征输入到初始图文预训练模型中进行图文匹配程度评估，得到初始图文匹配程度，并使用初始图文匹配程度、训练目标图像特征和训练目标文本特征进行跨模态信息交互，得到初始图像交互特征和初始文本交互特征，并进行迭代训练得到目标图文预训练模型。采用本方法能够提高训练的准确性。本发明实施例可应用于云技术、人工智能、智慧交通、辅助驾驶等各种场景。在不同领域中使用计算机设备(声称)训练图文预训练模型的方法。 用途包括但不限于个人电脑、笔记本电脑、智能手机、平板电脑、物联网设备和便携式可穿戴设备、智能音箱、智能电视、智能空调、智能车载设备、飞行器、智能手表、智能手环和头戴设备在云技术、人工智能、智能交通和辅助驾驶领域。该方法能够提高模型训练的预训练模型和图文预测模型的训练精度。该方法包括获取训练图像对应的训练图像的原始特征和训练文本对应的训练文本的原始特征。 将训练图像目标特征和训练文本目标特征输入初始图文预训练模型。 通过所述初始图文预训练模型进行图文匹配度评估，得到初始图文匹配度。 基于所述训练图像原始特征、训练文本原始特征、图像交互特征、文本交互特征和所述图片匹配度进行模型损失计算过程，得到训练模型损失信息。 基于所述训练模型损失信息对所述初始图文预训练模型进行训练。 得到目标图文预训练模型。 利用所述目标图文预训练模型基于图文训练模型进行跨模式预测过程。包括独立权利要求：(1)一种n图文预测模型训练方法； (2)图文预训练模型训练装置； (3)图文预测模型训练装置； (4)一种计算机可读存储介质，用于存储由处理器执行的用于训练图文预训练模型的指令集。 14
本发明公开了一种基于深度学习的图像跨尺度超分辨率方法，首先通过传统的图像处理算法创建生物图像数据集；然后基于深度学习网络U‑net，去除原始生物图像中的噪声及冗余信息，得到网络处理后的超分辨率的生物图像；接下来基于生物图像数据集和深度学习网络，提升图像的空间分辨率，实现生物图像的跨尺度超分辨率；最后基于网络输出的结果图，进行三维重构，得到跨尺度微纳结构的三维构象的高分辨率的还原。本发明可以在少量数据图像的情况下实现的生物图像跨尺度超分辨率，达到了比较好的效果。一种基于深度学习的图像跨尺度超分辨率方法。本发明能够在数据图像较少的情况下实现生物图像的跨尺度超分辨率，取得了较好的效果。该方法包括收集低分辨率的原始共焦生物图像。 图像处理算法用于去除所获取的原始共焦生物图像的噪声和冗余信息。 将原始共焦生物图像与相应的高分辨率清晰生物图像组合成图像对，构建生物图像数据集。 生成的生物图像数据集用于训练深度神经网络U-网。 将待检测的低分辨率原始共焦生物图像输入训练好的深度神经网络U-网。 将相邻原始共焦生物图像输入训练好的深度神经网络U-网，得到相应的清晰的超分辨率输出结果图。 这些结果图像的三维重建可以获得跨尺度微纳结构三维构象的高分辨率恢复。   6
本申请提供了一种对话数据生成方法、模型训练方法及相关装置，该方法包括：获取对话属性信息，所述对话属性信息至少包括对话角色、对话场景、对话流程阶段和对话目标；根据所述对话属性信息，生成任务指令；将所述任务指令输入预训练的大语言模型，以使所述大语言模型按照所述任务指令生成对话数据。根据本申请的技术方案，不仅能够实现对话数据自动生成，提高对话数据生成效率，满足对对话数据的数据量需求，还可以保证生成的对话数据的质量，且能够适应多领域、多场景的对话数据生成，灵活性高。用于生成心理咨询对话模拟场景和客户服务对话模拟场景等对话数据的方法。该方法实现了对话数据的自动生成，提高了对话数据的生成效率，满足了对话数据的数据量需求，保证了生成的对话数据的质量，并且适应多领域、多场景的对话数据生成，灵活性高。所述方法包括：获取对话属性信息(S101)，所述信息包括对话角色、对话场景、对话流程阶段和对话目标，所述对话流程阶段包括实现所述对话目标所需经历的各种对话阶段。 根据所述对话属性信息生成任务指令(S102)，所述任务指令指示接收所述任务指令的对象生成符合所述对话属性信息的对话数据。 将所述任务指令输入(S103)预先训练的语言大模型，以使所述模型根据所述任务指令生成对话数据。 根据所述对话属性信息确定对话数据生成任务，所述任务包括生成符合所述对话属性信息的对话文本的任务。独立权利要求包括以下内容：(1)模型训练方法； (2)对话数据生成方法； (3)对话数据生成装置; (4)电子设备； 以及(5)存储介质，其存储用于生成对话数据和模型训练的程序。 8
本发明提供一种在婚恋软件上根据条件搜索人脸的方法，包括以下步骤：使用开源数据集CelebA中的图像和人脸属性标签，训练人脸属性分类模型，提取40个类别的人脸属性标签，使用S1中训练好的模型提取用户生活照的人脸特征标签，使用S2中构建的数据集，对CLIP的预训练模型进行微调，实现文本描述和图像特征相结合的多模态对比学习，根据业务需求选择需要搜索的文本标签，使用CLIP模型提取人脸属性标签，用于条件人脸搜索。本发明提供的一种在婚恋软件上根据条件搜索人脸的方法及装置，通过多模态对比学习的方法，对CLIP模型进行微调训练，并结合用户基本的属性信息，实现了不同模态数据的联合搜索，通过本发明所述方法。一种在婚姻软件上基于条件进行人脸搜索的方法。该方法能够对CLIP的预训练模型进行微调训练，实现文字描述和图像特征结合的多模态对比学习，根据服务需求选择需要搜索的文字标签，利用CLIP模型提取人脸属性标签对条件人脸进行搜索，并结合用户的基本属性信息，从而实现了不同模态数据的联合搜索。该方法涉及在图像和面部属性标签中使用开源数据集CelebA。 训练人脸属性分类模型。 提取40个类别的人脸属性标签。 利用训练好的模型提取用户生命的人脸特征标签。 利用预先训练的人脸关键点提取模型提取所述特征点。 根据业务需求选择需要查找的文本标签。 采用剪辑模型提取所述文本标签。 将用户图像face face人脸特征标签和用户的基本信息写入一个ES聚类，实现不同模式的联合搜索。本发明还公开了一种基于条件的婚姻软件的人脸搜索装置。 2
本发明公开基于自监督学习和互信息解耦技术的语音合成方法，主要包括数据预处理；采用HUBERT和wav2vec模型作为预训练的大模型，并采用大量的无标签方式对齐进行训练；设计说话人分类和风格分类两个任务作为下游任务，固定训练模型的权重参数，用于得到任务相关的特征表示；利用互信息对Tspeaker和Tstyle进行解耦；将学习好的Tspeaker和Tstyle添加到端到端语音合成模型中，端到端语音合成模型采用encoder‑attention‑decoder结构。本发明提升多说话人和多风格语音合成的质量，同时提高合成模型对于少量数据的快速适应能力。基于自监督学习和互信息解耦技术的语音合成方法，用于将输入文本转换为对应的语音。该方法提高了多说话人、多风格语音合成的质量，提高了合成模型对少量数据的快速适应能力。该方法涉及进行数据预处理，其中文本需要在前端进行处理，通常以字符作为输入，文本和音频是配对的。 该数据可以用作训练数据。 预处理还需要提取梅尔光谱的特征。 采用自监督学习方法训练大模型，HUBERT和wav2vec模型作为预训练大模型，采用无人标签对齐进行训练。 设计说话人分类和风格分类两个任务作为下游任务，固定模型的权重参数，得到任务相关特征表示。 首先用大规模数据对端到端模型进行预训练，预训练时Tspeaker和Tstyle均为0的向量，对多说话人多风格数据集进行finetune得到最终模型。 3
本发明提供一种功能模块的控制方法、装置、设备以及计算机可读介质，该方法应用于不带有显示屏的电子设备，该电子设备中预配置了大模型；所述大模型包括多个功能模块，该方法通过获取用户的功能模块选择信息；其中，所述用户的功能模块选择信息用于说明所述用户选择启动的功能模块；所述用户的功能模块选择信息通过摄像头或者音频采集模块采集得到；根据所述用户的功能模块选择信息，识别出所述功能模块选择信息匹配的功能模块；启动所述大模型中的所述功能模块选择信息匹配的功能模块，实现了大模型在不带有显示屏的电子设备中的应用。用于在无显示屏的非屏幕设备即点读笔中控制大型号的功能模块的方法。该方法保证启动大机型中的功能模块选择与该信息匹配的功能模块从而实现大机型在无显示屏的电子设备中的应用。该方法包括获取用户的功能模块选择信息。 用户的功能模块选择信息用于解释用户选择并启动的功能模块。 通过摄像头或音频采集模块采集一个功能模块。 根据所述功能模式选择信息识别与所述功能模块选择信息匹配的功能模块。 当函数与大模型中的函数匹配时，在大模型中启动函数。独立权利要求包括用于：(1)功能模块的控制装置； (2)一种计算机可读介质，其上存储有计算机程序。  11
基于文本和视觉上下文关系时间融合的视频文本检索方法，涉及视频文本检索。使用预训练模型CLIP的文本编码器和视觉编码器提取文本特征和帧级别视觉特征；使用时间编码器对加入时间位置信息的帧级别视觉信息编码；使用文本上下文注意力TCA根据每个帧和文本的相似度估计每个帧的注意力权重；使用视觉上下文注意力VCA根据视觉上下文关系过滤无关的帧；使用文本上下文相似度和视觉上下文相似度的均值作为检索目标的相似度，根据得到的相似度计算损失函数。相比平均池化，基于文本和视觉上下文计算每个帧权重的方法更有利于排除不必要的帧，实现有效的时间融合。通过TCA和VCA的联合作用更好地理解文本和视觉之间关系，提高检索精度。基于文本和视觉上下文关系时间融合的视频文本检索方法。基于文本和视觉上下文计算各帧权重的方法更有利于剔除不必要的帧，实现有效的时间融合。 通过TCA和VCA的共同作用更好的理解文本与视觉的关系，提高检索精度。该方法涉及利用对比语言图像预训练(CLIP)模型的文本编码器和视觉编码器提取文本特征和帧级视觉特征。 对利用时间编码器添加了时间位置信息的帧级视觉信息进行编码，并且使用文本上下文注意力(TCA)根据每个帧和文本的相似性来估计每个帧的注意力权重。 根据具有视觉上下文注意(VCA)的视觉上下文来过滤不相关帧。 取文本上下文相似度和视觉上下文相似度的平均值作为检索目标的相似度，根据得到的相似度计算损失函数。 9
本发明公开了一种基于弱标签标注文本的公司名实体识别方法。该方法包括：将清洗后的弱标签文本集使用通用公司名词库继续标注并切分成多个包含5000样本的文本子集；然后由BERT预训练神经网络和Softmax回归模型构建的模型在每个文本子集上进行训练，在每轮训练结束后，识别并筛选文本中的未标注公司名字段，并使用分词模型过滤无用字段。重复该步骤，直至不再产生新的未标注公司名；最后，将未标注公司名在文本集上继续标注，并将模型在最终标注的文本集上继续训练。此外，本方法在弱标签公司名实体识别场景中，首次考虑了模型在欠拟合状态下能够识别未标注公司名的特性，并使用分词模型过滤模型识别出的无用字段，提高了弱标签公司名实体识别的准确率。基于弱标签标注文本的公司名称实体识别方法。考虑欠拟合状态下模型识别特征公司名称的公司名称实体识别方法，利用分割模型过滤模型识别无用字段，提高弱标签公司名称实体识别的准确率。公司名称实体识别方法涉及获取公司名称实体标签的弱标签文本集。 弱标签为英文字母大小书写统一，中英文标点符号统一，传统简体中文依次用文字中的文字集合标注。 删除乱码和印刷体字符清洗操作，得到清洗后的弱标签文本。 由通用公司名称词库生成新的弱标签标注文本，生成强弱标签标签文本集。 将强弱标签文本划分为包含三千到七千个子集的文本。 利用生物编码格式对每个文本子集中的文本进行编码。 通过双向编码器表示(BERT)预训练神经网络和软最大回归模型构建实体名称识别模型。  12
本发明公开了一种基于深度学习算法的电力设备缺陷短文本的分类方法和系统，其中分类方法具体包括：对描述不规则的电力设备缺陷短文本基于Bert算法进行语义表示，获取实施语义特征向量；将预训练家族特征矩阵和实施语义特征向量进行线性变换后，输入至改进的多头注意力模块进行加性注意力机制、残差连接、拼接以及线性变换运算, 从而提取预训练家族特征矩阵和语义特征向量的隐藏特征，得到转换后的特征向量；基于Softmax分类函数，对转换后的特征向量进行平均池化和非线性激活，确定描述不规则的电力设备缺陷短文本对应某一种标准化描述的缺陷类型的最佳匹配结果；实现对人工录入的不规则的缺陷描述进行标准化分类，同时提高分类的准确度。基于深度学习算法的电力设备缺陷短文本分类方法。该方法结合各类别的历史家族特征，通过归纳式学习处理，实现了对输入文本的增强语义表示，从而提高了短文本分类的准确性。 该方法允许根据训练阶段短文本的历史信息创建家族特征融合算法模型，有效利用同类文本特征，利用训练样本不断强化家族特征信息，更新家族特征矩阵，增强整个系统的学习能力。 将包含相同历史文本语义信息的家族特征做成基于多头注意力机制的语义表达，从而增强了语义类型特征，有助于消除类决策边界模糊的缺陷，提高了分离超平面的分类效果。该方法涉及基于Bert算法对描述电器设备不规则缺陷的短文本进行(S1)语义表示，得到短文本对应的一组实施语义特征向量。 两组相同的预训练的家族特征矩阵和一组语义特征向量被线性变换，并被输入(S2)到改进的多头注意力模块。 进行加性注意力机制、残差连接、拼接和线性变换操作，提取所述预训练的族和语义特征向量的隐藏特征，得到转换后的特征向量。 对转换后的向量进行平均池化/非线性激活(S3)，以基于Softmax分类函数确定对应于某类缺陷标准化描述的描述不规则电气设备缺陷的短文本的最佳匹配结果。包括独立权利要求用于一种基于深度学习算法的电力设备缺陷短文本的分类系统。 0
英文语法纠错是自然语言处理领域中的一个重要研究方向。传统的语法纠错系统多基于规则判断，能够检测出的错误种类有限，扩展能力差。现有的基于循环神经网络的语法纠错系统在面对长句子时，容易丢失头尾的信息，且由于无法并行提取特征，致使训练周期长。本发明提供了一种基于CNN与BERT模型的英文语法纠错方法。模型采用了CNN+Attention+BERT结构，实现方式采用了Encoder‑Decoder框架。通过卷积，能够高效并准确地提取上下文的特征；Attention层为不同的单词增加的权重，使得模型可以学到更重要的特征；BERT采用了Masked Language Model的方式来训练语言模型，通过fine‑tuning可以为其添加(0, 1)分类任务，用于为纠错系统输出的句子评分，提高系统准确度。该方法在自然语言处理领域中是有用的。该方法高效准确地提取上下文的特征，对不同的词添加权重使得模型能够学习到更重要的特征，使用掩蔽语言模型训练语言模型，对纠错系统输出的句子进行打分并提高纠错系统的准确率。基于卷积神经网络(CNN)和来自变换器(BERT)模型的双向编码器表示来纠正英语语法错误包括：使用基于编码器-解码器框架的CNN+模型来纠正英语句子; 以及使用BERT模型对所述英文句子进行打分。  11
本发明公开了一种碑文文字提取方法、装置、设备及介质，涉及图像处理领域，其技术方案要点是：以一个U‑Net网络作为重复网络单元进行网络的堆叠，获得第二生成器，其中U‑Net网络的卷积运算是由1×1大小的卷积核和3×3大小的平均池化依次完成的；根据第一生成器和第一判决器构成第一组生成对抗网络，根据第二生成器和第二判决器构成第二组生成对抗网络，依据两组生成对抗网络对第一生成器和第二生成器进行交叉训练，在训练次数达到预定次数时，得到对碑文图片的前景与背景具有分割提取能力的第二生成器，其中第二生成器的末位U‑Net网络为第一生成器。本发明解决了现有技术无法有效提取具有高度自相似前景与背景特征的碑文的问题。利用电子装置提取铭字的方法(权利要求书)和图像处理领域。该方法解决了现有技术无法有效提取具有高自相似性前景背景特征的药片的问题。该方法涉及通过使用U-Net网络作为重复网络单元来堆叠网络以获得第二生成器(S101)。 U-Net网络的卷积运算依次由1*1大小的卷积核和3*3大小的平均池完成。 U-Net网络由编码器和解码器构建。 编码器的激活函数的斜率大于1。 根据第一生成器和第一判断器形成第一组生成对抗网络(S102)。 根据第二生成器和第二判断器形成第二组生成反制网络。 所述第二生成器是在所述训练次数达到预定次数时，对所述铭文图片的前景和背景具有分割提取能力得到的。 根据所述第二生成器分割提取所述待处理铭文图片的铭文字符(S103)。独立权利要求还包括用于：铭文字符提取装置； 以及计算机可读存储介质，其包括用于提取题词字符的一组指令。   6
本公开提供了一种基于持续学习的事件抽取的模型训练、事件抽取的方法、装置及设备，属于自然语言处理技术领域，其中，该方法包括：获取文本流数据集；将文本流数据集输入至预训练的语言模型和自注意力机制中进行处理，得到与文本流数据集中文本对应的第一融合特征向量；采用知识蒸馏的方式，利用第一融合特征向量训练待训练的基于持续学习的事件抽取模型的学生网络和教师网络，得到基于持续学习的事件抽取模型，通过知识蒸馏框架实现知识迁移学习，利用历史增强特征转移网络使事件抽取模型能够在学习新事件知识的同时不会遗忘已经学习过的历史事件知识，在对新增事件类型检测的同时仍可以对历史事件类型进行检测，实现持续性事件学习和检测。所述方法和设备对于基于电子设备中的连续学习(声明)的事件提取的模型训练是有用的。该方法通过使用历史增强特征传递网络的知识蒸馏框架实现知识迁移学习，使得事件提取模型在学习新事件知识的同时不会遗忘已学习的历史事件知识，在检测新加入的事件类型的同时检测历史事件的类型，实现持续事件学习和检测。该方法包括获得文本流数据集。 所述文本数据集中设置有0-t-1模型的历史文本数据和第t-n个需要识别的新文本数据。 将第t个第一融合特征向量输入待训练的基于连续学习的事件提取模型的学生网络，得到第一特征向量。 根据第二特征向量和所述前t-1个第三特征向量通过历史增强特征传递网络得到第二损失值。 将所述第一损失值和所述第二损失数据的和相加，得到总损失值，利用所述总损失值训练事件提取模型的学生网络和教师网络，得到基于连续学习的事件提取模型。还包括独立权利要求，用于：基于连续学习的事件提取方法； 用于基于连续学习的事件提取的模型训练装置； 以及基于连续学习的事件提取装置。  11
一种利用大语言模型进行情感分类的方法，涉及自然语言处理技术领域，对大语言模型的小部分底层参数进行微调，而不是对所有参数进行训练调整，这种方式以较低的成本，根据提供的数据集，使大语言模型得以在特定任务或某专业领域上的到效果的有效提升，较为高效的完成了大语言模型的微调，且模型回答原先通用问题时的能力保持不变。通过使用大型语言模型例如Chinese-Vicuna(由Chinese company research in motion开发的Chinese语言模型)执行情感分类的方法。该方法能够有效提高大型语言模型对特殊任务或某些专业领域的效果，有效完成语言模型的微调，并保持模型在回答原通用问题时的能力。 根据所提供的数据集，该方法使用低成本。该方法包括对用户输入的语音句子执行语音识别。 语音被转换成字符。 选取大型语言模型作为预训练模型。 从一个情感分类数据集中选取M个数据作为微调任务。 所述数据设置有情绪标签。 所述情绪标签的内容为主动式或被动式。 对所述M个数据进行预处理。 在所述预训练模型之后增加线性层，得到情感分类模型。 对所述情绪分类模型进行优化，得到优化后的情绪分类模型。 将所述预处理文本输入所述优化情感分类模型并输出，得到正向或负向情感分类。独立权利要求还包括：一种用于利用大语言模型进行情感分类的装置； 以及计算机可读存储介质，其包括用于通过使用大型语言模型来执行情感分类的指令集。  11
本发明提供了一种基于翻译模型的跨语言知识图谱问答方法，包括以下步骤：步骤一：要回答输入问题文本，根据给定训练集的特点，在预训练的BERT模型的基础上构建了一个全局指针网络模型；步骤二：基于步骤一的基础，接收一个关键实体作为输入，并输出所有可能的答案路径，这些路径满足基准规则的要求，包括关于关键实体的知识图之间的转换；步骤三：接收步骤二提出的原始输入查询和相应路径，并输出最匹配的答案路径。本发明解决了跨语言的联合应用问题，得到了文本、跨语言两者兼顾，提升了模型的训练稳定性，提升了文本匹配的准确率，做到了文本解析、跨语言联合两者兼顾。面向自然语言智能问答领域的基于翻译模型的跨语言知识图谱问答方法。该方法：解决了跨语言联合应用的问题； 获得文本和跨语言考虑两者； 提高了模型的训练稳定性； 提高了文本匹配的准确性； 并同时实现了文本分析和跨语言融合。该方法涉及回答输入问题文本。 关键实体在应答路径开始时被识别，应答路径被视为具有仅一种类型的混合语言(中文、英文和法文)文本中的NER任务。 根据训练集的特点，在预先训练好的BERT模型的基础上构建全局指针网络模型。 接收密钥实体作为输入。 输出满足路径规则要求的所有可能的答案路径，包括关键实体的知识图谱之间的转换。 接收原始输入查询和对应路径。 输出最匹配的答案路径。  12
一种基于知识增强的预训练模型的代码摘要方法及系统，通过构建知识图谱，将代码知识引入预训练数据并用于对Transfomer模型进行代码知识增强的预训练，经代码摘要生成任务的微调后，通过Transfomer模型进行代码知识预测，生成代码摘要。本发明将知识图谱与训练代码语料结合，使用代码知识预测任务对模型进行预训练，从而将知识隐式地结合到学到的表征中，在不影响效率的情况下提升其在下游代码摘要生成任务上的准确性和可靠性。基于知识增强预训练模型的代码摘要自动生成方法。该方法能够将知识图谱与训练代码语料相结合，对模型进行预训练，从而隐式地结合学习表示中的知识，在不影响效率的前提下，提高下游代码摘要生成任务的准确性和可靠性。所述方法包括构建知识图谱，在所述知识图谱中，在代码摘要生成任务的精细调整之后，将代码知识引入到预训练数据中，以用于预训练变换器模型的代码知识增强。 知识预测是通过转化器模型进行的。 生成代码摘要，其中API结构知识包括实体和关系，实体包括模块、分组、类、函数、变量，关系包括模块对分组的包含关系。 返回函数和类的值关系。 使用函数与参数类型的关系，其中API描述性知识包括实体的自然语言描述。本发明还公开了一种基于知识增强预训练模型的代码摘要自动生成系统。  11
本发明公开了一种基于Google Bert的文档推荐方法及系统，属于文字采矿和信息挖掘等自然语言处理技术领域。该方法包括：获取输入的文本数据，并对其进行预处理，将所述文本数据转化为索引数组；使用Bert模型对所述索引数组进行编码，获取所述索引数组的最终编码；将所述索引数组的最终编码进行0.1的Dropout，并通过softmax计算得到相似度；根据所述相似度对文档进行排序，输出要推荐的文档。本发明提出的基于Google Bert的文档推荐方法通过预测屏蔽子词(先将句子中的部分子词屏蔽，再令模型去预测被屏蔽的子词)进行训练的这种方式在语句级的语义分析中取得了极好的效果。基于Google(RTM：Company Name)Bert的文档推荐方法，用于词挖掘、信息挖掘等自然语言处理技术领域的许多公司的生产工作中。该文档推荐方法通过预测屏蔽子词进行训练，在句子级别的语义分析中获得了优异的效果。该方法涉及获得(S101)输入文本数据。 对所述文本数据进行预处理。 对文本数据进行分词。 一个句子样本拼接成句子样本。 生成索引数组。 通过使用Bert模型对索引数组进行编码(S102)，以获得索引数组的最终编码。 对索引数组的最终代码执行0.1的丢弃(S103)。 相似度通过softmax计算获得。 根据所述相似度对所述文档进行排序(S104)。 输出要推荐的文档。对于基于Google Bert的文档推荐系统，包括独立声明。  12
本发明公开了联合预训练和图神经网络的政策文本标注方法及系统；其中所述方法包括：获取待标注的政策文本，对待标注的政策文本进行预处理；对预处理后的政策文本输入到训练后的政策文本标注模型中，输出政策文本的标注结果；其中，训练后的政策文本标注模型，其工作原理包括：对于处理后的政策文本提取单词向量和句子向量；基于预处理后的政策文本构建文本级图结构，获取文本级图结构对应的邻接矩阵；基于单词向量和句子向量，提取出政策文本的语义特征；基于单词向量和邻接矩阵，提取出政策文本的结构特征；基于语义特征和结构特征，确定政策文本标注结果。使用电子设备的组合预训练和神经网络的策略文本标记方法(权利要求书)。该方法能够使用预训练语言模型和图卷积网络相结合的学习方式，学习文本的结构信息和语义信息，从而减少了对系统资源的占用，并且实现了归纳新词和新文本，从而大大降低了策略分类的人力成本。该方法包括获取待标记的策略文本。 对所述政策文本进行预处理。 提取处理后的策略文本的词向量和句向量。 基于所述预处理后的策略文本构建文本层次图结构。 获取与所述文本级图结构对应的邻接矩阵。 提取所述策略文本的基于词向量的语义特征。 基于相邻矩阵提取所述语义特征。 提取所述策略文本的结构特征。 根据所述语义特征和所述结构特征确定策略文本标记结果，确定所述策略文本标记结果。独立权利要求还包括：一种结合预训练和神经网络的策略文本标注系统； 以及一种存储介质，包括一组预训练与神经网络相结合的策略文本标记方法的指令。  11
本发明公开了一种基于实体空间布局关系的街景图像评估方法，涉及城市规划、旅游规划、自然语言处理与城市交通技术领域，首先，采集研究区内的街景图像，并对街景图像进行语义分割处理。其次，对语义分割后的街景图像，计算图像内各种实体的像素数量占比，以及重要实体的色彩分布特征。进一步，对图像内各种实体之间的空间布局特征建立复杂网络模型，并计算所建立复杂网络模型的主要节点指标。再，对街景图像中各类实体的空间位置进行量化计算。最后，形成机器学习预训练模型，并完成所有图像的自动评估。本发明能够通过街景图像中实体空间布局关系实现街景图像的智能化评估。一种基于实体空间布局关系的用于评估现场使用的街景图像的方法。 用途包括但不限于城市规划，旅行规划，城市交通，复杂网络建模领域，自然语言处理和城市交通领域。本发明通过实体空间布局与街景图像的关系，实现街景图像的智能评价，增强街景图像评价的机器学习模型特征学习能力。该方法包括收集研究区域中的街景图像。 计算街景图像中的每个实体的像素数比以及该实体的颜色分布特性。 为语义分割的街景图像中的多个实体之间的空间布局特征建立复杂网络模型。 对语义分割的街景图像中的每个实体的空间位置进行量化计算处理。 记录每个街景图像的道路类型。 建立街景图像的学习样本库。 利用不同的机器学习算法模型训练机器学习预训练模型，得到训练好的机器学习预训练模型。 利用场景图像的待测机器学习预训练模型进行自动评分过程。 13
本发明公开了一种基于特征融合的中文事件抽取方法，步骤为：1)构建中文事件抽取网络BERT‑FF；2)构建训练数据集；3)下载预训练参数文件并利用对比学习方法进行优化；4)利用迁移学习的方法，在字级别特征提取网络中加载优化后的预训练参数文件；5)利用训练数据集进行训练，得到训练好的中文事件抽取网络BERT‑FF；6)从开放网络中爬取描述事件的文本，作为测试数据集输入到训练好的中文事件抽取网络BERT‑FF中进行事件抽取，输出结构化的事件信息，即事件抽取的结果。本发明通过特征融合方法增强了模型的语义表示能力，提升了中文事件抽取的性能，可用于新闻舆情分析、情报处理、金融风险评估等领域。一种新闻舆情分析、信息处理和金融风险评价领域的基于特征融合的中文事件提取方法。该方法能够通过特征融合过程增强模型的语义表征能力，提高新闻舆情分析、智能处理和金融风险评估等领域的中文事件抽取性能。该方法涉及构建来自变换器的中文事件提取网络双向编码器表示(BERT-FF)。 构建训练数据集，所述训练数据集中设置有从开放网络爬取的描述事件的文本以及与所述文本对应的标注文件。 从开放网络爬取描述事件的文本作为测试数据集输入到训练好的中文事件提取网络BERT-FF中进行事件提取。 输出结构化事件信息。 得到事件提取结果。 计算事件提取的精度和召回率。  12
本发明涉及图像标注数据的智能质检方法及系统，其方法包括：获取多张标注图像及其对应的标注文件；利用预训练模型对每张标注图像进行预测，得到一个或多个目标的预测结果；将所述一个或多个目标的预测结果与每张标注图像的标注文件进行对比，根据每个目标的交并比和类别判断两者的一致性；对判断为不一致的标注文件进行修正，利用修正后的标注文件训练所述预训练模型。本发明通过预训练模型、IOU计算和类别信息对图像标注文件进行质检，不仅能快速准确检测出标注文件的错误，同时也能评估模型对训练数据集的泛化能力和缺陷；最后将更新后的标注数据重新训练网络模型，提高了模型的各项性能指标。一种对图像标注数据进行智能质检的方法。该方法能够通过预测结果与标注文件中的每个标注目标进行联合(Iout)计算和类别信息比较，快速准确地检测出标注文件中出现的错误， 从而评估模型对训练数据集的泛化能力，并因此提高预训练模型的准确性，查全率或映射指数。该方法包括获得(S100)多个注释图像和相应的注释文件。 使用预先训练的模型(S200)来预测每个注释图像，以获得目标的预测结果。 将目标的预测结果与每个标记图像的注释文件进行比较，并且根据每个目标的交叉比率和类别来确定预测结果与注释文件的一致性(S300)。 校正被确定为不一致的注释文件，并且使用校正后的注释文件来训练预训练模型(S400)。本发明还涉及一种图像标注数据智能质检系统。 (2)电子设备； 和(3)存储用于对图像注释数据执行智能质量检查的程序的计算机可读介质。 14
一种基于大模型的知识图谱关系推理方法，利用大模型所具备强大的语义理解能力，将对图谱结构中的实体、关系在语义的程度上进行理解，根据图谱中节点与边或区域子图生成超维数据，利用大模型中的推理机制进行推理，能很好地解决了现有技术难以理解图谱结构中已有的实体和关系语义的问题。应用本发明公开的一种基于大模型的知识图谱关系推理方法，能够针对包含多方面信息的知识图谱实现人员关系清理、事件分析、风险分析等业务应用，不需要编写复杂图谱推理逻辑，对于相关行应用具有很好的实战应用意义。人员关系清洗、事件分析、风险分析的基于大模型的知识图谱关系推理方法。根据地图中的节点和边或区域子图生成超维数据，利用大模型中的推理机制进行推理，可以很好地解决现有技术中地图结构中存在的实体和关系语义难以理解的问题。 对包含多方面信息的知识图谱实施人员关系清理、事件分析、风险分析等业务应用。 消除了编写复杂图推理逻辑的需要，对相关线路应用取得了重大的实际应用意义。该方法涉及获得(S100)待处理的完整图结构，并基于图结构定义和描述实体和关系。 根据第一预设规则对实体和关系的定义进行转换，并将转换后的数据输入(S200)预设微调模型进行微调。 基于该数据集生成用于关系推理的人工智能(AI)提示词(S500)。 采用所述大模型基于所述AI提示词和问题进行推理并对推理结果进行自适应验证(S600)。 将推断出的结果在验证后更新到地图中，并更新地图关系的总数(S700)。本发明还涉及一种电子设备。  11
本发明公开了一种基于BERT孪生注意力网络与融合图嵌入特征的关系选择方法，运用命名实体识别技术从用户的问题中获取命名实体，将命名实体运用实体链接技术链接到知识图谱中的主题实体，在知识图谱上查询与实体连接的3跳内关系，得到候选关系集合，根据问题从候选关系集合中挑选关系，对问题和一个关系通过网络编码后得到两个向量，计算两个向量的余弦相似度作为语义相似得分，选择得分最高的关系，在知识图谱上查询三元组，返回三元组包含的属性值作为问题的答案。本发明采用目前先进的BERT预训练模型作为问题和关系文本的特征抽取器，增强了表示向量的表达能力，有助于提升关系选择效果。一种基于Berttwinborn注意网络和融合图像嵌入特征的关系选择方法。本发明能够使用先进的BERT预训练模型作为问题和关系文本的特征抽取器，增强了表示向量的表达能力，从而提高了关系选择的效果。该方法涉及通过使用命名实体识别从用户的问题中获得命名实体。 命名实体使用实体链接技术来链接知识地图中的主题实体。 生成候选关系。 查询知识图谱上与实体连接的3跳内部关系，得到候选关系集。 根据问题从候选关系集合中选择关系。 计算两个向量的余弦相似度作为语义相似度得分。 在问题被网络编码之后，返回包含在三元组中的属性值作为问题的答案。  12
本发明属于视频识别技术领域，涉及一种基于交叉U‑Net网络的视频异常检测方法及装置，该方法构建的基于自注意力机制的交叉U‑Net模型包括两个子网络，每个子网络都是U‑Net网络，两个子U‑Net网络分别接收前一帧和下一帧来预测当前帧，并且每个子网络由收缩路径和扩展路径组成，在收缩路径中进行交叉连接进行下采样过程，在扩展路径加入自注意力机制进行上采样过程；训练并使用训练后的基于自注意力机制的交叉U‑Net网络模型进行目标视频经FPN网络提取的每一帧进行异常检测。本发明在视频异常检测中引入了交叉U‑Net网络，既考虑了异常检测的精度，又考虑了视频监控中至关重要的异常检测速度。基于跨U-Net网络进行视频识别的视频异常检测方法。该方法在视频异常检测中引入了交叉UNet网络，考虑了异常检测的准确性，同时考虑了视频监控中至关重要的异常检测速度。该方法包括使用特征金字塔网络(FPN)网络进行目标检测并提取视频中的每一帧(S1)。 基于自注意力机制构建交叉U-Net模型(S2)。 基于自注意力机制的交叉U-Net模型包括两个子网络，每个子网络为一个U-Net网络。 分别接收前一帧和后一帧，以使用两个子UNet网络预测当前帧，并且每个子网络由收缩路径和扩展路径组成。 在用于下采样的收缩路径中进行交叉连接，并且在用于上采样的扩展路径中添加自注意机制。 基于自注意力机制训练cross U-Net网络模型(S3)。 基于训练后的自注意力机制使用cross U-Net网络模型得到预测的当前帧(S4)并使用判别器判断是否异常。还公开了一种基于跨U-Net网络进行视频识别的视频异常检测装置。 9
本发明公开了一种基于卷积神经网络模型的构件残余应力反演方法，包括以下步骤：测量构件散点残余应力；建立代理模型，所述代理模型由U‑net卷积网络组成，包括：划分构件有限元网格、生成代理模型的训练和验证样本、转换样本为图片矩阵形式、切割图片样本、搭建基于深度学习的代理模型网络和训练代理模型；优化模型参数，包括：构造残余应力实测值与模型优化值方差的目标函数，利用代理模型不断更新优化单元温度分布，直至满足收敛条件，此时由代理模型得到的残余应力场即为构件内真实残余应力分布。本发明用基于深度学习的代理模型替代现有技术中的有限元更新法，能够显著提高残余应力反演的效率。基于卷积神经网络模型的构件残余应力反演方法。该方法能够利用基于深度学习的智能体模型代替现有技术中的有限元更新过程，从而提高残余应力反演效率。该方法包括通过使用有损检测或无损检测测量构件表面或内部有限分散点的残余应力值来测量构件分散点残余应力。 建立代理模型，所述代理模型设置有U-net卷积网络。 生成所述代理模型的训练和验证样本。 在多个有限元温度分布场生成的不同随机温度场下运行多个自平衡应力场作为代理模型样本的输入。   4
本申请公开了障碍物识别方法和装置、电子设备及存储介质，涉及计算机技术领域，该方法包括：获取障碍物图片；将障碍物图片输入至预训练的元学习模型，输出对应的分类标识；在分类标识为空时，基于障碍物图片，获取与障碍物图片对应的任务，利用任务对预训练的元学习模型进行训练，得到中间元学习模型以识别障碍物图片对应的中间分类标识；确定训练训练任务的标识，在中间分类标识与训练任务的标识不一致时，根据中间分类标识和训练任务的标识确定中间元学习模型对应的损失函数值，根据损失函数值调整中间元学习模型的模型参数，得到目标元学习模型，以进行目标障碍物图片的识别。从而使得车端目标元学习模型可以准确识别更多类别的障碍物。本发明公开了一种利用设备识别障碍物的方法。本发明的方法通过车载端目标元学习模型，能够准确识别多种障碍物。该方法包括获得障碍物图像。 障碍物图像被输入到预先训练的元学习模型中。 输出与障碍物图像对应的分类标识。 基于障碍物图像调用模型训练引擎。 从预设任务集合中获取与障碍物画面对应的任务。 执行第一阶段模型参数更新。 执行第二阶段模型参数更新以获得目标元素学习模型，以通过目标元素学习模型识别目标障碍物图像。 根据损耗函数值调整中间件学习模型的模型参数。本发明还涉及一种用于识别障碍物的装置。 以及包括用于识别障碍物的指令集的计算机可读存储介质。 14
本说明书提供问题解答方法及装置，其中所述问题解答方法包括：获取待解答问题；将所述待解答问题输入问题解答模型的预训练语言层，获得所述待解答问题的语义向量；将所述语义向量输入所述问题解答模型的分类层，根据所述分类层输出的分类结果，确定所述待解答问题的正确答案。如此，可以通过问题解答模型的预训练语言层对输入的问题进行语义分析，获得问题的上下文语义，即语义向量，然后通过分类层对获得的语义向量进行分析，得到对应的答案类别，实现基于预先训练好的问题解答模型自动、高效、准确地分析出问题的正确答案，大大提高了问题的解答效率和正确率。问答法。该方法涉及提高问题回答效率和问题准确率以及实现高精度的自动回答过程。该方法包括获得(102)待回答的问题。 将所述待回答问题输入(104)问答模型的预先训练的语言层，以获得所述待回答问题的语义向量。 将所述语义向量输入(106)到所述问答模型的分类层中。 根据所述分类层输出的分类结果确定正确答案。 根据所述语义向量得到所述分类结果。独立权利要求包括：(1)问答装置； (2)一种计算设备，包括处理器和存储器，所述存储器用于存储由所述处理器执行以实现问答方法的计算机可执行指令； 以及(3)一种计算机可读存储介质，其存储有计算机指令，所述计算机指令由处理器执行以实现一种问答方法。  12
一种企业服务领域预训练对话式大语言模型的构建方法及系统，涉及人工智能技术领域。在该方法中，基于企业信息数据集对预设的基座模型进行语义预测训练，得到第一语义预测模型；基于预设的企业服务领域的指令集，对第一语义预测模型进行微调，得到第二语义预测模型；基于预设的问答分数数据集对第二语义预测模型进行训练，得到奖励模型；将第二语义预测模型作为强化学习算法的策略网络，将奖励模型作为强化学习算法的价值网络，并基于策略网络和价值网络，计算得到时间差误差，并更新策略网络的参数，得到预训练对话式大语言模型。实施本申请提供的技术方案，可以在企业服务领域的问答模型构建的过程中提高模型回答问题的准确程度和自然程度。用于构建企业服务领域预训练对话型大语言模型的方法。该方法在构建企业服务领域的问答模型过程中，提高了模型回答问题的准确率和自然度。该方法涉及基于企业信息数据集对预设的基模型进行(S12)语义预测训练，以获得第一语义预测模型。 获取企业服务字段的预设指令集(S13)。 基于预设的企业服务领域指令集对所述第一语义预测模型进行微调(S14)，得到第二语义预测模型。 获取所述预设问答评分数据集(S15)。 对所述第二语义预测模型进行训练(S16)。 将第二语义预测模型取(S17)为强化学习算法的策略网络，用于将奖励模型取为强化学习算法的价值网络，以便基于策略网络和价值网络得到时间差误差。 基于时间差误差更新策略网络的参数(S18)，得到预训练对话型大语言模型。包括的独立权利要求是：1。 一种企业服务领域预训练会话大语言模型构建系统； 2. 电子装置； 以及3。 一种计算机可读存储介质，所述计算机可读存储介质存储用于执行用于构建预训练会话式大语言模型的过程的计算机程序。  11
本申请公开了基于语义表示的文本生成方法和装置，涉及NLP领域。文本生成方法为：获取输入文本；获取目标文本之中第i个待预测词的占位符；获取第i个待预测词的向量表示，其中，第i个待预测词的向量表示是对应的占位符与源文本和第1个至第i‑1个预测词，通过自注意力机制计算得到的；根据第i个待预测词的向量表示，生成第i个预测词，以获取目标文本。该方法通过引入占位符，融合源文本和当前已预测出的词，得到与当前待预测词的向量表示，根据该向量表示预测当前待预测词，解码时即使预测出的前一个词错误，对当前待预测词的向量表示影响较小，在一定程度上缓解了曝光偏差，提高了解码准确率。上述方法可统一应用于预训练和微调。用于通过使用电子设备生成自然语言处理文本的基于语义表示的方法(要求保护)。该方法能够在预测错误发生时，进行前字解码，在一定程度上将向量表示为当前待预测字，避免曝光偏差，提高解码精度。该方法包括获得输入文本，其中输入文本包括源文本。 获取目标文本中待预测词的占位符。 获取所述待预测词的向量表示，所述待预测词的向量表示为对应的占位符、所述源文本和预测词，所述预测词通过自注意力机制计算得到。 根据所述待预测词的向量表示对所述预测词进行处理，得到所述目标文本。 根据语义词语列表替换所述预测词语。针对以下内容包括独立权利要求：一种用于通过使用电子设备生成自然语言处理文本的基于语义表示的设备； 以及计算机可读存储介质，其存储用于通过使用电子设备生成自然语言处理文本的指令集。  12
本申请涉及一种相关度模型数据处理方法、装置、计算机设备和存储介质。方法涉及机器学习领域，包括：获取相关性样本组；基于相对等级标记，得到相关性样本组中相关性样本之间的等级比较结果，构建样本对数据；来对预训练相关性识别模型进行微调训练，得到样本对数据的各类损失参数；基于损失参数，对预训练相关性识别模型进行参数调整处理，得到目标相关度模型。本申请通过标注等级比较结果，来对样本对进行标注，只需完成相对等级标注，即可构造出大量的模型训练数据。而且在预训练模型的基础上来完成对相关度模型的训练，可以有效地减少相关度模型训练过程所需的样本量，从而减少相关度模型训练过程中存储占用。利用机器学习领域中使用的计算设备(权利要求书)处理相关度模型的数据的方法。 用途包括但不限于笔记本电脑、智能手机、车辆、智能电视、个人电脑和智能手表。该方法通过标注级别比较结果对样本组进行标注，完成构建大量模型训练数据的相对级别标注，有效减少了相关度模型训练过程中所需的样本数量，从而减少了相关度模型训练过程中的存储占用。所述方法包括获得一组相关性样本，所述相关性样本包含一组相关性样本和所述相关性样本之间的相对等级标记。 基于所述相对电平标记得到相关样本组中的相关样本之间的电平比较结果。 构建具有所述电平比对结果标记的样本对数据。 将所述数据通过所述样本对预先训练的相关性识别模型进行细调训练处理，得到所述样本对所述数据的比对损失参数、等分损失参数和得分损失参数。 利用两个分类标记对相关性样本进行训练得到预训练相关性识别模型。 基于所述比较损失参数、所述等量损失参数和所述得分损失参数对所述预训练相关性识别模型进行参数调整处理，得到目标相关度模型。独立权利要求包括用于：(a)用于利用计算设备处理关联度模型的数据的设备； (b)计算机可读存储介质，用于存储利用计算设备处理相关度模型的数据的一组指令; (c)一种计算机程序产品，包括用于利用计算设备处理相关度模型的数据的一组指令。  11
本发明提供一种预训练模型的构建方法、计算机装置及计算机可读存储介质，该方法包括建预训练模型所需要的数据集，基于数据集形成数据集范式；对所构建的数据集进行离线增量训练，并对数据集进行在线强化学习；设计预训练模型的进化模式：从本地知识库提取目标知识信息，将目标知识信息进行变换形成满足离线增量训练需求的知识集合，将知识集合形成目标文档，按照预设的时间间隔将目标文档导入到离线增量训练的模型中并进行增量训练；在增量训练完成后得到包含增量知识的附加模型，将附加模型与预训练模型进行融合获得新的预训练模型。本发明还提供实现上述方法的计算机装置备及计算机可读存储介质。本发明能提高预训练模型进化的效率和效果。一种基于离线增量训练和局部知识库的用于人工智能(AI)实时训练的计算机设备(权利要求)构建预训练模型的方法。该方法能够提高预训练模型的进化效率和进化效果。该方法包括构建预训练模型所需的数据集。 基于所述数据集形成数据集模型。 对构建的数据集进行离线增量训练，进行在线强化学习。 从本地知识库中提取目标知识信息。 将知识集合形成目标文档。 将所述目标文档按照预设时间间隔导入离线增量训练的模型中并进行所述增量训练。 增量训练结束后得到包含增量知识的附加模型。 将所述附加模型与所述预训练模型进行融合，形成预学习模型。本发明还提供了一种计算机可读存储介质，其包括用于通过使用计算机设备来构建预训练模型的指令集。  11
本发明公开了一种生成式认知模型阅读理解能力提升方法和优化系统，主要包括如下步骤：选择生成式认知模型；构建指令微调数据；基于指令微调数据对生成式认知模型进行微调；对微调完成的所述生成式认知模型进行评估并迭代优化。经本申请提升优化后的生成式认知模型在处理阅读理解任务时，具备强大的自然语言处理能力，能够有效提高阅读理解能力，更准确地理解自然语言中的文本含义、结构化上下文、推断隐含信息以及作出准确的回答，以及处理各种复杂的自然语言任务。一种提高生成的认知模型在问答系统中阅读理解能力的方法及智能客服系统，用于准确地处理用户的问题和回答。本申请对优化生成的认知模型进行改进，在处理阅读理解任务时，具有较强的自然语言处理能力，有效地提高了阅读理解能力，更准确地理解自然语言中的文本含义，结构化上下文，诱导隐含信息并做出准确答案，处理各种复杂的自然语言任务。该方法包括选择生成的认知模型。 构造指令微调数据。 基于指令微调数据对生成的认知模型进行微调。 对微调生成的认知模型进行评估和迭代优化。 根据所述目标任务特征、所述模型规模、所述性能特征和所述预训练因子选择生成的认知模型。 通过增加输入数据的多样化，增加困难案例，引入常见语言错误和没有正确答案的样本来构建指令细调数据。本发明还公开了一种用于提高生成的认知模型的阅读理解能力的优化系统。  11
本发明公开了一种基于深度学习的图像语义分割方法及存储介质，图像语义分割方法包括在特征提取网络后串联一个平均全局池化层和全连接层作为分类的预训练模型，并采用Imagenet‑1K数据集对预训练模型进行分类训练；将训练后的预训练模型中的特征提取网络与轻量级ASPP模块和两个特征增强模块依次连接构成语义分割模型；通过翻转、旋转和缩放对数据集cityscapes进行扩充，并采用扩充后的数据集对语义分割模型进行训练，得到目标语义分割模型；将预处理后的新图片输入目标语义分割模型，在目标语义分割模型中进行一次前向传播，端到端地输出预测的语义分割结果。基于深度学习的语义图像分割方法。该方法是将特征提取网络、平均全局池化层和全连接层连接后，使用ImageNet-1K数据集对预训练模型进行分类训练，作为预训练模型。 所述特征提取网络在训练后的预训练模型中依次排列一个轻量级空洞空间金字塔池化模块和两个特征增强模块，形成语义分割模型。 数据集cityscapes被扩展以执行翻转、旋转和缩放过程。 利用扩展后的数据集对语义分割模型进行训练，得到目标语义分割模型。 将预处理后的图片输入所述目标语义分割模型。 在所述目标语义分割模型中进行前向传播处理。 将预测得到的语义分割结果输出给终端。还包括用于基于深度学习来分割语义图像的一组指令的计算机可读存储介质。 14
本发明提出一种基于深度卷积神经网络和模型压缩的十大功劳检测方法。上述方法包括，十大功劳图像数据采集、十大功劳预处理模型的搭建与训练、十大功劳识别模型搭建与预训练、模型的微调、模型压缩、十大功劳图像获取、提取十大功劳前景图像，该方法可支持无人设备实现在相关区域进行快速准确的对35类十大功劳进行识别，可以减少相关工作者的工作量，降低事故发生的概率。基于深度卷积神经网络和模型压缩的十大工作检测方法该方法能够支持无人值守设备快速，准确地识别出相关区域内的35型十大工作； 可减轻相关工作人员的工作量； 并能降低事故发生的概率。所述方法包括：利用工业CCD相机获取图像数据并生成训练数据。 对训练数据进行标记。 构建主体识别模型。 选择卷积核以执行原始图像特征提取处理。 提取高维抽象特征。 执行全连接神经网络学习过程。 通过ADAAM优化算法得到自监督学习参数。 执行颜色纹理提取处理。 识别十大工作类型判断，输出类型和识别率的模型。   4
本发明提供了一种深度Transformer级联神经网络模型压缩算法，它解决了现有技术的算法仍然具有进一步压缩空间的问题。其方法包括：在文本数据集上对深度Transformer级联神经网络进行预训练；将Transformer级联模型按照先后顺序划分成若干份模块；随机选择预训练完成的深度Transformer级联神经网络中的某一层Transformer作为替换模块，此模块命名为Transformer‑compress；在小数据集内对预训练模型进行微调，并且使用模块逐步替换和模块间参数共享的方式对模型进行压缩。本发明优点在于进一步提升模型压缩效率。深级联神经网络模型压缩算法。该算法提高了深级联神经网络模型的压缩效率。该算法具有一组用于在文本数据集上预训练深度级联神经网络的指令。 级联模型按顺序分为多个模块。 随机选择预先训练好的深级联神经网络的一层作为替换模块。 该模块被命名为卡可压缩性。 在小数据集中微调预训练模型。 通过模块渐进替换和模块间参数共享的方式对模型进行压缩。   4
本发明公开了一种基于NLP和KG的手机APP自动测试方法，涉及软件测试技术领域，其中，本方法利用基于DSSM语义相似度计算技术、BERT自然语言推理技术以及知识图谱存储技术，将该应用程序所具有的各个功能自动构建成一个图数据结构，图中的每一条路径则代表完成APP某个功能的一个完整的操作流程，与传统的自动测试相比，在训练完毕的深度学习模型的基础上，手机APP是完全进行离线测试的，并且通过自动生成手机APP的自然语言脚本及知识图谱数据模型，能够实现对测试用例的再次复用。一种基于自然语言处理和知识图的手机APP自动测试方法。基于训练好的深度学习模型，对移动APP进行完全离线测试。 本发明通过自动生成移动应用的自然语言脚本和知识图数据模型，实现了测试用例的再次重用。该方法包括上传移动APP测试所需的数据，以及连接到用于测试的移动电话和APP。 从公共路径列表中提取公共路径，并且提取当前路径中的每个操作节点或场景节点。 通过页面信息提取功能获取当前节点对应的APP页面信息。 通过组合先前的操作过程来生成新路径，并将其添加到当前路径列表中，然后执行对应于新节点的脚本内容。 当节点类型是结果节点时，完成当前操作过程，并将当前操作过程存储在结果列表中。 将操作路径转换为预定的知识图形数据结构，并通过测试图生成功能存储在图形数据库中。 生成测试报告并提供给测试者以供检查。  12
本发明涉及实体匹配技术领域，公开了一种实体匹配方法和装置，所述方法包括：获取第一数据集和第二数据集，数据集包括若干条实体记录，实体记录包括若干个属性；获取第一数据集和第二数据集的笛卡尔乘积，得到第三数据集，根据实体记录中多个属性间的预设潜在关系，将第三数据集中每个实体记录进行句子组合，获得包括第二组合的第四数据集；将第四数据集中的第二组合输入到预设的Bert模型，Bert模型用于判断第二组合的两个句子否匹配并输出匹配结果。有益效果：将第三数据集中的实体记录替换为根据属性潜在关系生成的句子，可以使第二组合输入到Bert模型中的数据保留属性之间的联系，使数据集的实体记录匹配结果更加准确。一种用于识别同一现实世界中的实体在不同数据源即结构化数据、脏数据和文本数据中的异构表达的实体匹配方法。该方法使得将第三数据集中的实体记录替换为根据属性潜在关系生成的语句，将第二组合输入到Bert模型中，得到数据保留属性之间的联系，保证数据集的实体记录匹配结果准确。该方法涉及获得第一数据集和第二数据集，其中第一数据集和第二数据集包括多个实体记录并且每个实体记录包括多个属性。 获得所述第一数据集和所述第二数据集的笛卡尔积。 获取第三数据集，所述第三数据集包括多组第一组合且所述第一组合为所述第一数据集的实体记录与所述第二数据集的实体记录的组合。 根据所述第三数据集的实体记录中的属性之间的预定潜在关系执行语句组合处理。 获取第四数据集，所述第四数据集包括多组第二组合且所述第二组合为所述实体记录对应的语句的组合。 将所述第四数据集中的所述第二组合的每组输入到预定的Bert模型。通过所述Bert模型将输入语句转换为实体嵌入向量。 判断所述第二组合的每组中的两个句子是否通过所述实体嵌入向量匹配。 输出匹配结果。 本发明还涉及一种用于匹配实体的设备，所述设备用于识别同一现实世界中的实体在不同数据源即结构化数据中的异构表达。  11
本发明提供一种模型训练方法、装置、电子设备及可读存储介质，属于自然语言处理技术领域。该方法包括：获取第一文本数据集；获取每个第一指令任务的应用属性，以及获取每个第一指令任务在应用属性下的层次等级；基于第一文本数据集中第一训练数据集，对第一模型进行训练；在第一模型针对第一层次等级的指令任务的学习增益处于饱和状态的情况下，基于第一文本数据集中第一验证数据集，提高第一训练数据集中第一应用属性下第二层次等级的第一指令任务的表述文本的比例，得到第二训练数据集；基于第二训练数据集，对第一模型进行继续训练。本发明可以提高大模型对指令任务的处理准确性。通过使用电子设备训练模型的方法(权利要求书)。该方法能够提高大型模型对指令任务的处理精度。该方法涉及获取文本数据组，第一训练数据组包括多个指令任务的多个表情文本。 新导向成本噪音一点美国来自乳腺支的匹配冷却in酸酐。 在所述应用属性下获取所述指令任务的层级级别。 所述指示任务的应用属性用于指示所述指示任务是知识应用任务还是推理任务。 以所述层级的第一指令任务在每个应用属性下的表达文本包含校验数据组。 基于第二训练数据组不断地训练模型。独立权利要求包括：用于通过使用电子设备训练模型的装置。 可读存储介质，用于存储执行使用电子设备训练模型的方法的一组指令。  11
本申请公开了一种语言模型的训练方法、文本匹配方法及相关装置，本申请提供的方案能够通过粒度划分，将目标领域的高频词语融入第一训练文本，并以SOP任务和MSP任务为第一阶段的训练任务，采用该第一训练文本预训练语言模型。由此，在预训练阶段，该方法不仅能够让语言模型学习到通用领域的知识，还能够学习到目标领域的知识。并且，该方法还能够以文本匹配任务为第二阶段的训练任务，采用从目标领域获取到的第二训练文本训练语言模型，从而使语言模型能够更广泛地学习到该目标领域的基础知识。由此，可以增加该语言模型的泛化能力，从而确保模型的训练效果。自然语言训练方法。本发明提高了语言模型的泛化能力，从而保证了模型的训练效果。该方法包括从文档库中的第一文档获得两个句子样本。 在划分粒度以获得第一训练文本之后，对两个句子样本的句子片段中的一个句子片段执行掩码处理。 预测第一阶段训练文本预训练语言模型。 句子预测(SOP)任务用于预测第一文档中的两个句子样本。 掩码片段预测(MSP)任务用于预测由掩码处理的句子片段。 文本匹配任务被用作使用第二训练文本的第二阶段训练语言模型的训练任务，其中第二训练文本包括目标字段的输入文本和目标字段中的第二文档的识别文本。 文本匹配任务用于预测第二文档和输入文本的程度。独立的权利要求书包括： (1)文本匹配方法； (2)语言模型训练装置； (3)文本匹配装置； (4)计算机设备； 以及 (5)计算机可读存储介质。  11
本发明公开了一种基于指针关键信息的自动摘要生成方法，首先，通过预训练模型获取文章的多维语义特征的句向量；其次，使用指针选取关键词语义特征词向量；最后使用编码器进行摘要的生成。该方法中，采用神经网络搭建模型框架，使用自动化的学习和训练，免去了过多的人工干预，训练过程采用预测和验证两种方式，然后使模型计算损失并自动提高模型的准确率。本发明方法应用性强，在新闻生成标题、文案生成等方面将会有很大的应用。一种基于指针关键信息的自动摘要生成方法，例如新闻中的短标题。该方法能够使用神经网络构建模型框架和自动学习和训练，避免了过多的人工干预。 训练过程采用预测和验证两种方式，模型计算损失减少，自动提高模型的精度。 避免了虚假模式对预测场景的严重依赖。 实现了文本的摘要信息的自动生成，避免了人工阅读长文章信息。 该方法使用简单的拷贝机制，避免了登录问题，提供关键词作为生成有效新闻正文的引导信息。该方法包括获得摘要生成模型，以及过滤低于200个字符的句子，以及文本中的特殊字符。 按标点符号划分句子。 根据接受度对单词进行分词。 通过比较文本字典将文本转换成数字。 通过数据集和优化训练模型。 得到摘要生成模型，并将训练好的模型存储在计算机中。 所述多类型摘要生成模型通过改变模型训练数据集或迭代次数得到。 摘要生成模型被称为。 将训练得到的模型打包成可执行、可视化的程序。 接收用户的输入，并对用户输入数据进行预处理，用于对句子进行分词和过滤字符。 对所述文本特征进行分类提取，调用所述摘要生成模型，用于生成泛化用户输入的简要摘要。  12
本申请提供一种文本信息处理方法、装置及存储介质，其中，方法包括：获取待处理文本，确定待处理文本中含有易混淆词的各待辨别语句；采用第一预训练模型对待辨别语句进行语句概率计算，获得待辨别语句的语句概率；并采用第二预训练模型对待辨别语句进行语义概率计算，获得待辨别语句的语义概率；采用集成学习模型对待处理文本的各待辨别语句的辨别特征进行计算，得到各待辨别语句各自对应的计算结果；其中，待辨别语句的辨别特征为由待辨别语句的语句概率、语义概率、语句长度以及待辨别语句中的易混淆词的索引编号组成的多维度特征；基于计算结果，从待处理文本对应的待辨别语句中确定出易混淆词使用错误的语句及使用错误的易混淆词。用于在例如出版行业中使用的处理文本信息的方法。该方法能够保证文本信息处理方式简单高效。该方法包括获得待处理的文本。 通过第一预训练模型计算待识别句子的句子概率，得到句子概率。 通过第二预训练模型对所述待识别语句进行语义概率计算。 获取所述句子的语义概率。 通过集成学习模型对应每个待识别语句计算每个语句的区分特征。 基于计算结果确定与所述待处理文本对应的易混淆词使用错误语句和易聚类语句。独立权利要求还包括用于：文本信息处理装置； 文本处理装置； 以及存储介质，其存储用于处理文本信息的一组指令，以用于例如出版行业。  11
本发明公开了一种基于解耦注意力的文物安全命名实体识别方法，包括以下步骤：将待识别的输入文本序列与词典进行匹配得到潜在单词，将潜在单词和输入文本序列融合得到最终的文本序列，通过预训练词嵌入向量和相对位置编码得到文本嵌入向量和位置嵌入向量；将嵌入层输出的文本嵌入向量和位置嵌入向量进行连接得到总的向量表示，作为编码层的输入，并通过解耦的自注意力机制计算注意力得到注意力矩阵，将经过残差连接和层正则化后得到的结果输入到前馈神经网络得到输出，再次进行残差连接和层正则化得到最终输出；将编码层输出作为解码层的输入，即输入条件随机场，解码预测搜索条件概率最高的标签序列。本发明识别效果好，能大大提高识别的准确性。基于解耦关注度的文物安全实体识别方法。该方法使得能够保证较好的识别效果，提高识别精度，将待识别的输入文本序列与词典进行匹配，得到潜在词，将潜在词与输入文本序列进行融合，得到最终的文本序列，保证简单有效的相对位置编码模式对相对位置信息进行编码。该方法包括将待识别的输入文本序列与词典进行匹配，得到潜在词语。 将一个潜在词与所述输入文本序列进行融合，得到最终的文本序列。 通过预训练词嵌入向量和相对位置编码得到文本嵌入向量和位置嵌入向量。 通过所述文字嵌入向量和所述位置嵌入向量连接嵌入层，得到总向量作为编码层的输入。 注意力通过解耦的自注意力机制计算得到注意力矩阵。 编码层的最终输出被选择为解码层的输入。 对标签序列的高概率的预测搜索条件概率进行解码。  12
本申请涉及的语音识别和语音合成的模型训练方法，包括：获取音频处理网络处理训练集中的第一数据对的语音数据后输出的第一高维向量，获取文本处理网络处理第一数据对的文本数据输出的第二高维向量；通过损失函数在训练集上训练音频处理网络和文本处理网络至训练收敛；训练收敛后，固定音频处理网络对应的第一参量集合以及文本处理网络对应的第二参量集合；第一参量集合和第二参量集合下，训练文本恢复网络和音频恢复网络至收敛；将音频处理网络和文本恢复网络，依次组合连接得到语音识别的声学预训练模型，将文本处理网络和音频恢复网络，依次组合连接得到语音合成的声学预训练模型。节省模型构建、训练成本。一种用于语音识别和语音合成的模型训练方法。所述模型训练方法获得用于语音合成的声学预训练模型。 节省模型建设和培训成本。所述模型训练方法包括：获取音频处理网络处理训练。 获得该组中第一数据对的语音数据之后输出的第一高维矢量。 以及获得由文本处理网络输出的处理第一数据对的文本数据的第二高维向量。 训练集由语音数据和文本数据组成数据对。 第一数据对是训练集中的任何数据对。 音频处理网络和文本处理网络通过丢失函数在训练集上训练，直到丢失。 当函数达到最小值时，训练收敛，其中损耗函数是第一高维向量和第二高维向量之间的空间距离。独立的权利要求书被包括在以下内容中： 一种计算机设备，包括存储器和处理器； 以及 一种计算机可读存储介质。 3
本发明公开了一种基于样本自适应的微表情放大方法及装置，包括：(1)获取微表情数据库；(2)将微表情视频转换为微表情帧序列，并对序列长度进行统一；(3)构建微表情放大模型，所述微表情放大模型包括：强度提取模块，强度变化曲线构造模块，强度校正模块，人脸增强模块，微表情特征整合模块，(4)将统一长度的微表情帧序列和对应的微表情类别标签作为样本输入微表情放大模型进行训练，训练时采用的损失函数包括微表情特征向量交叉熵损失、强度提取的损失和强度校正的损失；(5)将待放大的微表情视频进行长度统一后输入训练好的微表情放大模型，得到放大后的微表情特征向量。本发明可以根据每个微表情视频进行自适应放大，效果更好。基于样本自适应放大微表情的方法，用于健康诊断、国家安全、刑事审判等领域具有不可缺少的功能。该方法使得能够根据各个微表情视频进行自适应放大，从而效果更好。 该方法允许人脸增强模块将校正后的强度值与从微表情帧序列中提取的人脸特征进行积分，以获得增强后的人脸向量，因此以有效的方式增强了具有增强表情强度的人脸向量。该方法包括获取微表情数据库，所述微表情数据库包括微表情视频和对应的微表情类别标签。 将所述微表情视频转换为微表情帧序列。 搭建微表情放大模型，所述微表情放大模型包括强度提取模块，用于利用所述微表情帧序列。 强度变化曲线构建模块，用于构建基于高斯分布的微表情帧序列的强度变化曲线。 人脸增强模块，用于将修正后的强度值与从微表情帧序列中提取的人脸特征进行融合，得到增强后的人脸特征向量。 微表情特征整合模块，用于利用LSTM对属于一个微表情视频的所有帧的增强后的人脸特征向量进行整合，作为放大后的微表情特征向量。独立权利要求包括用于样本自适应的微表情扩增装置。 2
本发明涉及图像识别领域，具体实施例中提供一种基于自监督和小样本学习的医学图像识别方法、装置、计算机设备、可存储介质，利用图像增强技术对同一张pCLE图像进行两次随机增强得到不同的实例，并将两个实例分别输入到孪生神经网络获得相应的图像特征嵌入；接着，对两个图像特征嵌入进行特征混合，使用pCLE图像数据集对孪生神经网络进行无监督范式的训练，将获得的预训练模型与分类器进行结合来完成对常见疾病pCLE图像的识别，利用在自监督学习中获得的预训练模型与基于度量的元学习相结合来进一步微调孪生神经网络，以实现对稀有疾病下的pCLE图像的识别，具有较好的泛化性，有效实现了对常见类别疾病和稀有类别疾病两种场景下的pCLE图像的精准识别。基于自监督和小样本学习技术的常见类型疾病和罕见类型疾病的pCLE图像识别方法。该方法能够以较好的泛化效果实现对常见类型疾病和罕见类型疾病的pCLE图像的有效精确识别。该方法涉及使用图像增强技术对探针型共聚焦激光内显微镜(pCLE)图像进行两次随机增强，以获得两个不同的样品。 将所述两个不同的样本输入到孪生神经网络，用于获得对应的图像特征。 嵌入并融合相应的图像特征，用于正则化优化pCLE图像数据集。 利用所述pCLE图像数据集对所述孪生神经网络进行无监督训练，得到预训练模型和分类器。 所述预训练模型和所述分类器用于对所述pCLE图像进行粗识别。 应用小样本学习技术对预训练模型进行训练，得到小样本分类器。 所述小样本分类器用于对所述pCLE图像进行精细识别。包括独立权利要求：(1)基于自监督和小样本学习技术的普通型疾病和罕见型疾病pCLE图像识别装置； (2)基于自监督和小样本学习技术识别普通型疾病和罕见型疾病的pCLE图像的计算机设备； 以及(3)存储有计算机指令的非暂时性计算机可读存储介质，所述计算机指令被执行用于基于自监督和小样本学习技术来识别普通型疾病和罕见型疾病的pCLE图像。   4
本发明涉及情感分析技术领域，且公开了一种基于深度学习的情感分析系统及设备，包括BERT模型、transformer双向预测、RCNN模型和Attention注意力机制，所述BERT模型包括词嵌入，词嵌入包括BERT预训练模型和BERT模型，BERT预训练模型由输入层、编码层和输出层组成，本发明通过使用BERT模型进行中文情感分类，并通过transformer进行信息提取，对语句进行多层双向预测，更好地理解句子的深层含义，同时利用结合注意力机制的RCNN模型进行深度提取，能有效的根据用户评论和舆论的倾向性分析出用户的正面情感与负面情感，有助于企业以及政府通过相关的分析及时采取措施，挖掘出更大的社会价值，此外，本发明的中文情感分析还涉及到人工智能、计算机科学的融合，推动了人工智能的发展。基于深度学习的情感分析方法。该系统能够根据用户评论和舆情的倾向性，有效地分析出用户的正情绪和负情绪。 该系统有利于企业和政府通过相关分析及时采取措施，挖掘更多的社会价值。 中国人情感分析还涉及人工智能与计算机科学的融合，推动人工智能的发展。该方法涉及利用模型对汉语情感进行分类，并利用转化器进行信息提取，对句子进行多层双向预测。 利用结合注意力机制的模型进行深度提取，根据用户评论和舆情的倾向性分析用户的正负情绪。 对情绪进行了深入全面的分析，通过人工智能与计算机科学的融合。包括独立权利要求，用于一种基于深度学习的情感分析系统和设备。  12
本发明公开了一种基于认知的自然语言处理任务相似度量化方法，步骤1、从认知数据中获得文本刺激的特定任务句子表征，输入任务中经过微调或提炼的预训练语言模型；步骤2、分别将特定任务句子表征输入认知表征分析组件，将任务成对迁移训练输入认知神经映射组件，认知表征分析组件采用表征相似度分析RSA来估计NLP任务相似度；认知神经映射组件将特定任务的句子表示到fMRI信号的映射；步骤3、对任务成对迁移训练数据进行层次分析法AHP：为每个目标任务t构造矩阵Wt，任务矩阵[i, i′]中的元素为第i个任务比第i′个任务更优的概率；然后获得任务相似性矩阵。本发明能够用于任何NLP任务。基于认知的自然语言处理任务相似度量化方法。该方法使得能够利用基于认知的自然语言处理任务相似度量化方法来提高任务相似度估计的准确性。 该方法使得认知神经映射组件能够通过任务中的预训练模型建立任务中对句子进行精细调整时记录的fMRI信号的映射，从而利用映射相关系数作为任务表示，计算任务相似度，有效地对归纳任务进行分类。该方法涉及从认知数据获得文本刺激的任务语句表示。 在任务中经受微调或精炼的预先训练的语言模型。 具体的任务语句表示被输入到认知表示分析组件，认知表示分析组件将任务对迁移训练输入到认知神经映射组件，认知神经映射组件由认知表示分析组件(CRA)通过通用表示相似度分析(RSA)估计非线段(NLP)任务相似度，其中RSA通常用于衡量脑活动与计算模式之间的相关性。 认知神经映射组件用于建立从具有关于特定任务的微调模型的预训练句子表示到当人类受试者阅读句子时记录的功能磁共振成像(fMRI)信号的映射。  11
本公开关于一种语音意图识别模型的训练方法、语音意图识别方法和装置，训练方法包括：获取文本样本和携带有语义标签的第一语音样本，其中，第一语音样本与文本样本的内容对应，语义标签为文本样本的文本语义特征；利用第一语音样本，对待训练的语音意图识别模型中的语义提取网络进行预训练，得到预训练的语音意图识别模型，其中，预训练的语音意图识别模型中包括预训练的语义提取网络和待训练的意图识别网络；获取携带有意图标签的第二语音样本；利用第二语音样本，对预训练的语音意图识别模型进行训练，得到训练完成的语音意图识别模型。用于智能家居、手机语音助手等人机交互领域的语音意图识别模型训练方法。在保证模型精度的情况下降低了训练数据的准备成本，提高了模型训练的可行性。 全局优化目标一致，易于保证辨识精度，且只需要一个模型，系统架构简单，可以减少计算资源的消耗。该方法涉及获得(101)携带语义标签的文本样本和第一语音样本。 第一语音样本与文本样本的内容相对应。 所述语义标签为所述文本样本的文本语义特征。 在待训练的语音意图识别模型中预训练(102)语义提取网络。 所述预训练的语音意图识别模型包括预训练的语义提取网络和待训练的意图识别网络。 获取携带有意识图谱标签的第二语音样本(103)。 利用第二语音样本对预训练语音意图识别模型进行训练(104)，以获得已训练语音意图识别器模型。包括以下独立权利要求：一种语音意图识别方法； 语音意图识别模型的训练装置； 语音意图识别装置； 电子设备； 存储有用于训练语音意图识别模型的程序的计算机可读存储介质； 以及用于识别语音意图的计算机程序产品。 3
本发明公开了一种关系抽取联合模型训练方法、关系抽取方法、设备及介质，包括以下步骤：获取公告文本信息，将文本信息预处理以得到文本序列，利用预训练模型提取文本序列的特征向量，特征向量包括训练向量；利用训练向量训练得到文本二分类模型、关系抽取模型，联合文本二分类模型与关系抽取模型以得到联合模型，联合模型以分类结果及主语语义结果为中间输出，将分类结果与主语语义结果相乘以得到主语结果，以主语结果为条件，对输入的文本信息进行条件层归一化，得到第二关系结果及第二客体结果，联合模型以主语结果、第二关系结果、第二客体结果为最终输出。可以减少抽取结果中与目标关键信息无关的信息，提升关系抽取结果的精确性。关系抽取组合模型训练方法，用于自然语言处理技术领域。 还可用于环境和天气、计划等因素需要对外发布公示，缩短营业时间、恢复营业时间等公告内容。该方法将关系抽取模型与文本二分类相结合，减少了与指定关系无关的信息，从而提高了抽取结果的精度，提高了关系抽取的效率。该方法包括获取通知文本信息。 对所述文本信息进行预处理，得到文本序列，所述文本序列包括有效文本序列和无效文本序列。 利用预训练模型提取所述文本序列的特征向量，所述特征向量包括训练向量，所述训练向量用于训练第一模型和第二模型，以得到文本的第二分类模型和关系提取模型。 将文本二分类模型与关系抽取模型进行组合，得到组合模型。 文本信息被用作输入。 将分类结果和主语言语义结果作为中间输出。 将所述分类结果与所述主语言语义结果相乘，得到所述主语言结果。独立权利要求包括：(1)关系提取方法； (2)一种用于训练关系提取组合模型的电子设备； 以及(3)用于训练关系提取组合模型的计算机可读存储介质。  12
本申请公开了一种问答系统中基于语义的快速知识命中方法及装置，所述方法包括如下步骤：准备用于模型训练的语料，包括用户问句及对应知识库中的知识，并标注用户问句与知识是否匹配；基于Bert模型按二分类任务使用标注后的语料进行模型训练，训练完成后将模型输出设置为Bert模型的pooled_output层输出，并保存为语义模型；知识库向量表示，其包含的语义向量的集合为语义向量空间；采用随机森林对语义向量空间进行语义分割，同一语义向量空间生成N棵二叉树；将用户问句转换为语义向量，进行知识命中计算。本申请引入深度学习模型来提升知识命中的效果，并优化匹配的算法提升知识命中的速度，使智能客服能支撑庞大的知识库。问答系统中基于语义的快速知识打击方法。问答系统中基于语义的快速知识击球方法引入深度学习模型提高知识击球效果，并在知识击球中优化匹配算法提高速度。 智能客服支持大知识库。 问答系统中基于语义的快速知识命中方法实现了更快、更准确的知识命中，用户体验效果好。该方法包括准备(S1)语言学数据训练，并标记用户问题和知识匹配。 进行模型训练(S2)，通过根据两个分类任务使用已标记的语言学数据，并在完成训练后将模型输出作为Bert模型的池化-输出层输出。 由文本表示的知识库被转换(S3)成由语义向量表示的知识库。 随机森林用于(S4)语义向量空间的语义分割。 将用户问句转换(S5)为相应的语义向量，使用用户问句语义向量在N二叉树上进行遍历，搜索N个最相邻的叶子节点。 计算M个语义向量与用户查询语句语义向量的相似度(S6)，选择相似度最高的语义向量，确定命中中的知识。一种问答系统中基于语义的快速知识命中装置，包括独立权利要求。  12
本发明提供了一种预训练语言模型的训练方法、存储介质及服务器，该训练方法通过利用特定场景的文本语料对通用领域的语言模型进行预训练，所得到的专业领域的预训练语言模型可以更好地捕捉到特定场景下文本语料中的独有信息。通过分词工具分词，使得整体的词语作为是否被遮蔽的目标，能够加大语言模型的训练难度，提升语言模型的语义理解能力，进而提升经过训练所获得的预训练语言模型的准确性。增加的每条文本的类别标签信息也富有丰富的语义信息，通过加入类别标签信息，能够更好的让预训练语言模型理解整体的语言效果。改善采用预训练语言模型处理下游的自然语言处理任务过程中的准确性及效率。使用服务器预训练通用领域的语言模型的方法(要求保护)，以及用于自然语言推断、问答和序列标签的人工智能领域中的自然语言处理任务的文本语言数据特定场景。提高了预训练语言模型对下游自然语言进行处理过程中的准确率和效率。 可以增加语言模型的训练难度。 语言模型的语义理解能力，从而提高训练得到的预训练语言模型的准确性。 通过添加类别标签信息，可以使得整个语言效果理解预先训练的语言模型。 得到的专业领域的预训练语言模型的准确性，可以更好地捕捉到特定场景中文本语料中的唯一信息。 各文本的类别标签分类丰富，语义信息丰富，从而可以增强自然语言处理任务过程的准确率和效率。该方法包括获得特定场景的文本语言学数据。 文本语料中设置有多个文本。 类标签用于标记每个文本。 利用分词工具对每个文本进行分词，得到分词后文本。 在每次分词后的文本的前后分别添加起始标记和首结束标记。 在所述第一结束标识的后面添加每个文本的类别标签。 在所述类别标签之后添加第二结束标识。 获得每个文本的包含标签的文本。 通过Word2vec(自然语言处理应用)模型从词库中提取每个阴影词的相似词，以替换所述相似词。包括一个独立权利要求，用于包括用于训练预训练语言模型的指令集的存储介质。  11
一种基于transformer与不确定性的动态人脸表情识别方法，使用Vision Transformer有效地表示多尺度特征，以实现密集预测任务。引入全局到局部特征交互(GLI)，以利用CNN的局部连通性和transformer的全局上下文。最后，使用根据DS证据理论计算证据和不确定性，并通过DS证据理论对证据和不确定性进行组合，从而在保持良好性能的同时确保效率。该方法通过多特征融合的方式提高了表情视频的特征提取效果，并通过DS证据理论、多分支卷积、注意力机制深度学习了不平衡的动态表情特征。相较其他方法，本方法科学有效的降低了样本不平衡对表情识别带来的影响，充分利用时空特征挖掘视频表情的潜在语义信息，以此进行表情分类提高可靠性和准确率，解决表情识别的需求。基于功率和不确定性的动态人脸表情识别方法。该方法科学有效地降低了样本不平衡对表情识别的影响，并充分利用时空特性挖掘视频表情潜在的语义信息对表情进行分类提高了可靠性和准确性并解决了表情的需求。该方法涉及从Dweet数据集获得视频数据。 对所述视频数据进行预处理，得到人脸表情图像序列。 提取一个人脸表情序列的特征，得到所述人脸序列特征。 建立DEViT网络模型。 建立多尺度功率模型和不确定性判断器。 将所述人脸串联特征输入多级电源模型。 得到分类结果。 对一个待检测表情视频进行预处理。 将所述表情视频输入训练好的DEViT网络模型。   5
本发明实施例公开了一种模型训练、语音识别方法、装置、电子设备及存储介质。该模型训练方法包括：获取用于进行语音识别的预训练模型和原始识别模型，预训练模型中的对称卷积网络包括与当前时刻或当前时刻之前的过去时刻对应的第一卷积核，原始识别模型包括因果卷积网络；基于多个第一音频数据对预训练模型进行预训练；针对每个第一卷积核，确定因果卷积网络中与第一卷积核对应的第二卷积核，并基于预训练后的第一卷积核的第一参数，对第二卷积核的第二参数进行初始化，以得到初始化模型；基于多组训练样本对初始化模型进行训练，得到语音识别模型。本发明实施例的技术方案，训练出可适用于流式任务且具有较高识别准确率的语音识别模型。用于训练语音识别模型的方法。所述方法通过获取所述用于语音识别的预训练模型和所述原始识别模型，使得能够以较高的识别准确度训练用于流式传输任务的语音识别模型。该方法包括：获取语音识别的预训练模型和原始识别模型，所述预训练模型包括对称卷积网络，所述对称卷积网络包括第一卷积核，所述原始识别模型包括因果卷积网络。 所述预训练模型是基于一组第一音频数据预先训练得到的。 确定所述因果卷积网络中与所述第一卷积核对应的第二卷积核。 得到初始化模型。 基于多组训练样本对初始化模型进行训练，得到语音识别模型。独立权利要求包括：(1)一种语音识别方法； (2)模型训练装置； (3)语音识别装置； (4)一种电子设备，包括处理器和存储器，所述存储器存储由所述处理器执行的用于训练语音识别模型的一组指令； (5)一种计算机可读存储介质，包括用于训练语音识别模型的指令集。 3
本公开提供了一种舆情文本的事件图谱生成方法、装置、电子设备和计算机可读存储介质，涉及自然语言处理技术领域。其中，舆情文本的事件图谱生成方法包括：基于舆情文本所属领域配置命名实体的实体类型以及两个命名实体之间的关系种类；基于实体类型对关联的第一BERT模型与第一微调网络进行训练，生成实体识别模型；基于实体类型与关系种类对关联的第二BERT模型与第二微调网络进行训练，生成实体关系抽取模型；基于实体识别模型与实体关系抽取模型获取舆情文本中的命名实体的实体关系三元组，以基于三元组生成舆情文本的事件图谱。通过本公开的技术方案，训练生成的实体识别模型能够具有较高的识别精度。一种为公众情感文本生成事件地图的方法。训练生成的实体识别模型可以具有较高的识别精度。 保证了基于情感文本生成的事件地图的可靠性。 本发明保证了语义解析的准确性，并能解决情感文本中存在的多同义词，使得训练生成的事件识别模型具有较高的识别准确率。 实体类型数据和关系类型数据训练得到实体关系提取模型，有利于保证模型使用的通用性。所述事件地图生成方法包括：基于所述公共情感文本的域来配置所述命名实体的实体类型以及所述两个命名实体之间的关系类型。 关联的第一BERT模型和基于实体类型的第一微调网络。 所述实体识别模型基于所述实体类型和所述关系类型生成。 训练相关联的第二BERT模型和第二微调网络。 生成实体关系提取模型。 基于实体识别模型和实体关系提取模型，在情感文本中获取命名实体的实体关系三元组。 基于所述三元组来生成所述公共情感文本的事件地图。独立的权利要求书包括： (1)一种用于为公众情感文本生成事件地图的装置； (2)具有处理器的电子设备； (3)计算机可读存储介质，具有存储的指令，用于实现为公众情感文本生成事件地图的方法。  12
本发明提供了一种基于多种算法融合的聚类方法，包括：针对电话营销时进行沟通的语句进行收集获得电话营销的语料，并进行数据预处理；针对数据预处理后的训练语料通过神经网络模型BERT进行迭代计算，得到迭代过程中的损失值，然后反向传播梯度到神经网络的参数中，根据更新原则更新神经网络模型BERT中网络的权重值，得到神经网络模型BERT的优化模型；将预处理后的待聚类语料通过神经网络模型BERT优化模型进行特征信息提取，获得电话营销的语料中待聚类语料的特征信息向量，并针对电话营销的语料中待聚类语料的特征信息向量采用t‑SNE降维得到降维结果；将降维结果作为k‑means聚类的输入信息，针对降维结果进行k‑means聚类，通过更新迭代中心点得到最终聚类结果。基于多种算法融合的物理或抽象对象聚类方法。该方法能够以有效的方式对电话营销语言学数据中的语料为多语种的特征信息向量进行降维得到降维结果。 该方法允许根据电话营销的通信语句对数据进行预处理，从而能够以高效的方式对数据进行预处理。多算法融合聚类方法涉及在执行电话营销时收集用于通信的句子。 获得语言学数据营销。 针对所述语言学数据市场执行数据预处理过程。 对所述语言学数据进行训练。 通过神经网络模型BERT对数据进行迭代计算过程，得到迭代过程中的损失值。 根据更新原则对神经网络的权重值进行更新，得到神经网络的优化模型。 通过神经网络BERT优化模型对预处理后的待聚类对象进行特征信息提取。 通过更新迭代中心点得到聚类结果。 根据聚类结果输出聚类划分。  12
本发明公开了一种融合实体间关系的中文医学命名实体识别方法和装置，其中，该方法包括：通过预训练的编码模型对医学文本进行编码处理，并利用编码网络进行编码处理获得高层级特征向量；利用预训练的编码模型进行关系嵌入表示，同时采用注意力机制将第二文本信息作为上下文信息，并对医学文本中的关系嵌入和文本嵌入进行运算得到医学文本的关系特征信息；通过权重分配策略计算概率权重并融合上下文信息和关系特征信息，以对关系特征信息和医学文本进行权重分配平衡；通过实体识别模型的解码输出概率最高的命名实体类别，以得到对应医学文本的各标签结果。本发明可以将关系信息有效融入文本表示中，以增强医学领域实体识别能力。本发明公开了一种中医命名实体识别方法，用于融合实体之间的关联。本发明通过自适应权重分配策略分析文本与关系的相关性，有效地将关系信息整合到文本表示中，增强了医学领域实体识别能力。该方法包括将医学文本输入到用于文本嵌入的实体识别模型中。 通过预训练的编码模型对医学文本执行第一编码处理以获得第一文本信息。 通过使用编码网络基于权重分配平衡来执行第二编码处理以获得第二文本信息。 通过实体识别模型对命名最高的实体类型的概率进行解码。 通过所述标签结果获得与所述医学文本相对应的标签结果。本发明还公开了一种融合实体识别装置，属于生物医学技术领域。  10
本发明涉及一种医学命名实体识别方法及系统，所述方法包括：获取待进行医学命名实体的目标文本及所述目标文本中各实体对应的百科知识文本；将所述待进行医学命名实体的目标文本及所述目标文本中各实体对应的百科知识文本输入预先训练好的医学命名实体识别模型中，得到所述目标文本的医学命名实体识别结果；其中，所述预先训练的医学命名实体识别模型是基于预先标记好实体的文本获取的；所述预先训练的医学命名实体识别模型包括：BERT层、Bi‑LSTM层、知识层和CRF层。本发明提供的技术方案，基于对文本中各实体对应的百科知识信息查询，考虑百科知识与文本的关系，利用百科知识增强原文本表示，然后再进行目标文本的医学命名实体识别，进而增强了命名实体的识别效果。一种用于医疗信息系统和医疗知识信息化的医疗命名实体识别方法，包括医疗知识，诊断报告和电子病历。所述方法包括：获取医学命名实体的目标文本和所述目标文本中每个实体对应的百科知识文本，从而提高命名实体的识别效果。该方法包括获得医学命名实体的目标文本和与目标文本中的每个实体相对应的百科知识文本。 将待处理的医学命名实体的目标文本和每个实体中实体对应的百科知识文本输入到预先训练好的医学命名实体识别模型中，得到医学命名实体识别目标文本。 所述预先训练好的医学名称实体识别模型是基于所述实体的预先标注文本而获得的。独立的权利要求书包括： (1)一种医学命名实体识别系统，具有：获取模块，用于获取所述医学命名实体的目标文本和所述目标文本中的每个实体对应的百科知识文本； (2)计算机设备具有执行该方法的处理器； 以及 (3)用于存储计算机程序的非暂态计算机可读存储介质。  10
本发明公开了一种问答对生成方法、装置及计算机可读存储介质。其中，该方法包括：获取目标文档；对目标文档进行富文本特征解析，得到目标文档的富文本特征，以及解析后的目标文本内容；基于富文本特征，从目标文本内容中提取目标答案；采用预训练模型，生成目标答案对应的目标问题，并基于目标答案以及对应的目标问题生成目标问答对。本发明解决了由于仅能基于纯文本或依赖于人工来进行问答对生成造成的问答对生成效果差、人工成本高、不便利的技术问题。生成问答对的方法。根据提取的答案和生成的问题确定问答对，从而通过不同类型的文档直接，准确，有效地实现问答对的生成技术效果。该方法包括获取(S202)目标文档。 对目标文档执行(S204)富文本特征分析，以获得目标文档的富文本特征并分析目标文本内容。 基于富文本特征从目标文本内容中提取(S206)目标答案。 使用预训练模型生成与目标答案相对应的目标问题(S208)，并且基于目标答案和对应的目标问题生成目标问答对。 富文本特征包括目标文档的分层结构，目标文档的文本类型，目标文档的段落切换表示模式，目标文档的字体大小和分析的预定语句形式。本发明还涉及一种问答对生成方法。 问答对生成装置； 存储用于生成问答对的程序的计算机可读存储介质； 以及计算机设备。  11
本发明公开了一种基于对比自监督的无参考视频质量评估预测方法及系统，利用没有标注的高质量视频数据构造不同失真类型的视频，基于这些视频样本作为对比损失中的正负样本进行模型的训练，有效地使得网络模型能够获取捕获失真的能力。将训练得到的网络作为预训练的网络，用于现有的无参考质量模型中，能够获取比目前主流的视频质量评价方法所使用的预训练模型更好的性能，并获得更为准确的视频质量评估预测结果。一种用于视频处理和计算机视觉技术领域的基于对比自监督的无参考视频质量评估和预测方法。将训练好的网络作为现有无参考质量模型的预训练网络，可以获得比目前主流视频质量评估方法所使用的预训练模型更好的性能，获得更准确的视频质量评估预测结果。 本发明充分利用未标注的视频数据进行模型训练，并对数据增强后的样本进行自我监督的比较学习，使得网络能够自主学习捕获失真相关信息的能力。该方法包括收集包含不同类型的场景内容的视频。 对训练样本中的每个原始视频执行不同类型的失真处理以获得与原始视频相对应的不同类型的失真视频，并且对每个失真视频沿时间维度划分为持续时间相等的非重叠视频段。 构建质量评估预测模型。 所描述的验证样本用于微调所描述的质量评估预测预训练模型的参数，以获得最终的质量评估预测模型。 将测试样本输入到所描述的最终质量评估预测模型中以获得视频质量评估预测结果。本发明涉及一种视频质量评估和预测的系统，其特征在于，所述视频质量评估和预测是基于对比的自监督的。 9
本发明公开了一种面向大模型训练的张量存储管理方法，涉及计算机技术领域，具体为一种面向大模型训练的张量存储管理方法，包括大模型异构训练的内存管理软件，所述内存管理软件包括内存管理器和内存信息统计器，所述内存管理软件让张量在训练过程中动态分布在CPU‑GPU的存储空间内，从而让模型训练突破GPU的内存墙，所述内存管理器负责模型数据张量，所述内存管理器用于标记所述张量的状态信息，所述大模型训练包括预热阶段和正式阶段，定时采集系统的CPU或者GPU的内存使用情况，并根据每组的统计时刻，精确统计非模型数据数值，通过管理张量在CPU和GPU的存储方式，使大模型训练突破内存墙，在相同存储硬件配置下，可以完成更大模型的训练。一种大模型训练张量存储管理方法。该方法使得当张量的存储转移时，能够利用内存管理器调整张量的位置，以便在计算设备的存储空间不足时，将计算状态的张量放置在计算设备中。 本发明通过采样的方式利用预热阶段的内存信息统计装置，建立非模型来确定CPU和GPU内存的使用情况。该方法包括在内存管理软件上执行大模型异构训练过程， 其中存储器管理软件包括存储器管理器和存储器信息统计装置， 存储器管理软件允许在训练过程中在CPU-图形处理单元(GPU)的存储空间中动态地分配张量， 因此，当内存管理器负责模型数据张量时，模型训练过程可以突破GPU的内存墙，其中大型模型异构训练包括预热阶段和正式阶段。 所述内存管理器包括查询内存模块，转换张量状态和调整张量位置，所述查询内存的内存模块通过内存管理器占用CPU和GPU的内存。  11
本发明提出了一种能源负荷增量预测方法、装置及存储介质。其中，方法包括：利用预先采集的能源负荷中长期数据训练主网络：基于主网络结合权重网络及偏差纠正网络构建为增量网络；其中，主网络与偏差纠正网络为两个并行的网络分支，其输出的和构成增量网络的输出；权重网络将所述增量网络的输入赋予权重后分别作为主网络及偏差纠正网络的输入；冻结主网络的网络参数，基于预设的损失函数利用能源负荷短期数据训练权重网络及所述偏差纠正网络；利用训练后的增量网络基于能源负荷当前数据预测未来能源负荷。本发明实施例中的技术方案能够使用连续采集的数据对预训练模型进行快速更新，并自动处理分布偏移，实现对能源负荷的精确预测。用于能量管理系统的能量负荷增量预测方法。利用不断采集的数据对预训练模型进行快速更新，并自动处理分配偏移，实现对能源负荷的准确预测。方法(100)涉及使用(S101)预先收集的中长期能量负荷数据来训练主网络。 基于所述主网络结合所述权重网络和所述偏置校正网络构建增量网络(S102)。 主网络和纠偏网络是两个并联的网络支路，主网络和纠偏网络的输出之和构成增量网络的输出。 权重网络为增量网络的输入分配权重，并分别作为主网络和偏置校正网络的输入。 对增量网络进行训练(S103)。 冻结所述主网络的网络参数，并基于预设损失函数利用所述短期能量负荷数据训练所述权重网络和所述偏置校正网络。 使用训练后的增量网络基于当前能源负荷数据预测未来能源负荷(S104)。包括以下独立权利要求：(1)用于预测能量负荷增量的装置； (2)用于预测能量负荷增量的电子装置； (3)计算机可读存储介质，其存储用于预测能量负荷增量的程序； 以及(4)用于预测能量负载增量的计算机程序产品。 0
本发明涉及打分方法技术领域，具体涉及一种基于注意力和有效程度的BERT模型打分方法，包括以下步骤：(1)取待打分的数据集，将数据集进行有效程度的预处理，(2)在BERT模型的网络层后，引入注意力机制，(3)采用引入注意力机制的BERT模型，对预处理后的数据集进行打分处理；本发明针对待打分的数据集，通过对数据清洗，能够有效的去除数据中的无关符号，有效的提升了数据集中数据的有效程度，采用具有很强特征抽取能力的BERT模型进行打分处理，并在BERT模型中引入注意力机制，极大的提升了BERT模型的性能，可以关注句子中不同类别的语义信息，能够在提升注意力和有效程度的基础上，有效的实现打分的准确性以及速度。文本问题生成技术中基于注意力和有效度的BERT模型评分方法，如提取公式，基于人的语言特征生成公式等。该方法通过对数据进行清洗，能够有效地去除数据中的不相关符号， 有效地提高了数据集中的有效程度， 利用特征提取能力强的BERT模型进行评分处理， 在模型中引入注意机制，大大提高了句子中具有不同类型语义信息的模型的性能，从而在有效实现评分的准确性和速度的基础上，提高了关注度和有效程度，具有广阔的应用前景。该方法包括：获得待评分的数据集； 对数据集进行有效程度的预处理，对数据集中的数据进行清洗，以去除数据中的无关符号，将清洗后的数据按照句子的形式进行划分，并在每句句子之前和之后添加识别标记。 在BERT模型的网络层之后引入注意机制。 引入注意机制的BERT模型用于对预处理的数据集进行评分。  12
本发明提供一种融合事件属性的大宗商品事件分类方法及装置。所述方法包括：对采集的新闻语料进行事件抽取，将事件表示为一个触发词和多个与之关联的实体；基于大语言模型提示学习识别所述触发词和实体的类型，将所述事件保存为事件图；将所有事件图作为目标图输入到深度散度图核神经网络中，从目标图中抽取一部分图得到一组源图，基于目标图与源图的散度计算得到每个事件图的图表示向量；基于改进的金融领域情感词典，生成事件的情感向量，并与所述图表示向量拼接后输入到事件分类器，输出事件类别。本发明通过增强事件属性知识，使用深度图和神经网络学习事件属性和结构，提高了事件分类的准确率。结合事件属性对商品事件进行分类的方法。该方法通过增强事件属性知识，利用深度图和神经网络学习事件属性和结构，将事件的情感向量输入到事件分类器输出事件类型，提高了事件分类的准确率。该方法涉及使用Bert-Bilstm-Crf模型来提取收集的新闻语料库的事件。 事件被表示为触发词和与触发词相关的多个实体。 基于大型语言模型提示学习来识别所述触发词和所述实体的类型。 事件被存储为事件图。 将作为目标图的所有事件图输入到深度散度图核心神经网络中。 从所述目标图中提取一部分图，得到一组源图。 基于所述目标图和所述源图的散度计算每个事件图的图表示向量。 基于改进的金融领域情感词典来生成所述事件的情感向量。 所述情感向量与所述图表示向量拼接后输入事件分类器。 输出所述事件类型。包括独立权利要求的一种结合事件属性的商品事件分类装置。  12
本发明一种基于Bert和残差自注意力机制的政务文件主题分类方法，包括政务文件原始特征抽取和选择、政务文件原始特征清洗和优化、文本预训练以及基于残差自注意力机制的主题标签分类，本发明针对政务数据多源异构的特点，提出了统一的特征抽取、异常处理和特征选择方法，设计了具有针对性的特征清洗和优化策略，构建基于Bert预训练模型和残差自注意力机制的文件主题分类模型，解决了传统文件主题分类方法效率低和缺乏自适应能力的问题，实验基于公开政务文件数据集，在面向多达70种主题标签分类的实际应用场景中，分类准确率高达96.72％。用于人工智能领域的基于Bert和残差自关注机制的政务档案主题分类方法。该方法能够提供统一的特征提取、异常处理和特征选择，针对性地设计特征清洗和优化策略，构建基于Bert预训练模型和残差自关注机制的文件主题分类模型，从而实现智能高效的政府数据归档。 该方法在面向70种主题标签分类的实际应用场景中，分类准确率高达96.72%，并且避免了从文本中进行自然语言处理，有效降低了训练成本。该方法包括提取和选择政府事务档案的原始特征。 清理优化政务档案原有特征。 特征优化用于对原始特征清洗后得到的低噪声特征文本提取文件名和文件头的关键词。 所述文本是预先训练的。 基于优化后得到的特征文本采用Bert预训练模型嵌入所述特征向量。 基于残差自关注机制对主题标签进行分类。 基于所述特征向量构建用于对所述主题分类模型进行训练、调整、保存、测试的残差自注意力模型，得到最终的文件主题分类模型，利用所述模型对所述政务文件进行主题分类。  12
本发明属于语音翻译技术领域，涉及一种BERT嵌入语音翻译模型训练方法、系统及语音翻译方法和设备，训练方法包含：收集模型训练数据；利用训练数据中的源语言预训练BERT模型，并将预训练后的BERT模型作为机器翻译模型编码层，并利用成对的源语言和目标语言文本对机器翻译模型进行训练，通过设置机器翻译模型中解码层层数来获取多个机器翻译模型；利用源语言成对的语音翻译数据训练语音识别模型；将训练后的语音识别模型编码层作为语音翻译模型编码层初始化参数，并采用熵加权方式对多个机器翻译模型输出进行加权来训练语音翻译模型，结合模型损失函数完成语音翻译模型训练。本发明提升语音翻译模型的识别性能，进而提高语音翻译效率和质量。该方法可用于训练来自变压器嵌入的语音翻译模型的双向编码器表示。该方法提高了语音翻译模型的识别性能，从而提高了语音翻译的效率和质量。所述方法包括：收集模型训练数据，所述模型训练数据包括语音翻译数据的源语种和目标语种配对文本。 选择预训练的双向编码器来自变换器的表示(BERT)模型作为机器翻译模型编码层。 将所述源语言和所述目标语言文本用于训练机器翻译模型。 通过设置机器翻译模型中解码层的层数，得到多个机器翻译模型。 结合模型损失函数，完成语音翻译模型训练。独立权利要求还包括：基于熵加权知识蒸馏的来自变换器嵌入语音翻译模型的双向编码器表示的训练系统； 一种语音翻译方法； 以及语音翻译装置。  12
本申请公开了一种为视觉大模型添加适配器的方法及装置，涉及深度学习模型技术领域，将业务场景中的图‑文多模态大模型中的视觉大模型单独提取出来，在保证原始视觉大模型识别能力的基础上，针对不同的业务场景分别训练一种适配器，使视觉大模型具有面对多种场景的通用识别能力；根据不同的线上需求选择集中式部署或分布式部署，集中式部署中视觉大模型与各个适配器共用一个推理图，适用于单节点服务器，分布式部署中视觉大模型与各个适配器部署于不同节点，通过协议通信进行数据交互，适用于集群多节点服务器，减少部署成本的同时保证了识别速度。用于集群多节点服务器和深度学习模型领域的可视化大模型添加适配器的方法。集群多节点服务器降低了部署成本，保证了识别速度。 集中部署中的可视化大模型与每个适配器共用一个推理图，适用于单个节点服务器，通过协议通信进行数据交互。该方法涉及从原始图文多模态大模型中提取(S1)视觉大模型。 构建多个适配器(S2)。 所述多个适配器根据不同的业务场景进行训练。 将可视化模型和多个适配器转换(S3)为相同的文件格式。 进行所述大型视觉模型和多个适配器的融合(S4)。 根据需求向多个服务器部署大型可视化模型和多个适配器，其中，大型可视化模型为服务器，适配器为客户端，大型可视化模型与多个适配器之间通过协议通信发生数据交互。 文件格式提供为开放神经网络交换交换格式，协议通信提供为超文本传输协议/gPRC协议。包括独立权利要求，用于：(1)一种可视化大模型添加适配器的装置； (2)一种计算机设备，包括存储器和处理器，以执行一种可视化大模型的适配器添加方法； 以及(3)一种计算机可读存储介质，存储有执行一种视觉大模型的适配器添加方法的指令集。 14
本发明提出了一种基于深度神经网络的端到端的伪装目标的检测识别方法。该方法设计了一种‘分割‑识别’的双路神经网络。‘分割’路利用目标的整体图像信息，以反注意力卷积模块为主体，加入了Receptive Field Block以保证网络获得更大的感受野，其整体设计上采用了U‑net网络结构，能够更有效、精准的捕获伪装目标的颜色、纹理等深度视觉特征。‘识别’路采用双分支的Resnet结构，将目标像素信息转换为语义信息，以识别具体的目标类型。实验结果表明，该方法能够有效解决常规目标检测识别方法对于伪装目标难以检测、难以完整分割等问题，在多种复杂环境下如海洋、丛林、雪地、沙漠等区域中，有效分离并识别多种伪装目标如动植物、人体、军事设施等。该伪目标检测和识别方法可用于端到端伪装目标，如动植物、人体和军事设施等。该方法准确检测伪装目标是否存在，准确从图像中划分出伪装目标的二值化区域，识别出多个伪装目标，如人、动物、军事目标等伪装目标，在复杂的背景环境下，部署简单，易于实际应用。该方法包括构建伪装目标数据集。 数据集分为训练集数据、验证集数据和测试集数据。 构建假目标检测模型。 输出伪装目标图像分割识别结果。 所述训练数据用于训练构建的伪装目标检测模型。 在训练过程中周期性地使用训练结果，以对训练结果进行初步测试。 根据所述初步测试的反馈结果调整所述伪装目标识别模型的细节。 在训练完成后，利用所述测试数据测试所述训练模型的测试效果。 利用测试集数据对伪装目标检测模型进行测试，以测试训练后得到的模型的检测效果。 计算测试评价指标。   4
发明公开了一种基于bert模型的高校导师推荐管理方法，包括：使用爬虫爬取高校官网提供的教师基本信息以及研究方向数据；进行数据清洗，去除无效数据以及不能够进行分析的数据，抽取对应实体构建教师知识图谱，定义问答语句完善分类的训练集，添加自定义分类使用bert模型进行训练并得到分类模型，将用户输入问题添加到测试集进行测试，得到分类准确度并确定数据检索方向；对用户输入信息进行自然语言处理得到搜索关键信息，使用对应结果进行查询；封装结果供前台使用，进行数据的可视化展示以及推荐问答功能的使用；对查询的教师相似研究方向使用欧几里得距离相似度公式进行相似度的计算，对计算查询出的结果取前十项进行展示。基于BERT模型的高中指南推荐管理方法。该方法能够提高分类精度和确定数据检索方向。该方法涉及爬取学校教师数据。 得到原始数据集。 定义教师实体数据集。 采用Python(RTM：High-level programming language)脚本处理数据集，得到可用数据集。 提取数据集的属性。 得到分类模型。 用户输入信息表示为测试集。 调用模型识别测试集的数据以获得分类准确度。 根据所述分类模型识别数据检索路径。 用户查询信息通过开放的系统调用接口进行处理。 提供了用户教师实体数据可视化。  12
本发明属于大数据智能分析技术领域，特别涉及一种基于少量标注样本的增量学习方法及系统，收集样本数据；对少量已标注样本扩充增强，获得可靠标签数据集，利用该可靠标签数据集对网络进行学习获得预训练模型；基于网络预训练模型，对大量未标注样本进行预测分类，构建增量学习候选数据集；将可靠标签数据集和增量学习候选数据集组合得到增量学习数据集，对网络预训练模型进行增量学习，并利用可靠标签数据集对增量学习所得模型进行校准学习；利用校准学习后预训练模型对未标注数据进行预测分类，通过设置循环迭代条件来判定返回重新执行。本发明在仅有少量标注样本情况下通过增量学习得到用于分类识别的可靠样本数据，提升分类识别性能和准确率。基于少量标记样本的增量学习方法。该方法能够在仅有少量标记样本的情况下，通过增量学习获得可靠的样本数据进行分类识别，提高分类识别性能和准确率。该方法涉及组合可靠标签数据集和增量学习候选数据集，以获得增量学习数据集。 利用所述增量学习数据集对网络预训练模型进行增量学习。 可靠标签数据集用于校准和学习通过增量学习获得的模型。 所述预训练模型用于对未标记数据进行预测和分类。 进行判断，以检查是返回还是重新执行增量学习候选数据集。还包括以下独立权利要求：基于少量标记样本的增量学习系统； 以及一种视觉数据分类识别方法； 以及一种自然语言数据分析处理方法； 以及计算机可读存储介质包括用于实现基于少量标记样本的增量学习的处理器和存储器。  11
本申请实施例公开了一种内容交互方法、装置、电子设备和存储介质，涉及大模型领域，该内容交互方法可以包括接收针对交互模型的交互请求，所述交互请求携带待交互内容；基于所述交互请求，确定所述待交互内容的内容类型；根据所述内容类型对所述交互内容进行改写，得到预设搜索引擎对应的至少一个待搜索内容；通过所述预设搜索引擎搜索出所述待搜索内容对应的至少一个搜索内容；基于所述搜索内容，采用所述交互模型生成所述待交互内容对应的目标交互内容。本方案可以提升内容交互的质量。一种用于通过使用电子设备来交互大型语言模型的内容的方法，所述电子设备例如为终端，即移动电话、平板计算机、车载终端、智能蓝牙设备、笔记本计算机或个人计算机(PC)，所述服务器例如为单个服务器或服务器集群(要求保护)。提高了内容交互质量。该方法包括：接收针对交互模型的交互请求，所述交互请求中携带有待交互内容。 基于所述互动请求确定所述待互动内容的内容类型。 根据所述内容类型对所述交互内容进行改写，得到与预设搜索引擎对应的搜索内容。 通过待搜索搜索引擎搜索与所述搜索内容对应的搜索内容。 基于所述搜索内容，利用所述交互模型生成目标交互内容。 内容类型包括单用途内容和多用途内容。独立权利要求包括：内容交互设备； 电子设备; 以及计算机可读存储介质具有用于交互所述内容的指令集。  11
本申请的实施例揭示了一种提示文本生成方法、装置、电子设备和存储介质，所述方法包括：对获取到的目标问题文本进行逻辑拆解，得到多个拆解文本；对每个拆解文本进行问题提取，获取每个拆解文本的问题文本；通过多个路径获取每个问题文本对应的推理依据文本集合；将所有推理依据文本集合进行拼接，得到所述目标问题文本对应的提示文本；将本申请的提示文本应用在大语言模型中，使大语言模型根据提示文本的内容得到相关问题的推理结果，可以提高大语言模型处理复杂问题的准确性。用于在大型语言模型中生成提示文本的方法。该方法能够在大型语言模型中对应用程序的文本进行提示，使得大型语言模型根据提示文本的内容得到相关问题的推理结果，提高了大型语言模型处理复杂问题的准确性。该方法涉及对获取的目标问题文本进行逻辑反汇编，得到多个反汇编文本(S10)。 提取每个拆分文本的问题(S20)。 获取每个拆分文本的问题文本(S30)。 通过多条路径得到每个问题文本对应的推理基文本集。 根据文本集合拼接推理(S40)。 获取所述目标问题文本对应的提示文本。 使所述语言大模型根据所述提示文本得到所述目标问题文本的推理结果。包括独立权利要求，用于：(1)提示文本生成装置； (2)电子设备； (3)一种计算机可读存储介质，包括用于生成提示文本的指令集。  11
本发明属于机器翻译技术领域，提供了一种基于数据增强和多任务训练改善APE模型的方法、系统及可读存储介质，其中方法包括：步骤S1：训练一个NMT模型作为预训练模型；步骤S2：将训练集的源语言句子输入NMT模型中，生成n个最佳翻译结果的译文序列, 并随机挑选出一个译文序列作为额外的机翻译文mt^；步骤S3：以多任务共享参数的方式对NMT模型进行微调；其中，多任务包括change/unchange分类任务和APE任务，共享参数为NMT模型的编码器参数。采用本发明，能够有效地检测和纠正高质量NMT系统所造成的错误，经测试，TER和BLEU在开发数据集上与baseline模型相比的得分提高了‑2.848和+3.74。基于数据增强和多任务训练的APE模型改进方法。该方法能够有效地检测和校正高质量NMT系统带来的误差，TER和BLEU在开发数据集上的得分比基线模型提高了-2.848和+3.74。该方法包括训练NMT模型作为预训练模型(S1)。 输入训练集的源语言句子(S2)。 生成最佳翻译结果的翻译序列。 随机选择翻译序列作为附加翻译。 对多任务共享参数进行微调整，提高APE任务效果(S3)。 判断多任务是否在变化/未变化分类任务和APE任务中。 判断所述多任务共享参数是否为NMT模型的编码器参数。 利用交叉熵损失函数计算模型预测结果与真实标签的差异。独立权利要求包括用于：一种基于数据增强和多任务训练的APE模型改进系统； 以及计算机可读存储介质具有基于数据增强和多任务训练改进APE模型的指令集  11
本申请提供了一种面向GUI的任务自动执行插件生成方法及服务获取方法，属于人工智能技术领域。该方法包括：响应于针对训练指导控件的触控操作，显示目标服务的GUI；在用户基于GUI演示目标服务的获取过程中，获取目标任务中每个子任务执行时用户输入的目标信息及每个子任务对应的界面信息；调用多模态大语言模型，对每个子任务执行时用户输入的目标信息及每个子任务对应的界面信息进行处理，得到至少一个子任务对应的子任务自动执行脚本；根据至少一个子任务对应的子任务自动执行脚本，生成任务自动执行插件。本申请可自动生成目标任务对应的任务自动执行插件，降低了插件编写难度及开发成本。一种面向图形用户界面(GUI)的任务自动执行插件生成方法，用于订票、预订酒店、购买咖啡、管理目标和关键结果(OKR)。应用程序自动生成目标任务对应的任务自动执行插件，降低了插件编译难度和开发成本。该方法包括：当基于目标应用程序的语言用户界面接收到用户针对目标服务的第一获取意图信息时，显示(701)任务自动执行插件的训练引导控件。 响应于用于训练引导控制的触摸操作，显示(702)目标服务的图形用户界面GUI。 所述目标信息输入由用户获取(703)所述目标任务中的每个子任务执行时每个子任务对应的界面信息。 对应一个子任务获取所述子任务自动执行脚本。 根据至少一个子任务对应的子任务自动执行脚本生成(705)目标任务对应的任务自动执行插件。 任务自动执行插件，用于被会话式机器人代理调用，以控制GUI自动执行目标任务。独立权利要求被包括用于所述FGLOW：服务获得方法； 一种面向GUI的任务自动执行插件生成装置； 服务获取装置； 电子装置； 以及存储有用于生成面向GUI的任务自动执行插件的程序的计算机可读存储介质。  11
本发明公开了一种基于问题导向的交通事故文本因果关系抽取方法，属于信息抽取技术领域，包括：S1：采集数据并对数据进行预处理，将句子分别输入到BERT和BERT+CRF中得到句子特征和结果事件，将调查模板与结果事件结合得到完整的问题，再输入到BERT中得到问题特征。S2：融合S1中得到的句子特征和问题特征，并使用平均池化和最大池化对特征进行压缩，得到文本特征向量。S3：将文本特征向量输入到Bi‑LSTM中提取上下文信息并通过GAT挖掘隐含的因果语义信息，使用CRF模型提取出原因事件，并与结果事件组成因果对。本发明使用问题引导结果事件来抽取原因事件，提高了交通事故文本因果关系抽取的准确率，为事故分析、交通规划等场景提供技术支持。基于问题指导的交通事故文本因果关系提取方法。提高了交通事故文本因果关系提取的准确性，为事故分析、交通规划等场景提供了技术支撑。该方法涉及收集和预处理(S1)数据。 通过使用Stanford解析器工具获得语法依赖图。 将句子输入到BERT中提取句子特征。 输入句子(S2)提取结果事件，结果事件与调查模板组成完整的问题，然后将问题输入到BERT中，得到问题的特征。 进行池化操作(S3)，得到文本特征向量。 将文本特征向量输入到Bi-LSTM中以提取句子的上下文表示。 结合图注意力网络和句法依赖图挖掘文本的深度句法依赖信息。 将所述特征向量输入CRF，得到成因事件。 与结果事件形成因果对。  12
本发明公开了一种针对多模态评价对象情感分类任务的基于预训练模型的语法导向网络，该网络能够进行端到端的细粒度情感分析，在抽取评价对象的同时判断其情感极性。该方法首先采用预训练模型对所用的多模态社交媒体语料进行模态对齐和融合，获得基于外部信息的多模态特征；其次，基于选用的预训练模型，过滤多模态特征矩阵中的噪声；接着，基于句法依存树对模态融合序列进行注意力计算，以捕捉基于语法信息的上下文注意力表示；最后，对于评价对象抽取和评价对象情感分类任务，构建解码层并优化损失函数。本发明提出的模型网络在多模态细粒度端到端情感分析任务上有着出色的表现。在评价对象情感分类任务上的各方面性能都较基线方法有了一定提升。基于语法引导网络的多模式评价对象情感分类方法，用于细粒度情感分类任务。 也可用于细小颗粒情感分析，提取评价对象时判断情感极性。本发明能够在基于模型网络的多模式细粒度端到端情感分析任务上提供优异的性能。 评价对象情感分类任务各方面的性能较基线法有所提高。该方法包括通过编码层获得多模式融合文本向量矩阵和单模式文本向量矩阵。 编码层的噪声通过噪声过滤层被过滤。 通过在语法注意层中引入语法来建模句子之间的依赖关系，以增强模型语法的可解释性。 通过解码层得到解码层， 其中编码层使用L×MERT对语言数据进行多模式特征编码， 在LXMERT层之外，编码层获得字符级字向量和独立的BERT编码块，LXMERT在进行交叉模式编码之前首先需要处理单模输入。  12
本发明涉及人工智能技术领域及医疗健康领域，揭露一种基于机器视觉和AIGC的心理疗愈方法，包括：获取心理疾病患者和智能对话机器人的初始对话视频；根据视频播放顺序提取初始对话视频中的对话图片，得到对话图片队列，并从对话图片队列中提取心理疾病患者的表情变化大于预设阈值的对话图片集；利用机器视觉系统从对话图片集中提取心理疾病患者的面部表情，并查询面部表情对应的对话文本；基于面部表情和对话文本对心理疾病患者进行心理情绪分析，得到患者情绪，并基于患者情绪利用AIGC生成心理治疗方案对心理疾病患者进行心理疏导。本发明还提出一种基于机器视觉和AIGC的心理疗愈装置、设备及存储介质。本发明可以提升心理疗愈的效率。一种基于机器视觉和AIGC的心脏物理治疗方法，用于利用智能对话机器人治疗患者心理疾病。该方法利用AIGC根据患者的情绪生成心理治疗方案，疏通心理疾病患者的心理，提高心脏物理治疗的效率。 该方法智能对话机器人根据视频播放顺序提取初始对话视频中的对话图片，得到对话图片队列，并从对话图片队列中提取患者表情变化大于预设阈值的对话图片集合，从而根据患者的面部表情和对话文本分析患者的心理情绪，得到患者的情绪，提高了心脏治疗康复设备的效率。该方法包括基于心理疾病患者的心理诊疗需求，获取心理疾病患者与智能对话机器人的初始对话视频(S1)。 按照视频播放顺序提取初始对话视频中的对话图片(S2)。 使用机器视觉系统从对话图像单元提取心理疾病患者的面部表情(S3)。 基于面部表情和对话文本对心理疾病患者进行心理情绪分析(S4)。 获得患者情绪。 基于所述患者情绪生成心理治疗方案，利用AIGC对所述心理疾病患者进行心理疏导。独立权利要求还包括：一种基于机器视觉和AIGC的心脏物理治疗康复装置； 以及用于存储用于基于机器视觉和AIGC治愈心脏物理治疗的一组指令的计算机可读存储介质。 8
本申请公开了一种文本处理方法、电子设备以及计算机可读存储介质，涉及大模型技术、文本识别技术、内容生成技术、对话交互技术领域。其中，该方法包括：获取第一文本；对第一文本进行识别，确定第一文本是否为目标文本，其中，目标文本用于表征存在安全风险的文本；在第一文本不是目标文本的情况下，基于第一文本生成第二文本，其中，第二文本用于表征第一文本对应的回复文本；输出第二文本。本申请解决了相关技术中文本交互的过程中存在安全风险的技术问题。文本处理方法。该文本处理方法解决了相关技术中文本交互过程中存在安全风险的技术问题。该方法包括获取(S202)第一文本。 识别第一文本(S204)。 判断所述第一文本是否为目标文本。 所述目标文本用于表征具有安全风险的文本。 在所述第一文本不是所述目标文本的情况下，基于所述第一文本生成(S206)第二文本。 所述第二文本用于表示所述第一文本对应的回复文本。 输出所述第二文本(S208)。独立权利要求包括以下内容：(1)一种电子设备； 以及(2)存储用于文本处理的程序的计算机可读存储介质。  11
本公开的实施例提供了语音识别方法、装置、设备和存储介质。所述方法包括获取当前待识别语音信号的语音特征序列；将所述语音特征序列输入预先训练得到的Deep‑FSMN模型，得到表示各个音素的概率的输出序列；将所述输出系列输入预先训练的CTC模型，得到对应的音素序列；将所述音素序列输入语言模型，转换成最终的文字序列作为识别结果。以此方式，可以提升模型性能，减少语音识别的时延；减少了运算量，提高了语音识别效果。语音识别方法。该方法提高了模型的性能，降低了语音识别的延迟和计算量，保证了语音识别的效果。该方法包括获取待识别的当前语音信号的语音特征序列。 将语音特征序列输入预先训练好的FSMN模型，得到表示每个音素概率的输出序列。 输出序列被输入到预先训练的连接时间分类(CTC)模型中以获得相应的音素序列。 将音素序列输入到语言模型中。 将最终的文本序列转换为识别结果。独立权利要求包括如下：语音识别装置； 一种电子设备，包括用于存储用于执行语音识别方法的指令集的存储器； 奖励数据收集装置； 以及用于存储用于执行语音识别方法的指令集的计算机可读存储介质。 3
本发明提供了一种微博谣言检测方法，考虑了注意力机制，该方法包含如下步骤：收集微博事件和相应评论数据集作为样本数据；对所述样本数据进行预处理，分别提取原微博与评论的文本内容；采用BERT预训练模型对文本进行预训练，每句文本生成固定长度的句向量；构建字典，提取原微博与对应数条评论组成微博事件向量矩阵；采用深度学习方法Text CNN‑Attention对向量矩阵进行训练，构建多层次训练模型；根据多层次训练模型对向量矩阵进行分类检测，得到对应社交网络数据的谣言检测结果。本发明较之传统谣言检测方法提高了准确率。检测微博的方法提高了准确率。该方法包括收集微博事件和相应的评论数据集作为样本数据。 对样本数据进行预处理，分别提取原始微博事件和评论的文本内容。 利用预训练模型对文本进行预训练，并且为文本的每个句子生成固定长度的句子向量。 构造字典以提取原始微博事件和相应注释，从而形成微博事件事件向量矩阵。 利用深度学习过程文本注意力训练向量矩阵，建立多级训练模型。 根据多级训练模型对向量矩阵进行分类和检测，得到与社交网络数据对应的瘤胃检测结果。  12
本申请公开了一种数据生成方法、电子设备及存储介质，涉及数据处理技术、文本生成技术、大模型技术领域。其中，该方法包括：获取用户数据；利用数据生成模型处理用户数据，生成用户数据对应的反馈数据，其中，用于训练数据生成模型的训练对话数据是通过多个智能体的交互构建得到的，不同智能体用于生成训练对话数据中不同对话角色的发言数据；输出反馈数据。本申请解决了相关技术中用于训练模型的训练对话数据多样性较差，导致训练出的模型泛化性较低的技术问题。用于生成数据的方法。该方法能够提高训练模型的对话数据的多样性，实现训练模型的高生成性。该方法涉及获得用户数据。 利用数据生成模型对所述用户数据进行处理，生成所述用户数据对应的反馈数据。 通过训练数据生成模型对多个智能体进行交互构建得到训练会话数据。 不同对话角色的说话数据由训练对话数据中的不同智能体生成。 输出反馈数据。还包括独立权利要求，用于：(1)一种电子设备，包括处理器和用于生成数据的存储器； 以及(3)计算机可读存储介质，其用于存储用于生成数据的计算机程序。  11
本发明提供一种流道结构性能优化模型的训练方法及装置、优化方法、介质及终端。所述训练方法包括构建流道结构性能优化初始模型；获取预训练数据集；利用预训练数据集对所述流道结构性能优化模型进行训练获得预训练模型；获取二次训练数据集，所述二次训练数据集包括给定的流道结构参数及基于CFD模拟获得的对应的流场参数；利用所述二次训练数据集对所述预训练模型进行二次训练。本申请中提供的训练方法，引入基于物理守恒定律的损失函数进行训练，避免迁移模型过拟合，反应器的流道结构性能优化模型可用于对微通道反应器的流道结构及性能进行优化。化学反应领域质子交换膜燃料电池反应器流道结构性能优化模型训练方法。该方法引入基于物理守恒定律的损失函数进行训练，避免了迁移模型过拟合，该反应器流道结构性能优化模型可用于微通道反应器流道结构和性能的优化。该方法涉及构建(S11)流道结构性能优化初始模型。 获得预训练数据集(S12)。 利用所述预训练数据集对流道结构性能优化模型进行训练(S13)，得到流道结构性能优化模型，以基于流道性能优化算法训练所述流道结构优化模型。 提供二次训练数据集(S14)，其中二次数据集包括给定的流动结构参数和基于模拟获得的对应的流场参数。 利用二次训练集对所述预训练模型进行二次训练(S15)。独立权利要求书包括用于：(1)一种优化反应器流道结构性能的方法； (2)一种流道结构性能优化模型的训练装置； (3)计算机可读存储介质，其存储有优化反应器流道结构性能的程序; 以及(4)终端。  11
本发明适用于图像处理技术领域，提供了一种图像处理方法及装置，包括：获取待处理的目标图像；将目标图像输入到训练好的U_Net模型中进行处理以得到相应的输出图像：其中，U_Net模型中设置有多个下采样模块和多个残差模块，下采样模块和所述残差模块用于提取目标图像的高层特征。图像处理方法。该方法能够以有效的方式提取目标图像的高级特征。该方法包括获得待处理的目标图像。 将待处理的目标图像输入到训练好的U-网模型中，得到输出图像。 所述U型网模型具有多个下采样模块和多个残差模块。 利用下采样模块和残差模块提取待处理目标图像的高电平特征。 所述U网模型设有编码模块和解码模块。 所述编码模块中的每个编码层设置有一个下采样模块。本发明还涉及一种图像处理装置。 一种终端设备，包括存储器和用于执行图像处理方法的处理器； 以及用于存储用于执行图像处理方法的指令的计算机可读存储介质。   6
本申请实施例属于人工智能的自然语言处理技术领域，涉及一种适用于多中文医疗语言处理任务的端到端模型训练方法、装置、计算机设备及存储介质。此外，本申请还涉及区块链技术，用户的目标序列模型可存储于区块链中。本申请根据Seq2seq框架的mT5‑small模型创建初始序列模型，并通过大量的医疗语料数据针对实体识别任务以及尾部预测任务进行预训练，使得预训练后的序列模型可以学习到隐藏于其他任务的医疗知识，有效提高多中文医疗语言处理任务的准确性。针对多中文医学语言处理任务训练端到端模型的方法。该方法能够有效提高多语种医学语言处理任务的准确性。该方法涉及获得医疗领域的医疗处理语言数据。 对一训练语料数据执行实体匹配操作，用于获取一训练语料实体。 根据Seq2seq框架的mT5-small模型建立初始序列模型。 将实体标识训练数据作为输入数据。 将所述训练语料实体作为标签信息对所述初始序列模型进行实体标识训练操作。 将尾部预测训练数据作为输入数据。 将尾部实体作为所述初始序列模型进行尾部预测训练操作的标签信息。 在完成所述实体识别训练操作和所述尾部预测训练操作后取原始序列模型作为目标序列模型。包括独立权利要求：(1)一种用于多中文医学语言处理任务的端到端模型训练装置； (2)一种计算机设备，包括存储器和处理器，用于训练用于多中文医学语言处理任务的端到端模型； (3)一种计算机可读存储介质，用于存储用于训练针对多中文医学语言处理任务的端到端模型的指令集。  11
本发明公开了一种面向配电网的故障量预测方法及存储介质，其中方法包括词嵌入步骤、训练步骤、特征向量矩阵生成步骤和故障量预测步骤，该方法基于BERT模型，并融合了Bi‑LSTM模型和平滑注意力机制，能够在综合分析多类影响因素的基础上，对某一地区某一时段的配电网故障量进行精准预测，预测时具备较好提取语义与时序信息特征的能力，并具有较高的鲁棒性和泛化能力，具有较好的实用推广价值。一种面向配电网的故障量预测方法。本发明结合平滑注意机制，可有效解决传统注意在复杂多因素下特征提取不稳定的问题，提高模型的稳定性，降低噪声，充分挖掘深度特征之间的关系。 本发明具有很好的推广能力，不依赖于任何具体场景，具有很好的实际推广价值。该方法包括获取电网文本数据。 网格文本数据被转换成词向量。 基于BERT语言模型训练词向量。 基于训练后的字向量生成特征向量矩阵。 使用B-LSTM网络模型计算特征矩阵。 平滑关注矩阵基于特征矩阵和平滑关注机制来确定。 基于平滑关注来预测故障量。本发明还涉及一种计算机可读存储介质，包括一组用于预测面向配电网的故障量的指令。 0
本发明提供了配电网故障处置知识图谱构建方法及装置，方法包括：步骤1.通过配电网的调控系统获取配网设备台账数据、调度规程数据、配网缺陷库数据和故障处置数据四种数据，并进行预处理；步骤2.将前三种数据整理为三元组形式；步骤3.对第四种数据进行标注，得到每条数据中的多个命名实体以及多个实体类型，并得到标注后的故障处置数据集；步骤4.将标注后的故障处置数据集作为模型训练数据集，采用预训练的方法构建BERTwithDic‑BiLSTM‑CRF实体识别模型并进行微调训练，识别配电网领域复杂专业实体，并将故障处置数据整理为三元组形式；步骤5.根据三元组形式的数据构建配电网故障处置知识图谱。配电网故障处理知识图谱构建方法。该方法能够有效避免配电网包含训练数据少、标注成本高的问题，实现配电网领域复杂专业实体的高效识别，从而实现知识图谱应用的高度自动化，有效识别配电网领域复杂的数字和符号专业实体。该方法涉及通过配电网的控制系统获取配电网设备台账数据、故障处理数据、调度规则数据和配电网缺陷数据库数据。 进行数据清洗预处理。 对预处理后的故障处理数据进行标记。 获取每个数据中的多个命名实体和多个实体类型。 得到标记后的故障处理数据集。 得到配电网设备台账数据、配电缺陷数据库数据、调度规则数据和故障处理数据的三元组形式。 配电网文本数据通过图数据库进行存储和可视化。 构建配电网故障处理知识图谱。包括独立权利要求用于配电网故障处理知识图谱构建装置。 0
本发明公开了一种用于城市大脑的多模型融合问答方法，包括：依据知识图谱库获取用户输入问句的第一答案，确定第一置信度；依据问答库对用户输入问题进行匹配，确定第二答案及第二置信度；依据生成式预训练获取用户输入问句的预测答案；依据问答库对预测答案进行匹配确定第三答案及第三置信度；对第一置信度、第二置信度、第三置信度进行融合分类，获取目标答案。本发明还公开了一种用于城市大脑的多模型融合问答系统、计算机存储介质。该用于城市大脑的多模型融合问答方法目的是解决问答方法因选择具有很大经验性的人工设置阈值而导致的非最优化的的问题。面向城市大脑的多模型融合问答方法。方法以极大的经验解决了人为设定阈值的选取导致的非最优问答问题。多模型融合问答方法涉及根据知识图谱库获取用户输入问题的第一答案，第一置信度根据问答库确定。 将问句输入给用户，用户进行向量匹配以确定第二答案和第二置信度。 根据生成预训练得到用户输入问题的预测答案。 根据所述数据库确定所述第三答案和所述第三置信度以匹配所述预测答案。 将所述第一置信度、所述第二置信度和所述第三置信度进行融合分类，得到目标答案。包括以下独立权利要求：采用所述城市大脑多模型融合问答方法的问答系统； 以及计算机可读介质，其存储有用于实现所述城市大脑多模型融合问答方法的指令。  11
本发明公开了一种基于Transformer的医学图像分割方法，属于图像处理技术领域。本发明包括：一、获取医学图像数据集，并分配为训练集和测试集；二、对获得图像进行切割，得到patch图像；三、在U‑Net网络中用TransConvBlock代替原有卷积块，再用自注意力块代替原有Unet编码器剩余部分，获得改进的UNet编码器；四、在解码器部分使用卷积块并依次进行下采样与残差连接，最后将每个输入的patch图像拼接成原图大小；五、使用二进制交叉熵损失函数计算损失，对网络进行训练；六、用图像测试集测试UTCNet，并用图像分割评价指标对模型进行评价。本发明实现了高精度的医学图像分割。用于计算机辅助诊断和图像引导手术系统的基于图像的医学图像分割方法，以及医学扫描中器官或病灶的分割。该方法使得对加入Swin的基于U‑Net的医学图像分割模型进行改进，结合卷积模块得到TranConvBlock改进网络编码器部分，分为两个分支，在RConv块中引入ReLU激活函数，在模型中引入自注意力机制。该方法涉及获得医学图像数据集。 数据集被分配为图像训练集和图像测试集。 得到修补图像。 使用TransConvBlock替换U-net网络中的原始卷积块。 利用二元交叉熵损失函数训练网络。 利用图像测试组对网络进行测试。 通过图像分割评价指标对模型进行评价。 获得输入图像的宽度和高度。 获取所述图像对应的像素。   5
本发明公开了一种依存句法模型优化方法、装置、设备及可读存储介质，待优化的依存句法模型包括底层的预训练模型和上层的依存关系预测网络，所述预训练模型是采用领域无关的文本训练集训练得到，所述依存句法模型优化方法包括：采用所述预训练模型对目标领域的文本训练集中的训练语句进行底层向量提取处理，得到所述训练语句中各个词对应的词向量；采用所述依存关系预测网络对所述词向量进行上层预测处理，并对处理结果进行优化以优化所述依存句法模型。本发明能够极大地减少标注工作量，降低标注成本，提高模型优化效率。用于优化依存句法模型的方法。该方法能够降低标记工作量和标记成本，提高模型优化效率。该方法包括：利用预训练模型对目标领域的文本训练集中的训练语句进行底向量提取处理。 获取与所述训练语句中的每个词语对应的词向量。 利用依赖关系预测网络对所述词向量进行上层预测处理。 优化处理结果以优化依存句法模型。 用底层的预训练模型和上层的依赖关系预测网络进行待优化依赖语法模型。针对以下内容包括独立权利要求：一种用于优化依存句法模型的设备； 以及存储用于优化依赖关系语法模型的指令集的计算机可读存储介质。  11
本发明公开了一种基于大模型辅助的案件特征识别方法。本方法为：1)获取多个案件并进行标注，得到一训练案件特征训练文本集；2)获取用于辅助选择最优特征提示模板的伪标注数据，作为辅助测试集；3)利用所选大模型为设定案由下的每个案件特征生成P个特征提示模板，利用多个其他大模型对每个案件特征的特征提示模板打分，选出排名前p个模板；将所选模板组合成q组实验数据，并划分为训练集和测试集；采用每组实验数据的训练集训练同一目标模型，得到q个训练后的模型；4)利用训练数据集训练q个模型得到最终的模型；5)将一目标文书中用于识别案件特征的数据输入模型中，得到该目标文书的案件特征。本发明提高了特征识别准确性和可靠性。通过使用服务器(要求保护)基于大模型辅助识别案例特征的方法。 可用于深度学习信息提取领域。该方法能够提高特征识别的准确性和可靠性。该方法涉及获取多个病例。 将每种情况下的情况特征标记为一个训练样本。 得到训练案例特征的训练文本集。 得到伪标记数据，辅助选择最优的特征提示模板作为辅助测试集。 利用选定的大模型为设定原因下的每个病例特征生成多个特征提示模板。 利用多个其他大模型对每个案例特征的多个特征提示模板进行评分，取平均值。 使用多个训练模型对辅助测试集中的伪标记数据进行推理。 得到多组推理结果。 将每一个案例特征的最终特征提示模板作为训练时一个案例特征对应的特征提示模板。 将用于标识目标文档中的案例特征的数据输入模型model-0，得到所述目标文档的案例特征。独立权利要求还包括一种计算机可读存储介质，所述计算机可读存储介质包括用于通过使用服务器基于大模型辅助识别案例特征的指令集。  11
本发明公开了一种大语言模型驱动的人在回路电网调度系统及方法，调度系统包括数据处理模块、大语言模型模块、交互调控模块和人机交互模块；大语言模型模块采用基于人工智能的大语言模型生成精确的电网调度决策；交互调控模块负责将大语言模型模块的决策转化为具体的操作命令，然后通过D5000API控制DAS或其他系统将这些命令发送到电网设备中去；人机交互模块体现人在回路的原则，用于接收操作员向系统提供高级指令，同时也便于操作员监督系统的运行并在必要时进行干预。本发明所公开的系统及方法可以实现更精确、高效的电网调度决策，提高电网的稳定性和可靠性，保证操作员有效地监控和干预系统运行。大语言模型驱动的人在环电网调度系统。该系统实现了更准确高效的电网调度决策，提高了电网的稳定性和可靠性并保证运行人员对系统运行的有效监控和干预。系统具有数据处理模块，对多类数据进行处理，包括人为操作数据、系统反馈数据和模型推荐数据。 大语言模型模块，利用基于人工智能的大语言模型，在系统中发挥核心作用，了解和处理大量的电网数据，生成准确的电网调度决策。 交互控制模块将大型语言模型模块的决策转化为具体的操作命令，通过电力系统调度自动化系统API控制DAS或其他系统将这些命令发送给电网设备。 人机交互模块体现了人在环的原理并接收操作人员给系统提供的高级指令，允许操作人员监控系统的运行情况并在必要时进行干预。独立权利要求的是一种大语言模型驱动的人在环电网调度系统的调度方法。  11
本发明提供了一种视频知识点抽取方法及装置，属于自然语言处理技术和教育数据挖掘相结合的领域，方法包括：将字幕顺次输入至BERT模型进行编码生成语义向量；计算任意两个语义向量之间的余弦相似度，与字幕索引构建成语义相似度表；将语义相似度表线性转换为可视的二值图；使用边界检测方法找到二值图对角线上的公共下边界；以垂直于二值图对角线翻转二值图，找出公共上边界；将公共上边界与公共下边界两两最近组合，给出字幕分割意见，提取视频知识点。本发明解决了现有画面组织形式复杂视频的分割困难问题。教学视频知识点提取方法。该方法解决了现有图片组织形式中复杂视频难以划分的问题。 该方法以字幕语义内容为核心，对教学课堂视频进行知识点提取，利用BERT模型进行自然语言词编码技术，能够有效提出教学视频中身高凝结的知识点。 为了使基于语义向量生成的余弦相似度的规则可视化，将语义相似度表转换为二值图像。该方法包括将字幕顺序输入到BERT模型以编码并生成语义向量。 计算任意两个语义向量之间的余弦相似度。 用字幕索引构建语义相似度表。 将语义相似度表线性转换为视觉二值图。 通过使用边界检测方法在二值图像的对角线上找到公共下边界。 共同的上边界和共同的下边界被组合。 给出字幕分割意见。 提取视频知识点。包括用于教学视频知识点提取装置的独立权利要求。  12
本申请公开了一种多源异构数据的集成方法、装置、设备及存储介质，所述方法包括：对获取到的数据表进行预处理，得到预处理后的数据表；根据预训练的匹配模型以及线性规划算法对所述预处理后的数据表进行匹配，得到数据表的匹配关系；根据所述数据表的匹配关系以及预训练的融合模型进行数据融合，得到融合后的数据。根据本申请实施例提供的数据集成方法，可以打破数据孤岛，实现异构数据源的互联互通；实现系统数据库语义结构解析，快速辅助重构数据库字典、数据字典、手工数据的矫正等；而且模型适用于多种应用场景，高效辅助人工进行数据筛选，使得大规模的数据表查找、残缺数据表融合成为了可能。一种多源异构数据集成方法。 用途包括但不限于工业，制造业和中型企业。该方法能够打破数据孤岛， 实现异构数据源与系统数据库语义结构分析，快速辅助重构数据库字典，人工数据的数据字典和修正，多应用场景，高效辅助人工数据的互联，过滤大规模数据查表和不完全数据表融合。该方法包括预处理所获得的数据表(101)。 获得预处理数据表。 根据预先训练的匹配模型和线性规划算法对预处理后的数据表进行匹配，以获得数据表的匹配关系(102)。 根据数据表与预先训练的融合模型的匹配关系进行数据融合，得到融合数据(103)。 将预处理后的数据表输入到预先训练好的匹配模型中进行模式匹配。 获得相似性矩阵。 根据相似度矩阵和线性规划算法得到数据表的匹配关系。独立的权利要求书包括： (a)多源异构数据集成设备； (b)存储用于集成多源异构数据的一组指令的计算机可读介质。  11
本发明公开了一种基于AIGC的工单自动生成方法、装置及相关介质，该方法包括：采用生成式人工智能技术与客户进行会话交互，并对会话交互过程进行上下文总结，得到工单相关文本；将所述工单相关文本转换为文本向量，并利用Bert模型对所述文本向量捕捉语义关系，得到所述工单相关文本对应的工单关键词；获取预置的工单特征数据库，并利用所述工单关键词对所述工单特征数据库进行特征丰富处理，得到更新的工单特征数据；采用wide&deep算法对所述工单特征数据进行预测输出，得到对应的工单预测结果；将所述工单预测结果与工单特征数据库结合后填充至预置的工单模板中，得到最终的工单。本发明基于AIGC技术充分理解客户的会话内容，从而提高工单生成效率和准确度。基于AIGC的物业公司工单自动生成方法，用于记录和跟踪维护、保养、投诉和服务请求。本发明基于人工智能计算机(AIGC)技术，能够充分了解客户端的会话内容，从而提高工单生成的效率和准确性。该方法包括使用所生成的人工智能技术与客户端进行(S101)会话交互。 将工作表相关文本转换(S102)为文本向量。 Bert模型用于捕获文本向量的语义关系。 与所述工作表相关文本对应获取所述工作表关键字。 获取预设的工单特征数据库(S103)。 利用所述工单关键字对所述工单特征数据库进行特征富集处理，得到更新后的工单特征数据。 采用wide&deep算法(S104)对所述工单特征数据进行预测输出，得到对应的工单预测结果。 对所述预设工单模板进行填充，得到最终工单。 将所述工单预测结果与所述工单特征数据库结合(S105)。独立权利要求包括如下：一种基于AIGC的工单自动生成装置； 计算机装置； 以及存储有用于自动生成工单的程序的计算机可读存储介质。  12
本发明公开了一种拼接篡改图像的检测方法。本发明方法首先搜集并下载公共图像篡改数据集，包括CASIA数据集和COLUMBIA数据集，一部分作为训练集，其他作为测试集；然后使用训练集对混合transformer神经网络进行模型训练，包括：特征提取模块、自注意力U形块、交叉注意力模块、特征解码模块；最后使用训练好的网络模型对测试集图像进行测试，得到最终的检测效果。本发明方法将自注意力和交叉注意力整合到U2‑Net中，能够从不同尺度捕获更多的文本信息和空间相关性，提高预测结果的正确性。本发明可以利用卷积的归纳偏差避免大规模预训练，可以定位各种尺度的拼接篡改区域。计算机视觉和数字图像处理领域的基于混合变压器神经网络的拼接篡改图像检测方法。该过程将自我关注和交叉关注融合到U2Net中，从不同尺度捕获了更多的文本信息和空间相关性，提高了预测结果的正确性。 该过程利用卷积的感性偏差，避免大规模的预训练，定位各种尺度的拼接篡改区域。该方法包括收集和下载共同的图像篡改数据集，其中该数据集包括CASIA数据集和COLUMBIA数据集。 特征提取模块，用于提取输入图像的特征图像。 自注意力U型块用于远程依赖关系的输入图像建模和输入图像的全局信息提取。 交叉注意力过滤特征提取模块和特征解码模块之间的非语义特征由交叉注意力模块使用。 通过特征解码模块对具有全局信息和局部信息的特征图进行解码，并在像素级上预测篡改区域。 利用训练好的网络模型对所述测试集图像进行测试，得到最终的检测效果。   4
本申请提供了一种多模态预训练的相似图片检索方法、装置及电子设备，该方法包括：获取图片特征编码器，所述图片特征编码器是与文本编码器共同经多模态预训练得到的；基于所述图片特征编码器，获取待检索图片及图片数据库中图片的图片特征；基于所述待检索图片及图片数据库中图片的图片特征，从图片数据库中召回具有与所述待检索图片的特征相似的图片数据，作为召回图片数据；对所述召回图片数据进行排序，将最近邻的数据返回，作为所述待检索图片的检索结果。本申请通过多模态预训练、图片特征提取、相似图片召回、相似性排序，实现从海量的图片数据中，高效且准确的为一张图片检索出一组语义上和内容上相似的图片。基于多模式预训练的相似图片检索方法。该方法利用多模态预训练、图像特征提取、相似图像召回和相似度排序，从海量图像数据中高效准确地为一幅图像检索出语义和内容相似的一组图像。该方法包括获取图片特征编码器，所述图片特征编码器是与文本编码器一起通过多模态预训练得到的。 基于所述图片特征编码器获取所述待检索图片和所述图片数据库中图片的图片特征。 基于所述待检索图片和所述图片数据库中的图片的图片特征，从所述图片数据库中调取与所述待检索图片相似的特征作为调取图片数据。 对所述调出的图片数据进行排序，返回最近邻数据作为所述待检索图片的检索结果。包括独立权利要求：(1)一种基于多模态预训练的相似图像检索装置； (2)一种电子设备，例如，个人计算机； (3)—种可读存储介质。 14
本申请公开了一种数据处理方法、模型训练方法、电子设备及存储介质，涉及大模型技术、小样本标注领域。其中，该方法包括：获取待处理数据，其中，待处理数据包括至少一个待标记对象；利用数据处理模型对待处理数据进行处理，得到至少一个待标记对象的目标标注结果，其中，数据处理模型是基于训练样本和训练标注结果进行训练得到的，训练样本包括至少一个训练对象，训练标注结果是对初始标注结果中满足预设条件的目标训练对象进行重新标注得到的结果，初始标注结果是利用数据处理模型对训练样本进行标注得到的结果。本申请解决了相关技术中利用小样本训练得到的大模型或生成的生产链路，对数据处理的准确率较低的技术问题。数据处理方法。该方法解决了使用小样本训练的大模型或生成的生产环节时，数据处理的准确性较低的技术问题。该数据处理方法包括获取待处理数据，所述待处理数据包括待标注对象。 采用数据处理模型对所述待处理数据进行处理，得到所述待标注对象的目标标注结果。 基于训练样本和训练标注结果对所述数据处理模型进行训练，所述训练样本包括训练对象。 其中，训练标注结果为对初始标注结果中满足预设条件的目标训练对象进行人工标注得到的结果。 其中，初始标注结果为使用数据处理模型对训练样本进行标注的结果，预设条件为初始标注结果不正确的条件。独立权利要求包括：(1)模型训练方法； (2)一种电子设备，包括其中存储有可执行程序的存储器，以及用于运行所述程序的处理器； (3)一种计算机可读存储介质，包括存储的可执行程序。  11
本发明公开一种社会偏见测量方法、系统和计算机介质，方法包括：S1：划分数据集为训练集、验证集和测试集；S2：使用BERT对训练集进行表征，获得训练集中输入问答句子的表征Ci；S3：构建两阶段提示的对比学习神经网络，利用步骤S2得到表征Ci进行训练，并输出代表社会偏见的标签信息，保存对比学习神经网络训练学习到的参数集；S4：使用验证集验证对比学习神经网络在训练集上学习到的参数集，保存在验证集上效果最好的参数集作为最终参数集，并利用测试集对最终参数集进行测试，得到训练好的对比学习神经网络；S5：利用训练好的对比学习神经网络进行社会偏见类别预测。本发明完成了开放域对话社会偏见的细粒度测量任务。用于在社会偏差测量系统中使用预训练模型测量自然语言处理(NLP)任务中的社会偏差。该方法：能够以有效的方式对社会偏好数据集的社会偏倚进行分类。 该方法允许社会偏好类型预测模块将训练好的对比学习用于神经网络社会偏好类型预测，从而以高效的方式完成开放域对话社会可预判细粒度测量任务。该方法涉及划分数据集作为训练集。 验证一个集合和一个测试集合。 获取所述训练集输入问答语句的令牌。 构建两阶段提示的对比学习神经网络。 通过使用验证集来验证参数集神经网络。 将对验证集效果最好的参数集存储为最终参数集，并利用训练好的对比学习对神经网络出社会偏倚类型预测。独立权利要求还包括：社会偏倚测量系统； 以及一种计算机介质，包括一组用于社会偏倚测量方法的指令。  12
本申请提供一种词对齐模型的训练方法、装置、电子设备和可读介质。该方法包括：对于多个目标语种中每个目标语种，获取训练词对齐数据集，训练词对齐数据集中包含每个目标语种的训练词、多个目标语种中其他目标语种的目标词以及训练词和目标词之间的对齐结果；根据大语言模型中词对齐任务的数据输入格式，构建词对齐任务指令；将训练词对齐数据集中每个目标语种的训练词、其他目标语种的目标词和词对齐任务指令，输入到大语言模型中进行词对齐，得到训练结果；根据训练词对齐数据集中的对齐结果与训练结果的比对结果，对大语言模型进行模型调整，得到词对齐模型。该方法能够减少训练时间和计算资源消耗，提高训练效率。机器翻译中词对齐模型的训练方法。该方法减少了训练时间和计算资源消耗，提高了训练效率。该方法涉及获得(S210)针对多种目标语言中的每种目标语言的训练词对齐数据集。 根据大型语言模型中词对齐任务的数据输入格式，构建词对齐任务指令(S220)。 将训练词对齐数据集中的各目标语言的训练词、其他目标语言的目标词和词对齐任务指令输入(S230)语言大模型进行词对齐，得到训练结果。 根据所述对齐结果与所述训练词对齐数据集中的训练结果的比对结果对所述语言大模型进行模型调整(S240)，得到词对齐模型。独立权利要求包括以下内容：词对齐模型的训练装置； 电子装置； 计算机可读介质，其存储用于训练词对齐模型的程序； 以及用于训练词对齐模型的方法的计算机程序产品。  11
本申请公开了一种语音数据识别方法、装置、设备和介质，该方法包括：获取待识别语音数据，将所述待识别语音数据输入至基于非人工标注语音数据优化的预设识别模型中；其中，所述非人工标注语音数据是基于模拟标签数据优化的预设预训练模型得到的，所述模拟标签数据是基于预设无标签原始语音数据转换得到的；基于所述预设识别模型，对所述待识别语音数据进行特征提取处理，得到分类结果。本申请解决现有技术中因大量训练数据需要人为标记，造成说话人语音分离的分离效率低的技术问题。语音数据识别方法。本发明解决了大量训练数据需要人工标注，导致说话人语音分离效率低的问题。所述语音数据识别方法包括：获取待识别的语音数据；将所述语音数据输入到基于非人工标注的语音数据优化的预设识别模型中。 基于基于模拟标签数据优化的预置预训练模型获得非人工标注的语音数据，基于预置的未标注的原始语音数据的转换获得模拟标签数据。 对待识别语音数据进行特征提取处理，得到基于预设识别模型的分类结果。 模拟标签数据是通过用生成的未加标签的语音数据部分替换预设的未加标签的原始语音数据而获得的。本发明还涉及一种语音数据识别装置； 以及用于存储程序的介质。 3
本发明公开一种基于模型重用的带隐私保护的跨区域通信质量预测方法，包括多区域数据采集步骤、模型训练步骤、模型规约计算步骤、模型及对应规约上传步骤、新区域部署及测试步骤；首先在不同区域分别收集通信数据，训练通信质量预测模型；然后计算得出适用于描述该模型能力的规约，并将训练完成的模型和对应的规约上传至区域间公开可见的模型库中；最后在新的区域上，可以直接通过对无标记数据与模型库中多模型规约的匹配，找到最适合预测当前用户通信质量的模型进行预测，从而完成对通信质量评价收集困难的新区域的预测。本发明可以解决多区域之间有用户数据隐私保护需求，不能共享数据辅助新区域模型训练的难点，实现预训练模型中蕴含知识的针对性重用，具有广泛的适用性。一种基于隐私保护模型重用的跨区域通信质量预测方法。本发明降低了多区域之间用户数据隐私保护的难度，避免了共享数据来辅助训练最优区域模型训练，从而实现了对预训练模型中包含的知识的针对性重用，方便了广泛的应用。该方法包括调用标记的数据区域作为部署区域。 多个步骤由部署区域完成，以将预训练的模型和模型协议上传至模型库。 具有未标记数据的预测由访问模型库的最优区域来完成。 收集具有标签的用户通信数据以标记多个用户的通信质量。 用户通信数据用于训练机器学习模型以实现对该区域中的通信质量的预测。 通过使用用户通信数据和模型来建立协议。  11
本发明公开了一种基于多模态信息融合的大模型图文生成方法，通过嵌入空间之间的映射，将冻结的纯文本大语言模型(LLM)与预训练的图像编码器和解码器模型融合，在图像检索、图像生成和多模态对话方面展现强大的功能，本发明提出一种高效的映射网络，将LLM基础为现成的文本到图像生成模型，该映射网络将文本的隐藏表示转换为视觉模型的嵌入空间，利用LLM的进行视觉输出，除了新颖的图像生成之外，本发明还能够从预先指定的数据集中进行图像检索，并在推理时决定是检索还是生成，本发明在处理图像和文本输入，并生成检索的图像、生成的图像和生成的文本方面，在多个测量上下文依赖性的文本到图像任务中，其性能优于基于非LLM的生成模型。基于多模式信息融合的大模型图文生成方法。在多个上下文相关的文本到图像任务中，所生成的图像和所生成的文本方面在性能上优于基于非LLM的生成模型。该方法涉及学习过程图像以制作图像。 决策生成或检索用于数据和实施细节。 通过目标帽训练映射，以将图像转换成大型语言模型(LLM)令牌嵌入空间中的嵌入向量。 对决策模型进行多任务损失训练其他分量收敛后的鳃过程图像的训练。 LLM为标记生成的隐藏状态用于搜索或生成图像。 单个标记用于图像搜索模型，文本信息。 图像被生成和检索，这使得它能够被推广到广泛的视觉和语言任务中。  11
本发明公开了一种多种信息源的多模态大模型构建系统，属于人工智能技术领域。所述构建系统包括收集和处理目标人物的多种模态信息，并构建具备该目标人物语言语音特征的自生成式语音大模型。构建系统包括信息采集、处理、模型构建、训练、文本生成、输出和评价模块。通过模型的训练，使模型学习目标人物的语音、语言和情感特征，并生成模拟目标人物语言风格和情感特征的文本。同时，系统中的评价模块在训练过程中评价模型生成的语音和/或语言文本与目标人物特征的差异，并将评价结果反馈到模型训练模块优化模型，并最终获得满足用户要求的多模态大模型。多信息源的多模态大模型构建系统。管理系统中的软硬件结构采用模块化设计，便于日后升级或更改相关软硬件环境，降低使用成本。所述系统具有信息采集模块(10)，用于采集所述目标人物的多模态信息，所述多模态信息包括语音信息、图像信息和文字信息。 信息处理模块(20)，用于对所述多模态信息进行预处理，所述预处理包括语音识别、图像分类、文本分割和情感特征识别。 评估模块(70)，用于在模型训练过程中，评估所述预训练模型生成的语音和/或语言文本与所述目标人物的特征之间的差异。 将所述评估结果反馈至所述模型训练模块(40)，以缩小所述预训练模型生成的语音和/或语言文本与所述目标角色的特征之间的差异。 不断对所述预训练模型进行训练，以优化所述预训练模型。包括以下独立权利要求：一种多信息源的多模式大模型构建方法； 以及计算机系统。  11
本发明的目的在于提供一种基于X射线正弦图的增材器件内部结构几何参数测量方法，该方法首先利用增材器件的CAD信息构建仿真模体获取正弦图，输入基于U‑Net结构的神经网络和基于FNN结构的神经网络进行训练。然后对增材器件实物进行X射线扫描，无需重建，利用基于U‑Net结构的神经网络，提取出增材器件中感兴趣结构的正弦图。将此正弦图进行裁剪和变换，减少计算量。最后使用基于FNN结构的神经网络计算出感兴趣结构的内部几何参数，包括面内几何参数如半径、边长、面积，空间几何参数如壁厚、高、体积，结构间几何参数如中心距离。该方法相对于通过重建三维结构获取内部几何参数信息的方法，可以避免重建带来的伪影问题，还可以提高测量效率。本发明公开了一种基于X射线正弦图测量管壳相加器件内部结构几何参数的方法。本发明通过重构三维结构获得内部几何参数信息，避免了重构带来的伪影问题，提高了测量效率。一种基于X射线正弦波图的管壳相加器内部结构几何参数的测量方法， 对感兴趣结构的正弦图进行X射线扫描，切割和变换，计算坐标，以坐标为基准，取左右两侧的部分像素，完成正弦图的切割，将切割后的正弦图重新排列成正方形矩阵； 训练神经网络，模拟人体模型的感兴趣结构的正弦图和神经网络输出的正弦图，X射线扫描管壳相加器，将正弦图输入神经网络，得到感兴趣结构的正弦图； 对感兴趣结构的正弦图进行切割和变换，得到新的正弦图，并计算出管壳加法装置内部结构的几何参数信息。一种基于X射线正弦图的管壳相加器内部结构几何参数的测量方法，包括：基于管壳相加器的三维CAD信息构建仿真体模； 进行X射线扫描，得到器件的整体正弦图和感兴趣结构的正弦图， 切割和变换感兴趣结构的正弦图， 计算正弦图中每行投影数据的加权平均值所对应的坐标，以坐标为基准，以左右两侧的部分像素为基准，完成正弦图的分割，将分割后的正弦图重新排列成正方形矩阵； 训练基于U-网结构的神经网络和基于FNN结构的神经网络， 模拟人体模型的感兴趣结构的正弦图和神经网络输出的正弦图，X射线扫描管壳相加器，将正弦图输入基于U-网状结构的神经网络，得到感兴趣结构的正弦图； 对感兴趣结构的正弦图进行切割和变换，以减少计算量，得到新的正弦图，并通过基于FNN结构的神经网络模型计算管壳加法装置内部结构的几何参数信息。   6
本发明公开了一种基于BERT的意图数据层次聚类方法，包括以下步骤：S1：确定访客的数据；S2：通过BERT获取每条数据的向量；S3：使用层次聚类算法将步骤S2的向量进行聚类；S4：调整层次聚类算法的参数，使得聚类的结果符合标准。通过本发明的方案可快速确定某个领域访客的意图。基于BERT的意图数据层次聚类方法。该方法能够快速确定某个现场访客的意图。该方法包括确定访客数据(S1)。 通过BERT获得(S2)每个数据的向量。 输入句子由BERT转换成向量。 通过采用层次聚类算法对向量进行聚类(S3)。 通过聚类来确定输入句子的预期范围。 调整层次聚类算法的参数(S4)，以使聚类结果符合标准。包括基于BERT的意图数据分层聚类系统的独立权利要求。  12
本发明公开了一种基于卷积注意力机制的细胞凋亡计数方法、系统及平台。方案通过方法以及与所述方法相应的系统及平台，能够通过U‑Net语义分割网络很好的识别出细胞相衬图像中未凋亡的细胞、凋亡前期的细胞、凋亡后期的细胞的三种细胞类别，排除了复杂背景的干扰，提高了对尺度大小不一的细胞和堆叠细胞的计数准确率，通过VGG计数网络对三种类别的细胞进行计数。在对U‑Net语义分割网络和VGG计数网络进行训练和测试获得优化后的网络参数后，能够实现准确且快速的对目标细胞凋亡程度的衡量。基于卷积注意机制的细胞凋亡计数方法。该细胞凋亡计数方法能够准确、快速、低成本地识别和计数细胞，并且能够测量图像中的凋亡程度。 不同尺度的空腔卷积融合，结合通道注意力机制，可有效解决细胞大小不一，堆叠细胞识别困难的问题。 通过U-Net语义分割网络对未凋亡的细胞相差图像中的细胞、凋亡早期的细胞、凋亡后的细胞三种细胞类型，去除复杂背景的干扰，提高细胞的计数精度以及大小不一的堆积细胞，通过VGG计数网络对三种类型的细胞进行计数。该方法包括获得包含多个细胞的相差图像。 标记相位比较图像中的像素。 生成与原始细胞图像相对应的标签图像。 对所述相衬图像和所述标签图片进行裁剪。 将切割后的图片按照设定比例分为训练集和测试集。 构建计数网络数据集。 将所述训练集结合所述测试集按照计数网络进行语义分割处理。 实时生成不同细胞类型的三个连通域。 结合深度学习框架建立VGG计数网络。 对应三种细胞类型和计数标签对VGG神经网络模型进行训练和测试。 生成与相差图像对应的细胞凋亡状态计数数据。独立权利要求书如下：一种基于卷积注意机制的细胞凋亡计数系统； 以及基于卷积注意机制的细胞凋亡计数平台。   6
本发明公开了一种基于知识图谱的自然语言交互软件框架及其构建方法，该方法包括以下过程：用户自然语言输入模块采集输入并传送给用户指令解释引擎，用户指令解释引擎进行解析，并与通过基于知识图谱的三层存储框架的交互进行推理与操作指令生成，并将操作指令传递给软件系统进行结果反馈。大语言模型或专用语言模型仅在指令解释引擎生成操作指令失败时为指令生成提供帮助。本发明基于知识图谱的三层存储框架包括业务知识层、用户实例层和物理数据层。本发明可以降低专有场景下自然语言交互的实现成本，为一般软件提供了一种自然语言交互的通用架构与实现方法，对在垂直领域内实现更安全，更准确，更可信的自然语言交互具有很重要的现实意义。一种利用电子设备构建基于知识图谱的自然语言交互软件框架的方法(权利要求书)。该方法能够降低特殊场景下自然语言交互的实现成本。 该方法为通用软件提供了自然语言交互的通用框架和实现方法，对于实现垂直领域更安全、更准确、更可靠的自然语言交互具有重要的现实意义。该方法涉及将用户输入的指令转换为文本形式的指令。 以所述文本形式分析所述指令以确定用户意图。 采用基于知识图谱的三层存储框架分析服务类型和服务内容。 重复一个指令分析和指令推理的过程，直到推理成功。 通过所述指令解析的过程生成操作指令。 将所述用户指令传输至专用场景软件系统执行。 反馈执行结果。还包括独立权利要求，用于：基于知识图谱的自然语言交互软件框架； 以及存储介质，其存储有用于利用电子设备构建基于知识图谱的自然语言交互软件框架的指令集合。  11
本公开提供了一种基于大语言模型的暖通系统数据处理方法、装置及设备，涉及人工智能技术领域，尤其涉及数据处理领域，可以应用于建筑、工厂、数据中心等场景。具体实现方案为：响应于接收到针对暖通系统的输入信息，从多个信息中召回与输入信息相关的上下文信息；根据输入信息和上下文信息，确定多个候选工具中的N个目标工具和N个目标工具的调用顺序，N是大于等于1的整数；以及基于调用顺序，调用N个目标工具处理输入信息，得到N个目标工具的处理结果。用于通过使用在建筑物、工厂和数据中心中使用的电子设备(权利要求书)来处理加热通风系统的数据的方法。该方法使得能够接收用于加热系统的输入信息，其中从多个信息中调用与输入信息相关联的上下文信息，并且因此确保简单且有效的加热系统数据处理方法。该方法涉及接收用于加热通风系统的输入信息。 从多个信息中调用与输入信息相关联的上下文信息。 判断是否检查多个候选工具中的N个目标工具以及目标工具的调用顺序。 所述N为大于等于1的整数。 基于所述调用序列调用所述目标工具对输入信息进行处理，得到所述N个目标工具的处理结果。独立权利要求还包括用于：利用电子设备对暖通系统的数据进行处理的装置； 以及计算机程序产品，其存储用于通过使用电子设备来处理加热通风系统的数据的指令集。  11
本发明涉及一种基于多信息源增强的多选题干扰项排序方法及系统，其方法包括：S1：对输入文本进行预处理，构建语境和干扰项文本序列Xc和Xd，并输入到语境和干扰项特征匹配网络；S2：Xc和Xd经过BERT，输出单词级别语境和干扰项文本的特征矩阵Hc和Hd；S3：对Hc和Hd进行池化操作，得到文本级别的语境和干扰项特征向量ec和ed；S4：将ec和ed转换为语境‑语境相关性矩阵Mcc、语境‑干扰项相关性矩阵Mcd和干扰项‑干扰项相关性矩阵Mdd；S5：构建二源相关性矩阵Mcc+dd和多源软标签Lsoft1；S6：构建三源相关性矩阵Mcc+cd+dd，从中挑选困难负样本；S7：构建模型的损失函数本发明从多方面考虑来为每个样本分配合理的软标签并挑选出更具有挑战性的困难负样本，提升模型精度。基于多信息源增强的多选题干扰项排序方法。该方法能够从多个方面考虑构建模型的损失函数，为每个样本分配合理的标签，选择具有挑战性的困难负样本，提高模型精度和网络效率，并根据干扰项候选项的相关性，采用多源软标签机制分配合理标签。该方法包括预处理输入文本。 构建上下文文本序列和干扰项文本序列。 构建上下文与干扰项特征匹配网络。 输出词级上下文文本和词级干扰词文本的字符矩阵。 将所述词语级别的特征矩阵转换为文本级别的特征向量。 将所述文本级别的上下文特征向量和所述文本级别的干扰词特征向量转换为上下文-上下文关联矩阵。 构建双源相关矩阵。 从所述三源相关性矩阵中选取负样本。 构建上下文与干扰项特征匹配网络的损失函数进行训练。本发明还公开了一种基于多信息源增强的多选题干扰项排序系统。  12
本发明公开了一种面向产品属性的观点倾向性分析方法及系统。该方法主要包括：面向互联网产品评论数据集的预训练词嵌入模型；生成依赖产品属性的深层语义表示；基于词语空间信息和交互式注意力网络的识别影响产品属性观点倾向性的语义信息；面向产品属性的句子级观点倾向性分类器实现。另外实现了基于上述技术的面向产品评论的观点信息检索系统。本发明运用深度学习技术手段设计了依赖产品属性的深层语义表示，运用文本序列中词语的空间信息和交互式注意力网络，实现了面向产品属性的句子级观点倾向性分析方法，并运用上述相关技术实现了面向产品评论数据集的产品属性观点信息检索系统，提高了用户兴趣点(产品及产品属性)的观点信息精准查询。产品属性观点分析法。该方法能够利用深度学习技术设计产品属性的深度语义表征，以有效的方式提高对产品的用户兴趣点的视点信息和产品属性的准确查询。该方法通过预先训练好的词嵌入模型将输入语句中的词和对应的评价对象映射到高维向量空间，得到词向量。 利用所述词向量和神经网络模型获取所述评估对象的上下文关系和所述输入语句。 利用所述神经网络模型的输出结果进行词位编码处理。 通过注意力机制得到带有注意力权重的句子向量表示和评价对象向量表示。 根据具有所述注意力权重的句子向量表示和所述评价对象向量表示计算所述评价对象的视点分析结果的概率分布。还包括以下独立权利要求：产品属性观点分析系统产品属性观点信息检索系统产品属性观点信息检索方法。  12
本发明提供一种用于航空领域的知识元抽取方法，具体实施步骤包括：将航空领域的结构化标注数据输入到Bert模型，输出结构化标注数据的特征向量；将输出的特征向量和Word2Vec模型学习到的特征向量进行融合，并做Concat叠加步骤；将得到的字向量输入到层次归一化层，得到标准化的字向量；利用高层强化学习过程对得到的每个字向量进行解码，按句识别字向量中的关系触发词；建立面向航空领域长实体的头尾指针模型，得到预测出的关系和尾实体起止位置序列；将预测出的实体输出后，根据实体的标签信息进行就近原则以及匹配方式进行匹配。本发明面向航空领域，基于郑码、五笔、拼音和笔画等特征融入的方式，与Bert输出的向量相结合，提升了准确率与召回率。一种用于在航空领域中提取知识元素，用于识别诸如人员，组织和位置之类的命名实体的方法。本发明能够根据不同的识别结果对模型参数进行不同的参数优化，以解决头实体不饱满，一个约束对应多个知识元的问题，从而提高提取三元组的查全率和准确率。该方法包括将航空领域的结构化标记数据输入到BERT模型。 获得词向量。 使用Word2VEC模型得到每个词的笔划特征向量。 采用高层增强学习方法对得到的词向量进行解码。 设置总模型的参数优化机制。 优化高级增强学习的模型参数以识别关系实体的不同类型。 触发下层增强学习执行的实体识别过程，对当前关系对应的实体进行解码。 根据LTP依赖语法提取航空领域标记数据中的知识元数据，得到知识元的三元组。  12
本发明适用于人工智能领域，提供一种政务热线案件自动分类分拨方法，包括：步骤S1、建立样本集并训练预训练模型；步骤S2、根据训练好的预训练模型，遍历样本集，生成案件类别相关链表和部门相关链表；步骤S3、使用预训练模型预测样本的概率最高的案件类别和主管部门，并结合案件类别相关链表和部门相关链表，得到案件类别增强向量和部门增强向量，通过训练和参数更新，得到案件分类模型和部门分拨模型；步骤S4、获取输入的案件内容，通过案件分类模型和部门分拨模型处理，输出预测的案件分类结果和分拨部门结果。本发明方法案件分类和案件分拨准确率更高，能够将便民政务热线中的投诉案件自动分类，并分拨到主管部门处理。用于执行政务热线案件的自动分类和分发的方法。该方法能够实现较高的案件分类和案件转移准确率，能够自动对便民政务热线中的投诉案件进行分类，并将投诉案件分配给主要部门进行处理。 该方法提高了便民政务热线的服务效率，降低了人力成本，提高了热线的智能化、自动化程度和人民群众的服务水平。该方法包括建立样本集和训练预训练模型(S1)。 根据训练好的预训练模型对遍历样本集进行遍历。 生成案例种类关联链表和部门关联链表(S2)。 使用预先训练的模型(S3)来预测病例类型和样本的主要部门的最高概率。 通过训练和参数更新得到病例分类模型和所述科室分布模型。 获取输入案例内容。 输出预测案例分类结果和划分部结果(S4)。  11
本发明涉及自然语言处理技术领域，公开一种破产文书命名实体识别方法及系统，该方法包括：通过预训练得到的BERT语言模型对破产文书进行字编码，抽取文本特征生成字向量；对生成的字向量进行双向编码，得到文本标签序列数据；并对所述文本标签序列数据进行最优解码，得到最优文本标签序列；根据所述最优文本标签序列，确定每个字符所属标签类别。本发明通过加入BERT预训练语言模型作为特征表示层，较完整地保存了文本语义信息，提升了模型的上下文双向特征抽取能力，对语义信息的利用更为充分，并较好地解决了命名实体的边界划分问题，提升了模型对实体的识别率。破产工具命名实体的识别方法。加入BERT预训练语言模型作为特征表示层，更完整地存储了文本语义信息，提高了模型的上下文双向特征提取能力，充分利用语义信息的同时更好地解决了命名实体的边界划分问题。该方法涉及通过预先训练的BERT语言模型对破产文档进行(S101)词编码，提取文本特征生成词向量。 对生成的词向量进行双向编码(S103)以获得文本标签序列数据，并对文本标签序列数据进行最优解码以获得最优文本标签序列的过程。 执行根据所述最优文本标签序列确定(S105)每个字符的标签类型的过程。包括用于破产文档命名实体识别系统的独立权利要求。  12
本发明公开了一种基于记忆库的机器翻译模型训练方法，包括如下步骤：S1、基于目标语言检索生成三元组训练数据；S2、基于去噪语言模型生成三元组训练数据；S3、基于生成的三元组训练数据训练机器翻译模型。本发明先利用基于去噪语言模型生成三元组训练数据训练得到机器翻译预训练模型，再利用基于目标语言检索生成三元组训练数据去微调得到机器翻译训练模型，保证机器翻译训练模型的精确性，提高工作效率和翻译质量。该方法可用于训练基于存储体的机器翻译模型。所述方法：使得能够利用所述去噪语言模型生成三元组训练数据训练得到所述机器翻译预训练模型； 利用目标语言搜索对生成的三元组训练数据进行微调，得到机器翻译训练模型； 保证模型的准确性； 并提高了工作效率和翻译质量。该方法涉及基于目标语言搜索生成训练数据的三元组。 基于所述去噪语言模型生成所述三元组训练数据。 在任意一个句子中获取并行语料的目标单语言数据。 进行加噪，得到加噪后的句子。 所述去噪语言训练数据组用于训练去噪语言模型。 基于去噪语言模型利用生成的三元组训练数据并拼接成句子。 不断对机器翻译预训练模型进行裁剪，得到最终的基于内存库的机器翻译模型。  11
本发明公开了一种基于深度聚类的文本分类算法，首先利用BERT模型获取到文本词向量，紧接着利用CNN获取文本局部特征和利用BiGRU获取上下文语境特征，再将两种特征拼接融合，加载到K‑means聚类算法中，使得特征提取更加全面，同时也提高了文本分类的准确率。基于深度聚类的文本分类算法，用于机器学习，深度学习和自然语言处理技术领域，包括文本分析，商业应用，网页搜索，推荐系统和生物医学领域。同时特征提取更加全面，提高了文本分类的准确性。 本发明对数据要求高，采用深度神经网络实现数据还原和特征提取功能，有利于更好的聚类。 结合预训练模型和下游任务模型，为下游任务提供精确的词向量。 该方法利用卷积神经网络实现文本内容局部特征提取和双向长期记忆网络(BIGRU)获取上下文特征，然后将这两个特征拼接融合，加载到K-means聚类算法中。一种基于深度聚类的文本分类算法，首先获取中文新闻文本数据， 进行包括运动在内的十个分类， 财务， 小区， 家庭， 教育， 科技， 时尚， 时间， 游戏娱乐， 将新闻文本数据和类别标签数据组成训练集， 验证装置和测试装置， 将其存储在文本文件中，用BERT预训练模型对文本进行词嵌入，并用不同的向量表示文本中的每个词，得到融合特征，加载得到的融合结果进入K-means聚类模型，得到最终的聚类结果。  12
本发明公开了一种基于U‑NET网络双编码器结构的纤维束分割方法，涉及白质纤维束分割技术领域，包括：获取患者的DWI图像和T1w图像，将DWI图像处理成配准到T1w图像的FA颜色编码图，基于U‑Net网络中采用卷积神经网络结构的编码器以及每一层均添加残差结构和一个CBAM注意力模块的解码器，构建出纤维束分割网络模型；将FA颜色编码图像作为纤维束分割网络模型的输入，输出分割图像；根据分割图像获得脑肿瘤患者MR图像中的白质纤维分割效果图；有效地提高了神经网络的表达能力以及网络对目标物体的关注程度，减少了与目标无关的信息干扰，提高图像分割的准确性。基于U-NET网络双编码器结构的患者医学图像白色纤维束分割方法。该方法有效提高了神经网络的表达能力和网络对目标对象的关注度，减少了与目标无关的信息干扰，提高了图像分割的准确性。该方法包括将彩色编码图像输入到编码器中进行特征提取。 将提取的特征图像输入到注意力模块，所述注意力模块根据输入的特征图像和全局上下文特征图像计算注意力图像。 将T1w图像、提取的特征图像和注意力图像进行拼接，得到解码器第一层的特征图像。 解码器的该层的第一个特征图像被输入到CBAM注意力模块。 提取所述特征图像的通道维度和空间维度的特征。 将提取的特征图像残差连接到所述层的第二特征图像，用于输出分割图像。   6
本发明属于大模型技术领域，涉及一种针对中文大语言模型的对齐测评方法，包括：1)、构建对齐数据集，每条对齐数据都包括一个任务导向的用户问题、一个规则校准的参考答案和所述任务导向的用户问题对应的分类类别；2)、将对齐数据输入到待评测的中文大语言模型中，由待评测的中文大语言模型针生成对应的模型回复；3)、构建AlignBench，AlignBench规定了对齐测评任务指令、按照类别选择的打分维度和解释规则、测评流程以及打分规则；4)、由GPT‑4基于对齐数据、模型回复和AlignBench对待测评的中文大语言模型的对齐能力进行测评，以获得一个从1到10的最终评级和一个多维度的分析解释。其具有显著更好的人类偏好，增强了可靠性且平衡了评测的透明性和有效性。中文大型语言模型(LLM)如生成预训练变换器(GPT)-3、pathways语言模型(PaLM)、开放预训练变换器(OPT)、通用语言模型(GLM)和大型语言模型元AI(LLaMA)的对齐评估方法。该方法具有明显更好的人为偏好性，加强了可靠性，平衡了评价的透明度和有效性。该方法包括构建对准数据集。 将所述比对数据集中的每个比对数据输入待评估中文大语言模型。 由所述待评估中文大语言模型为每个比对数据分别生成对应的模型回复。 基于与面向任务的用户问题对应的分类类别构建所述对齐准则，所述对齐准则规定了对齐评估任务指令、根据所述类别选择的评分维度和解释规则、评估流程和评分规则。 通过GPT-4基于所述对齐数据、所述模型回复和所述对齐准则对所述待评估中文大语言模型的对齐能力进行评估，得到最终评级从1到10以及所述待评估中文大语言模型的多维度分析解释。  11
本申请提供了一种图像处理模型构建方法、装置、电子设备和可读存储介质，其中，该方法包括：对待训练图片集进行特征提取，以得到该待训练图片集的目标元特征向量；根据该目标元特征向量，在预存的模型候选库中筛选出目标预训练模型；使用该目标预训练模型计算该待训练图片集的高语义数据；使用网络架构搜索算法，根据该高语义数据搜索得到目标网络结构；对该目标预训练模型和该目标网络结构构成的初始网络模型，使用该待训练图片集进行训练，以得到目标图像处理模型，能够提高模型构建的效率。一种用于构造电子设备(要求保护)的图像处理模型的方法。本发明通过对待训练图像组进行训练，得到目标图像处理模型，提高了模型构建效率。所述方法包括：对待训练图像组进行特征提取，以获得所述待训练图像组的目标元素特征向量。 根据目标元素特征向量在预存的模型候选库中筛选出目标预训练模型。 使用目标预训练模型获得待训练图像组的高语义数据。 根据高语义数据，使用网络架构搜索算法得到目标网络架构。 训练待训练图像组以建立目标图像处理模型。本发明还涉及一种用于构建电子设备的图像处理模型的装置； 以及计算机可读存储介质，用于存储一组用于执行用于构造电子设备的图像处理模型的方法的指令。 14
本申请公开了基于模板匹配结合小样本深度模型的口语语言理解方法，所述方法包括如下步骤：(1)建立了一种基于BERT+CRF模型的意图识别和语义槽填充联合建模，通过基于BERT+CRF的联合模型，利用BERT中特殊字符[CLS]在模型训练后代表着整句话的语义信息，因此将其作为意图识别的分类输入；(2)使用SOFTMAX分类器进行意图分类，在此联合模型中，槽位提取的任务则除了直接使用BERT各字符的输出结果进行序列标注以外，另外还接入一层CRF改善实验效果。通过该种方法更好应用SLU中意图识别和槽位提取的强相关性特点，更好的在用户较短的对话文本中准确理解用户意图，使用单模型做多任务可以学习提取到更好，更丰富的特征来提升SLU任务的效果。基于模板匹配和小样本深度模型的口语理解方法。该方法能够在口语理解中利用意图识别和槽位提取的强关联特性，能够更好地理解用户会话短文本中的用户意图，并利用单模型进行多任务处理，学习提取更丰富的特征，提高口语理解任务的效果。该方法包括建立(1)基于双向编码器从变压器表示(BERT)和条件随机场(CRF)模型的意图识别和语义凹槽填充组合建模。 利用softmax分类器进行意图分类。 利用组合模型中BERT各字符的输出结果，直接利用凹槽位置提取任务(2)进行序列标注。 将文本分类任务转化(3)为基于模板和词覆盖的完整形状填充任务的半监督训练。 将针对一般样本设计的描述模板和当前句子生成的模板作为提示信息，作为联合模型的输入。 在具体联合训练中，利用交叉熵(4)作为分类的损失函数，其中意图识别和槽提取两个损失的权重比设置为3：1。  12
本发明属于自然语言处理技术领域，公开了一种多标签文本分类处理方法及系统、信息数据处理终端。步骤包括：获取数据集；对数据集进行预处理并划分为训练集和测试集；通过BERT预训练模型微调提取文本序列中单词的全局特征向量，采用卷积神经网络对全局特征向量进行聚合，得到文本序列中单词的语义向量；构建注意力权重系数矩阵，分别将每个单词的语义向量与最优权重系数矩阵中权重系数向量加权，得到标签的注意力向量；对标签的注意力向量进行归一化处理，得到每个标签的概率，选取概率最大的几个标签做为文本的类别。本发明提取了文本序列的全局和局部特征，考虑了文本中关键词对标签类别的影响，提高了分类准确性。多标签文本分类处理方法，用于信息数据处理终端(Seart)。提取文本序列的全局和局部特征，兼顾文本中关键词对标签类别的影响，提高分类准确率。该方法包括获得(S101)包含文本序列和标签空间的数据集。 对数据进行预处理(S102)，以去除无意义的词，将繁体字转换为简体字，并将数据集划分为训练集和测试集。 通过预训练模型对文本序列中所有词的全局特征向量进行微调提取(S103)，并利用卷积神经网络对得到的全局特征向量进行聚合，得到文本序列中每个词的语义向量，保存最佳语义向量模型。 计算(S104)每个标签和文本序列中所有词语的权重系数，以构建注意力权重系数矩阵，并获取最优权重系数矩阵。 对所有标签的注意力向量进行归一化处理(S105)，得到每个标签的概率，选择概率最高的标签作为文本类别。包括以下独立权利要求：多标签文本分类处理程序； 以及一种多标签文本分类处理系统。  12
本发明提供一种辅助无人系统视觉决策的解释序列产生方法，为无人系统的监督任务提供层次化的决策依据，赋予系统决策透明性，方便开发者持续优化模型，其特征在于，包括以下步骤：步骤S1，将图像数据输入至预训练好的卷积神经网络模型获取最后一层的特征图张量以及每一层梯度信息；步骤S2，基于特征图张量和每一层梯度信息，采用人工智能可解释方法，获取决策显著图集合；步骤S3，基于决策显著图集合获取激活的输入数据图像集合；步骤S4，将激活的输入数据图像集合输入至预训练好的卷积神经网络模型，采用全局工作空间映射获取各显著图组对应的权重系数；步骤S5，基于各显著图组对应的权重系数合成显著图，并基于权重系数的预定顺序得到决策序列。一种用于辅助无人值守系统视觉决策的解释序列生成方法。该方法能够为无人值守系统的监控任务提供分级决策依据，赋予系统决策透明性，方便开发人员不断优化模型。 该方法允许模型用户根据时间了解模型决策的时间，将解释明显的具有语义的图形信息纳入全局工作空间机制。该方法包括将图像数据输入(S1)预训练的卷积神经网络模型，以获得最后一层的特征图张量和每层的梯度信息。 基于特征图张量和各层的梯度信息，使用人工智能可解释方法(S2)来获得决策显著图集。 基于该判定显著图集获得(S3)激活的输入数据图像集。 将激活的输入数据图像集输入到预训练的卷积神经网络模型中，并且使用全局工作空间映射(S4)来获得每个显著图组的相应权重系数。 基于对应于显著图组的权重系数合成显著图，并且基于权重系数的预定顺序获得判定序列(S5)。本发明还涉及一种用于辅助无人驾驶系统的可视化决策的解释序列生成系统。   4
本发明提供一种矿区自动驾驶场景数据标注方法及系统，属于数据标注技术领域，该方法包括：将矿区自动驾驶场景的图像数据输入各第一单任务感知模型中，得到对应任务的第一标注预测结果；将矿区自动驾驶场景的点云数据输入第二单任务感知模型中，得到任务的第二标注预测结果；将图像数据和点云数据输入多任务云端感知大模型中，得到任务的第三标注预测结果；根据各任务的第一标注预测结果、第二标注预测结果和第三标注预测结果，确定各任务的最终标注预测结果；确定各任务的最终标注预测结果的质量评价得分，选择小于第一预设阈值的质量评价得分对应的图像数据和点云数据供人工标注。本发明实现面向矿区自动驾驶场景的数据半自动准确标注。矿区自动驾驶场景数据标注方法。该方法实现了矿井区域自动驾驶场景的数据半自动精准标注。该方法涉及将矿区自动驾驶场景的图像数据输入(101)至各第一单任务感知模型，得到各第一单任务感知模型输出的对应任务的第一标注预测结果。 将矿区自动驾驶场景的点云数据输入(102)第二单任务感知模型，得到每个第二单任务感知模型输出的任务的第二标注预测结果。 每个第二单任务感知模型是以第一点云数据样本为样本，以第一点云数据样本的实际标注结果为标签训练得到的。 所述多任务云感知大模型是以第二图像数据样本和第二点云数据样本为样本，以第二图像数据样本的实际标注结果和/或第二点云数据样本的实际标注结果为标注训练得到的。独立权利要求包括以下内容：矿区自动驾驶场景数据标注系统； 电子装置； 以及存储有用于标记矿区自动驾驶场景数据的程序的非暂态计算机可读存储介质。 13
本发明涉及一种基于注意力机制的针对信息抽取任务的数据增强方法，包括以下步骤：将信息抽取数据集文本标注为关系分类数据集，每条信息抽取数据包含文本和三元组两部分，三元组由主体、客体和关系组成，将三元组中的关系作为文本的标签，构成一条关系分类数据；将标注完成的关系分类数据集在基于BERT的文本分类模型训练；将待增强文本输入训练完成的分类模型进行分类预测，待分类文本被切分成由若干个字或单词组成的序列；将针对每个字或单词的多头注意分数进行叠加，得到每个字或单词的注意力分数，将字或单词按照注意力分数进行排序，排序靠后的字或单词按照进行随机删除，产生增强文本，增强文本与原三元组共同构成一条信息抽取数据。一种基于关注机制的信息提取任务的数据增强方法。该方法通过多头关注和头选择器从文本中提取重要信息，避免了信息冗余。 可以通过注意力得分来检测单词对相应文本的重要性，并且在不改变文本的含义的情况下选择性地提取重要单词以生成新的数据。 本发明可以在数据标注量较少的情况下，通过BERT预训练模型训练出所需的文本分类模型。 本发明基于注意机制保证了增强样本与原始样本语义的一致性。该方法包括预处理待分类的文本。 文本被分成由多个词或多个词组成的序列。 根据注意力得分排序后随机删除单词或单词。 生成增强文本。 合并增强文本和原始三元组以形成提取数据的信息。  11
本发明属于临地安防技术体系中的群体智能技术领域，公开了一种基于大模型的无人集群编队控制算法智能生成方法，该方法通过将大语言模型与数学模型库和专家知识库相结合，能够根据用户的设计开发需求，自动完成控制算法的生成、仿真环境的构建和控制算法的调参。在该方法中，大语言模型主要用于理解用户的设计开发需求，并将需求分解成子任务：控制算法生成、仿真环境生成和控制算法调参。在执行子任务时，大语言模型会按任务需求访问数学模型库和专家知识库，以获取相关的先验知识，并调用Matlab软件以求解复杂导函数和方程，同时调用AirSim软件来构建仿真环境和进行控制算法调参的工作。应用于军事领域和民用领域，尤其是面向未来临时安全系统的低空安全的基于大模型的无人集群编队控制算法智能生成方法。该方法将大型语言模型与数学模型库和专家知识库相结合，能够根据用户的设计开发需求，自动完成控制算法的生成、仿真环境的构建和控制算法的参数调整。该方法是由用户通过交互对话窗口以语音或字符的形式向语言大模型输入无人集群编队控制算法的设计开发需求。 需求理解是根据大语言模型对用户输入的设计开发需求进行的。 通过大语言模型根据需求对需求任务进行理解和分解。 执行所述三个子任务。 生成最终控制算法u，输出对交互对话窗口中的用户的最终控制算法u。 根据所述测试结果对所述控制算法的设计开发结果进行评估反馈。 由所述大型语言模型根据所述评估结果优化对应的智能生成环节。  11
本发明涉及自然语言处理领域，公开了一种症状数据处理方法、装置、计算机设备及存储介质，其方法包括：获取症状数据；通过预设BERT编码器将症状数据处理为表征向量，表征向量基于症状数据中的症状特征数据而生成；症状特征数据包括症状名称和症状属性；预设BERT编码器经预训练任务训练后获得；预训练任务用于确定表征向量与症状名称和症状属性之间的关联关系；将表征向量输入预设TextCNN模型，获取预设TextCNN模型输出的分类结果。本发明可以提高分诊结果的准确性，提升分诊结果的质量。本发明还可应用于智慧城市的建设。基于自然语言的症状数据处理方法。该方法提高了诊断结果的准确性和质量。该方法包括获得症状数据。 征兆数据由来自变换器(BERT)编码器的预置双向编码器表示进行处理。 基于所述征兆数据中的征兆特征数据生成表征向量，所述征兆特征数据包括征兆名称和征兆属性。 确定所述表征向量与所述症状特征数据之间的关联关系。 将所述特征向量输入预设的文本卷积神经网络(CNN)模型。 通过所述预设文本CNN模型输出症状分类结果。独立权利要求还包括如下：一种征兆数据处理装置； 一种计算机设备，包括处理器，用于对征兆数据进行处理； 以及包括一组用于处理症状数据的指令的可读存储介质。  12
本发明公开了一种基于预训练模型的领域词语扩展方法及系统，其基于海量外部通用语料预训练的词模型，设计叠加内部流水文本词模型精调算法，并辅以自然语言处理工具流程，实现对少量行业专属文本的词语理解以及人工经验词库构建提效，有效地提升了对非经营性收入流水的识别能力，通过这样的方式，能够自动地从流水数据中挖掘出与非经营性收入相关的关键词，实现经营流水关键词扩展，提升非经营性流水识别，并且具有较高的准确度和泛化能力，进而有效刻画用户的经营能力。信用场景下用户偿债能力评价中基于预训练模型实现领域词扩展的方法。该方法能够实现少量行业专用文本的词理解和人工经验词库构建，有效提高非运营收入管线的识别能力，从而自动从管线数据中挖掘出与非运营收入相关的关键词。 该方法能够实现操作流关键字扩展，从而提高非操作流识别，从而提高准确性和泛化能力，以有效描述用户的操作能力。该方法涉及获得用户事务流水线化文本数据。 对用户交易运行文本数据进行预处理，得到预处理后的用户交易运行文本数据。 将预处理后的用户交易流文本数据按照词频顺序排列。 将行业特殊词单元和行业特殊词向量与第一待评估种子池进行相似度关联分析，得到第一待评估种子池。 合并第二待评估种子池、第三待评估种子池和所述第一待评估种子池，得到最终种子池。本发明还公开了一种基于预训练模型的字段词扩展系统。  11
本发明提供一种联合光谱、植被指数和纹理特征的高分影像滑坡检测方法，包括获取待检测高分辨率遥感影像及对应栅格化的滑坡真实标签；提取光谱特征，通过光谱波段计算植被指数，并对待检测高分辨率遥感影像进行主成分分析，计算第一主成分的灰度共生矩阵，利用灰度共生矩阵提取多个纹理特征；采用离差标准化进行影像归一化；采用Relief‑F算法进行特征选择来降低数据冗余；通过图层叠加、滑动窗口算法扫描、数据增强来生成训练样本，利用深度U‑Net方法进行训练；基于测试样本进行模型测试、精度评价及输出滑坡检测结果图。本发明提供了一种有效的滑坡检测方法，能充分挖掘高分辨率遥感影像信息，有效提高滑坡的识别精度。一种光谱、植被指数和纹理特征相结合的滑坡检测方法。该方法使得能够利用改进的图像特征提取、高分辨率图像滑坡检测过程的植被指数和纹理特征的组合光谱，避免信息冗余。 该方法能够充分挖掘高分辨率遥感影像信息，有效提高滑坡的识别精度。该方法涉及过滤掉归一化的辅助特征，得到作为滤波器后的辅助特征。 将一个归一化的光谱特征、所述滤波后的辅助特征和一个归一化的滑坡真实标签重叠构建多维数组。 将多维数组切割成网格块。 划分训练样本和测试样本。 对所述训练样本进行数据扩充，得到扩充后的训练样本。 扩充后的训练样本用于训练深度U-Net网络。 结束训练后得到训练好的鲁棒模型。 测试样本用于测试训练好的鲁棒模型。 评价检测精度。 输出滑坡检测结果图像。   6
本发明公开了一种针对企业项目管理任务电子看板系统，包括服务器、客户端以及数据库，所述服务器与客户端通过网络连接，所述服务器与数据库连接，所述服务器包括AIGC文档助手、多模式视图功能、可量化管理功能、灵活的工作流功能、监控功能和安全功能；所述客户端设置有电子看板。本发明提高了工作效率：提供了一站式的管理平台，包括项目管理、协同办公、智能报表等功能，用户可以在一个系统中完成多种任务，有效降低了工作复杂度和时间成本, 提高了管理效果：可以根据项目需求提供多维度报表分析和可视化展示，帮助管理者更好地掌握项目进度、质量、成本等关键指标，从而更加精准地制定管理策略, 提高了用户体验。企业项目管理任务电子标识牌系统。用户可以在一个系统中完成多个任务，有效降低工作的复杂度和时间成本，提高管理效果。 可以根据项目需求提供多维度报表分析和可视化展示，帮助管理者更好地掌握项目进度、质量、成本等关键指标，从而更加准确地制定管理策略，提高用户体验。该系统具有通过网络与客户端连接的服务器。 服务器与数据库连接。 服务器包括AIGC文档助理、多模式视图功能、可量化管理功能、灵活工作流功能、监视功能和安全功能。 所述客户端上设有电子广告牌。 多模式视图功能支持诸如Kanban、Scrum和XP的多个灵活管理方案的模式视图。 1
本发明涉及一种基于U‑net网络的窄束X射线激发发光断层成像方法，包括下列步骤 : 生成模拟数据集；训练U‑net网络：对U‑net网络进行修改，保留原网络的上采样部分，下采样部分以及跳跃连接层，在U‑net网络基础上连接一个全连接层用来输出剖分后仿体各个节点处的荧光纳米粒子密度，再使用平方和损失函数计算纳米荧光粒子的损失值，利用所得到的模拟数据集进行网络模型的训练，学习测量信号中的有效信息。调整网络并测试网络模型。用作基于U-Net网络的窄束X射线激发发光层析成像方法。一种窄束X射线激发发光层析成像方法，包括：生成模拟数据集； 建立相应的仿真系统， 将人体模型分割成连续且不重叠的三角形单元， 结合辐射传递方程得到正演模型的一般方程， 采集X射线激发的纳米荧光粒子在各扫描角产生的近红外光信号，以光通量密度的测量值为特征量输入， 修改， 训练网络模型， 学习测量信号中的信息， 调整网络并对网络模型进行测试，调整超参数对上述网络进行重新训练，得到最佳模型，保存训练好的模型，将实际实验中采集到的幻影表面光通量密度的测量值输入训练好的网络模型中，实现XLCT图像重建。   6
本发明公开了一种电力数据大模型构建方法及系统，涉及电力系统数据分析与模型构建技术领域，其包括：采集电力系统的运行数据进行数据预处理构建电力系统数据模型；根据电力系统的拓扑结构和运行状态，对图数据库中的数据进行拓扑分析，计算各个节点和边的拓扑参数；利用智能文档分析平台对电力相关的文档进行内容解析，提取出与电力系统运行数据相关的文本信息；将抽取出的文本信息与图数据库中的数据进行关联，构建电力数据大模型。本发明通过数据预处理技术，确保电力系统数据的质量，结合拓扑分析准确地捕捉电力系统的结构和运行状态。利用智能文档解析挖掘了与电力系统运行相关的关键文本信息。为电力系统决策提供了更为精确的技术支持。电力系统数据分析与模型构建领域的电力数据大模型构建方法。该方法通过数据预处理技术保证了电力系统数据的质量，结合拓扑分析准确捕捉电力系统的结构和运行状态。 利用所述智能文档分析挖掘出与系统运行相关的关键文本信息。 该方法为系统决策提供了更精确的技术支持。 智能文档分析平台，用于对文档中与电力相关的内容进行分析，将提取的文本信息与图谱数据库中的数据进行关联，构建电力数据大模型。该方法涉及采集电力系统运行数据对数据进行预处理，构建电力系统数据模型。 根据电力系统的拓扑结构和运行状态对图数据库中的数据进行拓扑分析，计算出各节点和侧的拓扑参数。 智能文档分析平台，用于对与电力相关的文档内容进行分析，提取出与电力系统运行数据相关的文本信息。 将提取的文本信息与图数据库中的数据进行关联，构建电力数据大模型。独立权利要求包括以下内容：一种使用分布式电源无功响应方法的系统； 计算机装置； 以及计算机可读存储介质，其存储用于构建电力数据大模型的程序。 0
本发明提供一种基于自然语言处理的智能育儿系统和装置，属于设备监控技术领域，包括：育儿百科模块，其配置获取育儿资源数据，利用育儿资源数据对语言大模型进行训练；育儿纠错模块，其配置为对日常对话进行实时监控，捕获到语音后进行文本转换，利用预训练的分类模型对文本进行分类，得到文本标签和概率值，文本标签包括文本需要纠错，将文本标签为文本需要纠错的文本传输至知识库中，得到纠错反馈，根据概率值确定纠错反馈的方式并传达给用户；智能陪伴模块，其配置为根据年龄阶段形成对应的陪伴方式，结合知识库对不同年龄阶段的儿童进行智能陪伴。本发明不仅能提供健康科学的育儿知识，还能有效监督育儿方法的有效应用。基于自然语言处理的智能儿童看护系统。该系统提供了健康、科学的育儿知识，并对育儿方法的有效应用进行了有效监控。所述系统具有育儿百科模块，所述育儿百科模块被配置为获取所述育儿资源数据。 子育资源数据用于训练语言大模型。 将训练好的语言大模型作为知识库。 育儿纠错模块，其被配置为对所述日常对话进行实时监控。 利用所述预训练分类模型对所述文本进行分类，得到文本标签和概率值。 将所述文本标签作为所述待校正文本传输至所述知识库，得到所述校正反馈。 根据所述概率值确定所述校正反馈方式并传输给所述用户。 智能陪伴模块，其被配置为根据所述年龄阶段形成对应的陪伴模式，并结合所述知识库对不同年龄阶段的儿童进行智能陪伴。独立的权利要求包括一种基于自然语言处理的智能幼儿设备。 8
本申请实施例提供了一种基于大模型增强的垂直领域小样本知识抽取方法和系统，涉及人工智能领域。所述方法包括：获取目标领域的第一高质标注样本，并基于预先训练的大语言模型，对第一高质标注样本进行数据增强，得到目标领域的第二高质标注样本；以从第二高质标注样本中提取的多个实体，以及多个实体中每两个实体之间的关系为训练样本，训练得到知识抽取模型；基于知识抽取模型，对输入知识抽取模型的目标领域的非结构化文本进行知识抽取，得到目标领域的目标知识图谱。本申请不仅降低了数据标注的人力成本需求，还使得知识抽取模型拥有更强的可持续化学习能力以及泛化能力，从而能够灵活应用于垂直领域的多种场景，具有较好的可扩展性。基于大模型增强的垂直领域小样本知识提取方法。该方法确保降低数据标记的人力成本需求。 知识抽取模型具有更强的可持续学习能力和泛化能力，从而可以灵活应用于垂直领域的多个场景，具有良好的可扩展性。该方法包括获取目标字段的第一高质量标注样本(S101)。 基于预先训练的大规模语言模型对所述第一优质标注样本进行数据增强处理，得到基于所述数据增强处理的所述目标字段的第二优质标注样本。 对应预设知识训练预设知识抽取训练文本语言素材和预设知识图谱。 从第二优质标注样本中提取多个实体(S102)。 对输入有知识抽取模型的所述目标领域的非结构化文本进行知识抽取处理(S103)，得到目标知识图谱。包括一种基于大模型增强的垂直领域小样本知识提取系统。  11
本发明公开了一种产品标题实体识别方法及装置，应用于人工智能技术领域，其中该方法包括：获取当前产品的标题文本；确定当前产品的标题文本中每一词语及对应的语义特征；将每一词语及对应的语义特征输入预先建立的产品标题实体识别模型中，识别得到当前产品的标题实体；所述产品标题实体识别模型根据多个历史产品标题数据集样本预先建立，在建立所述模型的过程中，利用预训练模型对每一历史产品标题文本中每一词语进行语义特征的标注。本发明避免了人工标注，减少了人力成本，提高了产品标题实体识别的效率和准确率，进而提升了后续产品搜索和推荐的准确性，提升了用户体验感。应用于人工智能中的商品名称实体识别方法。该方法避免了人工标注，降低了人力成本，提高了商品标题实体识别效率和准确率，以提高后续商品搜索和推荐的准确率，提升了用户体验。该方法涉及获得(201)当前产品的标题文本。 确定所述标题文本中的词语和对应的语义特征(202)。 将所述词和所述语义特征输入(203)到预先建立的产品标题实体识别模型中，以识别当前产品的标题实体。 商品名称实体识别模型是根据多个历史商品名称数据集样本预先训练得到的。 在建立模型的过程中利用预训练模型对语义特征进行标注。包括以下独立权利要求：一种产品标题实体识别装置； 计算机设备； 存储用于识别产品标题实体的程序的计算机可读存储介质； 以及用于识别产品标题实体的计算机程序产品。  11
本申请实施例提供了一种容器运行时异常行为检测方法、模型训练方法、装置及存储介质，该容器运行时异常行为检测方法包括：获取待检测容器的属性信息，以及获取待检测容器在运行过程中的系统调用序列信息；基于预设行为检测模型对属性信息和系统调用序列信息进行异常行为检测，得到检测结果；基于检测结果，确定待检测容器是否存在异常行为。这样，通过容器的属性信息和系统调用序列信息，能够检测容器是否存在异常行为，从而弥补了无法采集到容器内部行为的缺陷，提高了容器运行过程中的安全性。容器运行过程中异常行为的检测方法。该方法检测容器是否存在异常行为，以弥补容器行为中没有收集到的缺陷，从而提高了容器操作过程中的安全性。该方法涉及获取(S101)待检测容器的属性信息，在运行过程中获取待检测容器的系统调用序列信息。 基于预设行为检测模型对所述属性信息和所述系统调用序列信息进行异常行为检测(S102)，以获得检测结果。 根据检测结果，检查要检测的容器是否具有异常行为被确定(S103)。以下包括独立权利要求：用于训练模型的方法； 用于检测容器操作过程中的异常行为的装置； 用于训练模型的装置； 以及存储用于检测容器操作期间的异常行为的程序的计算机存储介质。  11
本发明涉及人工智能技术领域，揭露一种事件检测方法，包括：获取待检测事件中的各个传播节点，并将各个传播节点按照发布时间依次排序，得到节点排序，并根据节点排序计算每两个节点的发布时间差；根据发布时间差将节点排序中的传播节点划分为多个阶段的传播节点，并获取各个阶段中所有的传播节点的文本信息，得到多个阶段文本；通过BERT网络将阶段文本转化为嵌入向量，将嵌入向量输入预设的GRU单元，得到GRU单元更新状态，将GRU单元更新状态输入预设的神经网络，计算各个阶段文本的谣言概率；根据各个阶段文本的谣言概率判断待检测事件是否为谣言事件。本发明还提出一种事件检测方法装置、设备及存储介质。本发明可以提升对事件检测的准确率。用于在人工智能领域中使用的检测流言事件的方法。该方法使得能够准确识别检测时间是否为谣言时间，因此提高了检测事件的准确性。 将传播节点划分为多个阶段的传播节点，从而结合了谣言传递过程中的动态特征，实现了待检测的谣言事件片段，最后通过计算每一阶段文本的谣言概率来判断待检测事件是否为谣言事件。该方法涉及获得待检测事件中的每个传播节点。 根据发出时间对每个传播节点进行排序。 根据所述节点排序计算每两个节点的发布时间差。 根据发布时间差，在节点排序中将传播节点划分为多个传播节点阶段。 由所述GRU单元输入的每个所述嵌入向量依次获取预设GRU单元，得到多个GRU单元更新状态。 通过所述激活函数计算每个所述舞台文本的流言概率。 根据各个舞台文本的谣言概率判断所述待检测事件是否为谣言事件。独立权利要求包括：(1)一种事件检测设备； (2)一种计算机可读存储介质，用于存储用于检测流言事件的指令集； (3)电子设备包括用于检测流言事件的处理器和存储器。  11
本发明公开了一种命名实体识别方法及装置，本发明并未直接调用使用特定领域的训练样本训练得到的神经网络模型，而是采用现有的预训练语言模型得到待分析文本对应的向量集合，进而不需要生成适用于待分析文本所在领域、且用于将文本转换成词向量的神经网络模型，并且，预训练语言模型的结构复杂，训练样本数量较多、且可以在各个领域通用，则采用预训练语言模型确定待分析文本的向量的方式，相比于调用神经网络模型确定待分析文本的向量的方式，能够提高生成的待分析文本的向量集合的准确度，进而使得命名实体识别结果更准确。一种在电子装置中识别命名实体的方法(权利要求)。本发明提高了生成的待分析文本的向量集的准确性。 命名实体识别结果更加准确。该方法包括：获取(S11)待分析文本；以及确定与包含在待分析文本中的字符相对应的识别信息。 调用预训练语言模型(S12)来处理识别信息，以获得对应于待分析文本的向量集。 对与待分析文本对应的向量集执行命名实体识别处理(S13)，以获得待分析文本中的命名实体数据。独立的权利要求书被包括在以下内容中： 命名实体识别装置； 以及 一种计算机可读存储介质，用于存储用于识别电子设备中的命名实体的方法的程序。  12
本发明公开了一种基于RoBERTa模型的长文本信息立场检测方法。本发明在长文本信息立场检测任务中引入基于文本切割的RoBERTa模型，用于编码各索引片段；引入BiLSTM和CRF模块，用于标记关键证据；引入基于Self‑training的半监督学习方法，用于训练BiLSTM和CRF模块。与现有长文本信息立场检测方法相比，本发明通过创新文本分割过程，解决RoBERTa模型对文本长度的限制问题，使其可更关注全局信息，避免因文本长度限制导致的局部信息丢失；通过基于半监督学习的关键句标注，提高模型的可解释性，并抑制长文本噪声对模型最终预测的干扰。基于RoBERTa模型的长文本信息stand检测方法。该方法能够解决RoBERTa模型限制文本长度的问题，使其更关注全局信息，避免文本长度限制导致的局部信息丢失。 提高了模型的可解释性，并基于半监督学习抑制关键句对最终预测模型的长文本噪声干扰。长文本信息支架检测方法包括输入证据文档和待检测语句。 输入预先训练的位置检测模型。 对所述证据文档中每个句子的词向量序列进行词级注意力机制加权融合，得到句子向量。 通过句子级别注意力机制对每个句子中的句子的句子向量进行句子向量加权融合处理。 得到关键句加权平均向量。 将所有关键语句的语句向量进行加权融合，得到所述关键语句的加权平均向量。 输出声明的分类结果。  12
本公开的实施例提供的信息生成方法和装置，通过响应于获取到目标用户的音频数据和视频数据，对音频数据进行音频特征提取，得到音频数据对应的音频特征，然后对视频数据进行视频特征提取，得到视频数据对应的视频特征，之后将音频特征和视频特征输入至预训练模型的特征提取网络和多头注意力层，获取音频特征和视频特征对应的融合特征集合，最后基于融合特征集合，生成目标用户对应的状态分析信息，能够对目标用户的学习数据进行实时分析，对目标用户的音频特征和视频特征进行融合分析，使得目标用户可以及时了解在学习和训练过程中的技巧和姿态等方面。用于由诸如膝上型计算机和电视(来自附图)的终端设备生成用户状态分析信息的方法。该方法能够对目标用户的学习数据进行实时分析，从而对目标用户的音频特征和视频特征进行融合分析，使得目标用户能够及时了解学习训练过程中的技能和姿势。该方法包括：响应于获取目标用户的音频数据和视频数据，提取所述音频数据的音频特征，得到所述音频数据对应的音频特征。 提取所述视频数据的视频特征，得到所述视频数据对应的视频特征。 将所述音频特征和所述视频特征输入至预训练模型的特征提取网络和多头注意力层。 获取与所述音频特征和所述视频特征对应的融合特征集。 基于所述融合特征集生成与所述目标用户对应的状态分析信息。包括独立权利要求，用于：(1)终端设备生成用户状态分析信息的装置； (2)一种电子设备，包括处理器和存储器，用于由终端设备生成用户状态分析信息； (3)一种非瞬时计算机可读存储介质，用于存储终端设备生成用户状态分析信息的一组指令。 9
本发明公开了一种基于图注意力机制的深度学习问答推理方法及装置。本发明提出了一种基于图点乘注意力算法的推理模型AGTF，针对问答中的多跳问题，提出了融合ALBERT与图注意力机制(GAT)的混合模型，该模型包含了编解码层和图神经网络预测层，经过实验结果表明，与现有的多跳问答推理算法相比，AGTF模型有效的提高了多跳问答的推理能力。集成Albert与图形注意机制的深度学习问答推理方法AGTF模型有效地提高了多跳问答的推理能力。该方法包括提取数据的特征。 表示提取单元的输入问题和相关段落。 输出相应问题和段落的词向量。 从词向量中提取语义向量。 执行实体计算推理过程。 利用动态图形注意机制，利用图形神经网络将节点信息传递给各相邻节点，实现推理过程。 传输动态图中的信息。 使用Graph2DOC模块将来自实体流的信息保存回上下文中的向量。 在日志上计算交叉熵损失。 输出预测结果。还包括独立的权利要求： 一种基于图形关注机制的问答推送装置； 以及 一种计算机可读存储介质，包括一组用于基于图形注意力机制推理深度学习问答的指令。  12
本发明涉及一种代码示例库的构建方法，包括如下步骤：收集全部场景的任务数据；输入到大模型中获取操作序列；对操作序列进行标签提取，获得第一标签列表；基于第一标签列表对API文档进行打标；对所收集的全部场景的任务数据进行人工标注，以获得基础示例库；基于大模型对基础示例库中的每一示例数据进行标签提取，以获得示例任务的标签列表；获得每一示例数据对应的标签，即示例代码的标签列表；基于示例任务的标签列表中的标签和示例代码的标签列表中的标签，计算用于评估基础示例库的质量的示例代码有效性的准确率。本发明在最大程度上提高代码示例库的构建质量，在少量样本的情况下，通过提高召回示例的代码质量来提升生成代码的性能。构建用于最终代码生成的代码实例库的方法。该方法最大限度的提高了代码实例库的构建质量，在样本数量较少的情况下，通过提高召回实例的代码质量，提高生成代码的性能。该方法包括收集(S101)所有场景的任务数据。 将采集到的所有场景的任务数据输入(S102)到大模型中，以获得对应的操作序列。 对采集到的所有场景的任务数据进行人工标注(S105)，得到基本实例库。 基于大模型对基础实例库中的每个实例数据进行标签提取(S106)，得到实例任务的标签列表。 对所述基本实例库中的每个实例数据进行代码语法分析(S107)，以获得所有被调用的函数名。 从加标签的应用程序编程接口(API)文档中查找所有被调用函数名的对应标签，以获得实例代码的标签列表。 基于示例任务的标签列表中的标签和示例代码的标签列表中的标签，计算用于评估基本示例库的质量的示例代码有效性的准确性(S108)。本发明还公开了一种代码实例库的使用方法。  11
本公开涉及一种网络训练方法及装置、图像处理方法及装置。所述网络训练方法包括：将训练集中的样本图像以及所述样本图像的变换图像分别输入第一网络中处理，得到所述样本图像的第一处理结果以及所述变换图像的第二处理结果，所述变换图像是对所述样本图像进行几何变换得到的；将所述样本图像的变换图像输入预训练的第二网络中处理，得到所述变换图像的第三处理结果；根据多个样本图像的标注结果及第一处理结果，所述多个样本图像的变换图像的第二处理结果及第三处理结果，训练所述第一网络。本公开实施例可提高训练后的学生网络的性能。网络训练方法。提高了训练学生网络的性能。所述方法包括：将训练集中的样本图像和所述样本图像的变换图像输入第一网络进行处理，得到所述样本图像的第一处理结果和所述变换图像的第二处理结果，所述变换图像是对所述样本图像进行几何变换得到的。 将所述样本图像的变换图像输入预先训练的第二网络进行处理，得到所述变换图像的第三处理结果。 根据所述多个样本图像的标注结果和所述第一处理结果，所述多个样本图像的变换图像的第二处理结果和第三处理结果训练所述第一网络。独立权利要求包括：图像处理方法一种电子设备包括处理器和用于存储处理器可执行指令的存储器以及计算机可读存储介质。 14
本发明公开了一种基于BiLSTM与知识图谱的建筑规范审查方法与系统，其中方法包括：1、对标准施工图审查规范条文进行规范预处理和BIO标注，获取标注数据集StandData；2、使用StandData训练基于BERT嵌入BiLSTM‑CRF神经网络模型，得到施工图审查规范实体属性识别模型SubModle；3、对待审查施工图的规范约束条文进行处理后输入SubModle；经viterbi解码并进行实体属性抽取，构成实体属性集EnityData；4、对EnityData进行关系抽取，建立规范约束文本的三元组列表，使用Neo4j建立施工图审查规范知识图谱；5、将待审查BIM施工图文件与施工图审查规范知识图谱进行规范匹配得到审查结果。该审查方法能够实现智能审查，提高了建筑施工图的审查效率。该方法可用于建立基于BiLSTM和知识图谱的规范考试。该方法：实现智能考试； 并提高了建筑施工图纸的考试效率。该方法涉及对标准施工图考试标准条款中的文本数据进行预处理。 得到打标数据集。 建立施工图表审核规范实体属性识别模型。 将预文本中的单句输入到子模型中。 获取每个单句词元素的最大标签类型概率。 提取所述预文本中单句的实体属性，形成实体属性集实体数据。 将用户输入的建筑信息建模(BIM)施工图文件标准化，并与施工图考试规范知识图谱进行匹配，智能获取考试成绩。一种基于双向长短期记忆(BiLSTM)和知识地图的建筑规范考试系统，还包括独立权利要求。  12
本发明公开了一种问答互动方法、系统、装置及存储介质。问答互动方法包括：获取语句文本；将语句文本转化为多个矢量数据；根据语料库对各个矢量数据进行权重分析，生成矢量权重；根据矢量数据与矢量权重，通过基于注意力机制的BERT模型分析语句文本的语义；根据语义识别语句场景；根据语义和语句场景生成应答。本发明通过建立收集有乡村场景互动数据的语料库，提高了应答的可靠性与针对性，使得应答更贴合乡村教育互动场景；通过将语句文本转化为矢量数据，并分析矢量权重，降低了矢量的维度，提高了矢量表示的准确性，同时通过基于注意力机制的BERT模型进行语义分析，提高了语义的稳定性和准确性，进一步提高了应答的针对性。一种用于农村建设辅助中的问答互动方法。本发明能够提高农村教育对讲互动真实场景中应答的可靠性和针对性，使应答更加贴合农村教育互动场景。 通过将句子文本转换为向量数据，并对向量权重进行分析，可以降低向量的维度，提高向量表示的准确性。 还可以提高语义的稳定性和准确性。该方法包括获得句子文本。 将句子文本转换为多向量数据。 根据身体对每个向量数据执行权重分析。 生成向量权重。 所述本体上设置有预采集和实时采集农村场景交互数据。 基于注意机制的来自变压器(BERT)模型的双向编码器表示来分析根据向量数据和向量权重的句子文本的语义。 根据语义和语句场景生成响应。独立的权利要求书被包括在以下内容中： (1)问答交互系统； (2)问答交互装置； 以及 (3)存储介质。  12
本发明公开了一种基于预训练模型的头相关传输函数的个性化方法，具体涉及电子行业信号处理技术领域，包括：HRTF特征预处理模块、多数据库的预训练模块、生理特征预处理模块、个性化模型微调模块与人体生理参数测量模块，HRTF特征预处理模块用于对头相关传输函数进行预处理；基于多数据库的预训练模块，用于产生位置相关且用户无关的预训练模型。本发明中，采用公开的多个数据库得到预训练模型，充分利用了可用数据中与定位、个性化相关的信息，得到更准确的个性化头相关传输函数的估计。实际应用时，只需要针对个性化生理特征对预训练模型进行微调，复杂度低，使用简单，可以快速对任意目标对象生成个性化头相关传输函数，具有较高的实用价值。基于预训练模型的头部相关传输函数个性化方法，用于电子工业信号处理技术领域。该方法能够利用公共数据库获得预训练模型，充分利用可用数据和定位、个性化相关信息中的信息，获得个性化头部相关传输函数的准确估计，并通过扩大数据库规模来提高性能。 该方法能够允许小的生理特征测量和目标对象的模型精细调整，具有低复杂度、简单使用和高应用价值。该方法涉及通过利用多数据库HRTF特性预处理模块针对数据库的HRTF执行时频一致性。 进行频率一致性的采样和处理值归一化。 基于数据库，选择模块的输出端作为预训练模块的输入。 多数据库预训练模块，与所述多数据库HRTF特征预处理模块连接。 独立于用户对预训练模型进行微调。 生成个性化的头部相关传输函数模型。  11
本发明提供了一种基于预训练模型滤波器提取的卷积神经网络初始化方法，涉及视频处理技术领域，本发明利用最小熵损失及最小重构误差方法，提取预训练模型中滤波器参数，用以初始化目标任务网络模型，实现满足实际应用问题中小规模网络初始化问题。本发明由于使用最小熵损失及最小线性重构方法，从预训练模型中提取滤波器参数，对目标任务网络模型进行初始化，本发明不要求目标任务网络结构和预训练网络结构一致，可使目标任务根据实际应用灵活设计网络结构，满足实际应用问题中内存开销与计算速度要求。一种基于预训练模型的卷积神经网络初始化方法。该方法能够根据内存使用和计算速度请求确定实际应用问题。该方法包括选择预训练网络模型。 获得目标任务网络结构。 计算最小熵损失或最小重构误差。 通过使用预训练模型来提取滤波器参数。 计算滤波器尺寸。 表示高斯混合分布。 建立高斯模型数的混合模型。 过滤器在过滤器单元中被移除。 计算滤波器的最小交叉熵。 基于滤波器参数提取技术确定最小重构误差。 计算加权因子。 表示滤波器的重构误差。 根据加权参数调整正比例系数项。 过滤器对过滤器参数进行评估，实现目标任务网络的初始化。   4
本发明涉及自然语言处理领域的文本检索技术，提升了现有方法在语义匹配上的不足，包括以下步骤：围绕在工程咨询报告范围获取实验所需数据，每个标题标注60段文本数据；将数据以[CLS]标题[SEP]段落[SEP]的形式传入BERT模型，得到标题和段落的向量表示；基于向量分别构建图拓扑结构，并利用图卷积神经网络GCN获取全局结构特征；针对具有上下文信息和全局特征的向量表示，利用排序模型得到第一个得分；将段落对应关键词利用Word2Vec得到向量表示，基于余弦相似度得到第二个得分，对两个得分加权平均得到最终匹配结果；训练模型并更新参数，在测试集上提取文本特征并进行检索。本发明能够提升文本检索的准确性。基于图卷积拓扑特征和关键词特征的文本检索方法，用于自然语言处理领域。该方法使咨询工程咨询报告历史文本通过相似度计算和人工标注标题与段落标签之间的相关性来查询标题，对输入的标题和段落尽可能地提取文本的语义特征，为下一步奠定语义基础，从而提高了标题与段落匹配计算的准确性。 关键词作为段落文本的语义表征特征，标题的匹配分数可以作为段落匹配语义信息补充。 该方法在捕获上下文信息的基础上获取文本的全局特征，并分别采用联合排序模型Vanilla Bert、DRMM、KNRM和PACRR模型计算匹配排序得分。该方法涉及获得实验所需的数据，包括标题数据和文本段落数据。 将每条数据以预定名称的形式传入预先训练的语言模型BERT中，分别得到标题和段落的向量表示。 分别构建图拓扑结构，对得到的标题和段落向量使用图卷积神经网络得到文本的全局结构特征。 采用Word2Vec模型得到所述段落的关键词信息的向量表示。 根据训练数据对检索网络模型和更新参数进行训练，然后在测试集上提取文本特征并进行检索。  12
本申请提出了一种信息分析模型的训练方法及信息分析方法，包括以下步骤：获取信息分析数据并输入到预训练好的T5模型中得到第一信息分析结果；构建自建模型，在所述训练样本中获取至少一信息分析数据组成信息分析集合，以第一信息分析结果为训练目标，以信息分析集合为训练数据对所述自建模型进行训练得到普适模型；构建数据校正模型并获取微调数据集，使用微调数据集对自建模型进行迭代训练得到信息分析模型，所述数据校正模型在迭代训练过程中对微调数据集进行更新。本方案以T5模型的输出为训练目标来构建自建模型，并对其进行迭代训练得到信息分析模型，从而使用信息分析模型以更小的计算资源来进行信息分析。使用电子设备(索赔)训练信息分析模型的方法，所述电子设备用于通过社交媒体、新闻文章、论坛帖子和其他大量文本数据来理解和分析公众的特定主题、品牌以及产品或事件的情感和态度。该方法能够以T5模型的输出为训练目标构建自构建模型并进行迭代训练得到信息分析模型，从而能够以较小的计算资源有效地利用该分析模型进行信息分析。该方法涉及获得与信息分析相关的信息分析数据。 将对应的情感标签标记为训练样本。 将所述训练样本输入预先训练的T5模型，得到信息分析结果。 基于变压器架构构建自建模型。 在所述训练样本中获取信息分析数据，形成信息分析集。 将信息分析集作为输入数据。 构建用于识别数据集错误的数据校正模型。 得到标注有情绪标签的细调数据集。 增加了分类头。 将所述细调数据集与所述情感标签输入通用模型进行迭代训练。独立权利要求还包括用于：信息分析方法； 以及一种可读存储介质，包括用于使用电子设备训练信息分析模型的指令集。  11
本发明公开了一种基于反馈机制的自然语言处理模型测试用例约简方法。本发明可以有效削减测试成本，提升测试效率，并提升这类模型的质量。本发明包括：步骤1)、在原有数据集基础上依据数据类别分层抽样获取小的数据集D；2)、依据已有的测试用例评价函数将数据集D分为两类，第一类为容易使模型出错的类别第二类为不容易使模型出错的类别；3)、使用分类好的数据集训练SVM模型，并使用训练好的SVM模型对剩余数据进行分类得到初始测试集T；4)、引入反馈机制，使用初始测试集进行测试得到错误数据，将错误数据反馈到SVM模型中对其参数进行及时调整，并重新对剩余数据进行分类和得到新的错误数据，迭代到最大迭代次数停止得到最终约简后的测试用例集。一种基于反馈机制的自然语言处理模型测试用例还原方法。本发明能够有效降低测试成本，提高模型的测试效率和质量。 本发明定义了测试用例的错误分类可能性的函数，降低了算法成本，减少了向算法及时反馈信息，从而提高了反馈机制提取错误测试用例的效果。该方法包括根据待测目标模型提取测试集的特征向量。 获得测试集特征向量形式的数据集。 根据现有评估测试用例的错误分类概率的评估函数和截取的数据集的评估函数对初始数据集进行分类。 通过使用分类的初始数据集来建立支持向量机(SVM)模型。 利用训练好的SVM分类剩余数据得到模型误差数据。 将初始数据集中的数据与模型误差数据相结合，得到初始测试集。  11
本发明公开了一种基于机器阅读理解的自然语言系统的处理方法，首先基于现有的预训练ALBERT模型，分析模拟机器阅读理解任务中多项选择的文章、问题和答案之间的关系，在交互层提出了一种双向多头共注意力模型，分别将输入的文章和问题答案作为两个查询方向进行编码，并与自注意力机制相结合；在编码层参考transformer结构加入残差网络、前馈网络与层归一化网络；输出结果是每个回答选项被选中的概率值，根据概率值大小确定答案。本发明方法基于大规模预训练语言模型ALBERT，模拟人在解决机器阅读理解问题时的换位思维经验，更好的利用文章、问题、回答三者的自然联系，有效提升了对正确选项的预测精度，解决了自然语言处理中的多项选择问题。将本方案应用在自然语言处理的遮蔽处理和掩码模型、句子预测等领域，可以充分捕捉文章、问题和各个答案选项的信息，能够有效提升机器问答、自然语言推理或文本匹配这些需要句间理解推理的自然语言处理任务上的性能。基于机读理解的自然语言系统处理方法。可以有效地改进机器问题、自然语言推理或文本匹配所需句子之间理解推理的自然语言处理任务的性能。 有效提高了正确选项的预测精度。该方法包括输入文章内容、问题和回答选项。 在用于输入文章的公共预训练模型中使用自然语言处理字段。 单词元素用于问题和选项。 编码层得到的张量，一个交互层使用多头双向共同关注机制进行处理。 通过链接处理对问题选项张量进行处理，然后对问题选项张量进行自定义注意力处理。 通过融合输出张量以获得预测张量来融合解码层，将对应于每个选项的预测张量输入到选项的选择概率中以确定正确答案。  12
本发明涉及计算机领域，具体提供一种智能体决策方法、控制方法、电子设备及存储介质，旨在解决现有的仿真技术控制智能体时不够逼近现实真人驾驶行为的问题。为此目的，本发明的方法包括：获取环境信息和待决策智能体的驾驶意图；将环境信息和待决策智能体的驾驶意图输入训练好的智能体决策模型，得到智能体决策结果；其中，智能体决策模型至少基于以下步骤进行训练：基于大语言模型构建初始智能体决策模型；基于交通环境数据对初始智能体决策模型进行训练，得到训练好的所述智能体决策模型。通过上述实施方式，能够有效地控制智能体执行多种行为，并且多种行为的因果关联性较强，决策灵活度较高，实现了仿真数据对真实世界驾驶行为更好的覆盖。智能体决策方法，用于机器人或智能驾驶模拟。可以有效地控制智能体执行多种行为，并且多种行为的因果性强，决策灵活性高，仿真数据能够更好地覆盖真实世界驾驶行为。该方法包括获得要决定的主体的环境信息和驾驶意图(S101)。 将环境信息和待决策智能体的驾驶意图输入(S102)训练好的智能体决策模型，得到智能体决策结果。 基于对智能体决策模型进行训练，基于所述大语言模型构建初始智能体决策模型，基于交通环境数据对所述初始智能体决策模型进行训练，得到训练后的智能体决策模型。独立权利要求包括以下内容：一种智能车身控制方法； 电子设备； 存储用于代理决策的程序的计算机可读存储介质。 13
本发明涉及计算机技术，具体涉及利用多文档摘要和多轮引导问答的可解释企业征信评价方法，获取企业文档集合，对非结构化文本进行预处理；通过多文档摘要技术生成企业描述文本；构建企业征信评价关键元素集合和问题集合；利用BERT‑QA问答模型根据企业描述文本和问题集合中征信问题文本，生成答案；通过预训练的BERT语言模型对文本进行篇章粒度向量化表征，搭建Question‑S问题选择网络进行多轮引导式提问；根据问答情况构建征信元素向量；使用分类模型依据元素向量判断企业是否征信违法。该方法能够在文本信息层面实现大规模、批量化的文本自动解析，可为企业征信可解释性评价、企业有效监管以及企业风险预警提供有力支持。一种利用多文档摘要和多轮指导问题讲解企业信用评价的方法。该方法可实现大规模批量文本信息层上的文本自动分析，可为企业信用解释评估，企业有效监控和企业风险预警提供有力支持。该方法包括输入企业文档集。 预处理非结构化文本。 企业描述文本由多文档摘要技术生成。 构建企业信用评估要素集合和问题集合。 企业描述文本和问题文本组合在问题集中。 利用Bert-QA问答模型生成提问答案。 根据问答条件生成信用要素向量。 根据所生成的信息元向量，判断企业是否为非法企业。  12
本发明适用于视频处理技术领域，尤其涉及一种基于自监督预训练的监控视频异常识别方法及系统，所述方法包括：采集多个场景下的监控视频，构建预训练数据集，并采集居家多模态信号；对预训练数据集进行采样处理，基于采样结果提取tokens，对预设比例的tokens进行掩码处理，构建异常识别模型，并对其进行预训练，得到预训练模型；构建多层感知机构，基于预训练模型对多层感知机构进行训练；进行打分处理，基于打分结果判定是否存在异常。本发明采用先进的监控摄像头采集的数据，结合了多模态居家信号，使得输入信息更加丰富，可以在不改动模型结构的前提下，利用特定场景下的监控视频进行预训练，使模型增强该场景下的异常检测能力。智能城市、平安校园、平安工厂等建设领域的基于计算机视觉和数字图像处理中的自监控预训练的视频异常监控方法。该方法采用先进的监控摄像头采集的数据，结合多模式的家居信号，使得输入的信息更加丰富，在不改变模型结构的前提下利用特定场景中的监控视频进行预训练，使得模型增强了场景中的异常检测能力。该方法涉及采集多个场景下的监控视频。 构建预训练数据集。 采集家庭多模信号。 对所述预训练数据集进行采样。 基于采样结果提取所述令牌。 令牌以预设比例进行插补。 构建异常识别模型。 对所述异常识别模型进行预训练，得到预训练模型。 构建了多层传感机构。 基于预训练模型训练所述多层感知机制。 将新的待检测视频引入多层感知机制进行评分。 根据评分结果，进行检查是否存在异常的判断。包括独立权利要求的一种基于自监控预训练的监控视频异常识别系统。 9
本发明提供一种融合句法信息的GCN‑RN方面级情感分析方法和系统，涉及情感分析领域。本发明构建了GCN‑RN模型，包括词嵌入层、隐层、特征提取层和输出层；将待分析文本输入词嵌入层，获取待分析文本的向量表示；将向量表示输入隐层，采用LSTM获取对应的隐层状态；将预先构建的邻接矩阵和方面词距离权重矩阵、隐层状态输入特征提取层的第一个图卷积残差块的GCN层，获取输出向量；将隐层状态和输出向量进行残差连接，并输入下一个图卷积残差块，最终获取文本特征表示；将文本特征表示输入输出层，获取待分析文本中方面词的情感极性预测结果。采用LSTM学习长距离依赖信息，进行特征融合；构建句法依存树并用多个图卷积残差块提取句法信息，提升情感分类准确率。一种基于融合语句的GCN-RN方面情感分析方法。本发明的GCN-RN级情感分析方法将待分析文本插入到词嵌入层，得到文本的向量表示，从而保证了图卷积残差块提取语句方法的简单高效构造，也提高了情感分类的准确率。该方法包括将待分析的文本输入(S1)词嵌入层以获得文本的向量表示。 向量表示被输入(S2)到隐藏层中。 将字距权重矩阵和隐藏层状态预先构造(S3)为特征提取层的图卷积残差块的GCN层。 获得GCN层的输出向量。 获得与待分析文本中的词相对应的文本特征表示。 根据对输出层的文本特征表示，获得文本中单词的情感极性预测。 将文本特征表示输入(S4)到输出层，以获得待分析文本中的情感极性预测。还包括独立的权利要求： 一种基于融合语句的GCN-RN方面情感分析系统； 以及 一种存储介质包括一组用于基于融合语句分析GCN-RN方面情感的方法的指令。  12
本发明涉及一种基于大语言模型与提示工程的领域知识图谱自动构建方法，属于自然语言处理领域。首先将任务需求与维基百科文档输入到检索增强生成模型的检索器中进行编码，得到与任务需求最相关文档索引；根据得到的文档索引找到相关文档后，将其与任务需求输入到检索增强生成模型的生成器中，得到二者相结合的上下文信息，进而获取关键事件，最后大语言模型对上下文信息进行事件提取；以思维树链式提示方式将事件输入至Role‑Playing框架中，进行大语言模型自动反馈过程，生成构建领域知识图谱的文本数据；最后对反馈的文本数据进行数据清洗得到最终的领域知识图谱。本发明能够高效、准确以及自动化地构建知识图谱。基于大型语言模型和提示工程的领域知识图谱自动构建方法。该方法能够以高效、准确、自动的方式高效、准确、自动地构建知识图谱。 该方法允许搜索者在根据得到的文档索引查找到相关文档后，将维基百科文档输入搜索增强生成模型的搜索者进行编码得到与任务需求最相关的文档索引。该方法涉及将任务需求和维基百科文档输入搜索增强生成模型的搜索器中进行编码，以获得与任务需求最相关的文档索引。 根据获取的文档索引查找相关文档。 将所述相关文档和所述任务需求输入到所述搜索增强生成模型的生成器中，得到上下文信息，结合两者得到所述关键事件，并通过所述大语言模型提取所述上下文信息的事件。 以思维树链型提示的方式将事件输入到角色-Phab帧中。 执行大级别模型自动反馈过程。 生成文本数据。 对所述反馈文本数据进行清洗。 得到最终的领域知识图谱。  11
本发明提供一种基于长篇科学文献的关键词抽取方法。对科学文献的单词进行统计，统计字数长度在8000‑40000字，人工统计时间在10‑60分钟，将长篇科学文献进行分块处理，再对文档进行标记并用词性Part‑Of‑Speech(POS)标签标记文档。本发明提供的基于长篇科学文献的关键词抽取方法，通过引入“分块”的概念，极大的完善了BERT模型固有的对输入端长度的限制，提出了Block‑BERT模型进行处理，联合全局和局部信息，保留全面的语义信息，有效的对长篇科学文献进行关键词的提取，与现有的模型相比，性能得到了极大的提升，尽量避免了关键词语义信息的缺失，提出新的节点中心性的计算排名方法Block‑Rank，局部信息采用基于图结构模型来衡量节点的重要程度。基于长期科学文献提取关键词的方法。该方法有效提取了长科学文献的关键词，提高了关键词提取的性能，避免了关键词语义信息的删除，提供了一种新的节点中心度计算排序方法block‑rank。该方法涉及将长期科学文献划分成块。 用词汇词性(POS)标签来标记和标记文档。 从文档中提取的候选短语被表示为(CP0, CP1, …, CPn)。 通过使用所述BERT来获得上下文动态向量表示(BERT)。  11
本发明涉及大模型对话技术领域，具体公开了一种基于多个大模型对话的表决共识系统，包括如下步骤，S1：构建模型，搭建多组LLM大语言模型，S2：用户提问，将问题传递至所有搭建好的LLM大语言模型中，各个LLM大语言模型均对用户问题进行回复，S3：模型回复打分，各个LLM大语言模型将各个回复分别传递至除自身以外的其他LLM大语言模型中，要求对方对此回复进行打分，S4：回复用户，获取最高分的回复作为最终回复反馈给用户，LLM大语言模型至少搭建有三组或三组以上，该基于多个大模型对话的表决共识系统，通过设置多个LLM大语言模型达成共识的方式，能够有效降低人工智能答非所问与一本正经胡说八道的可能性，提升用户体验。用于自然语言处理领域的基于多大模型会话的投票共识系统。该系统有效地降低了人工智能回答问题和正确频道的可能性，提高了用户体验。该系统具有构建单元，用于构建模型和构建多组大型语言模型(LLM)。 转移单元，将一个问题转移给所有构建好的LLM大语言模型，每个LLM大语言模型回复一个用户问题，每个LLM大语言模型分别将每个回复发送给除自身之外的其他LLM大语言模型。 回复单元，对所述用户进行回复。 获取单元，获取评分最高的回复作为最终回复并反馈给用户。 8
本发明公开了一种基于Transformer的三维模型视图选择方法，包括如下步骤：首先采用CNN网络提取待测对象的多视图特征信息，获得多视图局部特征token序列，并对其进行位置编码。之后将其输入至Transformer编码器进行特征编码，获得初始全局视图特征。然后利用最优视图选择模块将初始全局特征序列通过注意力得分矩阵选择最优视图特征。最后将最优视图特征与全局分类token拼接一同输入Transformer层得到基于最优视图的全局分类token，将其输入分类器获得最终分类概率。在训练阶段使用动态掩码策略随机丢弃视图特征，增大模型学习难度，提高模型泛化能力，使用对比学习方法最大化相同类别分类的相似度。本发明利用三维模型类别的语义信息选择最优视图，适合三维数据集的高效浏览。用于自动驾驶、医学成像、虚拟现实领域等的基于薄膜晶体管的三维(3D)模型的视图选择方法。该方法利用3D模型类型的语义信息选择最优视图，适用于3D数据集的高效浏览。该方法涉及提取(S1)特征。 将所述待检测对象输入所述局部视图特征提取模块，提取所述多视图特征信息，生成所述局部特征令牌序列。 将所述多视角局部特征令牌序列通过特征编码和多码融合(S2)为初始全局特征序列。 由最优视图选择模块通过注意力分数矩阵从初始全局特征序列中选择(S3)最优视图特征。 将最优视图特征和全局分类令牌一起进行拼接(S4)。 在训练阶段利用动态掩模策略随机丢弃视图特征(S5)。 增加了模型的学习难度。 利用比较学习方法对同一类分类的相似度达到最大。 根据基于远程的3D模型的最优视图选择模型来选择(S6)3D模型的最优视图。   5
本申请涉及图像处理技术领域，公开了一种基于Vision Transformer的鲁棒水印方法，包括：构建Vision Transformer网络；将医学图像输入至Vision Transformer网络，利用最后一层Transformer编码器输出医学图像的特征向量；对医学图像的特征向量进行DCT变换，得到医学图像的特征序列；将医学图像的特征序列和加密水印逐位进行异或运算，以将水印信息嵌入至医学图像中。这样通过Vision Transformer网络可以学习到医学图像中的复杂特征，再经过DCT变换后，可真实可靠地提取出医学图像的特征序列，在嵌入水印信息后，不仅可以保护医学图像本身，还能对病人的隐私信息进行保护。此方法具有较强的鲁棒性和不可见性，能够有效地抵御各种几何攻击和传统攻击，如旋转、高斯噪声等，保障医学图像的数据安全。基于视觉变换器的鲁棒水印方法。鲁棒水印方法具有很强的鲁棒性和不可见性，有效抵抗不同的几何攻击和传统攻击，保证了医学影像的数据安全。鲁棒水印方法涉及构建视觉网络。 医学图像被输入到视觉网络。 医学图像的特征向量由简单编码器的最后一层输出。 对所述医学图像的特征向量进行离散余弦变换(DCT)转换，得到所述医学图像的特征序列。 将所述医学图像的特征序列与所述加密后的水印比特进行异或运算，以将所述水印信息嵌入到所述医学图像中。 补丁嵌入和构建编码器被组合以构建visionover网络。   5
本发明提供一种基于BERT模型的MOOC学习者认知行为识别方法，包括：获取MOOC论坛中学习者讨论文本数据，生成MOOC评论领域的专业语料；对语料进行预处理，生成包含MOOC领域专业知识预训练数据；结合预训练数据，使用MLM和NSP策略对BERT模型进行再训练，得到MOOC‑BERT；构建MOOC学习者认知行为标注数据集；使用标注数据集对MOOC‑BERT中参数和权重微调，生成面向MOOC学习者的认知行为识别模型。本发明基于BERT模型的MOOC学习者认知行为识别方法，用于提高对在线学习环境中学习者认知行为的识别能力，有效帮助教师分析大规模场景下MOOC学习者的认知行为类型。基于BertModel的MOOC学习者认知行为识别方法本发明能够提高在线学习环境中学习者认知行为的识别能力，从而有效地帮助教师分析大规模场景下MOOC学习者的认知行为类型。该方法包括获取MOOC论坛学习者讨论文本数据。 生成MOOC评论字段专业语言数据。 将所述语言数据生成MOOC领域专业知识预训练数据，并将所述预训练数据进行组合。 MLM和NSP策略用于重新训练BET以获得MOOC-BET。 构建MOOC学习者认知行为标签数据集。 利用标记数据集微调Mooc-Bert中的参数和权重，生成面向Moo学习者的认知行为识别模型，该模型能够有效识别Moo学习者交互式语音中隐含的认知行为类型。  12
本发明公开了一种基于多任务深度神经网络的表头分类与表头列语义识别方法，属于自然语言处理技术领域，使用深度学习来进行表格场景分类和表头列映射，将表格场景分类任务转成了文本分类任务，将表格列映射任务转成了序列标注任务，使用Bert预训练模型增强了语义表示能力，使用多任务的结构将上述两个任务结合到一起，在训练的过程中，两个的任务的损失函数会合并到一起，互相提升对方的效果。基于多任务深度神经网络的头分类和头列语义识别方法。增强了语义表征能力。 两个任务的损失函数在训练过程中合并在一起。该方法涉及用定义的场景标记首标样本库中的所有首标。 header列标记有每种场景需要提取的自定义标准信息字段。 对标记后的头样本进行预处理，形成模型向量。 基于所述头样本库中包含的所有不同词语构建词典。 词典用于将表头中的单词映射到词典位置。 为所述表头的场景标签和所述表头列的映射字段标签创建对应的字典。 建立场景类别标签和场景序列标签的向量序列。 将预处理后的样本输入到模型中。 对训练损失函数值loss进行优化。 输出同时处理头场景分类和头列映射的统一模型。  12
本发明公开了一种基于宽时间范畴的多模态情境情感识别方法及系统，包括以下步骤：利用自然环境下的音视频资源，构建基于情境的视频情感数据集；基于BERT模型对视频情感数据集进行文本情感识别；通过引入通道注意力机制，对人物面部情感进行识别；构建基于注意力机制的多模态多分支融合模型，并通过多模态多分支融合模型得到最终的情感识别结果。本发明用于解决现有的多模态情感识别技术存在的仅针对当前时刻包含的信息进行情感挖掘、不能有效区分出对情感状态有影响的区域、跨模态不一致以及跨模态不平衡等的技术问题，从而实现具有鲁棒性的、情感表征能力更强的情感识别系统的目的。基于宽时域的多模态情境情感识别方法，用于情感识别系统中。该方法使得能够实现具有更强情感表征能力的情感识别系统。该方法涉及通过在自然环境中使用音频/视频资源来基于情境构建视频情感数据集(S1)。 对视频情感的数据集进行文本情感识别(S2)。 通过引入通道注意机制来识别人的面部情感(S3)。 基于注意力机制构建多模态多分支融合模型，通过多模态多分支融合模型得到最终的情感识别结果(S4)。本发明还公开了一种基于宽时域的多模态情境情感识别系统。 9
本发明涉及自然语言处理技术领域，提供一种中文文本纠错方法、装置、电子设备及存储介质，通过对原始样本进行处理得到错误样本，从而基于原始样本及错误样本构建样本对时，扩展了样本对的数据量；以语句为切分单位对样本对进行切分并以声母、韵母、音调为基本单位对样本对的拼音进行转换得到拼音序列，能够提高拼音转化的正确率，从而提高中文文本纠错模型的训练效果；最后调用第一BERT模型提取拼音序列对的拼音向量及调用第二BERT模型提取样本对的文本向量，以拼音向量及文本向量作为数据对训练中文文本纠错模型，能够适用于任何长度的文本，不必对文本进行任何处理，使用中文文本纠错模型处理待纠错文本时，能够提高待纠错文本的纠错质量。中文文本纠错方法。该方法能够提高拼音转换的正确率，从而提高中文文本校正模型的训练效果和待校正文本的纠错质量。该方法包括获得原始样品。 基于模糊拼音对所述原始样本进行处理，得到误差样本。 根据所述原始样本和对应的误差样本构建样本对。 将拼音向量和对应的文本向量作为训练数据。 基于所述训练数据训练中文文本校正模型，以对所述训练端进行训练。 通过所述中文文本纠错模型对待纠错文本进行纠错处理，得到纠错后文本。本发明还公开了一种中文文本纠错装置，包括：(a)一个中文文本纠错装置; (b)一种电子设备，包括用于执行中文文本纠错的处理器和存储器; (c)计算机可读存储介质，其存储用于执行中文文本纠错的一组指令。  11
本发明涉及图像处理和自然语言领域，具体提供了一种自动抽取发票关键信息的跨模态分析方法，首先将发票图像输入至文本检测模块，使用ResNet‑50作为主干网络提取图像深度视觉特征，采用不同尺度的特征图进行特征融合；其次，将检测到的文字形状以及坐标信息输入至文字识别模块，接着将分别计算文本检测特征与文字识别特征注意力权重，将注意力权重与特征融合，将有权重的特征进行拼接融合，得到带有注意力信息的图像视觉特征；接着进行实体识别，将文本序列的位置信息、视觉特征进行编码得到Embedding，输入至BERT模型中，获取到关键信息。与现有技术相比，本发明解决了面对多种多样的不同版面发票图片时，能够快速准确提取关键信息的问题。一种图像处理和自然语言领域的发票关键信息自动提取的跨模态分析方法。在面对各种不同版面的发票图片时都能快速准确的提取出关键信息。该方法涉及分别计算文本检测特征和字符识别特征的注意力权重，并将注意力权重与特征进行融合。 将加权后的特征进行拼接融合，得到具有注意力信息的图像视觉特征。 进行实体识别，对所述文本序列进行位置信息和视觉特征编码，得到所述编码。 编码被输入到来自变换器的双向编码器表示(BERT)模型中。 连接双向长短期存储器(BiLSTM)和伴随射频(CRF)模块，得到最终的实体识别结果，从而得到关键信息。包括独立权利要求用于自动提取发票关键信息的跨模态分析装置。   6
本公开提供了一种模型预训练方法、装置、设备、存储介质以及程序产品，涉及人工智能技术领域，具体为自然语言处理和深度学习技术领域。该方法的一具体实施方式包括：利用样本自然语言文本对初始生成模型进行第一阶段训练，得到生成模型，其中，第一阶段训练中生成样本伪自然语言文本；为生成模型增加初始判别模型，得到初始预训练语言模型；利用样本自然语言文本和样本伪自然语言文本对初始预训练语言模型进行第二阶段训练，得到预训练语言模型，其中，预训练语言模型既用于生成伪自然语言文本，又用于判别自然语言文本和伪自然语言文本的真实性。该实施方式提供了一种模型预训练方法，提升了模型生成质量。模型预训练方法。本模型生成的伪文本分布更接近真实文本，从而进一步加快了模型的收敛速度，提高了模型生成质量。该方法包括使用样本自然语言文本对初始生成模型执行第一阶段训练以获得生成模型。 生成样本伪自然语言文本。 为生成模型增加了初始判断模型。 获得初始预训练语言模型。 样本自然语言文本用于对初始预训练语言模型进行二级训练。 预训练模型用于生成伪自然语言文本，并用于判断自然文本和伪文本的真实性。本发明还涉及一种用于生成文本的方法； (2)模型预训练装置； (3)用于生成文本的设备； (4)具有处理器和存储器的电子设备； (5)一种非临时性计算机可读存储介质，包括多个计算机指令，这些指令被执行以执行预训练方法； (6)计算机程序产品包括多个计算机指令，这些指令被执行以执行预训练方法。  11
本发明公开了一种基于Transformer的遮挡行人重识别方法，包括以下步骤：(1)对待识别图像进行分块，并分别添加结构信息，构成图像序列，(2)把带有类标签的图像序列附加位置信息以及边信息，构造Transformer层可处理的图像序列；(3)将上述序列馈入由多头自注意力机制和多层感知机构成的残差Transformer层，进行图像特征提取；之后在最后一层残差Transformer层将特征分为全局分支和局部分支特征；(4)将得到的特征使用ID损失和质心三元组损失进行联合优化。本发明有效聚焦于显著性特征，使特征具有鲁棒性，对于行人重识别遮挡问题进行了有效处理。基于用户的屏蔽行人的识别方法。有效处理了行人再识别屏蔽问题。 利用ID损失和质元中心损失对得到的特征进行组合优化，得到行人图像显著特征。 全局注意力可以捕获图像中信息量最大的部分，并排除其他干扰信息，有效关注显著性特性，同时可以使特性具有鲁棒性。 层中使用简单的残差连接，避免了计算复杂度。该方法涉及对待识别图像进行分割，并分别添加结构信息。 形成所述图像序列。 将图像序列输入到由多头自注意机制和多层感知机组成的残差层。 得到所述一次图像特征。 将初级特征分别输入到全局注意力模块和局部混洗模块。 所述全局分支特征，并对应得到所述局部分支特征，并结合所述质心函数和所述整体损失函数以基于所述全局分支特征、所述局部分支特征进行优化。 得到行人图像显著特征。   5
提供了一种文本处理方法，涉及人工智能领域。该方法包括：将第一文本输入至预先训练的特征提取器，得到第一文本特征；将第二文本输入至所述预先训练的特征提取器，得到第二文本特征；获得所述第一文本特征和所述第二文本特征之间的相似度预测结果；其中，所述特征提取器包括N个循环编码器，每个所述循环编码器根据循环记忆机制和Transformer模型中的编码器构建获得，所述循环记忆机制用于根据上一时刻的状态信息和本次时刻的输入信息处理数据。还提供了一种文本特征提取方法，该方法包括：将第三文本输入至上述预先训练的特征提取器，得到第三文本特征。还提供了一种文本处理装置、文本特征提取装置、设备、存储介质和程序产品。文本处理方法。该方法通过文本特征提取装置对文本的串行化数据结构进行串行化处理，实现文本纵向的深度排序功能， 允许用户将文本输入到文本特征提取装置以有效地获得文本特征。该方法包括将第一文本输入到预先训练的特征提取器中以获得第一文本特征。 将第二文本输入到预训练特征提取器以获得第二文本特征，其中预训练特征提取器包括多个循环编码器。 获得第一文本特征和第二文本特征之间的预测结果。 每个循环编码器根据循环存储机制和变压器模型中的编码器建立。 利用循环存储机制根据状态信息和输入信息对数据进行处理。独立的权利要求书包括： (1)文本特征提取方法； (2)文本处理装置； (3)文本特征提取装置； (4)电子设备； (5)计算机可读存储介质； 以及 (6)计算机程序产品。  11
本发明提供一种炼钢知识的精细回答方法、装置、终端及存储介质。该方法包括：对用户输入的炼钢问题进行文本向量化，得到问题向量；将问题向量与炼钢知识向量库中的知识向量进行相似度匹配，得到炼钢问题的相关知识；其中，炼钢知识向量库基于炼钢知识库生成；基于炼钢语言大模型对炼钢问题的相关知识进行语法和逻辑处理，得到炼钢问题对应的回答内容；其中，炼钢语言大模型基于炼钢知识库数据集对通用型语言大模型进行微调得到，炼钢知识库数据集包括多条炼钢知识样本，每条炼钢知识样本具有联合主题和知识标签，联合主题基于炼钢知识的标题、段落主题、段内TF‑IDF关键词和相关知识生成。本发明能够提高炼钢辅助的效果。一种炼钢知识精答的方法。该方法能够提高炼钢辅助效果。该方法涉及对用户输入的炼钢问题进行文本向量化，得到问题向量。 将所述问题向量与所述炼钢知识向量库中的知识向量进行相似度匹配，得到所述炼钢问题的相关知识。 基于所述炼钢知识库生成炼钢知识向量库。 基于炼钢语言大模型对炼钢问题的相关知识进行语法逻辑处理。 得到所述炼钢问题对应的答案内容。 所述炼钢语言大模型是基于炼钢知识库数据集对通用语言大模型进行微调得到的。 基于炼钢知识题目、段落题目、段落中的术语频度和逆文档频度关键词以及相关知识生成联合题目。包括独立权利要求，用于：(1)炼钢知识精答装置； (2)一种终端，包括存储器和处理器，以执行一种炼钢知识精答执行方法； (3)计算机可读存储介质，其存储有执行一种炼钢知识精答方法的指令集。  12
本发明属于图像处理技术，特别涉及一种可识别的人脸匿名化处理方法及系统，所述方法包括将原图像进行匿名化处理，并将原图像与匿名化预处理后的图像进行融合得到匿名图像，将匿名图像作为进行人脸识别的图像；通过深度图像融合网络对原图像和匿名化预处理后的图像进行融合，深度图像融合网络包括两个孪生U‑Net深度神经网络，一个网络用于处理原始图像，另一个用于处理匿名化预处理后的图像，两个U‑Net在解码器进行图像融合，得到融合图像；本发明保证处理后的图像在视觉上与匿名化处理的图像相似，同时保证处理后的图像可用于机器识别，既保护原始图像的隐私，又保证了图像的可用性，可用于多种需要人脸隐私保护的场景中。用于社交媒体场景下图像视频分享或分发的可识别人脸匿名化处理方法。处理后的图像在视觉上与匿名化处理后的图像相似，同时，处理后的图像可以用于机器识别，它既保护了原始图像的隐私，又保证了图像的可用性。 该方法具有较强的通用性，即能够支持不同外观和强度的人脸匿名化效果(包括模糊化、像素化和人脸变形)的隐私保护。 其识别可用性，仅依赖于预先训练好的人脸识别模型完成识别任务，即用作现有人脸识别模型的扩展，提供隐私增强功能。 其具有高效性，通过实验证明，该方法提出的匿名模型只需要小规模的深度神经网络即可完成匿名化任务，效率高。该方法包括对原始图像进行匿名化预处理。 将所述原始图像和所述匿名化预处理图像进行融合，得到匿名图像。 匿名图像在视觉上与匿名化预处理图像相似。 通过预先训练的机器识别模型从所述匿名图像中提取人脸的原始身份特征，并对所述人脸进行识别。包括用于可识别的人脸匿名化处理系统的独立权利要求。 2
本公开提供了一种用于运算装置的功耗控制方法、装置、芯片、设备及介质，涉及计算机技术领域，尤其涉及芯片技术领域、人工智能领域。实现方案为：获取功耗评估周期内的数据请求信号的第一数量，其中，功耗评估周期包括第一预设数量的连续的多个运算周期，数据请求信号用于请求运算装置的输入数据；基于第一数量，获取运算装置在功耗评估周期内的平均功耗表征值；基于平均功耗表征值和预设功耗阈值，获取功耗评估周期内的功耗评估结果；以及基于功耗评估结果，调整运算装置的工作频率。用于控制使用芯片的操作装置的功率消耗的方法和电子装置(所有要求保护)。该方法能够判断功耗的有效评估，从而以有效的方式提高功耗调整的效率。所述方法包括：在功耗评估周期中获得第一数量的数据请求信号，其中所述功耗评估周期包括第一预设数量的多个连续操作周期。 在功耗评估周期中获得操作设备的平均功耗表示值。 基于平均功耗特征值和功耗评估周期中的预设功耗阈值来获得功耗评估结果。 基于所述功耗评估结果来调整所述操作装置的工作频率。独立的权利要求书包括： (1)用于操作装置的功耗控制装置； (2)用于控制操作装置的功耗的计算机程序产品； (3)一种非暂态计算机可读存储介质，用于存储一组指令以执行一种用于控制操作设备的功耗的方法。  11
本发明公开一种基于半监督预训练模型的细粒度情感分析方法和装置，将掩码遮蔽预测任务与BERT模型结合，在随机掩码训练的基础上，通过只对情感单词进行全部掩码，来进一步训练BERT模型从而提高BERT模型的掩码单词预测能力，以便更好地捕捉情感表达，得到参数优化后的预训练BERT模型。在此基础上，以预训练BERT模型结合多个预测模块来构建细粒度情感分析模型，该模型利用了包含注意力机制的预训练BERT模型的优势，可以使用最少量的标记向量来实现高准确度的细粒度情感分析效果，解决了细粒度情感分析中缺乏标签数据和低准确性这两个重要问题，同时使用多标记向量进行分类以最大限度地减少对多个方面主题信息的干扰。基于半监督预训练模型对主体进行细粒度情感分析的方法。该方法能够使用最少量的标注向量实现高准确率的细粒度情感分析，解决了传统细粒度情感分析过程中缺少标注数据、准确率低的问题，并且使用多标注向量进行分类，能够最大限度地减少多方面话题信息的干扰。该方法涉及使用半监督学习模式的来自变换器(BERT)模型的情感掩蔽增强预训练双向编码器表示。 用评论语句中的情感表达对情感词进行筛选。 使用BERT模型提取句子样本的隐藏向量。 根据所述隐藏向量使用线性映射层预测掩蔽情感词的预测概率。 在监督学习模式下建立细粒度情感分析模型。 利用所述细粒度情感分析模型对评论文本进行话题分类和细粒度情感分类。包括独立权利要求用于基于半监督预训练模型对主体进行细粒度情绪分析的装置。  12
本发明公开了改进Transformer融入知识的端到端对话方法，首先收集以对话和知识组成的二元组，将该二元组作为训练数据；对训练数据进行清洗，将训练数据组成包括对话、知识和回复的三元组形式，并对该三元组进行预处理；构建由编码运算模块、知识解码器运算模块和解码器运算模块组成的改进的Transformer模型；利用训练数据与三元组训练改进的Transformer模型，并保存；将以对话和知识组成的二元组输入训练好的改进的Transformer模型中，模型预测输出回复结果；用户对模型输出的回复结果进行回复后，将模型输出的回复结果和用户回复拼接到对话记录串中，并选取新的知识输入训练好的改进的Transformer模型中持续进行端到端对话。该方法充分利用Transformer模型结构将知识细致融合用于生成对话。一种用于执行端到端对话的方法，所述端到端对话具有改进的集成知识，所述集成知识可用于自然语言处理领域，并且使用神经网络来累积互联网数据以产生回复开始流行度。该方法充分利用模型的模型结构，精心组合知识，生成对话； 通过使用该模型，能够提供对文本特征的强提取能力； 对输入的对话和知识进行编码； 允许输入对话的改进模型进行特征提取和编码，从而生成对话代码，并将输入知识与由编码器生成的对话代码相结合以有效地提取和编码信息。该方法包括：收集由会话和知识组成的二元组； 以二元组为训练数据， 对三元基团进行预处理， 构建由编码运算模块组成的改进模型， 知识解码器操作模块和解码器操作模块， 利用训练数据和三组训练改进模型进行存储， 接收用户输入； 选择相关知识， 对用户输入及相关知识进行预处理， 将用户输入和相关知识预处理到训练好的改进模型中， 模型预测输出回复结果，用户回复模型输出的回复结果后，将模型输出的回复结果和用户回复拼接成对话记录串，选择新的知识输入训练改进模型继续首尾对话。本发明还涉及一种具有改进的集成知识的端到端对话装置； 以及计算机可读存储介质，包括一组用于以改进的集成知识执行端到端对话的指令。 8
本发明公开了一种基于事件抽取的舆情分析方法、装置及相关组件。该方法包括利用语言表征模型对新闻文本进行文本特征提取，并对提取的文本特征进行多分类，得到不同类型的事件；利用命名实体识别方法抽取每一所述事件的论元信息，得到事件论元；将所述事件与所述事件论元进行匹配组装，得到结构化事件信息；按预设的配制规则的配制信息对预训练的评分模型进行参数化初始化，利用所述评分模型对所述结构化事件信息进行打分，得到对应的正负面评分。该方法通过对事件与事件论元进行匹配组装，定向输出用户关心的事件信息，并得到对应事件的评分，方便用户快速了解新闻文本中感兴趣的内容。一种基于事件提取的公众情感分析方法。本发明能够定向输出用户感兴趣的事件信息，得到相应事件的得分，便于用户快速理解新闻文本中的感兴趣内容，提高用户阅读体验。该方法涉及使用语言表示模型来提取新闻文本的文本特征。 对所提取的文本特征执行多重分类(S101)以获得不同类型的事件。 利用命名实体识别技术提取每个事件的推理信息。 获得事件推理(S102)。 将事件与理论元素进行匹配(S103)，以获得结构化事件信息。 根据预先设定的准备规则，对预先训练的评分模型进行参数化初始化(S104)。 通过使用评分模型对结构化事件信息评分。 得到相应的正负得分。独立的权利要求书包括： (1)一种基于事件提取的公众情感分析装置； (2)一种计算机设备，包括存储器和处理器，用于基于事件提取分析公众情感； (3)计算机可读存储介质，其存储用于基于事件提取分析公众情感的一组指令。  12
本发明提供了一种基于大语言模型的智能问答方法，根据用户的私有数据在本地创建问答库和资料库；问答库包括多个标准问题以及关联的标准答案；资料库包括多个标准段落；根据问题查询问答库和/或资料库；当问答库中存在与问题匹配的标准问题时，输出问答库中标准问题关联的标准答案，作为问题的答案；获取资料库中与问题匹配的标准段落，将标准段落和问题输入至大语言模型中；当大语言模型输出的答案与问题匹配时，可定义答案为问题的标准答案, 加入问答库。该方法根据用户的私有数据创建问答库和资料库，并结合大语言模型共同完成智能问答，克服了部分领域公开的现成数据较少，大模型在该领域训练不充分，导致大模型在该领域精准度低的缺陷。智能问答方法，用于与大型语言模型配合使用。该方法根据用户的隐私数据创建问答库和数据库，与语言大模型共同完成智能问答，克服了大模型训练不充分导致的大模型在领域中精度低的缺陷。智能问答方法是根据用户的隐私数据在本地创建问答库和数据库。 所述问答库中设置有多个标准问题和相关联的标准答案，所述数据库中包括多个标准段落。 根据问题和数据库查询问题。 在所述答案库中存在与所述问题匹配的标准问题时，在所述问题答案库中输出与所述标准问题相关的标准答案，作为所述问题的答案。 所述标准段落是在获取与所述查询中的问题匹配的标准段落时，在所述数据库中获取的。 将所述大型语言模型输出的答案与问题进行匹配时的答案定义为标准答案。  11
本申请公开了一种计算字向量方法、系统、电子设备及存储介质，计算字向量方法包括：字典组建步骤：从预训练词向量模型中抽取词语，将所述词语切分成字，并对所述字进行处理后，使用处理后的字组成字典；构词贡献计算步骤：统计所述字的字频以及共现频率，并根据所述字频以及所述共现频率计算字信息增益后，通过所述字信息增益计算字构词贡献；字向量计算步骤：根据所述字构词贡献，加权计算获取字向量。本发明提供了一种不需要大规模训练数据集，基于信息增益由基于预训练词向量模型计算字向量的方法。一种通过使用电子设备(要求保护)来计算词向量的方法。本发明不需要大规模的训练数据集，基于基于信息增益的预训练词嵌入模型计算词向量。该方法包括：从预训练词嵌入模型中提取词； 将字切成字， 对词进行处理， 用处理过的词构成字典， 统计单词的词频和公共频率，根据词频和公共频率计算单词信息增益，通过单词信息增益计算单词形成的贡献，根据单词形成的贡献通过加权计算得到单词向量。还包括独立的权利要求： 计算词向量的系统； 以及 电子设备可读存储介质包括一组用于计算字向量的指令。  12
一种用于OCT图像角膜层分割的边界增强卷积神经网络, 通过模块替换的方式将拟设计的卷积模块整合到BiO‑Net网络中同时作为编码和解码卷积模块，从而构建一个边界增强的卷积神经网络。该网络借助BiO‑Net中的前向和反向跳跃链接将边界卷积特征和非边界卷积特征传递给不同层次的卷积模块，通过两种卷积特征的学习与探测，共同提升图像中的兴趣目标及其边界区域的探测敏感性和有效性，降低目标边界区域的分割误差, 本发明可实现OCT图像中不同角膜层的同时准确提取，并且优于现有的U‑Net和BiO‑Net等网络的分割性能。光学相干断层成像(OCT)图像角膜层分割边界增强卷积神经网络模块。该模块通过两个用于降低目标边界区域分割误差的卷积特征的学习和检测，能够提高OCT图像中感兴趣目标和目标边界区域的检测灵敏度和有效性，实现了OCT图像中不同角膜层的同步精确提取功能，提高了分割性能。该模块涉及根据高斯差分边界检测算法在卷积神经网络模块中修改的卷积模块。 建立电流卷积模块，用于实现对多种图像特征的检测并将检测结果分为边界卷积特征和非边界卷积特征，得到边界增强卷积特征。 当前卷积模块与卷积神经网络模块框架连接，建立边界增强的卷积神经网络，用于进行各种边界特征和非边界特征的提取和整合操作，以实现边界特征的增强功能和目标边界区域的检测。   6
本申请提出一种多领域自适应的端到端语音识别方法，所述方法包括：提取待识别语音的第一特征；将所述第一特征和领域标签输入训练好的端到端语音识别模型；所述领域标签是为所述待识别语音的预先设定的口音标签；基于所述训练好的端到端语音识别模型，根据所述领域标签提取第二特征，将所述第一特征与所述第二特征拼接后进行编码得到第三特征；对所述第三特征进行解码，得到多条候选文本，输出第一文本候选列表，所述第一文本候选列表包括所述多条候选文本。本申请通过使用多领域自适应的方法，利用丰富资源领域预训练模型、多目标领域数据及多目标领域鉴别特征来提升在多个目标领域上的语音识别性能。一种用于识别多域自适应端到端语音的方法，用于多域自适应语音识别系统(要求保护)。本发明采用多域自适应方法，利用丰富的资源域预训练模型，克服了现有语音识别系统对小数据量域建模能力不足的缺陷。 多目标域数据和多目标域认证特征增强了多目标域上的语音识别性能。该方法包括提取(S201)待识别语音的第一特征。 将第一特征和域标签输入(S202)训练好的端到端语音识别模型，其中域标签是待识别语音的预设重音标签。 基于训练好的端到端语音识别模型，根据域标签提取第二特征， 拼接后对第一特征和第二特征进行编码，得到第三特征，对第三特征进行解码，得到多个候选文本，输出第一文本候选列表(S203)，其中第一文本候选列表包括多个候选文本。 基于训练的语言模型计算(S204)第一文本候选列表中的每个候选文本的概率值。 根据每个候选文本的概率值评估(S205)每个候选文本的合理性；独立的权利要求书被包括在以下内容中： 多域自适应端到端语音识别系统； 以及 一种用于识别多域自适应端到端语音的电子设备。 3
本发明公开了一种社区智慧养老服务系统及方法，通过社区硬件采集系统采集老人的人体姿态数据和热成像图像，通过对图像进行矩阵分割，应用情绪概率分布网络计算获取老人的情绪概率分布，应用BERT模型预测评估老人当前的身心健康，并拟合出老人的当前安全风险指数；最后采用聚类方法，得出老人的服务需求、建议指导和文章推荐。老人通过佩戴的智能设备观察到自己的需求，通过携带的老人智能终端获取智能化平台给出的服务推荐，采用一键式操作，进入共享平台来获取想要的服务。本发明实现了多重智能化服务与安全保障的服务体系，可以为老人解决实际需求，有助于解决养老困难的社会问题。智慧社区养老服务系统。该系统实现了多种智能服务和安全保障的服务体系，可以解决老百姓的实际需求，有利于解决老百姓的社会问题。所述系统具有智能监控装置，所述智能监控装置设置有热成像和彩色摄像头，用于采集指定老人的热成像和彩色图像数据。 一种老年人佩戴的具有定位和体征监测功能的智能设备。 所述云服务平台获取所述老年人的身心健康状况和安全风险指数。 智能终端，根据所述智能平台为所述老年人提供服务推荐。 旧的一键输入共享平台信息和服务。还包括用于社区智能养老服务方法的独立权利要求。  12
本申请公开一种应用软件开发方法和装置、存储介质和电子设备，所述方法包括：根据应用软件非标准化开发模式，获取开发提示模板类型，以及基于所述开发提示模板类型输入的开发需求信息；根据所述开发提示模板类型对应的提示模板描述信息与所述开发需求信息，生成目标提示；根据所述目标提示，获取大语言模型提供的与所述开发需求信息对应的输出结果；其中，所述输出结果满足所述应用软件非标准化开发模式的开发要求和所述开发提示模板类型的类型要求。从而能够协助开发人员实现应用软件开发过程中需要的开发代码内容，且开发代码内容符合非标准化开发模式的规范和开发提示模板类型要求。开发应用软件的方法。该方法能够辅助开发人员实现应用软件开发过程中所需的开发代码内容，使应用代码内容以有效的方式满足非标准开发模式的标准和开发提示模板类型需求。该方法包括：根据应用软件的非标准开发模式，获取开发提示模板类型。 基于所述开发提示类型输入开发需求信息。 根据所述开发提示模板类型对应的提示模板描述信息和所述开发需求信息生成目标提示。 得到与所述大型语言模型提供的开发需求信息对应的输出结果。独立权利要求包括用于：(1)应用软件开发装置； (2)计算机存储介质，用于存储由网络平台生成的数据和用于处理由网络平台生成的数据的程序； (3)一种电子设备，包括存储器。  11
本发明提供了一种语言模型的训练方法和装置，涉及翻译技术领域。语言模型的训练方法包括：从多个平行语料对中选择目标平行语料对，将目标平行语料对中的第一语料作为预训练模型的输入语料，第二语料作为预训练模型的目标语料，对预训练模型进行微调训练，在达到预设的微调结束条件的情况下，将预训练模型作为目标语言模型。由于标准语言和方言的语法和语义知识相同，语言模型在预训练阶段可以使用大量的标准语言语料进行训练，学习标准语言和方言的语法和语义知识，在微调训练阶段由于模型已经学习到标准语言和方言的语法和语义知识，因此可以使用少量的平行语料对即可训练得到具有准确翻译能力的语言模型。语言模型的训练方法。使用少量的并行语言数据就可以得到具有精确翻译能力的语言模型。 由于标准语言的语法和语义知识与汉语的语言知识相同，因此该语言模型可以在预训练阶段使用大量的标准语言语言数据集。该方法包括从多个并行语言数据中选择目标并行语料库对。 所述并行语料对中设置有标准语言语言数据对应的汉语语料。 将第一语言数据作为预训练模型的输入语言数据。 第二语言数据被用作预训练模型的目标语料库。 对预训练好的模型进行微调训练过程。 通过对原始语言模型进行预训练来获得预训练模型。本发明还涉及一种语言模型训练装置。  11
本发明公开了一种基于EDC系统的临床诊疗数据管理方法，涉及临床诊疗数据管理技术领域，包括使用EDC系统收集临床试验数据，包括患者的基本信息、临床症状、治疗方案；对收集的数据进行预处理和存储操作；收集目标药物相关历史临床研究数据，使用词向量技术获取各症状特征向量，构建以症状特征向量为样本的高维数据模型；利用偏离预警模块获取患者的身体状态偏离值，构建偏离预警模型。本发明所述方法通过使用电子数据捕获系统和大数据处理工具，可以自动化地收集、处理和分析大量的临床试验数据，同时通过加密处理，确保了数据的安全性；通过病症关键词库和BERT模型，实现了对患者病症的自动识别和分类，确保了患者的隐私信息得到了保护。一种基于电子数据捕获(EDC)系统实现临床诊疗数据管理的方法。该方法能够利用电子数据捕获系统和大型数据处理工具对大量临床检验数据进行自动采集、处理和分析。 该方法通过疾病关键字库和BERT模型实现了对患者疾病的自动识别和分类，保证了患者的隐私信息得到保护。该方法通过偏差预警模块获取患者的身体状态偏差值。 构建偏差预警模型。 通过使用患者跟踪和研究模块来获得患者信息数据。 收集患者的临床症状。 标记患者。 计算患者身体紧急状况估计值。 当计算患者身体紧急状况估计值时，分析本地医疗机构状况。 调度信息由管理员端口发送。 当地医疗机构定于标记患者就医随访。  10
本申请提供了一种大语言模型训练方法、装置及相关设备，通过获取预训练大语言模型；采用初始微调数据集对预训练大语言模型进行微调，得到微调大语言模型；基于提问数据以及答复数据构建优化微调数据集，答复数据是由微调大语言模型输出的针对提问数据的答复数据；利用优化微调数据集，对微调大语言模型进行迭代优化，获得训练好的大语言模型。本申请的这种大语言模型训练方法，基于用户的使用反馈，不断迭代优化微调大语言模型的方法，在迭代优化微调大语言模型的过程中产生了大量的数据对优化数据集进行调整，可以有效的减少训练及优化过程使用的样本数据获取的成本，并有效提高调整后的大语言模型的性能。用于训练大型语言模型例如BLOOM的方法。所述对大型语言模型进行微调的方法基于用户的使用反馈不断迭代优化，在迭代优化对大型语言模型进行微调的过程中产生大量数据以调整优化数据集，有效降低了获取训练优化过程中使用的样本数据的成本，有效提高了调整后的大型语言模型的性能。该方法包括获得(S101)预训练大型语言模型。 采用初始微调数据集对所述预先训练的语言大模型进行微调(S102)，得到微调语言大模型。 基于问题数据和回复数据构建优化细调数据集(S103)，回复数据是细调大语言模型输出的针对问题数据的回复数据。 利用优化后的微调数据集对微调后的语言大模型进行迭代优化(S104)，得到训练后的语言大模型。独立权利要求包括以下内容：大型语言模型训练装置； 以及计算机存储介质，其存储有用于训练大型语言模型的程序。  11
本申请实施例提供一种物体感知方法、装置及电子设备。在本实施例中，通过目标物体感知模型从待检测图像中划分出候选对象区域并输出候选对象区域对应的视觉特征(非文本特征)、以及大规模视觉语言预训练模型输出的各候选类别(预先设定好的类别)对应的文本特征，来确定候选对象区域中候选对象所属的目标类别，实现了基于大规模视觉语言预训练实现物体感知；基于如上描述的大规模视觉语言预训练模型输出的各候选类别对应的文本特征，这相当于借助大规模视觉语言预训练模型的先验知识(预先设定好的候选类别对应的文本特征)，并结合大规模视觉语言预训练模型超大范围的感知能力，提高了最终物体感知结果(也即候选对象所属的目标类别)的准确度。应用于电子设备(权利要求书)的对象感知方法，用于对齐待处理图像中包含的诸如亮度、边缘和纹理等对象的视觉特征。该方法能够结合大规模视觉语言预训练模型超大范围的感知能力，从而提高最终对象感知结果的准确性。该方法涉及将待检测图像输入(S110)到已训练的目标对象感知模型中，使得目标对象感知模型从待检测图像中划分出备选对象区域并输出与备选对象区域对应的视觉特征，视觉特征为非文本特征。 通过大规模视觉语言预训练模型获取(S120)每个候选类别输出对应的文本特征。 利用所述候选对象区域对应的视觉特征和获取到的各个候选类别对应的文本特征(S130)确定所述候选对象区域中的候选对象与各个候选类别之间的置信度。 利用候选对象区域中的候选对象与各个候选类别之间的置信度确定(S140)候选对象所属的目标类别。独立权利要求包括：(1)对象感测装置； 以及(2)电子设备。 14
本申请公开了一种视频场景分割点判断方法、系统、存储介质及电子设备，视频场景分割点判断方法包括：视频特征获取步骤：对视频进行划分获得多个所述视频等份，通过深度学习预训练模型对每个所述视频等份进行提取特征，获得对应每一所述视频等份的第一视频特征；模型处理步骤：将多个所述第一视频特征输入到通过临近一致性正则化约束后的分割点判断模型进行处理获得对应每一所述视频等份的分类概率；判断步骤 : 通过阈值对每个所述等份视频的分类概率进行判断确定场景分割点。本发明通过一致性正则化约束，能够提高表征能力。视频场景分割点的判断方法。该方法能够通过一致性正则化约束提高表征能力。 该方法让视频场景分割点判断系统有较好的特征表达，每个点的特征如视频等和左右两视频，有较大的感觉和较好的特征表达。该方法涉及划分视频以获得多个视频和其他分量。 通过深度学习预训练模型提取各视频的特征。 获取每个视频对应的第一视频特征。 将所述多个第一视频特征输入相邻一致性正则化约束后的分割点判断模型进行处理，得到所述视频对应的分类概率等。 通过阈值判断各视频的分类概率来确定场景分割点。本发明还公开了一种视频场景分割点的判断方法，包括以下步骤：(a)判断视频场景分割点; (b)一种电子装置，包括一存储器以及一处理器，用以判断一视频场景分割点; (c)存储用于判断视频场景分割点的指令集的存储介质。 9
本发明公开了一种基于ACU‑Net的MRI多模态图像分割方法和系统，包括多模态图像预处理、图像浅层与深层结构特征提取、像素级标注和活动轮廓约束；构建深度可分离卷积，解耦分离学习空间相关性与通道相关性；根据残差密集块的局部特征自适应学习，将特征进行融合并联合学习前面的局部特征，利用在U‑Net长跳跃连接中加入ResNet短跳跃连接的方式实现像素标注；活动轮廓约束将边界线分割与区域分割相结合，针对图像梯度和能量函数对分割边缘进行约束，并通过模型的训练和优化获得病灶区域。本发明较好地克服图像噪声和边缘夹缝，解决多模态图像病理组织高异质性与分辨率不明显问题。用于分割病变区域的MRI多模式图像的基于ACU-Net的方法。该方法能够降低图像噪声和边缘裂纹，从而解决多模态图像病理组织异质性高、分辨率不清晰的问题。该方法包括获得MRI多模式图像以预处理多模式图像。 构建非对称紧凑U网(ACU-Net)划分网络。 对数据集进行图像浅层和深层结构特征提取和像素级标记处理。 利用可移动轮廓模型来检测分割边缘。 利用活动轮廓边缘约束将病变区域划分为核心坏死区域。 区分病变区域的边界线和核心坏死区域的边界线。 对ACU-Net分区网络进行训练。 计算网络的划分精度。本发明还涉及一种基于ACU-Net的用于分割病变区域的MRI多模式图像的系统。   6
本发明公开了一种用于电商直播场景的小样本多轮对话的生成模型，包括：使用一元语言模型构建包含字和词的中文词表，用jieba参照该词表对输入文本进行分词，用分词后得到的字和词对输入进行表征；字或词，角色，轮数和位置嵌入的和作为嵌入的表征输入到模型；模型一共包含12个Transformer块，每个块中将解码器和编码器融合在一起，实现上下文理解和生成回复能够实现参数共享；在每个块中使用两种自注意掩码的方式来控制当前词对上下文词的访问；处于上下文位置的词，能够看到所有的上下文的词，处于回复位置的词，只能看到其之前的词；在最后的一层输出每个字对应的隐状态。本发明使用电商直播过程中的真实场景的对话，采用prompt的方式，在基于少量样本的数据集上，实现对话系统。小样本多轮会话的生成模型用于电商直播场景。该模型使用直播数据集，使用LM模型，从而在使用直播数据集训练模型时，基于直播字段训练生成模型。 该模型从而实现了针对电商现场场景的对话系统，并最小化了负对数似然损失函数。 训练目标函数最小化负对数概率损失函数，从而最小化对话生成模型的训练参数，进而最小化训练模型所需的时间。A生成模型使用元语言模型构建包含词和词的中文词表，使用jieba参考词表对输入文本进行分词，使用分词后得到的词和词表示输入。 将嵌入的词或词、角色、轮号和位置的总和作为嵌入表示输入到模型。 该模型包括12个块。 块解码器和编码器中的每一个融合在一起，实现上下文理解并生成可以实现参数共享的答复。 8
本说明书实施例公开了一种人机交互方法、装置及设备，该方法包括：获取预先训练的对话模型针对目标用户的输入信息而输出的回复信息，如果预先建立的表情图像与表情主题信息的对应关系中存在与所述回复信息相匹配的第一表情主题信息，则获取所述第一表情主题信息对应的表情图像，所述对应关系中的表情主体信息是通过预先训练的多模态预训练模型对表情图像和所述表情图像中包含的字符信息进行识别得到，所述多模态预训练模型是通过包含表情图像的训练图像和所述训练图像中包含的字符信息进行模型训练得到，可以将所述第一表情主题信息对应的表情图像作为对所述输入信息的回复提供给所述目标用户。人机交互方法。本发明提高了人机交互中对话的交流效率，降低了用户转向人工服务的概率。该方法包括获得预训练的对话模型以输出目标用户的答复信息。 获得与表情主题信息相对应的表情图像。 获得表情图像与表情主题信息之间的预先建立的对应关系。 表情主题与回复信息相匹配。 通过对多模态训练模型进行预训练，得到识别表情图像，得到表情主体信息对应关系。 训练多模式训练模型以获得包含表情图像和训练图像中的字符信息的训练图像。还包括独立的权利要求： 人机交互装置； 以及 一种存储介质，包括一组用于实现人机交互的指令。  11
本发明公开了一种面向数据命名实体识别的主动学习方法，包括步骤：S1、获取数据的粗粒度数据集和细粒度数据集，进行BIO标记；S2、构建数据命名实体识别模型，执行：S21、预训练Bert模型；S22、将标注后的细粒度数据集输入，获得初始字符向量；S23、输入BiLSTM层预测标签；S24、利用CRF层获得最优标签序列，完成训练；S3、利用训练好的数据命名实体识别模型对未标注的细粒度数据集的数据预测，通过查询策略标注数据，并将标注好的数据归为标注后的细粒度数据集；S4、返回步骤S22，直至获得满足要求的模型。该方法提高了命名实体的识别准确度，并解决了标记语料匮乏、标记成本高的问题。面向数据的命名实体识别主动学习方法。该方法能够提高命名实体的识别精度，降低标记成本，避免标记语料缺失的问题。该方法包括获取数据的粗粒度数据集和细粒度数据集，并将细粒度数据集划分为第一细粒度数据集和第二细粒度数据集。 构建数据命名实体识别模型。 标记的粗粒度数据集用于预训练来自变压器的双向编码器表示(Bert)模型。 将标记后的第一细粒度数据集输入预先训练的Bert模型进行编码，得到初始字符向量。 利用训练好的数据命名实体识别模型对所述第二细粒度数据集中的数据进行预测。 若预测准确度大于预设阈值或训练次数达到预设次数，则得到最终的数据命名实体识别模型。  12
本发明公开了基于U‑Net网络的两阶段多源数据融合地质填图方法，包括：获取待填图区域的多源地质数据；对多源地质数据进行预处理；采用U‑Net神经网络对整个待填图区域的基础地质图Ωtotal进行粗分；采用U‑Net神经网络对第一阶段粗分的智能填图结果进行细分；将第二阶段结果整合至第一阶段结果上，得到整个待填图区域的智能填图结果；对整个区域的智能填图结果进行野外验证，得到修正后的智能填图结果；根据修正后的智能填图结果，完成地质解译图。本发明有益效果是：可以利用较少的训练区域，GPU环境下加速完成待填图区的预测，具有较高的分辨率和泛化能力，并且对覆盖区和受限工作区的填图工作有一定的指导意义。基于U-Net网络的两级多源数据融合地质测绘方法 也可用于人工智能，图像分类，语义分割，目标检测，图像生成等领域。两级多源数据融合地质填充方法使用较少的训练面积， 图形处理单元(GPU)环境加速完成待映射区域的预测，具有较高的分辨率和泛化能力，对覆盖区域和有限工作区域的填充工作具有一定的指导意义。该方法包括获取(S1)待测绘区域的多源地质数据。 对多源地质数据进行预处理(S2)，以获得预处理后的多源地质数据。 使用U-Net神经网络(S3)分析待测绘区域的基本地质图，以获得第一阶段粗略分类的智能测绘结果。 使用U-Net神经网络(S4)获得第二阶段粗略分类的智能映射结果。 将第二阶段粗略分类的智能测绘结果整合(S5)到待测绘区域的第一阶段粗略分类的智能测绘结果中，得到待测绘区域的基础地质图的智能测绘结果。 对要绘制的区域的基本地质图的智能绘制结果进行现场验证(S6)，以获得校正后的智能绘制结果。 根据校正后的智能映射结果完成(S7)地质解释图。   6
本发明公开了一种基于深度学习特征与人工提取特征融合的白细胞分类方法，包括以下步骤：从分割出的白细胞细胞核以及整个白细胞中，提取颜色、纹理和形态三方面的多个人工特征；引入迁移学习的方法，将在Image Net数据集上预训练好的Inception V3网络模型迁移到白细胞数据集上，去掉Inception V3网络模型最后的两层，并加入一个全局平均池化层以及一个全连接层，以该全连接层的输出作为深层特征；将深层特征与人工提取特征拼接融合后，将融合特征送入输出层，构建白细胞分类模型，实现白细胞的分类。本发明充分地利用了图像的特征信息，提高了分类准确率，并引入迁移学习的方法，在只拥有小数据集的情况下，实现准确高效的图像分类。基于深度学习和人工提取特征融合进行白细胞分类的方法。该方法能够充分利用图像的特征信息，提高分类精度，在小数据集条件下实现准确、高效的图像分类。一种基于深度学习和人工提取特征融合的白细胞分类方法，包括从分裂的白细胞细胞核和全白细胞(WBC)中提取人工特征的颜色、纹理和形状三个方面。 引入迁移学习方法，将在图像净数据集上预先训练好的Inception V3网络模型迁移到白细胞数据集上，去掉Inception V3网络模型的前后两层，增加全局平均池层和全连接层，全连接层的输出作为deep特征。 将得到的深层特征与人工提取的特征进行拼接融合，得到融合特征，将融合特征送入输出层构建白细胞分类模型，实现白细胞分类。   6
一种语音识别中说话人停顿处理的方法，包括如下步骤：步骤一：获取语音，通过ASR对语音进行识别；步骤二：通过使用LLM大语言模型的Prompt提示词话术来实现断句检测；步骤三：若步骤二检测断句语意完整则输出该ASR文本送入后续处理流程；步骤四：若步骤二检测断句语意不完整则等待一定时长的阈值，等待说话的声音，若有声音，则等说完，合并两次或多次的ASR文本，送入后续处理流程，若该时长阈值内未发现说话声音，则不再等待，直接将本次ASR文本送入后续处理流程。本发明能够解决在ASR中由停顿带来的断句问题，同时本发明还有极低的研发投入、极高的准确率、并发压力小等优势，从而能够在语音识别领域广泛推广和应用。语音识别中说话人暂停的处理方法。该方法避免了ASR中停顿导致的断句问题，减少了研究投入，提高了准确性，可广泛推广。该方法包括获得语音。 通过自动语音识别(ASR)来识别语音。 通过LLM大语言模型的提示词检测断句。 如果断句语义完整，则输出ASR文本，发送给后续处理流程。 如果断句语义不完整，则直接将ASR文本发送给后续处理流。 语音与ASR文本相结合。 3
本申请提供一种信息处理方法、电子设备及存储介质，应用于人工智能技术领域，其中方法包括：确定智能体对应的待处理信息；将所述待处理信息和节点序列信息输入到大模型，其中，所述节点序列信息用于指示任务流程中包含的多个节点以及节点之间的边，节点表示针对智能体的行动指令，边表示节点间的跳转，以使所述大模型根据所述待处理信息，确定待执行的目标节点，并控制所述智能体执行所述目标节点对应的行动指令。本申请可以实现复杂流程的规划以及执行过程的可控，使智能体更加高效、准确地完成任务，并且，能够支持不同场景定制不同的任务流程，满足不同场景下的使用需求，提升用户体验度。一种应用于人工智能技术领域的提高大模型驱动智能体任务处理效果的信息处理方法。本申请能够实现复杂流程的规划和执行过程的控制，使得智能代理能够更加高效准确的完成任务，并且能够支持不同场景定制不同的任务流程，满足不同场景下的使用需求，提高用户体验。该方法涉及确定(201)与智能代理相对应的要处理的信息。 将该信息和节点序列信息输入(202)大型模型。 其中，序列信息用于指示任务流中包含的多个节点以及节点之间的边。 所述节点表示针对所述智能体的动作指令。 所述边表示所述节点之间的跳转，从而所述大模型根据所述信息确定需要执行的目标节点。 控制所述智能代理执行所述目标节点对应的动作指令。 交互信息具有从环境获得的智能代理输出信息和智能代理输入信息。独立权利要求包括以下内容：一种电子设备； 以及计算机可读存储介质，其存储用于处理信息的程序。  11
本发明涉及人工智能技术领域，公开了一种电力专用插件构建以及电力设备检索问答方法，电力专用插件构建方法包括：获取预训练模型以及训练数据；使用预训练模型初始化检索模型和重排模型；采用分步迭代优化方法基于训练数据对检索模型和重排模型进行联合训练；使用联合训练后的检索模型和重排模型构建电力专用插件。本发明采用分步迭代优化方法联合训练检索模型和重排模型，使用训练后的检索模型和重排模型构建电力专用插件构建，采用插件化的方式将该电力专用插件与大语言模型结合，实现了为大语言模型补充电力专业知识的目的，达到了将传统电力领域任务与大语言模型相结合的效果，解决了大语言模型缺乏电力领域专业知识的问题。一种利用电力设备为大型语言模型提供电力领域专业知识的电力专用插件构建方法。该方法能够为大型语言模型补充电力专业知识，从而达到预设电力现场任务与大型语言模型相结合的效果，解决了语言模型缺乏电力现场专业知识的问题。 该方法基于预训练模型和训练数据对搜索模型和重排模型进行联合训练，以有效地提高电力专用插件和电力装置检索问答过程的性能。该方法涉及获得预训练模型和训练数据。 利用所述预训练模型初始化检索模型和重排模型。 采用逐步迭代的优化过程，基于所述训练数据对所述检索模型和所述重排模型进行联合训练。 利用所述联合训练检索模型和重排模型构建电力专用插件。包括独立权利要求，用于：(1)电力装置检索问答方法； (2)电力专用插入式建筑装置； (3)一种计算机设备，包括存储器和处理器，用于构建电源专用插件； 以及(4)计算机可读存储介质，所述计算机可读存储介质用于存储用于构建电力专用插件的指令。 0
本发明提出未登录词词向量计算方法、系统、电子设备及存储介质，方法技术方案包括先验知识获取步骤，获取用于预训练的一先验知识，所述先验知识包括字典、未标注文本语料库和未登录词；语料库预处理步骤，对所述未标注文本语料库进行预处理；文字共现统计步骤，统计所述字典中一汉字在所述未标注文本语料库中的共现数据；字熵数据计算步骤，根据所述共现数据，计算所述汉字的熵数据；词向量计算步骤，根据所述熵数据计算所述汉字对所述未登录词的构词贡献，并根据所述构词贡献计算所述未登录词的词向量。本发明解决了现有预训练模型不能处理未登录词的问题。计算未注册词的词向量的方法。本发明解决了现有的预训练模型无法处理未注册词的问题。所述方法涉及获取(S1)用于预训练的先验知识，其中所述先验知识包括词典，未标注文本语料库和未注册词。 预处理未标记的文本语料库(S2)。 对未标注文本语料库中的字典中的汉字的共现数据进行计数(S3)。 根据共现数据计算(S4)汉字的熵数据。 根据熵数据计算汉字对未注册词的词形贡献，根据词形贡献计算未注册词的词向量。独立的权利要求书被包括在以下内容中： 未注册词的计算系统； 电子设备； 以及 一种存储用于计算未注册词的词向量的程序的计算机可读介质。  12
一种基于预训练模型的级联二进制中文实体关系提取方法，包括：利用预训练模型Bert将文本的语义及位置信息提取联合生成嵌入向量；将关系建模为主体到客体的一种函数映射，抛弃了以往主客体同时识别的方式，首先通过对每个字的嵌入向量进行二分类任务预测三元组中主体所在的位置，然后在提取关系及客体的过程中，将文本及主体的联合嵌入信息作为输入，在每种关系映射之下对每个字的嵌入向量进行二分类任务预测三元组中客体所在的位置。本发明能够提取出非结构化文本的人物，组织，事件等实体及其之间的多种关系并有效的解决了三元组之间的重叠问题，预测结果准确率高、误差小，计算复杂度低，有很高的实用价值。基于预训练模型的级联二进制中文实体关系提取方法本发明能够提取非结构化文本，组织，事件等实体的特征，有效解决三组之间的重叠问题，实现预测结果的高精度，误差小，计算复杂度低，具有较高的实用价值。该方法包括从初始中文非结构化数据中过滤有效数据以获得字典，实体和关系三元组形式的文本，以及对所获得的文本进行分类，其中非结构化数据包括文本，实体内容，实体类型和关系。 通过使用预先训练的模型BERT来生成有效数据的嵌入向量。 文本的语义信息通过嵌入向量生成，其中语义贡献关系捕获单词和单词。 设置位置嵌入信息以获得文本中的句子向量句子。 对句子中的每个词向量执行主标记分类。 在每个关系中执行对象标记分类。 最后将结果组合以在句子中生成总的三元组。  12
本发明公开了一种基于迁移学习的癌组织图像细胞核分割方法。先对图像作数据预处理，得到数据规模增大且图像色彩归一化、尺寸为256*256的图像，然后将图像送到VCRNet网络中进行若干次训练，在训练的过程中只保存验证集损失最小的权重文件，最后在MoNuSeg测试集上, 先对图像做颜色归一化，再将图像输入模型中进行测试，得到细胞核的分割结果，本发明中，基于Unet搭建了VCRNet模型。VCRNet模型以Vgg16‑1卷积模块在ImageNet数据集上的预训练模型作为编码模块和分类依据；利用改进后的残差块mr‑block作为解码部分和定位依据，最后利用跳跃连接完成特征图间的特征融合。在先对测试集做标准化再输入模型测试后，实验结果表明，与针对病理图像中细胞核的粘连问题，VCRNet有着较好的分割效果。基于迁移学习的癌症组织图像细胞核分割方法。可以有效地分割出病理图像中细胞核的粘连问题。 可以减少内存占用，节约计算资源。该方法包括预处理数据集。 执行图像切割处理。 图像切割完成后进行颜色归一化处理。 执行数据增强处理过程。 图像和训练集的对应标签被转动以旋转和切割，以增加训练数据的规模和多样性。 分割网络用于分割。 所述分割网络中设置有编码模块和解码模块。 所述编码模块设置有Vgg16-1结构。 用13个卷积层和MaxPool构成特征图层，构成提取特征图层特征的采样系列。 通过使用1×1的卷积核来检查特征图案。  7
本发明公开了基于预训练语言微调与依存特征的半自动需求抽取方法，包含以下步骤：预处理，实体抽取，实体融合确认，意图抽取，意图融合确认，主体关系后处理，输出建模。本发明提供的半自动需求抽取方法，融合了预训练语言微调模型与依存分析特征优势：一方面针对软件需求建模的领域问题设计了规则，通过领域知识提升了系统的可解释性与可靠性；另一方面利用了预训练语言模型泛化的便利性进行适当微调，又不至于为准确率溢价支付额外的大规模数据集标注训练。预训练语言微调和基于依赖特征的半自动需求实体抽取方法。该方法将预训练语言微调模型与依赖分析特性相结合，从而设计软件需求建模领域问题的规则，通过领域知识提高系统的可解释性和可靠性。 该方法使得能够利用预训练语言模型泛化的便利性来进行适当的微调，并且避免超大规模数据集标记训练以提高准确度。该方法包括输入待处理需求句。 基于预训练语言模型对意图信息进行序列标签推理。 输出初始待定意图信息序列。 通过所述预先训练的语言模型的初始未确定推理结果执行依赖特性分析。 执行相关特性分析处理。 对输出序列的异常边界特征进行剪枝。 将上一步骤中确定的实体信息序列与所述实体信息进行匹配。 输出最终的未待定意图提取结果。 应用所获得的结果来获得意图提取结果。 将得到的主体关系应用于得到的结果，得到最终的包含主体关系。 详细意图信息的序列结果用于需求建模。  11
本申请公开了一种基于大语言模型的面试技能训练方法、设备及介质，方法包括：将面试类型下设置的若干个面试问题，输入至预先训练的大语言模型中，获取大语言模型输出的回答内容，基于面试问题的预设标准答案或面试官表现，对回答内容进行人类反馈标注，形成面试问题对应的价值标注数据，训练生成强化学习生成模型，并输出回答内容对应的优化内容，进行面试技能训练。在面向垂直行业中面试技能培训这一特定场景下，进行训练强化学习生成模型所需数据的快速全面采集，通过人类反馈标注，使得采集到的训练数据更符合人类用户的预期和偏好。面试官无需经历面试实战场景，即可在相对真实的场景下进行面试技能的训练。基于大语言模型的面试技能训练方法，应用于面试实战领域。该方法能够快速全面地收集训练加强学习生成模型所需的数据，并通过人为反馈标签使得收集到的训练数据更加符合人为用户的期望和偏好。 面试官在不经历面试实际场景的情况下，在相对真实的场景中训练面试技能。该方法包括确定(S101)与多个预设的面试类型中的每个面试类型对应的知识图谱。 将所述面试类型下设定的多个面试问题输入(S102)预先训练的语言大模型。 基于预设的所述面试问题的标准答案或面试官方表现，获取与所述面试类型对应的分析标准(S103)。 在所述面试类型下，基于所述面试类型的分析标准对回答内容进行人为反馈标注(S104)，形成与所述面试问题对应的价值标注数据。 构建面向面试技能训练的内容数据集。 基于内容数据集生成强化学习生成模型(S105)。 根据所述强化学习生成模型输出与所述答案内容对应的优化内容，以根据所述优化内容进行面试技能训练。独立权利要求包括以下内容：基于大型语言模型的面试技能训练装置； 以及存储有面试技能训练程序的非易失性计算机存储介质。  11
一种基于U‑net卷积神经网络模型的自由液面识别和提取方法，属于图像处理及自动化检测技术领域。首先，对液面图像进行处理并人工标注自由液面，构成带有已分割完成的液面图像的数据集，将数据集分为训练集，验证集和测试集三个部分。其次，搭建U‑net卷积神经网络模型；在U‑net卷积神经网络中导入训练集，对图像进行特征学习，对自由液面进行预测。再次，使用验证集对模型进行验证并调整模型，当损失函数不在下降时保存最优模型。最后，将训练好的U‑net卷积神经网络模型进行部署，用于对测试集中的液面图像进行自动检测并对模型进行评估。本发明通过无接触测量和人工智能相结合的方法能够提取破碎波的自由液面，能够解决破碎波液面识别困难的技术难题。基于U-网卷积神经网络模型的自由液位识别与提取方法本发明通过非接触测量与人工智能相结合的操作，提取出破碎波的自由液位，避免了破碎波液位识别困难的技术问题。该方法包括构建样本训练集、验证集和测试集。 取流体自由表面运动图像作为原始图像。 原始图像中的自由表面被手动标记。 将图像划分为水域和空中区域。 在图像上使用全局阈值分割。 对图像进行反相后进行去噪处理。 所述水域和所述空中区分别标记为黑白区。 将分割图像和对应的原始图像组合在一起以形成数据集。 数据集分为训练集、验证集和测试集。 训练集用于模型构建。 部署训练好的U-net卷积神经网络模型，用于自动检测测试集中的液面图像。 使用骰子系数来评估模型结果。   4
本申请实施例公开了一种文本语义匹配方法及设备。通过预设相似度组合算法，对用户输入的文本与预设语料库中的文本进行第一相似度计算，以在预设语料库中筛选出参考语料集合；其中，参考语料集合中的语料所对应的第一相似度大于预设相似度阈值；预设语料库包括多个语料以及多个语料分别对应有文本语义；将用户输入的文本以及参考语料集合输入预设SBERT模型，通过预设SBERT模型对用户输入的文本进行第一序列向量提取，以及通过预设SBERT模型对参考语料集合中的语料进行第二序列向量提取；通过预设SBERT模型，确定出第一序列向量与多个第二序列向量分别对应的第二相似度，以根据第二相似度确定出与用户输入的文本所对应的文本语义。文本语义匹配方法。准确地确定用户输入的文本的文本语义。 减少了语义选择的范围。该方法包括对用户输入的文本和预置语料库中的文本执行第一相似度计算， 筛选预设语料库中的参考语言数据； 其中对应于参考集合语言数据中的语言数据的第一相似度大于预设相似度阈值， 将用户输入的文本和参考语言数据集输入到预先设置的SBERT模型中， 通过预设的Sbert模型对用户输入的文本进行第一序列向量提取，其中，文本语义根据第二相似度与用户输入的文本相对应。本发明还涉及一种文本语义匹配装置。  11
本发明公开了一种基于深度学习算法的羊只个体身份识别方法，包括：采用SSD网络预训练模型，对羊只个体的数据集进行边界框检测，并对边界框进行切割处理；采用迁移学习的预训练模型Resnet18，对羊只个体特征进行学习；采用三元组损失函数与交叉熵损失函数的联合优化损失函数，对羊只个体进行身份识别；其中，采用实验对比方法，确定最佳的联合优化损失函数的系数。对于羊只个体，能够自动高效进行基于图像的智能识别，从而节省了专业养殖人员人工标记的时间成本与标记成本之外，以“无接触，低成本，高收益，无伤害”的原则不伤害羊只个体的同时，提出了羊只个体身份识别的深度学习思路，为相似度高的动物个体身份识别也提供了研究思路。基于深度学习算法的绵羊个体身份识别方法。该方法以非接触、低成本、高利润、无伤害的原则，在不损伤绵羊个体的前提下，实现自动、高效的基于图像进行智能识别，节省了专业养殖人员人工标记的时间成本和标记成本，为高相似度绵羊个体的识别提供了研究思路。该方法利用SSD网络预训练模型对绵羊个体的数据组进行边界框检测。 通过使用迁移学习的预训练模型残差神经网络(Resnet)-18来学习绵羊个体的特征来划分边界框。 通过使用组合优化损失函数、三元组损失函数和交叉熵损失函数来识别绵羊个体的身份。 在实验比较过程中确定联合优化损失函数的最优系数。   6
本公开关于一种文本处理方法及装置，该方法包括：接收用户输入的第一问句，并从数据库中的多个问句中获取任意一个问句，得到第二问句，由第一问句和第二问句构成待测问句对；获取待测问句对的多维度特征；对待测问句对的多维度特征进行组合，得到待测问句对的组合特征；将待测问句对的组合特征输入预训练的神经网络模型进行处理，得到表征第一问句和第二问句是否相似的结果；在结果表征第一问句和第二问句相似的情况下，获取第二问句对应的回答语句，并将回答语句作为第一问句的答案输出，本公开至少解决相关技术中难以准确地确定待测问句和已知问句对之间的相似度，进而难以为待测问句确定对应的答案的问题。文本处理方法。本发明能够降低对待测问题语句与已知问题语句对的相似度进行准确判断的难度，从而确定答案对应的问题语句的问题。该方法包括接收用户输入的第一问题，从数据库中的一组问题语句接收第一问题语句以获得第二问题语句。 由第一提问句和第二提问句组成待测提问句对。 数据库存储有一组提问语句和答复语句。 获得待测提问句对的多维特征。 组合多维特征以获得待测提问句对的组合特征。 将待测问题语句对的组合特征输入到预训练的神经网络模型中，以获得表示第一问题语句和第二问题语句是否相似的结果。 获得对应于第二问题句子的答案句子。 将答案语句作为第一问题语句的答案输出。本发明还涉及一种电子设备，其包括处理器和用于处理文本的存储器； (2)用于存储一组用于处理文本的指令的计算机可读存储介质； (3)包括一组用于处理文本的指令的计算机程序产品。  11
一种人岗需求文本的知识图谱的构建方法及存储介质，其中方法包括如下步骤：步骤101、将BERT与BiLSTM‑CRF模型相结合，对人才岗位需求文本进行BIO词性标注，根据预设的实体类型，对所述人才岗位需求文本的相应实体类型进行标记，将人才岗位需求文本转换为稠密字向量，作为BiLSTM层语义抽取任务的输入，BiLSTM层输出每个词在所有标签下的得分，输入到CRF层，该层输出作为最终标注结果；上述方案能够通过采用正则匹配的方法对实体标注集进行实体生成，然后进行基于上下文的实体对齐和基于标点符号的实体隐藏关系学习。提取到岗位关键词后，基于树模型对岗位信息进行三元组构造，将岗位关键词转化为岗位三元组结构化表达式，并构建知识图谱。人岗位需求文本知识地图构建方法。本发明能够高效，准确地构建满足人的岗位需求文本处理的知识地图，并以统一的岗位需求类型安排组合互补关系，提高人的岗位匹配效率。该方法包括将来自变压器(BERT)的双向编码器表示与BILSTM-CRF模型(101)组合。 根据预置的实体类型标注出人才岗位需求文本对应的实体类型。 将人才岗位需求文本转换为密集词向量。 标签下的单词的得分被输入到CRF层。 基于所获得的单词标记结果生成(102)实体。 获取人才岗位需求文本中的岗位需求描述。 获得后关键字(103)。 使用树模型对POST关键字执行存储分组。 从实体关系集中提取(104)序列。 构建关系树。 使用树模型的搜索算法提取描述后三元组序列，并以资源描述框架(RDF)的形式存储。 基于RDF数据构造(105)知识地图。本发明还涉及一种存储媒体，用于存储一组指令，用于构造人后需求文本知识地图。  12
一种基于ResUnet的3视图PET图像分割方法，包括以下步骤：步骤1，针对淋巴瘤病灶特点设计或修改网络模型，使之适合淋巴瘤的分割；步骤2，将3维的训练数据沿3个视图方向(俯视，正视，左视)进行切片，得到3个视图方向的2维数据；步骤3，将3个视图方向的2维数据分别输入到网络中进行训练，得到3个分割模型，分别对应3个视图方向的数据；步骤4、将测试数据分别输入到3个预测模型，将3个预测结果进行加权求和得到测试数据的最终的预测结果。本发明增加了2维模型对3维数据的空间信息利用，提高了分割的准确率。基于ResUnet的三视角PET图像分割方法。PET图像分割方法增加了2维模型对三维数据空间信息的利用，提高了分割的准确性。该方法涉及根据淋巴瘤病灶的特征设计或修改网络模型，使其适用于淋巴瘤的分割。 将三维训练数据沿三个视图方向进行切片，得到3视图方向的二维数据。 将三个视角方向的二维数据输入到网络中进行训练，并对三个预测结果进行加权求和，得到最终的分割结果。 将所述测试数据输入所述预测模型，得到所述测试数据的分割结果。  7
本发明公开了一种基于BERT与SemiCRF的中文命名实体识别方法，构建命名实体识别模型，所述方法包括步骤：获取预训练好的BERT模型；对命名实体识别的原始语料数据进行预处理，构建命名实体识别的训练集；将构建的命名实体识别的训练集数据输入到预训练好的BERT语言模型；将BERT语言模型的输出依次输入到双向LSTM神经网络以及CRF与SemiCRF联合模块中，对双向LSTM神经网络及联合模块进行多次迭代训练；使用训练完成得到的完整命名实体识别模型，对中文文本进行命名实体识别。本发明解决了传统的word2vec无法区分多义词的问题，并通过引入的基于SemiCRF的方法，将传统的CRF方法往往会忽略掉的词级别信息与字级别的信息结合起来，在一定程度上提高了中文命名实体识别的效果。用作基于来自变压器和半条件随机场的双向编码器表示的中文命名实体识别方法。该方法克服了Word2vec(RTM : Group of related models for producing word embedding)无法划分多个同义词的问题，在一定程度上提高了中文命名实体识别的效果。基于双向编码器表示和半条件随机场的中文命名实体识别方法，包括：获取预先训练的双向编码器表示(BERT)语言模型; 对命名实体识别的原始语料数据进行预处理，构建命名实体识别的训练集; 将构建的命名实体识别的训练集数据输入到预先训练的BERT语言模型中; 将BERT语言模型的输出依次输入双向LSTM神经网络和条件随机场(CRF)与半CRF组合模块，对双向LSTM神经网络和组合模块进行多次迭代训练，利用训练后得到的完整命名实体识别模型对中文文本进行命名实体识别。  12
本申请提供一种基于自然语言模型的拟人对话方法、装置及电子设备，涉及计算机技术领域，该方法包括：获取对话过程中的第一文本信息以及对话过程中的第二文本信息，并确定与第一文本信息的技术领域相关的第三文本信息，以及与第一文本信息的话题场景相对应的第四文本信息；将第一文本信息、第二文本信息、第三文本信息、以及第四文本信息进行拼接合并，得到目标文本信息，并将目标文本信息输入自然语言模型，得到与用户当前问题对应的目标回复内容。本申请提供的基于自然语言模型的拟人对话方法及装置，用于提高以自然语言模型LLM驱动的聊天机器人针对专业领域问题的对话生成能力和对话质量，同时，还能使聊天机器人的对话更加拟人化。针对专业专业领域的问题，基于自然LLM的聊天机器人的拟人化对话过程实现方法。该方法能够提高自然LLM驱动的聊天机器人对专业领域问题的对话生成能力和对话质量，有效实现拟人化的聊天机器人对话过程。所述方法包括：在对话过程中获取第一文本信息和第二文本信息，所述第一文本信息包括用户当前问题，所述第二文本信息包括所述用户当前问题的上下文信息。 确定与所述第一文本信息的技术领域相关的第三文本信息，所述第三文本信息包括多个领域知识。 确定与所述第一文本信息的话题场景对应的第四文本信息，所述第四文本信息包括会话提示模板。 将所述第一文本信息、所述第二文本信息、所述第三文本信息和所述第四文本信息拼接组合在一起，得到目标文本信息。 将所述目标文本信息输入自然大型语言模型(LLM)，得到与所述用户当前问题对应的目标回复内容。包括独立权利要求，用于：(1)基于自然LLM的拟人化对话装置； (2)一种电子设备，包括存储器和处理器，所述处理器用于执行用于执行拟人化对话过程的计算机程序； 以及(3)计算机可读存储介质，其存储用于由处理器执行拟人化对话过程的计算机程序。 8
本发明提供了一种目标字段抽取方法、系统、终端及介质，该方法包括：获取病历文书的病历图像，对病历图像进行文本识别，得到文本识别结果；将文本识别结果中的文本信息、方位信息和视觉信息输入多模态预训练模型进行实体预测，得到实体列表；根据文本识别结果中的行信息和实体列表进行字段对齐，得到键值实体对，查询预设置的目标字段；根据目标字段和所述键值实体对对病历文书进行字段抽取，得到病历文书的目标字段值。本发明通过将文本识别结果中的文本信息、方位信息和视觉信息输入多模态预训练模型进行实体预测，以达到多模态预测实体的效果，提高了实体预测的准确性，降低了信息粒度，无需大量训练数据，提高了目标字段抽取效率。利用终端设备提取病历文档的目标字段的方法(权利要求书)。该方法通过将文本识别结果中的文本信息、方向信息和视觉信息输入多模式预训练模型进行实体预测，达到多方向预测实体的效果，提高了实体预测的准确性，降低了信息粒度，从而避免了训练数据的需要，提高了目标领域的提取效率。该方法涉及获得病历文档的病历图像。 对所述病历图像的文本进行识别，得到文本识别结果。 将文本识别结果中的文本信息、方向信息和视觉信息输入多模式预训练模型进行实体预测，得到实体列表。 根据所述文本识别结果中的行信息和所述实体列表进行字段对齐处理，得到键值实体对。 查询预设的目标字段。 根据所述预设目标字段和所述键值实体对提取病历文档字段，得到所述病历文档的目标字段值。独立权利要求还包括用于：一种利用终端设备提取病历文档的目标字段的系统； 以及一种计算机可读存储介质，包括用于通过使用终端设备提取病历文档的目标字段的指令集。  10
本申请公开了一种短信文本的审核方法和装置，本方法通过获取待发送短信的短信文本内容，基于自然语言处理算法对所述短信文本内容进行分词处理，得到所述短信文本内容对应的短信词集；利用预训练语言模型BERT模型将所述短信词集转换为词向量，得到所述短信词集中每个词对应的短信词向量；当所述短信词向量的数量不小于预设值时，查询获取缓存中的与所述待发送短信对应的短信模板的模板词向量，将所述短信词向量与所述模板词向量进行余弦相似度匹配得到匹配结果，基于所述匹配结果确定所述短信文本的审核结果。本申请解决相关技术中短信检测性能较低、耗费资源多的技术问题，实现在满足检测精度的同时，又能满足高并发的性能要求，节约了服务器成本。一种短信文本审核方法，用于计算机领域。该检查短信文本的流程在满足检测精度的同时，实现了高并发性能要求，节省了服务器成本。该方法包括获得待发送的短消息的短消息文本内容(S101)。 基于自然语言处理算法对短信文本内容进行分词处理。 获取所述短信文字集合对应描述短信文本内容。 利用预训练语言模型双向编码器(BERT)模型(S102)将短消息词集转换成词向量。 获取短信词集合中每个词对应的短信词向量。 在缓存中查询获取与待发送短信对应的短信模板的模板词向量，当所述短信词向量的数量不小于预设值时。 将短信词向量与模板词向量进行余弦相似度匹配(S103)以获得匹配结果，基于匹配结果确定短信文本的审核结果。包括独立权利要求：(1)一种用于检查短消息文本的装置； (2)电子设备； 以及(3)存储用于检查短消息文本的程序的计算机可读存储介质。  12
本发明公开了基于多因素和模型融合的区域运力预测方法，包括如下步骤：S1，GPS轨迹数据降采样；S2，运力值预处理，并利用熵权法计算区域运力值。本发明利用熵权法获取区域历史运力得分，采用基于BERT的政策因素提取模型提取政策文本输出对应的政策文本因素特征并生成对应的向量化特征表示。使用基于权值修正的天气因素生成方法，根据历史天气数据构建修正权值对天气预报数据进行修正，获取天气因素特征并生成对应的向量化特征表示。最后使用XGBoost和LSTM模型分别进行序列预测，并融合两个模型的预测结果作为区域运力的预测结果，其准确率高，取得了良好的效果。一种用于物流企业运行能力预测的基于多因素与模型融合的区域行使力预测方法，特别是用于预测承载货物的车辆在各个流向上的区域运行能力。该方法将两个模型的预测结果进行融合，作为区域操作力的预测结果，准确度高，效果好。该方法包括执行全球定位系统(GPS)轨道数据的下采样。 计算30天内所有GPS连续点之间的距离，作为所述车辆在所述30天内的一个运行里程。 将车辆在30天内下采样后所有GPS连续指向的时间差的累加值作为运行时长。 对所述操作力值进行预处理。 一个区域作业力由作业里程、作业天数、作业时长和作业价格、货运周转金额五个因素来衡量。 采用熵权法计算所述区域操作力度值。  12
本申请提供一种健康管理系统、方法、电子设备和计算机可读存储介质，涉及计算机领域。该健康管理系统包括：个性化分析模块、建议生成模块和建议优化模块；个性化分析模块用于构建用户画像；建议生成模块用于根据用户历史数据、用户需求和用户画像，生成初步建议；建议优化模块用于基于大型语言模型优化初步建议，并生成优化建议；其中，优化建议用于提供给用户进行健康管理。使用本申请实施例提供的健康管理系统能够基于用户提供的数据，提供实时的、个性化的建议，并且可以整合分析用户饮食、运动以及健康数据，为用户提出个性化的、精确的健康管理建议。健康管理体系。健康管理系统根据用户提供的数据进行实时、个性化的建议，对用户的饮食、运动和健康数据进行整合分析并为用户提供个性化、精准化的健康管理建议。该系统具有用于构建用户画像的个性化分析模块。 建议生成模块，用于根据所述用户历史数据、所述用户需求和所述用户画像生成所述初始建议。 建议优化模块，用于基于所述大语言模型对所述初始建议进行优化，生成所述优化建议，所述优化建议用于为所述用户提供健康管理。 用户需求分析模块，用于获取用户的自然语言需求，并将所述自然语言需求转换为需求文本数据，对所述需求文本数据进行预处理。独立权利要求被包括用于：(1)健康管理方法； (2)一种电子设备，包括存储器和处理器，以执行一种健康管理方法； 以及(3)计算机可读存储介质，其存储执行健康管理方法的一组指令。  10
本发明涉及电动汽车充电管理技术，旨在提供一种基于BERT的非侵入式台区充电桩状态监测与电价调整方法。该方法包括：获取变电站台区的总功率历史数据和充电桩状态历史数据，作为训练样本；搭建BERT模型，从前往后依次包括嵌入层、Transformer层和输出层；确定训练用损失函数；使用梯度下降算法训练BERT模型；将变电站台区中智能电表的历史总功率数据输入到训练好的BERT模型中，得到各充电桩的历史工作状态数据和历史充电功率数据，实现台区充电桩状态监测。本发明可直接应用在现有充电桩上，无需更新充电桩硬件设备；减少了充电桩设计和生产成本，比传统方法更加经济、高效。可以通过实时调整充电电价来引导用户改变用电习惯，有利于电网削峰填谷，提高电能利用率。基于BERT的非侵入式平台充电桩状态监测及电动汽车电价实时调整方法。降低了充电桩的设计和生产成本。 提高了电能的利用率。 用户可以通过实时调整充电价格来改变用电习惯。 电动汽车实时价格机制更加经济高效。该方法涉及获取变电站区域的总功率历史数据和充电桩状态历史数据作为训练样本。 建立BERT模型。 确定用于训练的损失函数。 随机初始化模型参数。 将训练样本传输至所述BERT模型以获得输出。 根据损失函数计算损失。 将变电站区域内某智能电表的历史总电量数据输入训练好的BERT模型中。 获取各充电桩的历史工作状态数据和历史充电功率数据，实现对台区充电桩的状态监控。 实现了对站区充电桩的状态监控。 0
本发明提供了一种基于深度学习的车牌字符分类识别方法及介质，包括S1：构建并训练基于深度学习的车牌识别模型；模型采用resnet分类网络作为基本框架，通过若干基本块堆叠构成，其中基本块包括两个分支通道相加后连接一个relu层构成，第一分支通道为1×3的卷积层、归一化层和relu层构成，第二分支通道包括3×3的卷积层、归一化层和relu层的降维通道模块和对应的升维模块构成；采集车牌图像数据对车牌进行标注后输入模型中进行训练；S2：获取定位好的待识别车牌图像，输入到车牌识别模型中，得到输出结果。本发明基于深度学习，利用分类模型实现识别功能，运算量小，便于部署，且不需要字符级坐标标注，减少人力成本。机动车车牌字符分类识别方法。基于深度学习利用分类模型实现识别功能。 字符的计算量变小。 可以以较低的人力成本，且不需要字符级坐标标注的方式实现字符识别。该方法涉及构建并训练基于深度学习的车牌识别模型。 所述车牌识别模型是采用分类网络作为基本框架，由若干个基本块叠加而成。 每个基本块包括两个分支通道，所述两个分支通道相加后与relu层连接。 采集车牌图像数据，构建训练集。 对所述训练集中的图像数据进行车牌号标注，得到有标注训练集。 将标记后的训练集输入车牌识别模型进行训练。 获取定位后的待识别车牌图像，将所述车牌图像输入所述车牌识别模型，得到输出结果。包括一个独立权利要求，用于存储实现所述车牌字符分类识别方法的程序的计算机可读存储介质。 13
本发明公开了一种基于BERT的中文关系抽取方法及系统，包括以下步骤，处理模块下载中文语料并进行处理，得到词序列；深度学习模块构建神经网络模型；训练模块对所述神经网络模型进行训练；使用训练后的神经网络模型进行关系抽取。本发明的有益效果：使用本发明提供的关系抽取方法，不需要构建特征工程，能够有效地减少噪声的影响，提高抽取的准确性，最终得到较高质量的特征，并提高关系抽取的性能。基于BERT的自然语言处理汉语关系抽取方法 也可用于从海量非结构化文本中提取有意义的信息。该关系抽取方法不需要构建特征工程，能够有效降低噪声的影响，提高抽取的准确性，最终得到更高质量的特征，提高关系抽取的性能。该方法包括通过处理模块(100)下载和处理中文语言学数据以获得单词序列。 通过深度学习模块(200)构建神经网络模型。 通过训练模块(300)对神经网络模型进行训练，并利用训练后的神经网络模型进行关系提取。 所述中文语料包括搜国新闻语料重量百分比、公开可下载内容重量百分比。 通过使用LTP-CONN来分析句子，以获得最短依赖路径、语音标签的部分、实体的类别和语法关系。 使用双向编码器表示从变换器(BERT)模型、双向长短期记忆(BILSTM)模型、卷积神经网络(CNN)层、MAX-posing层和softmax层，并且由BERT模型提取语句的词向量。对于基于BERT的中国关系抽取系统，包括独立权利要求。  12
本发明公开了一种商机转化概率的预测方法、装置及计算机可读存储介质，所述方法包括：获取至少一个商机数据；对所述每个商机数据进行数据处理，得到每个商机数据对应的概率预测数据；将每个商机数据对应的概率预测数据输入至商机转化概率预测模型中，得到每个商机数据对应的商机转化概率，其中，所述商机转化概率用于表征商机数据对应客户的成交概率，且所述商机转化概率预测模型包括BERT网络以及文本分类输出层；本发明避免了传统经验判断所存在的判断不准确的问题，同时，销售人员也可根据预估出的成交概率，来优先拜访成交概率高的客户，从而避免无效拜访，不仅可提升销售人员的工作效率以及业绩，还可提高公司的整体营收。一种业务机会转换概率预测方法。本发明能够准确地进行预测操作，使销售人员根据估计的交易概率优先访问交易概率高的客户，避免无效访问，提高工作效率，提高销售人员的绩效，增加公司的收入。所述方法涉及获取商务机会数据(S1)，其中所述商务机会数据具有访问记录。 在商业机会数据中执行(S2)数据处理操作。 获得与所述商业机会数据相对应的概率预测数据。 将概率预测数据输入(S3)到商业机会转换概率预测模型中。 文本分类输出层根据用于输出概率预测数据的特征信息执行分类预测操作。独立的权利要求书包括： (1)业务机会转换概率预测装置； (2)计算机可读存储介质，用于存储用于执行商业机会转换概率预测操作的一组指令。  11
本申请涉及一种肿瘤自动分割系统、方法及电子设备。包括：步骤a：获取肿瘤部位的原始图像；步骤b：对所述原始图像进行剪裁处理，保留图像的非零区域，分析图像并获取间距、强度分布和形状数据；步骤c：结合U‑Net网络、注意力机制及双阶段级联架构构建MILU‑Net网络模型，所述MILU‑Net网络模型包括最小化信息损失模块、注意力机制模块和双阶段级联架构模块；步骤d：将所述间距、强度分布和形状数据输入MILU‑Net网络模型，得到肿瘤分割结果。本申请通过结合多种分割网络特性的网络架构的特点，取长补短，改善现有的单调网络框架，提高了模型的泛化性能和分割精度，同时也提高了训练效率。用于通过使用电子设备自动肿瘤分割的方法(要求保护)。该方法将网络架构的特点与多个分割网络特征相结合，取长补短，提高了单调网络框架、模型的泛化性能和分割精度以及训练效率。一种肿瘤自动分割方法，包括以下步骤：(i)获取肿瘤部位的原始图像; (ii)裁剪原始图像，保留图像的非零区域，分析图像，获得图像的间距、强度分布和形状数据; (iii)结合UNet网络、注意力机制和两级级联架构，构建MILU-Net网络模型，所述MILU-Net网络模型包括最小信息损失模块、注意力机制模块和两级级联架构模块； (iv)将距离、强度分布和形状数据输入米伦特网络模型，得到肿瘤分割结果。本发明还涉及一种用于自动肿瘤分割方法的系统。  7
本发明提供了一种对话摘要生成方法及系统，属于自然语言处理中的自动摘要领域。为了解决现有摘要生成方法难以聚焦对话中的关键信息，引入过多对话中的无用信息等问题，本发明所提供方法包括：对话预处理；将对话语料转变为对话文本序列；提取对话多粒度语义特征；构建多特征融合过滤模块来过滤对话；基于预训练语言模型BART和分层Transformer模型生成摘要；根据摘要生成器的输出，利用beam search算法搜索得到最佳的对话摘要。本发明能够根据关键词、主题、语句和对话全文过滤对话中的无用信息，并通过分层Transformer将关键词信息融入到摘要的生成过程中，使得生成的摘要包含更多的重要信息。用于为诸如民审中的法庭辩论、客户服务与用户之间的服务会话以及多个参与者的电话会议等场景生成对话摘要的方法。该方法能够根据关键词、主题、句子和会话全文过滤会话中的无用信息，并将关键词信息分层融合到摘要生成过程中，使得生成的摘要包含更重要的信息。该方法包括预处理对话。 对所述会话中的噪音词进行处理。 将会话转换为文本序列的形式。 获取会话上下文表达式。 将预处理后的会话文本序列编码为词向量表达式。 提取多粒度语义特征。 采用无监督的方法提取对话中的语义特征。 根据所述对话和所述多特征融合过滤后的关键词信息生成对话摘要。包括对话摘要生成系统的独立权利要求。 8
本发明公开了一种基于大语言模型的表单生成方法、装置、设备及介质，涉及表单生成技术领域。所述方法是在获取用户对期望表单的文本描述信息后，将该信息输入已完成预训练的且能够根据输入内容选择表单生成调用接口和/或为已选定的表单生成调用接口选择接口入参的大语言模型，以便选定用于生成期望表单的接口和/或接口入参，然后针对各个已选定接口，检查对应的且已选定的接口入参是否完整且正确，如否，则提醒用户补充或纠正，最后在各个已选定接口的接口入参均完整且正确时，触发调用已选定接口来生成期望表单，并将生成结果返回用户，如此不但可提升在表单生成过程中的灵活性及易用性，还可大大降低使用难度及学习成本，进而提升用户体验。用于表单生成领域的基于大型语言模型的表单生成方法。触发选择的界面生成期望表单，并将生成的结果返回给用户，从而可以提高表单生成过程中的灵活性和易用性，大大降低使用难度和学习成本的同时还可以提高用户体验。 所述预先训练的大型语言模型能够根据输入内容选择调用接口并针对所选择的表单生成调用接口进行接口选择，以选择用于生成所需表单的接口和/或接口输入参数，然后针对每个所选择的接口。发明结构通过极的成功拥有从烟枪连接输出可以可用于消息数据。 将所述文本描述信息输入(S2)预先训练的大型语言模型，所述大型语言模型能够根据输入的内容选择表单生成调用界面和/或为所选择的表单生成调用界面选择界面。 进行确定(S3)以检查对应和选择的界面输入参数是否完整和正确。 向用户返回用于提醒并补充或修正相应界面输入参数的提醒信息，然后返回执行步骤，并在各选定界面的界面参数完整正确时触发(S4)调用各选定界面生成预期表单，然后执行步骤。 将生成的预期表单返回(S5)给用户。独立权利要求包括以下内容：基于大型语言模型的表单生成装置； 计算机装置； 以及计算机可读存储介质，其存储基于大型语言模型的表单生成程序。  11
本发明提供了一种大语言模型私有化训练和部署方法及系统，包括步骤S1：下载并加载预训练的大语言模型作为基础模型，进行私有化训练和部署；步骤S2：对所述基础模型进行问题匹配或微调；所述微调包括全参数微调和基于Lora的部分参数微调；步骤S3：将经过调整后的模型进行部署，得到用于回答用户问题的私有化模型。本发明提供的方法及系统通过租用其他用户的GPU来实现分布式训练，大大减少了数据的运算量，提高了效率；降低了使用大语言模型的标准，能够广泛地应用于自然语言处理领域中。用于客服、电商、金融、教育、医疗、法律、旅游酒店和自然语言处理等领域的大型语言模型的私有化训练和部署方法。本发明通过租用其他用户的图形处理器(GPU)实现分布式训练，大大减少了数据的运算量，提高了效率。 该方法降低了使用大型语言模型的标准。该方法涉及下载并加载预先训练好的大型语言模型，作为私有化训练和部署的基本模型。 对所述基本模型进行问题匹配或微调。 微调包括全参数微调和基于远程(Lora)的部分参数微调(RTM：源于线性调频扩频(CSS)技术的无线调制技术)。 当使用基于问题匹配的解决方案时，使用向量数据库进行匹配。 将匹配结果提供给大型语言模型以回答用户问题。 当使用基于微调的解决方案时，部署调整后的模型以获得用于回答用户问题的私有化模型。独立权利要求包括用于大型语言模型的私有化训练和部署系统。  11
本发明公开了一种基于自适应不确定性正则化的情感分类持续学习方法。该方法包括：预训练用于情感分类的BERT模型，该模型包括多头注意层和完全连通层；在学习新任务时，利用贝叶斯在线学习不确定性正则化方法来控制所述BERT模型中多头注意层和完全连通层的线性变换中每个权重参数的更新。本发明在保证BERT情感分类任务性能的情况下，同时避免了BERT模型在持续学习过程中对先前的知识发生灾难性遗忘的情况。一种基于自适应不确定性正则化的情感分类连续学习方法。本发明能够保证BERT情感分类任务的性能。该方法包括预训练用于情感分类的来自变压器(BERT)模型的双向编码器表示。 BERT模型具有多头注意层和完全连接层。 贝叶斯在线学习不确定性正则化过程用于在学习新任务时控制BERT模型中多头注意力层与完全连接层线性变换中权重参数的更新。 每个元素从所选标量的正态分布中选择。 确定平均权重矩阵和方差项。本发明涉及一种计算机可读存储介质，用于存储用于基于自适应不确定性规则化实现情感分类的连续学习的指令； 以及一种计算机设备，包括存储器和处理器，用于基于自适应不确定性规则化实现情感分类的连续学习。  12
本发明公开了一种基于提示学习的自监督视觉模型的知识迁移方法，包括：将训练数据集中所有图像输入自监督视觉模型的对比分支中，计算不同类别的类中心向量；从训练数据集中随机抽取一张图像作为查询图像，并将该查询图像输入自监督视觉模型的查询分支中，获得特征向量；计算该查询图像的特征向量与不同类别的类中心向量之间的相似度，预测类别结果；通过多实例‑原型对比损失函数遍历训练数据集所有图像计算损失，通过反向传播算法对模型参数微调，将模型中的知识进行迁移并适用于下游任务。本发明使用提示学习重构下游任务，缓解了上下游任务间的目标差异对于预训练模型迁移性能的影响，同时引入更少可学习参数，实现性能和训练成本之间平衡。应用于深度学习技术领域的基于即时学习的自监督视觉模型知识迁移方法。该方法采用快速学习的方式重建下游任务，缓解了上下游任务目标差异对预训练模型迁移性能的影响，引入的可学习参数较少，实现了性能和训练成本的平衡。该方法包括读取训练数据集中的图像和对应的类别标签，加载预先训练好的自监督视觉模型，该模型包括比对分支和查询分支。 将训练数据集中的图像输入到加载的自监督视觉模型的比较分支中，根据类别标签计算不同类别的类别中心向量作为视觉提示。 通过多实例-原型对比度损失函数遍历训练数据集中的图像计算损失，并通过反向传播算法对加载的自监督视觉模型的参数进行微调。 从自监督视觉模型中转移知识，并将其应用于下游任务。 多实例-原型对比度损失函数是一种改进的交叉熵对比度损失函数，其改进之处在于增强了同类型样本的特征相似性，适合下游任务。 14
本发明公开了一种融合Transformer和U‑net网络的语音增强方法，包括如下步骤：S1，采集原始的干净语音数据集和带噪语音数据集，并将采集的数据集分为训练集、验证集和测试集；S2，构建融合Transformer和U‑net网络的语音增强模型；S3，使用步骤S1中的训练集和验证集对步骤S2中构建的语音增强模型进行训练；S4，将步骤S1中的测试集作为待增强的语音信号输入训练好的语音增强模型，输出干净的语音信号。本发明在U‑net网络中加入了Transformer模块，有效提取局部和全局的上下文特征信息；同时使用时域损失、时频域损失和感知损失三类损失函数一起训练语音增强网络，从而获得更高的语音可懂度和感知质量。一种融合和U-net网络的语音增强方法，用于学术界和工业界，也可用于深度神经网络、递归神经网络(RNN)、卷积神经网络模块(CNN)、U-net神经网络和神经网络。该方法使得在U-net网络中加入该模块，从而利用时域损失、时频域损失和感知损失三种损失函数训练语音增强网络，同时有效提取局部和全局上下文特征信息，从而获得更高的语音可懂度和感知质量。该方法包括收集原始的干净语音数据集和无噪声语音数据集。 将采集到的数据集分为训练集、验证集和测试集。 构建融合和U-net网络的语音增强模型。 所述训练集和所述验证集用于训练所述语音增强模型。 将所述测试集作为待增强语音信号输入训练语音增强模型。 输出干净的语音信号。 3
本发明提供了一种基于预训练模型T5的编程问答帖子标题自动补全方法，属于计算机技术领域，解决了开发人员不能很好的总结提炼问题帖标题，导致标题质量低而不能及时得到有效回复的问题。其技术方案为：包括以下步骤：(1)搜集高质量问题贴；(2)语料库的构建及预处理；(3)标题补全模型的构建；(4)标题补全模型的应用。本发明的有益效果为：减少开发人员编写标题时所需的时间和精力，帮助他们编写更高质量的标题。基于预训练模型的编程问答帖题目自动补充方法，用于计算机技术领域。该方法减少了开发人员撰写标题的时间和精力，有助于他们撰写质量更高的标题。 基于预训练模型T5的编程问答帖自动补充题目的方法，属于计算机技术领域，它解决了开发人员不能很好的对问题帖题目进行总结和细化使得题目质量较低，不能及时得到有效回复的问题。该方法涉及使用编程语言标签从堆栈溢出收集相关问题粘贴。 设计了四个启发式规则来过滤低质量问题粘贴。 从问帖中提取有效信息，形成问题标题、问题描述、代码段和三元组。 形成初始语料库。 对每个实例的完整标题执行变体操作，其中在每个变体的末尾屏蔽不同数量的单词以形成缺陷标题。 通过连接不完整标题和帖子内容，即问题描述和代码段，对多模式输入进行建模。 通过分析开发人员提供的问题帖的内容和提示信息，在开发人员编辑问题题目时向已训练的模型提供完整的补充建议。  11
本公开的实施例公开了用于处理文本的方法、装置、电子设备和介质。该方法的一具体实施方式包括：获取待处理文本；将该待处理文本输入预设的文本向量提取模型，生成与该待处理文本对应的隐向量，其中，该预设的文本向量提取模型中包括预训练文本编码模型和预先训练的编码器；基于该隐向量对该待处理文本进行处理，生成处理结果。该实施方式实现了在减少有监督训练所需标注样本的基础上提高文本向量的表征效果，进而提高应用文本向量的文本处理任务的质量。一种用于处理文本的方法，用于计算机技术领域。本发明在减少监督训练所需的标记样本的基础上，提高了文本向量的表示效果，从而提高了应用文本向量的文本处理任务的质量。该方法(200)包括获取(201)要处理的文本。 将待处理文本输入(202)到预设的文本向量提取模型中，以生成与待处理文本相对应的隐藏向量。 预置文本矢量提取模型具有预训练文本编码模型和预训练编码器。 基于隐藏向量来处理(203)要处理的文本，以生成处理结果。 将待处理文本输入预训练文本编码模型，生成与待处理文本对应的初始文本向量。 初始文本向量被输入到预训练编码器，以生成对应于初始文本向量的隐藏向量。独立的权利要求书被包括在以下内容中： (1)用于处理文本的设备； (2)用于处理文本的电子设备； 以及 (3)存储用于处理文本的程序的计算机可读介质。  12
本发明公开了一种基于Bert的意图确定方法，应用于目标Bert模型，所述目标Bert模型是将Bert模型中的全连接隐藏层替换为非全连接隐藏层，包括：确定输入语句中的mask向量，将所述mask向量作为预测目标；基于所述非全连接隐藏层，获得所述预测目标对应的目标向量；对所述目标向量进行多意图识别，确定所述输入语句的目标意图。上述的确定方法中，所述目标Bert模型中将Bert模型中的全连接隐藏层替换为非全连接隐藏层，全连接隐藏层会令计算量成倍的增加，而非全连接隐藏层降低了模型的结构复杂度，需要更少的计算时间，因此，减少了基于Bert模型进行意图预测的时间开销。该方法对于确定基于Bert的意图是有用的。该方法：降低了模型的结构复杂度； 所需计算时间较少； 并且降低了基于Bert模型进行意图预测的时间开销。确定基于来自变换器的双向编码器表示(Bert)的意图包括应用于所述目标Bert模型，用非完全连接的隐藏层替换所述Bert模型中由目标Bert模型所述完全连接的隐藏层包括确定所述输入句子中的所述掩码向量，将所述掩码向量作为所述预测目标，基于所述非完全连接的隐藏层获得对应于所述预测目标的目标向量，以及对所述目标向量执行多意图识别以确定所述输入句子的目标意图，为所述预测目标提供备选答案， 以及当所述输入句子是单句时，删除所述Bert模型中针对句子级别特征提出的分类方法。独立权利要求还包括：一种基于Bert的意图确定装置； 存储介质，包括用于确定基于Bert的意图的指令集； 以及处理器。  12
本发明公开了一种全尺度连接的深度学习相位展开方法，包括创建InSAR模拟数据集；将S1创建好的两种数据放入全尺度连接的深度学习中进行训练；将待解缠相位图像放入已训练好的全尺度连接的深度学习中得出解缠出的真实相位图像。本发明以U‑Net3+为骨架，实现从缠绕相位到真实相位的直接映射。在编码模块与解码模块之间利用全尺度跳跃连接把编码模块中不同尺度的特征图与解码模块中携带高级语义信息的特征图有机的结合在一起；在编码层和解码层添加残差网络，防止因网络层数过深带来的梯度弥散和网络退化问题；完成训练后的网络能有效解缠不同类型干涉图，不需要进行任何后处理。实验结果表明本文网络具有很好的泛化能力以及较高的解缠效率。一种全尺度连通深度学习阶段的解包方法。该方法通过在编码层和解码层增加剩余网络，避免了由于网络层过深而导致的梯度色散和网络退化的问题； 不需要进行后处理就能有效地展开不同类型的干涉图； 提高了网络的通用化能力和解捻效率。该方法包括创建干扰模式数据集。 得到实相图和相绕组。 将生成的两种数据加入深度学习模型全量表中，进行训练连接。 训练后得到体重。 将待解卷的相位图像加入到相连的深度学习模型全尺度中，得到解卷后的真实相位图像。   6
本发明实施例涉及文本纠错技术领域，公开了一种文本纠错方法、电子设备及存储介质。通过线下生成的纠错词典对待纠错语句进行识别，确定语句中是否存在纠错词典中的混淆词；当待纠错语句中包含混淆词，则将该混淆词替换为纠错词典中与该混淆词对应的纠正词，并通过长短时记忆LSTM语言模型计算混淆词替换前后的该语句对应的困惑度值；最后，根据混淆词替换前后的语句对应的困惑度值，确定是否将语句中的混淆词纠正为对应的纠正词，并执行相应操作。本方案中，通过在线下预先构建纠错词典，在线上通过该纠错词典以及轻量级的长短时记忆LSTM语言模型进行词语纠错，可以在线上保证低时延前提下，获得更好的纠错准确率。文本纠错方法。该方法能够在线路下预先构建纠错字典，在线上通过纠错字典和轻量级长度记忆LSTM语言模型进行单词纠错，保证线路上的低时延，获得较好的纠错精度。该方法包括识别要校正的句子。 判断所述语句中的纠错词典中是否存在混淆词，所述纠错词典包括多个混淆词和与所述混淆词对应的校正词。 计算与用LSTM语言模型替换混淆词之前和之后的句子相对应的混淆度值。 根据混淆词替换前后的句子对应的混淆度值，判断是否将句子中的混淆词校正为用于执行相应操作的相应校正词。针对以下内容包括独立权利要求：一种电子设备，其包括用于执行用于执行文本纠错的指令集的存储器和处理器； 以及计算机可读存储介质，用于存储用于执行文本纠错的指令集。  11
一种提高大型语言模型适配多模态任务效率的方法，属于高效视觉语言指令调优领域。1)引入模态标记指示输入模态；2)定义混合模态适配器；3)基于混合模态适配器进行混合模态训练，利用ScienceQA执行多模态科学问答任务，利用Alphaca‑52k和LLaVA‑158k两个数据集执行多模态对话任务；4)将视觉特征转化为与大型语言模型输入特征的相同维度；5)定义大型语言模型的输入；6)大型语言模型预测下一个词。减少将多模态能力拓展到大型语言模型所需的训练时间和参数量且获得与之前该领域最好方法相当的精度，该大型视觉语言指令模型具有成为通用聊天机器人的巨大潜能。增强大型语言模型适配多模式任务效率的方法。该方法能够减少向大型语言模型扩展多模态能力所需的训练时间和参数量，并获得精度等值。该方法涉及获得混合模态适配器。 输入特性在实践中由基于模态标记的混合模态适配器动态地调整。 基于混合模态适配器进行混合模态训练。 调整插入的适配器的参数。 视觉特性被转换成与大型语言模型的输入特性相同的维度。 获得所述大型语言模型的输入。 Science-QA用于执行多模式科学问答任务。 通过使用两个数据集Alphaca-52k和LLaVA-158k来执行多模式对话任务。  11
本发明提出了一种多神经网络协作的军事领域命名实体识别方法，包括以下步骤：步骤A：获取公开的微博数据，形成原始数据集；步骤B：结合领域知识，提出考虑实体模糊边界的军事领域实体标注策略，制定军事领域命名实体分类标准；步骤C：针对原始数据集进行文本预处理，结合步骤B实体标注策略及实体分类标准构建军事语料集MilitaryCorpus；步骤D：利用深度学习和统计学习的框架，训练了基于BERT‑BiLSTM‑CRF网络结构的多神经网络协作军事领域命名实体识别模型，以进行针对微博为代表的中文社交文本的军事领域命名实体识别任务。多神经网络协作的军事领域命名实体识别方法。多神经网络协同军事实体识别方法结合人物特征、句子特征、位置特征生成词向量并使用变换器训练词向量。 充分考虑了上下文信息对实体的影响。 解决了结合词级特征向量只考虑词的特征而忽略结合上下文的实体识别的缺点。 该方法取得了更高的有效性和更好的识别效果。该方法包括获取发布的文本数据以形成原始数据集。 结合领域知识，提出考虑实体模糊边界的军事领域实体标注策略并制定军事领域命名实体分类标准。 对所述原始数据集进行文本预处理。 将实体标签化策略和实体分类标准相结合，构建军事语料MilitaryCorpus。 提供深度学习和统计学习的框架，训练基于变压器的双向编码器结合双向长短期记忆神经网络和条件随机场(BERT-BiLSTMCRF)网络结构的命名实体识别模型，用于军事领域的多神经网络协作，对文本数据执行军事领域的命名实体识别任务。  12
本发明提供了一种正交化低秩适应矩阵的语音检测模型的训练方法及装置，具体涉及语音识别技术领域，通过获取新训练数据集；加载预训练语音大模型并冻结其参数，引入第一低秩适应矩阵和第二低秩适应矩阵，得到待训练语音检测模型；将新训练数据集输入至待训练语音检测模型中，通过正交优化第一低秩适应矩阵和第二低秩适应矩阵的参数，结束训练，得到语音检测模型。针对实际获取的新数据集，使用上述训练方法对语音检测模型进行训练，引入低秩适应矩阵，对模型进行微调，不仅可以显著降低训练成本，还可以极大的提高模型对新数据集下生成音频的检测能力，同时几乎不影响模型对先前已学习的语音算法的检测能力。正交化低秩自适应矩阵的语音检测模型的训练方法。该方法能够以成本有效的方式训练正交化低秩自适应矩阵的语音检测模型。 该方法提高了模型在新数据集下产生音频的检测能力，并且避免了模型对之前学习的语音算法的影响，因此降低了语音识别系统的训练成本。所述方法包括：获得(101)新的训练数据集，所述新的训练数据集包括通过采用预训练语音大模型未知的生成算法生成的多个语音。 加载(102)所述预训练语音大模型，并冻结所述预训练语音大模型的参数，引入第一低秩自适应矩阵和第二低秩自适应矩阵，得到待训练语音检测模型。 将新的训练数据集输入(103)待训练的语音检测模型，通过正交优化第一低秩自适应矩阵和第二低秩自适应矩阵的参数完成训练，得到语音检测模型。 所述第一低秩自适应矩阵和所述第二低秩自适应矩阵在每个独立的数据集上训练，并且从学习的训练数据集中学习的知识被遗忘。独立权利要求书包括如下：一种正交化低秩自适应矩阵的语音检测模型的训练装置； 电子装置； 以及存储有用于语音检测模型的训练方法的计算机程序的计算机可读存储介质。 3
本发明提供一种虚拟人脸图像生成方法、装置及电子设备，可以获得随机噪声和目标风格类型的真实人脸图像；对随机噪声进行类型化人脸特征映射，获得目标风格类型的虚拟人脸特征数据；对真实人脸图像进行特征提取，获得真实人脸特征数据；对虚拟人脸特征数据和真实人脸特征数据进行混合处理，获得混合数据；将混合数据输入至训练好的虚拟人脸生成器，获得虚拟人脸生成器生成的目标风格类型的虚拟人脸图像；其中，虚拟人脸生成器是通过使用第一随机噪声和第一风格类型的真实人脸图像，对预训练模型进行训练获得的。本发明可以有效提高目标风格类型的虚拟人脸图像的图像成品率。生成虚拟人脸图像的方法。该方法解决了现有技术生成的虚拟人脸图像的图像成品率低的缺陷。 有效提高了目标风格类型的虚拟人脸图像的图像良率。该方法涉及获得(S101)随机噪声和目标风格类型的真实人脸图像。 对所述随机噪声进行类型化人脸特征映射(S102)，得到所述目标风格类型的虚拟人脸特征数据。 对所述真实人脸图像进行特征提取(S103)，得到真实人脸特征数据。 对所述虚拟人脸特征数据和所述真实人脸特征数据进行混合处理(S104)，得到混合数据。 将混合数据输入(S105)至训练好的虚拟人脸生成器，以获得由虚拟人脸生成器生成的目标风格类型的虚拟人脸图像。 所述虚拟人脸生成器是利用随机噪声和一种风格的真实人脸图像对所述预训练模型进行训练得到的。包括独立权利要求：(1)虚拟面部图像生成装置； 以及(2)电子设备。 2
本公开提供了一种内容排版方法、装置及电子设备，涉及人工智能技术领域，具体为大模型、智能排版、大数据等技术领域。具体实现方案为：基于N个排版方式对目标内容进行排版，得到所述目标内容的N个排版，N为大于1的整数；向用户发送所述N个排版，并获取所述N个排版中每个排版的用户交互数据；根据所述用户交互数据，计算所述N个排版中每个排版的交互指数评分；在所述N个排版中确定所述交互指数评分满足预设筛选条件的目标排版，并输出所述目标排版。本公开提高了用户与目标内容的交互程度。用于人工智能领域的内容排版方法。该方法能够基于交互指标分值确定满足预设筛选条件的目标排版，使得用户提供更多的浏览目标内容的欲望，提高了用户与目标内容的交互度。该方法包括基于N个排版方式对目标内容进行排版，得到一个目标内容的N个排版，其中，N为大于1的整数。 将所述N个排版发送给用户。 获取所述N个排版中每个排版的用户交互数据。 根据所述用户交互数据计算所述N次排版中每一次排版的交互指标得分。 确定所述N次排版中交互性指标分值满足预设筛选条件的目标排版。 输出目标排版。 在所述N个子用户群组中的每个子用户群组处，将排版对应一个子用户群组发送给所述子用户群组中的第一目标用户。所述用户交互数据包括浏览时长数据、点击数据、评论数据和分享数据中的一种。 包括独立权利要求，用于：(1)内容排版装置； (2)用于对内容进行排版的电子设备； (3)包括用于排版内容的一组指令的计算机程序产品。  11
本发明公开了一种基于大模型构建企业领域知识库的方法，包括以下步骤：准备初始提示词，作为冷启动的初始样本；将待识别文本输入到动态提示词层，根据相似度计算和召回结果选择提示样本，并构建问题‑回答形式的提示样本；将提示样本和待识别文本输入到推理层，综合利用复原相似度和实体召回率计算评估值；如果评估值超过设定阈值，则认为该三元组识别正确，并更新提示准确率；如果评估值小于等于设定阈值，则重新触发动态提示词层挑选新的提示样本，重新执行完整流程；将成功识别的三元组用于知识图谱的构建。可以在不对LLM重新训练微调的情况下，引入自反馈与长短期记忆机制使得LLM较为容易迁移到新的垂直场景。基于大模型的企业领域知识库构建方法。该方法实现了自反馈和引入的长期和短期记忆机制，使得知识图谱(LLM)变得更加容易，从而实现垂直场景，而不需要对LLM进行重新训练。该方法包括将初始提示词确定为冷启动的初始样本。 将待识别文本输入至动态提示词层。 根据相似度计算和召回结果选择提示样本。 构建问答形式的提示样本。 实体关系三元组通过大型语言模型识别。 通过恢复相似度和实体召回率计算评估值。 重新触发动态提示词层选择目标提示样本。 当所述评估值超过预设阈值时，重新执行完整流程。 通过识别出的三元组构建知识图谱。  11
本发明公开一种基于边缘感知网络的腺体细胞图像分割方法及装置。本发明提出了一种边缘感知模块以及引入空间金字塔池化模块。以U‑Net网络为主干网络，在编码端最后一层特征提取时引入空洞金字塔池化模块，实现多尺度腺体信息的融合。并在主干网络的解码端设计了边缘感知模块，在单个训练流水线中解开边缘和纹理信息，通过主干网络和边缘感知模块的输出来共同学习语义和边界，解决了分割边界模糊以及锯齿状的问题，且提高了分割精度。改方法易于实现，数据预处理操作简单，具有更好的鲁棒性和准确率。一种基于边缘感知网络的腺细胞图像分割方法。本发明能够解决边界模糊和锯齿分割问题，提高分割精度，以简单的方式实现数据预处理操作，具有较好的鲁棒性和准确性。所述方法包括获得一目了然的黑素细胞原始图像。 根据训练数据调整俯视图像元原始图像的大小。 一种基于边缘感测网络构建的粗略小区划分网络。 在边界级处理特征图的形状流。 编码层的输出端与腔锥池模块的输入端连接。 空腔金字塔池模块的输出端通过融合模块与编码层的输入端连接。 基于边缘感测网络来训练所述粗略小区划分网络。本发明还涉及一种基于边缘传感网络的腺细胞图像分割装置。   6
本发明涉及人工智能、自然语言处理，特别涉及一种基于生物医学领域预训练模型的命名实体识别方法，包括对于输入的文本的每个词汇对应预训练结果中的词表进行分词处理，通过BioBERT的Embedding层赋予初始权重；对于超过max_batch_size的句子进行截断；连接所有的句子对，对于句首使用[CLS]标签，句尾使用[SEP]标签；通过在PubMed和PMC文本下预训练完成的BioBERT模型进行第一特征提取；将BioBERT结构的输出再次通过BiLSTM网络模型进行第二特征提取；使用CRF网络对第二特征提取得到的特征进行识别；本发明能够更精确识别生物医学领域预的实体。基于生物医学领域的识别训练模型的命名实体，例如生物医学文本中的基因，疾病，蛋白质和其它生物医学实体。本发明能够更准确地识别生物医学领域中的前体。该模型具有用于对与预训练结果中的词表相对应的输入文本的每个词汇进行词处理的预训练结果。 初始重量由生物惰性包埋层给出。 当句子超过超过最大尺寸的句子时，该句子被截断。 所述句子对是连接的。 第一特征由生物惰性模型提取。 BIOBERT结构的输出再次由双向长期短期存储器(BILSTM)网络模型提取。 条件随机场(CRF)网络用于识别从第二特征提取的特征。  12
本发明实施例提供一种命名实体识别方法、装置、设备及介质。该方法包括：获取第一训练数据集和第二训练数据集；对第一训练数据集进行字符级预处理、实体级预处理、短语级预处理，得到第三训练数据集，基于第一训练数据集构建句子正样本和句子负样本，得到第四训练数据集；利用第三训练数据集和第四训练数据集进行训练，得到Transformer语言模型；对第二训练数据集进行字符级预处理，得到第五训练数据集；将第五训练数据集中的文本语料数据输入到Transformer语言模型，得到标注序列，根据标注序列训练条件随机场CRF模型，得到命名实体识别模型；利用命名实体识别模型识别待识别数据，得到命名实体识别结果。通过本发明实施例能够提高实体识别准确率。训练命名实体识别模型的方法，所述命名实体识别模型用于识别目标领域的文本语言学数据的命名实体。该方法能够提高实体识别的准确性。 命名实体识别模型具有更强的特征提取能力、语法和语义表示能力，从而有效地通过上下文内容识别实体标签。所述方法包括：获取第一训练数据组和第二训练数据组，所述第一训练数据组包括领域的语言学数据文本，所述第二训练数据组包括目标领域的文本语言学数据。 对所述第一训练数据组进行字符级预处理、实体级预处理和短语级预处理，得到第三训练数据组。 基于所述第一训练数据组构建句子正样本和句子负样本，得到第四训练数据组。 利用所述第三训练数据组和所述第四训练数据组得到变压器语言模型。 对所述第二训练数据组进行字符级预处理，得到第五训练数据组。 将所述第五训练数据组中的文本语言学数据输入所述变压器语言模型，得到标签序列。根据标注序列训练条件随机场(CRF)模型，得到命名实体识别模型。 本发明还公开了一种命名实体识别方法，包括以下步骤：a)一种命名实体识别装置; b)一种命名实体识别方法; c)一种包括处理器和存储器的命名实体识别装置; d)一种用于训练用于识别目标领域的文本语言学数据的命名实体的命名实体识别模型的装置; e)一种计算机可读存储介质，包括一组用于训练用于识别目标领域的文本语言学数据的命名实体的命名实体识别模型的指令。  11
本发明实施例提供一种新意图发现方法、装置、电子设备及存储介质，该方法包括：获取当前意图识别模型的意图标注数据；利用意图标注数据训练预训练的第一语言模型，得到第二语言模型；将意图识别模型未有效实现意图识别的语料数据输入到第二语言模型，得到语料数据的句子的第一向量；通过降维处理将第一向量压缩成具有预设维数的第二向量；通过对第二向量进行聚类计算，得到聚类结果，根据聚类结果得到新意图的意图名称及对应的语料数据。本发明实施例提供的新意图发现方法、装置、电子设备及存储介质，实现了新意图识别，并实现了新意图识别时行业知识信息的融入，优化了行业内的文本表示效果，提高了新意图识别的准确性。用于在垂直行业中发现意图的方法。该方法优化了行业内文本表示的效果，提高了新意图识别的准确性。 该方法能够在发现新意图时实现行业知识信息的整合，并将语言学数据识别模型输入到第二语言模型中，而不会有效实现数据输入的目标识别。 该方法使得能够保证持续对意图标注数据训练预训练的语言模型进行训练，得到第三语言模型，从而利用第一语言模型根据行业意图和对应的训练语言数据对语言数据进行预训练。所述方法包括获取当前意图识别模型的意图标注数据，所述意图识别模型是利用所述意图标注数据训练的第一语言模型根据行业意图和对应的训练语言数据进行预训练得到的第二语言模型。 向所述第二语言模型输入语言学数据识别模型，得到所述语言学数据的第一语句向量。 通过降维处理将所述第一向量压缩为包含预设维度的第二向量。 对所述第二向量进行聚类计算，得到聚类结果。 根据聚类结果获取所述新意图的意图名称以及对应的语言学数据。包括独立权利要求：(1)一种新意图发现装置； (2)一种电子设备，包括存储器、处理器和存储在所述存储器上的计算机程序，所述计算机程序用于执行用于发现垂直行业意图的方法； (3)一种非暂时性计算机可读存储介质，其存储用于执行用于发现垂直行业中的意图的方法的计算机程序。  11
本发明提供了一种多轮问答系统意图分类和命名实体识别的研究方法。其包括以下步骤：1)在进行意图分类时，通过对话状态追踪模块，将上下文的历史信息作为输入，传入了意图分类预测模型；2)在命名实体识别预测时，将本轮的意图识别结果作为特征，传入命名实体预测模型; 3)将命名实体识别和意图分类通过一个多任务模型进行训练，并根据前两点的需要，对模型进行改进。本发明将NLU和DM直接改为双向模型，上下文信息能够提高意图分类的准确率，将命名实体识别和意图分类通过一个多任务模型Bert模型融合，可以方便进行部署。多圈问答系统意图分类及命名实体识别研究方法本发明将NLU和DM直接转化为双向模型，通过上下文信息提高意图分类的准确性，通过多任务模型BERT模型融合命名实体识别和意图分类，方便部署。该方法包括在执行意图分类时通过对话状态跟踪模块使用上下文的历史信息作为输入。 发送意图分类预测模型。 在对命名实体进行识别和预测时，以轮的意图识别结果为特征，并将其传入命名实体预测模型。 通过多任务模型训练命名实体识别和意图分类，并根据前两点的要求细化模型。 DM模块中的DST上下文数据作为BERT模型的输入之一。 融合命名实体识别模块和利用BERT多任务的意图分类模块。 8
本发明公开了一种新的基于预训练语言模型的电信工单智能判障方法，属于计算机技术领域。其中，包括如下步骤：首先先对工单信息进行预处理，从描述信息中提取出告警信息和关键描述文本，以及系统中的定位信息；使用基于预训练语言模型BERT进行文本匹配，判断工单定位与工单描述是否对应；根据文本匹配模型的结果再进行文本分类任务，使用DPCNN模型预测出定位不准确的工单可能对应的故障类别，从而实现工单的自动智能判障。本发明能够有效地解决电信业务中传统人工判障方法存在的效率和精度问题，使用深度学习方法不仅能够大大减少业务人员工作量，实现自动化解析判断，同时判断精度也非常准确，整体准确率能够达到95%以上。基于预训练语言模型的智能电信工作表故障判断方法。该方法提高了电信业务中故障判断过程的效率和准确率，减轻了业务人员的工作量，实现了自动化分析判断，判断准确率高，总体准确率可达95%以上。该方法涉及对DPCNN分类模型执行文本分类处理。 根据工单操作信息字段对上一阶段匹配结果不准确的工单进行模型计算操作。 预测相应的故障类别，并将其作为最终工单故障类别输出。 将上一阶段的判断结果自动导出为Excel文件，供业务人员下载进行最终验证。 将相应的数据加入到一个历史数据集中，不断迭代优化模型效果。  12
本公开提供一种电梯内外识别方法、装置、电子设备及存储介质。该方法包括：获取机器人拍摄的原始电梯图像，对原始电梯图像进行处理得到样本训练集，其中原始电梯图像为机器人所在位置的上方对应的电梯内部的环境图像；基于样本训练集以及预训练的指导模型，对电梯内外识别模型进行训练；将训练后的电梯内外识别模型部署到机器人中，以使机器人在采集上方环境图像后，将上方环境图像作为电梯内外识别模型的输入，利用电梯内外识别模型对机器人在电梯内外的结果进行预测，并当判断机器人在电梯内时，输出机器人对应电梯内的空间位置。本公开提高了机器人在电梯内外识别的效率和准确率，提升电梯内外识别的效果。该方法涉及获取(S101)机器人在历史任务中拍摄的原始抬起图像，并按照预定标注方式对原始抬起图像进行处理，以获得样本训练集。 对预设的电梯内外识别模型进行训练(S102)，以便基于样本训练集和预训练的引导模型更新电梯内外识别模型中的参数。 将训练好的升降机内外识别模型部署(S103)到机器人中，以使上层环境图像作为内外识别模型的输入。 利用举升机内外识别模型预测机器人在举升机内外的结果，输出机器人在举升机内部时对应举升机内部的空间位置。 14
本发明涉及自然语言理解技术领域，公开了一种基于多个大语言模型统计特征融合的生成文本检测方法，通过由统计特征融合模型和分类模型组成的检测模型，检测生成的文本的类别标签；检测模型的构建方法包括：构建基于多个大语言模型的统计特征融合模型；构建分类模型；通过计算预测类别标签和真实标签的交叉熵损失函数来训练检测模型。本发明基于多个大语言模型的统计特征融合模型有效缓解了在多种类型语言模型生成不同的文本的情况下，模型拟合能力差和缺乏鲁棒性的问题。多统计特征融合降低了检测模型的不准确性和脆弱性。基于多个大型语言模型统计特征融合的生成文本检测方法。该方法使得在多类语言模型生成不同文本的情况下，有效解决模型拟合能力差，鲁棒性不足的问题，使得多统计特征融合降低了检测模型的不准确性和脆弱性。该方法涉及构建分类模型。 所述分类模型设置有一个输入层、两个隐藏层和一个输出层。 在给定条件下测量由语言模型生成的文本的条件概率。 计算对数似然度、对数秩、熵和困惑度。 熵用于反映由语言模型生成的文本的多样性。 输入层包括四个神经元，其中每个隐藏层包括16个神经元和ReLU激活函数。 最终得到文本的分类标签概率分布。 利用交叉熵损失函数训练检测模型。  11
本发明公开了基于Transformer编码器的中文文本信息缺失的补全方法，对待处理的中文文本公开语料的人工预处理，通过计算机识别句号，将文本分割为以句为分割的大量短句语料，短句通过minibatch的方式转变为Bert词向量，产生的词向量将传入SVM进行文本二分类任务，模型将通过训练决定缺失位置的信息补全结果；采用大量遮盖[mask]标签产生的噪声，对模型进行训练，使得模型具有文本的生成能力，对文本缺失信息位置生成机器预测的缺失文本结果；本发明完成对中文文本的信息缺失的检测、信息缺失的补全任务，来帮助中文自然语言处理的文本预处理更加规范，使中文自然语言处理任务准确率进一步提高。基于变压器编码器的缺失中文文本信息补全方法。该方法完成文本中信息缺失的中文检测和信息缺失的完成是为了帮助中文自然语言处理的文本预处理更加规范，中文自然语言处理任务的准确率进一步提高。该方法涉及人工对待处理的中文文本公共语料进行预处理，形成有监督的数据进行模型训练，主要采用标注。 中文文本输入关键词的方法是针对给定的未处理的自然文本语料。 计算机识别时段，将文本分割成大量按句子划分的短句语料，然后人工判断每个句语料是否存在主题。 若存在缺失现象，则在文本末尾添加[tag]，表示需要对文本进行缺失文本信息处理。 通过优化方法对文本缺失信息预测的结果进行优化，以训练模型。 优化方法使用随机梯度下降(SGD)。 求解落入局部最优解，使得模型求解的结果逼近全局最优解，实现文本信息的补全。  12
本发明涉及一种基于CNN和LSTM的Web服务推荐方法。目前，传统的协同过滤技术在应用系统中占据很高的地位，但是还存在着数据稀疏性的问题。一种基于CNN和LSTM的Web服务推荐方法，将CNN与LSTM进行有效结合，构建深度学习模型以实现最佳的推荐结果，在计算用户偏好特征时，采用用户的历史行为这种隐式反馈信息来提取用户的偏好，使用基于BERT的语言表征模型词向量化方法对用户、API、Mashup的自然语言类属性进行训练，得到其各属性的特征矩阵，构建基于CNN和LSTM的评分预测模型，将各特征矩阵输入到评分预测模型，得到用户对Web服务的预测评分，推荐策略选取用户评分Top_3的Web服务为用户生成推荐，本发明应用于互联网领域。该方法对于推荐基于CNN和LSTM的web服务是有用的。该方法：能够有效地结合CNN和LSTM，构建深度学习模型； 在计算用户偏好特征时实现了较好的推荐结果； 利用所述用户的历史行为的隐式反馈信息提取所述用户的偏好； 获取各属性的特征矩阵； 基于CNN和LSTM构建评价预测模型； 向评价预测模型输入特征矩阵，得到预测得分； 以及用户到所述web服务，并且选择用户得分Top-3的web服务以生成针对所述用户的推荐。一种基于卷积神经网络和长短期记忆的web服务推荐方法，包括：构建深度学习模型，实现最佳推荐结果; 在计算用户偏好特征时，利用用户历史行为的隐含反馈信息提取用户偏好，得到各属性的特征矩阵; 构建基于卷积神经网络和长短期记忆的评分预测模型，将评分预测模型输入评价预测模型，得到用户对web服务的预测评分; 以及选择所述用户评分的web服务作为所述用户以生成推荐。  12
本发明公开了一种基于小样本的命名实体识别方法、装置及相关介质，该方法包括：获取样本数据，并对所述样本数据标注实体标签，以此构建第一样本集；在所述第一样本集中选取枢纽字符，并基于所述枢纽字符构建标签映射空间；利用所述标签映射空间将所述第一样本集映射为第二样本集；利用所述第二样本集对预训练语言模型进行微调；采用微调后的预训练语言模型对指定文本进行命名实体识别预测。本发明通过选取最具有代表性的枢纽字符构建标签映射空间，以对样本数据进行映射，然后利用映射得到的第二样本集对预训练语言模型进行微调，从而利用微调后的预训练语言模型进行命名实体识别预测，如此可以提高命名实体识别效率和精度。基于小样本识别命名实体的方法。该方法使得能够利用精调整后的预训练语言模型对指定文本的命名实体进行识别和预测，从而能够提高命名实体的识别效率和精度。该方法涉及获得(S101)样本数据。 为所述样本数据标注实体标签，构建第一样本集。 在第一样本组中选择铰链字符(S102)。 基于所述铰链字符构建标签映射空间。 利用标签映射空间，将第一样本组映射到第二样本组(S103)。 对预训练的语言模型进行精细调整(S104)。 利用预训练语言模型对指定文本的命名实体进行识别(S105)并进行细调整后预测。包括以下独立权利要求：一种基于小样本的命名实体识别装置； 计算机设备； 以及基于小样本的命名实体识别的计算机可读存储介质。  11
本申请实施例提出了一种基于人工智能的文本聚类方法、相关设备及存储介质，该方法包括：获取待聚类的多个文本；将待聚类的多个文本中的每个文本输入向量提取模型，以得到所述每个文本对应的输出向量，其中，所述向量提取模型是利用训练样本以及训练样本中的关键词对基于变换器的双向编码表示BERT模型进行预训练以及微调后得到的；根据词频‑逆文件频率TF‑IDF算法和所述每个文本对应的输出向量确定所述每个文本的表示向量；利用聚类算法对所述多个文本对应的多个表示向量进行聚类处理，得到至少一个类簇，可以使得文本的向量表示充分学习到文本的关键信息和上下文信息，基于该向量表示进行聚类，有助于提高文本聚类的准确度和效率。用于通过使用服务器基于人工智能对文本进行聚类的方法(权利要求书)。该方法能够提高文本聚类处理的准确性和效率。该方法包括获取多个待聚类文本。 提取待聚类文本的文本输入向量模型，得到各文本对应的输出向量。 利用训练样本和训练样本中的关键词对基于变流器双向编码的BERT模型进行预训练和微调，得到向量提取模型。 根据词频-逆文件频率算法以及所述文本对应的输出向量，确定所述文本的表示向量。 对多个表示向量进行聚类，得到聚类。独立权利要求还包括用于以下一种基于人工智能对文本进行聚类的装置； 服务器； 以及计算机可读存储介质，其存储用于基于人工智能对文本进行聚类的指令集。  12
本说明书公开了一种基于拟态结构动态防御的模型训练方法及装置。所述任务执行方法包括：获取预训练模型，将训练预训练模型所使用的第一图像输入到预训练模型中，得到第一图像对应的识别结果。根据第一图像对应的识别结果以及第一图像对应的实际标签，确定出第二图像。将第二图像输入到预训练模型中，以通过预训练模型中的权重网络层，确定预训练模型中设置的各子识别网络对应的权重，以及通过每个子识别网络，分别对第二图像进行识别，得到各识别结果，并根据确定出的各子识别网络对应的权重，对各识别结果进行加权，得到最终识别结果，以最小化最终识别结果与实际标签之间的偏差为优化目标，对预训练模型进行训练。用于图像识别、自然语言处理、语音识别等人工智能和深度学习领域的基于拟态结构动态防御的神经网络模型训练方法。神经网络模型训练的准确性是提高亟待解决的问题。 解决了神经网络模型识别对抗样本时，输出结果的准确度下降，对抗样本的种类不断增加，目前的训练方法不足以得到准确度更高的神经网络模型的问题。该方法涉及获得(S101)预训练模型。 将使用的第一图像输入(S102)训练到预训练模型中，得到第一图像对应的识别结果。 根据第一图像对应的识别结果和第一图像对应的实际标签确定(S103)第一图像对应的梯度信息。 根据与梯度信息的梯度方向对应的反向梯度方向生成干涉数据(S104)。 将所述干涉数据添加(S105)到所述第一图像中，以获得第二图像。 以最终识别结果与实际标签的偏差最小为优化目标，对预训练模型进行训练(S107)。独立权利要求书包括用于：(1)基于拟态结构动态防御的神经网络模型训练装置； (2)存储有基于拟态结构动态防御的神经网络模型训练程序的计算机可读存储介质； (3)一种电子设备。 14
本发明提供了一种基于AIGC的资讯文档收集系统，包括数据接入模块、场景标注模块、收集采纳模块、文档管理模块和交互处理模块，所述数据接入模块用于连接资讯站点并获取文本信息，所述场景标注模块用于对每份文本信息进行场景标注，所述收集采纳模块用于收集符合要求的文本信息并生成对应的文档，所述文档管理模块用于对文档进行整理理清资讯内容的发展关系，所述交互处理模块用于输入要求信息并显示收集结果；本系统能够根据需要收集网络上的资讯信息并进行整理，使用户能够更加全面地了解事件内容。基于AIGC的信息文件采集系统，用于电数字数据处理领域的网络信息采集。该系统可以根据需要收集网络上的信息并对信息进行整理，使用户更加全面的了解事件内容。该系统具有用于连接信息站的数据访问模块，并且获得文本信息。 场景标注模块，用于对所述文本信息进行场景标注。 收集收集模块，用于收集符合要求的所述文本信息，并生成对应的文档。 文本分析单元，用于对所述文本信息进行语义分析。 场景标记单元，根据语义分析结果为所述文本信息添加相应的场景标记。 所述收集收集模块包括条件匹配单元和文档生成单元。 条件匹配单元，用于对所述文本信息进行筛选匹配，选择符合要求的文本信息。 所述文档生成单元基于所选择的文本信息生成具有特殊形式的所述文档。 1
本发明提出一种面向多语言大模型的词语表示学习方法。所述方法在表示能力上能够显著高于主流的静态和动态词向量模型。本发明突破性地将单语词的向量表示改进为多点的流形表示。这种新的框架有望增加词向量空间的整体容量，更好地应对一词多义与细微上下文含义变化的场景。从流形学习与模式匹配的这一观点出发，充分利用现有的语言模型，挖掘词的空间表征能力，提高词语表示空间的完整性，使语言空间和词空间具有形式统一的表示。一种机器翻译系统非并行语言数据监督下的多语言大模型的词表达学习方法。该方法使得能够将单个词的向量表示改进为多点流形表示。 增加词向量空间的整体容量更好地应对一词多义小上下文义变化的场景，并充分利用现有语言模型挖掘词的空间表示能力，提高词表示空间的完整性，使语言空间和词空间具有统一的表示性。该方法涉及使用预先训练的大规模语言模型在单一语言材料上学习提取词的上下文表达集合。 通过参考流形学习技术，基于局部内部维度的词流形样本生成多点词表示。 得到词大小相同的词流行表示。 根据多语言词表达式提取跨语言词典。 将流行词之间的最佳匹配转换为点对点匹配。  12
一种基于深度残差收缩网络的多模态情感识别方法，属于语音情感识别方法的领域。现有的情感识别方法受到周围环境噪音的影响，在提取特征的时候由于特征冗余，存在过拟合的问题。本发明将语谱图特征送入加入注意力机制的深度残差收缩网络，去除语谱图特征的冗余特征，之后通过深度神经网络进行深层次特征处理，之后进行情感识别分类；将文本信号送入XLnet模型进行特征处理，之后经过深度神经网络进行深层次特征处理，进行文本情感识别；得到的两个结果进行决策层融合，得到情感识别结果。本发明通过提高情感分析模型预测的准确性，以及将深度残差收缩网络运用到声谱图的特征选择上，提高情感识别方法的准确性。基于深度残差收缩网络的多模态情感识别方法，用于人机交互和情感识别，是情感计算的基础。 使用包括但不限于文本，语音，面部表情，姿势姿势和其它多模态数据。提高了情感分析模型预测的准确性。 将深度残差收缩网络应用于声谱的特征选择，提高了情感识别方法的准确性。该方法包括处理语音原始信号以获得频谱。 频谱特征被传输到深度剩余收缩网络中，在深度剩余收缩网络中增加注意机制以去除频谱特征的冗余特征。 对冗余特征的谱特征进行深层特征处理。 文本信号被发送到用于特征处理过程的XLNET模型。 在完成深度神经网络特征处理过程后，进行文本情感识别处理。 对得到的结果进行决策层融合处理，得到情感识别结果。 3
本发明公开了一种脑肿瘤图像分割方法、系统及计算机可读存储介质，所述脑肿瘤图像分割方法包括：获取脑肿瘤图像，并对所述脑肿瘤图像进行预处理，得到预处理图像；构建基于分阶段式残差结构的U‑Net3+网络模型；其中，所述U‑Net3+网络模型使用FRN标准化层；输入所述预处理图像至所述U‑Net3+网络模型中进行训练，得到脑肿瘤分割图像。本发明能够较准确地提取脑肿瘤图像中的特征，有效提高了脑肿瘤图像的分割精度。一种通过使用计算机可读存储介质来分割脑瘤图像的方法。本发明能够准确提取脑肿瘤图像的特征，从而有效提高脑肿瘤图像的分割精度。该方法包括获得脑肿瘤图像。 对脑肿瘤图像进行预处理以获得预处理图像。 基于分数段残差结构构建u-Ne3+网络模型。 U-Ne3+网络模型由FRN标准层构成。 预处理后的图像输入U-Ne3+网络模型进行训练，得到脑肿瘤分割图像。 预处理后的图像被分成多个子图像。 子图像被划分为多个子图像。本发明还涉及一种脑肿瘤图像分割系统。 以及计算机可读存储介质。  7
一种基于深度网络学习的颅神经自动成像方法，该方法是利用深度学习的方法，将标记好的数据作为深度学习的数据集，使用在传统的卷积神经网络模型基础上进行修改的U‑net网络模型，在解剖像中自动分割颅神经区域。能够解决迂曲纤细的颅神经对感兴趣区域人为依赖性问题，并为纤维跟踪提供解剖先验知识。以深度学习分割得到的颅神经区域作为感兴趣区域(ROI)，将多个相邻体素中纤维矢量元素的方向信息进行整合，进行纤维跟踪，最后基于解剖结构约束，筛选纤维跟踪后符合条件的纤维束，保留颅神经区域内的纤维，将错误、无效的纤维束剔除。本发明能够精准显示颅神经与病灶之间的位置关系。基于深度网络学习的脑神经自动成像方法。该方法准确显示了脑神经与病灶的位置关系。基于深度网络学习的颅神经自动成像包括：(1)在解剖图像中自动划分颅神经区域，解决迂曲纤细的颅神经对感兴趣区域的人为依赖，为纤维追踪提供解剖学先验知识； (2)将深度学习分割出的脑神经区域作为纤维跟踪的兴趣区域池化(ROI)进行纤维跟踪，综合多个相邻体素中纤维矢量元素的方向信息，得到纤维路径; (3)基于解剖结构约束对光纤进行解剖结构约束跟踪筛选，在光纤跟踪后筛选出满足条件的光纤束，剔除错误和无效的光纤束。   4
本申请提供了一种推荐理由生成模型的优化方法及装置。该方法包括：确定用户特征和商品特征；将用户特征和商品特征输入至推荐理由生成模型以输出推荐理由；确定用户对推荐理由的反馈类型；根据反馈类型实时调整推荐理由生成模型的模型参数，以对推荐理由生成模型进行优化。本申请结合大语言模型的优势生成推荐理由，并基于海量的文本数据进行训练优化，对推荐理由的生成有更高的准确性，且无需人工维护推荐理由库，降低推荐理由库的运维成本，结合用户的历史行为和推荐内容的特点进行推荐理由的生成，具有更高的可解释性，可以增加用户对推荐系统的信任度和透明度，提升用户体验和忠诚度。用于通过电子设备优化推荐原因生成模型的方法(请求保护)。该方法能够基于海量文本数据进行训练和优化，提高推荐理由生成和维护推荐理由库的准确性，降低推荐理由库的运维成本。该方法涉及确定(S201)用户特征和商品特征。 将用户特性和商品特性输入到推荐理由生成模型(S202)，输出推荐理由。 确定所述用户对所述推荐理由的反馈类型(S203)。 根据所述反馈类型实时调整所述推荐理由生成模型的模型参数(S204)，以优化所述推荐理由生成模型。 基于数据库中的标签数据确定用户属性和商品属性。 根据所述用户属性确定用户特征。 根据所述商品属性确定商品特征。还包括独立权利要求，用于：实现电子设备对推荐理由生成模型的优化的装置; 以及包括实现电子设备对推荐理由生成模型的优化的指令集的计算机可读存储介质。  11
本发明涉及数据可视化技术领域，具体为基于AI大语言模型的数据大屏生成方法及系统，包括以下步骤：基于行业源数据，采用数据清洗和数据标准化算法，结合BERT模型进行数据解析，生成结构化数据集；基于所述结构化数据集，利用数据绑定技术提取数据。本发明中，通过结合BERT和GPT模型，提高了数据的结构化程度和准确性，使得从行业源数据中提取有用的信息变得更加高效和精确。利用散点图和折线图生成算法，以及三维渲染技术，能够创建更加动态和交互式的数据可视化，这不仅提高了数据展示的直观性，还增加了用户参与感。采用强化学习算法调整数据布局样式，使得最终的数据大屏更加个性化和用户友好，以满足不同用户的具体需求。基于人工智能(AI)大语言模型的数据大屏幕生成方法。该方法通过结合BERT和GPT模型，更高效、更准确地从行业源数据中提取有用信息，提高数据的结构化程度和准确性，通过采用增强学习算法调整数据布局模式，保证最终的数据大屏更加个性化和人性化，满足不同用户的具体需求，通过利用散点图和三维渲染技术，以及采用折线图生成算法，创建更加动态和交互的数据可视化， 从而提高了数据显示的直观性和用户的参与度。该方法基于工业源数据，通过双向编码器表示从变压器(BERT)模型，采用数据清洗和数据标准化算法进行数据分析操作，生成结构化数据集。 基于结构化数据集，利用数据绑定技术提取数据，采用模板匹配算法选择模板，生成大屏幕草图。 基于所述大屏幕草图组合用户提出的自然语言查询。 利用生成预训练变换器(GPT)模型执行语义理解和信息提取操作，并通过SQL(RTM：域专用语言)分析器搜索数据，以生成查询响应的数据集。基于查询响应的数据集，采用折线图生成算法将散点图转换成图，以结合布局优化算法调整图，生成可视化图表集。 交互式三维场景是基于视觉图表集通过三维渲染技术创建的。 数据时间通过基于三维数据大屏采用D3.js(RTM：JavaScript library for producing dynamic，interactive data visualizations in web browsers)进行显示，用于生成动态交互数据大屏。 基于所述动态交互数据大屏结合用户反馈和偏好，用于采用增强学习算法调整数据布局模式，生成最终的个性化数据大屏。 本发明还公开了一种基于AI大语言模型的数据大屏幕生成系统。  12
本发明公开了一种基于遥感影像的城区充电桩配置需求评估方法和装置，通过获取包含目标城区的建筑的遥感影像数据；采用预先构建的学习偏移向量模型对所述遥感影像数据进行建筑足迹的提取；其中，所述学习偏移向量模型是基于U‑Net模型与SegNet模型融合构建得到的；基于格雷厄姆扫描法的凸包算法计算所述建筑足迹的矢量形状面积，得到建筑占地面积，并根据所述建筑占地面积计算建筑容积；对建筑环境自变量和充电桩灵活资源进行回归分析，以计算所述目标城区的充电桩规模。采用本发明，能够利用多光谱遥感影像对建筑足迹进行识别并算出占地面积，进而实现对地区充电桩灵活资源容量的相关性分析，从而精准地预测城区的充电桩需求。基于电动汽车开发遥感影像的城市充电桩配置需求评估方法。利用多光谱遥感影像识别建筑占地面积并计算占地面积，实现区域充电桩灵活资源容量的相关性分析，以准确预测市区的充电桩需求。该方法涉及获得(S11)包括目标城市区域的建筑物的遥感图像数据。 利用(S12)预先构建的学习偏移向量模型提取遥感影像数据的建筑物足印。 基于Graham扫描方法的凸包算法计算(S13)所述建筑占地面积的矢量形状面积，并获取建筑楼层面积，根据所述建筑楼层面积计算建筑量。 对所述建筑环境自变量和所述充电桩柔性资源进行回归分析(S14)，以计算所述目标城市区域的充电桩规模。 所述建筑环境自变量包括建筑楼层面积和建筑体积。以下包括独立权利要求：1。 一种基于遥感影像的城市充电桩配置需求评估装置； 2. 一种基于遥感影像的城市充电桩配置需求评估装置。   6
本申请公开了一种实体相似度计算方法，包括：概念相似度计算步骤、距离相似度计算步骤、语义相似度计算步骤以及属性相似度计算步骤。所述概念相似度计算步骤为融合路径权重的实体概念相似度计算步骤。所述语义相似度计算步骤为基于Bert的语义相似度计算步骤。所述属性相似度计算步骤为基于TextRank的属性相似度计算步骤。本申请实施例提供的实体相似度计算方法，利用概念层次和距离来衡量实体之间的差异，利用语义和属性来衡量实体之间的共性，得到的正确率、召回率以及F1值较高，相较于传统的单独使用路径或者概念层次的方法取得了更好的效果。该方法对于使用电子设备(要求保护的)计算实体相似度是有用的。该方法：利用概念层次和距离来衡量实体之间的差异； 利用语义和属性来衡量实体之间的共性； 有正确率，得到的召回率和F1值较高； 并取得较好的效果。计算实体相似度包括计算概念相似度步骤、计算距离相似度步骤、计算语义相似度步骤和计算属性相似度步骤，其中计算概念相似度步骤是一个包含路径权重的实体概念相似度计算步骤，计算语义相似度步骤是一个基于Bert的计算语义相似度步骤。独立权利要求还包括：一种实体相似度计算装置； 以及计算机可读存储介质，包括用于计算实体相似度的指令集。  12
本发明属于自然语言处理技术领域。具体涉及一种基于GPT的智能客服多轮对话优化方法。采用GPT技术解决智能客服中最核心的一块对话管理，旨在基于GPT强大的数据拟合能力，提供一种端到端、通用可行的对话管理方案，这种端到端主要体现在只需要定义用户实体，用户意图，机器人行为，构建符合业务逻辑的对话故事线，即可通过训练GPT模型实现多轮对话管理能力。本专利的另一个特点是用户的话术有一个实体或者多个实体时，可以将实体的嵌入表示融入到用户意图的嵌入表示中，从而完成更高级别的对话管理方案。基于GPT的智能客服多轮会话优化方法，用于自然语言处理任务和对话管理。仅通过定义用户实体、用户意图、机器人行为并按照业务逻辑构建对话故事情节，训练GPT模型实现多轮对话管理能力。 实体的嵌入式表示在用户的语音时被合并到嵌入式表示中，因此完成更高级别的对话管理解决方案。该方法涉及基于用户意图、用户实体和机器人动作建立词典。 变量用户被定义为表示用户。 结合围绕用户意图、用户实体和机器人的对话故事逻辑。 如果NLU传送用户意图的同时传送用户实体，则将用户意图嵌入到表示输入GPT模型中并预测机器人行为。 用户实体与历史信息进行拼接，再次预测下一个机器人动作，完成会话管理。 当机器人的初始状态开始时，由NLU识别的用户意图由用户输入以通过GPT预测机器人的动作，并且实际信息由机器人传输给用户。 当预测到所有故事逻辑时，清空历史信息并开始新对话。 8
本发明公开了一种模型训练方法、文本检测方法、装置、设备及存储介质。该模型训练方法包括：获取若干目标词对应的训练样本，每个目标词对应的训练样本包括该目标词对应的应被检出的正例句子集合和/或不应被检出的负例句子集合；对于每一训练样本，将正例句子集合和/或负例句子集合中的句子输入BERT模型，根据目标词，得到每个正例句子的目标词位置平均向量和/或每个负例句子的目标词位置平均向量；利用每个正例句子的目标词位置平均向量和/或每个负例句子的目标词位置平均向量，训练识别模型；识别模型用于根据待检测句子的目标词位置平均向量识别待检测句子为正例句子或负例句子。应用此方法训练得到的模型，可以提高目标词检测正确率。一种计算机设备的模型训练方法，用于在客户看护主管与客户的对话呼叫中检索目标词所在的句子。本发明提高了训练样本的目标词检测精度，提高了目标词句子搜索的正确率。 该方法还提高了重要关键词的查全率。所述方法包括：获取与多个目标词相对应的训练样本，其中，所述训练样本具有与所述目标词相对应的正例句集合和负例句集合。 基于转换器的双向编码器输入正例句集和负例句集以表示BERT模型。 获得正例句的目标词位置平均向量和负例句的目标词位置平均向量。 根据目标词位置平均向量识别待检测句子。独立的权利要求书被包括在以下内容中： 文本检测方法； 模型训练装置； 文本检测装置； 以及 一种计算机可读存储介质。  11
一种基于意图识别与模板匹配的混合问答方法，基于特征词匹配进行意图初识别；基于BERT‑textCNN进行意图再识别；将得到的识别结果进行融合，确定用户意图；基于用户输入的问句中的实体、实体类型以及确定的用户意图，生成对应的Cypher查询语句；调用Cypher在图谱上进行查询，保存返回的结果，然后套用预先定义好的回复模板，对返回的结果进行组织和处理，生成相应的答案返回给用户。本发明将复杂的问答任务转化为意图识别任务和模板匹配任务，不仅解决了深度学习模型无法同时识别出单句中多个意图的弊端；而且有效解决了传统模板匹配无法理解用户真正意图的问题，提高了问答准确率。在保证准确率的同时，提高了整体效率。自然语言处理中基于知识地图的人工智能领域中基于意图识别和模板匹配的混合问答方法一种混合问答方法，包括：接收用户输入的提问语句； 其中问题语句基于实体进行分析，从而保证了问题答案系统的准确性和效率，提高了用户意图识别和模板匹配的准确性，也提高了问题答案的准确性，从而提高了整体效率。该方法涉及从用户输入的问题句子中匹配实体和触发词。 根据实体类型和触发词类型综合确定意图数。 基于Bert-TextCNN重新识别意图。 通过使用意图识别直接识别用户的真实意图。 确定用户意图。 一种密码器 (药物洗脱冠脉支架)查询语句是基于问题语句中的实体生成的。 产生答案。 所述的密码器 (药物洗脱冠脉支架)在地图上被调用以供查询。 存储返回的结果。 利用预定义的返回模板来组织和处理返回的结果，以生成相应的答案返回给用户。  12
本发明公开了一种文本中特定内容识别存储方法及系统，属于文特定词识别的技术领域，其方法包括生成特定词库和规则库；获取待识别的文本集合；提取当前特定文本数据集中的新特定词，得到新特定词集合；将需要训练的词组输入BERT模型；从特定文本中获取疑似新特定词集合，利用BERT模型计算特定词库中各词的特征向量与疑似新特定词集合中各词的特征向量的余弦相似度，并基于计算结果判定新特定词。本发明解决了现有技术中基于预构建模式规则的匹配方式仅局限于特定匹配规则模式，匹配方式不够灵活，结果不够全面，难以及时识别海量新出现的特定词及其变体词，且由于文本中涉及大量错综复杂的词语，容易造成特定词的模糊匹配，导致误识别的问题。文本中特定内容的识别和存储方法。利用特殊字库初屏的文本数据集可以提高识别效率。 具有一定概率的词无法正确拆分新的特定词的缺陷可以进行优化。 可以避免预先构建的模式规则的限制。该方法涉及生成特定词语和基于现有特定词语的规则库。 所述特定词由多个特定词组成。 得到待识别文本集合。 文本集合中设置有多个文本，每个文本由文本数据语言学数据组成。 从所述特定词库中选择一个词作为特定文本数据集。 将待训练的短语输入到来自变换器的双向编码器表示(BERT)模型中。 从特定文本中获取疑似新的特定词语集合。 利用所述BERT模型计算所述特定文本中每个词语的特征向量的余弦相似度。 在所述疑似新词集合中计算所述特征向量。 根据计算结果确定新的特定词语。本发明还涉及一种用于文本中的特定内容的标识存储系统。  12
本公开提供了用于基于隐式相关性反馈来提供QA训练数据以及训练QA模型的方法和装置。可以从搜索日志中获得问题‑文段对以及对应的用户行为。可以从所述用户行为中提取行为特征。可以通过隐式相关性反馈模型，基于所述行为特征来确定所述问题与所述文段之间的相关性分数。可以基于所述相关性分数，向所述问题‑文段对添加相关性标记。可以利用所获得的自动标记的QA训练数据来对QA模型进行预训练，并且利用人为标记的QA训练数据来对经预训练的QA模型进行精调。一种基于隐式关联反馈的问答训练数据提供方法，用于在搜索结果页面(SERP)中提供问答(QA)服务。本发明有效地提供了问答(QA)训练数据，并基于隐式相关性反馈训练QA模型，从而准确地确定了文章与问题之间的文章相关性，进而实现了确定文章相关性的Web规模，开放域问答，机器学习模型。该方法(700)包括从搜索日志中获得(710)问题-通道对和相应的用户行为。 从用户行为中提取(720)行为特征。 通过基于行为特征的隐式相关性反馈模型来确定(730)问题和文章之间的相关性得分。 基于相关性得分将相关性标签添加到提问-通道对。 用户行为包括点击行为类型，重查询行为类型和浏览行为类型中的一种。 分别获得与提问-通道对的印象相对应的用户行为组。本发明还涉及一种基于隐式相关性反馈的QA模型训练方法。 以及用于基于隐式相关性反馈来提供QA训练数据的装置。  11
本发明提供一种黑产手机号及黑产用户设备识别方法、系统及存储介质，该方法包括：获取预设时间段内的移动信令数据；基于移动信令数据提取用户行为特征数据和用户设备特征数据；根据各手机号在预设时间段内的关联用户设备的总去重数量以及各时间区间内的关联用户设备的数量确定疑似黑产手机号；基于用户行为特征数据和用户设备特征数据确定真实黑产手机号；基于真实黑产手机号、白名单手机号及对应的各行为特征数据生成训练集；将训练数据输入至网络模型进行训练得到预训练模型；将待识别手机号及相应的行为特征数据输入至预训练模型得到识别结果，基于待识别手机号的移动信令数据确定黑产用户设备。该方法可有效的识别黑产手机号及黑产用户设备。在电子商务，应用游戏发行渠道等互联网平台上的通信技术领域，识别黑产手机号码和黑产用户设备的方法。本发明能够基于预训练模型有效识别黑色行业手机号码和黑色行业用户设备，从而提高手机号码的黑色行业和识别系统的用户设备。所述方法包括：获取预设时间段内的移动信令数据，所述移动信令数据包括时间戳信息，用户手机号码信息，国际移动用户身份信息，国际移动设备识别信息和附加基站码信息。 基于所获得的移动信令数据来提取用户行为特征数据和用户设备特征数据。 将待识别手机号码和相应的行为特征数据输入到预训练模型中，得到预测识别结果。 基于与待识别的移动电话号码相对应的移动信令数据来确定用户黑色行业。本发明还涉及一种用于识别黑产品手机号码的系统和一种黑产品用户设备。 和(2)存储有计算机程序的计算机可读存储介质。  11
本发明提供了一种基于词汇增强的军事命名实体识别方法及装置，通过对已经标注的训练数据集，对训练集中的每一条数据进行预处理得到字符序列，引入军事词典进行分词处理得到词汇序列，将每个词汇的边界标识符放入每一条数据的结尾标识符之后构造输入语句，输入到BERT+CRF模型中，充分利用了语句中的字符语义特征和词汇语义特征，增强了输入数据的信息，提升了命名实体识别的精度。在构造输入数据时，通过将词汇边界标识符与该词汇所在的待识别文本中共享位置编码，因此推断速度更快、内存占用小。基于词汇增强的军用命名实体识别方法，应用于实体识别领域。本发明能够增强输入数据的信息，从而提高命名实体识别的精度。 本发明使得文字边界识别符与待识别文本中的文字共享位置码，推断速度更快，内存占用小。所述方法包括：获得标记的训练数据集；以及预处理所述训练数据集中的数据的每个部分。 引入军事领域专用字典，利用分词算法对每个预处理后的数据进行分词。 将经分词处理的每条数据的输入数据构造为训练样本。 每个训练样本被输入到来自变换器(BERT)模型的双向编码器表示中以进行编码，从而获得每个训练样本包含上下文语义信息的向量表示。 语义信息向量被输入到条件随机场(CRF)层，CRF层根据语义信息向量捕获相邻标签之间的相关性。 获得训练的网络模型。 获得待识别文本。 将待识别文本输入到训练好的网络模型中，得到待识别文本中的军事命名实体。本发明还涉及一种基于词汇增强的军用命名实体识别装置。  12
本申请公开了一种基于LLaMA的财税问答模型构建方法、装置、设备及介质，涉及模型训练领域，包括：通过低阶自适应技术利用预设中文训练集对预设LLaMA‑7B模型进行微调，以得到通用中文语言大模型；获取预设财税数据，并基于预设过滤规则对所述财税数据进行数据过滤，以得到过滤后财税数据；对过滤后财税数据进行分词处理，以将所述过滤后财税数据切分为若干分词结果序列，并基于所述分词结果序列创建中文财税训练集；基于所述中文财税训练集对所述通用中文语言大模型进行训练，以得到基于LLaMA的目标财税问答模型。这样一来，可以基于收集的财税语料在垂直领域对模型进行训练，减小模型训练难度，得到应用于财税行业专项领域的问答模型。基于LLaMA(RTM：Open and Efficient Foundation Language Models)的财税问答模型构建方法。基于采集的金融税务语料在垂直领域训练模型，降低了模型训练难度，得到应用于金融税务行业特殊领域的问答模型。该方法涉及利用预设的中文训练集，通过低阶自适应技术，对预设的LLAMA-7B模型进行(S11)微调，得到通用的汉语言大模型。 获取预设的金融税务数据(S12)，基于预设的过滤规则对金融税务数据进行数据过滤，得到过滤后的金融税务数据。 对过滤后的金融税务数据进行分词处理(S13)，以将过滤后的金融税务数据切分为多个分词结果序列，并基于分词结果序列创建中文金融税务训练集。 基于中文财税训练集对通用汉语言大模型进行训练(S14)，得到基于LLaMA的目标财税问答模型。独立权利要求包括如下：基于LLaMA的税务问答模型构建装置； 电子装置； 以及存储有财税问答模型建立方法的计算机程序的计算机可读存储介质。  11
本申请公开了一种任务型对话响应方法及装置。其中，该方法包括：获取任务型对话的基础对话信息，其中，基础对话信息中至少包括：当前轮次请求的意图信息、历史对话信息；利用对话状态大语言模型对基础对话信息进行分析，得到基于特定领域语言的目标对话策略请求；利用对话策略加载器加载与目标对话策略请求对应的目标对话策略样例；利用对话策略大语言模型对目标对话策略样例进行分析，得到目标对话生成策略；利用工程化对话生成模块执行目标对话生成策略，得到请求响应信息，并输出请求响应信息。本申请解决了相关技术中对话系统处理多轮任务型对话的能力较差，用户体验不佳的技术问题。对话系统中的任务类型对话响应方法。该方法解决了对话系统处理多轮任务类型对话的能力差，用户体验差的技术问题。该方法包括获取任务类型对话的基本对话信息(S202)。 利用所述对话状态大语言模型(S204)对所述基本对话信息进行分析，得到基于所述特定领域的语言的目标对话策略请求。 对话策略加载器，用于加载与所述目标对话策略请求对应的目标对话策略样本(S206)。 利用对话策略大语言模型(S208)对目标对话策略样本进行解析，得到目标对话生成策略。 工程化对话生成模块，用于(S210)执行所述目标对话生成策略，获取请求响应信息，并输出所述请求响应信息。独立权利要求包括以下内容：任务类型对话响应装置； 非易失性存储介质，存储有任务类型对话响应程序； 以及电子设备。 8
本发明提供了基于BERT和改进PCNN的食品安全关系抽取方法，针对收集到的食品安全领域数据集，利用BERT和PCNN模型的分段最大池化最大程度捕获句子的局部信息，并根据中文是以词而并非以字为基本单位的特性以及注意力机制的优点，结合多核处理、分词技术、注意力机制以及损失函数等方法提出改进的模型BERT‑PCNN‑ATT‑jieba的模型，实现了提高抽取食品安全领域关系的性能的功能，提升了食品安全领域的关系抽取的性能。本发明减少了手工对于食品安全数据标注的成本，为下一步工作奠定了基础。一种基于BERT的食品安全提取方法，改进PCNN用于食品知识地图内容的传播，作为食品安全领域中的MAT的下一步知识推理。降低了人工标注食品安全的成本，为下一步工作奠定了基础。 提高了食品安全提取性能的领域关联性，并提高了食品安全领域的关联提取性能。该方法包括在食品安全领域构建数据集并导入图形数据库。 构建食品安全领域关系模型。 通过人工标注的方法对大规模文本进行预处理。 从所述语料库中获得句子词嵌入向量和位置嵌入向量。 加入分词处理，对PCNN分段卷积神经网络模型进行改进，得到Bert-PCNN-ATT-Jieba模型。 通过比较评价指标来评价模型的性能。 结合PCNN分段卷积神经网络模块的特点和特殊语料库的特点。  12
本发明公开了一种基于U‑Net网络的遥感影像建筑物提取方法、系统、电子设备，在U‑Net网络的解码层加入一个多尺度模块，并引入空洞卷积网络，由于空洞卷积可以在不损失分辨率的情况下扩大感受野，因此可以在保留细节信息的同时提升网络挖掘语义信息的能力，同时多尺度模块增强了网络获取多尺度特征的能力；本发明中考虑将卷积层的卷积模式设置为填充，即卷积后，特征图大小完全不变，原来特征图实际会收缩2，这样每通过一个卷积层，特征图的大小就会减小2倍，采用这种卷积方式，经过4层编码层，最后一层编码层输出的特征图大小将会收缩为输入图片的1/16倍，再经过反卷积操作来恢复图像分辨率，这时候特征图的大小将开始扩大，有效的缩小训练时间。用于通过使用电子设备提取基于U-Net网络的遥感图像建筑物的方法(要求保护)。该方法使得能够通过去卷积运算恢复图像分辨率，并且扩展特征图的尺寸，从而减少训练时间。该方法涉及收集数据集的多遥感图像。 对每幅遥感影像进行分割切割，得到包含被分类对象的地表矢量文件。 在所述地表矢量文件中绘制有建筑物标签。 将所述建筑物的表面矢量样本的矢量数据转换为网格数据。 得到栅格化后的建筑物样本。 选取U-Net网络作为地基建筑提取模型。 将所述建筑物样本设置为输入数据，以训练建筑物提取模型。 确定U-Net网络解码层的第M级，其中多尺度模块包含N个并行支路。 将遥感影像从建筑物输入到网络中。 提取所述遥感影像。还包括用于基于U-Net网络的遥感图像建筑物提取系统的独立权利要求。   6
本发明公开的一种一种表面缺陷检测系统，包括图像获取模块与U‑Net模型；通过图像获取模块进行获取工件的图像，对图像进行预处理，并提取工件原始图像数据，将工件原始图像数据进行滤波处理，将滤波后的图像数据输入U‑Net模型，所述U‑Net模型包括编码器，通过U‑Net模型压缩图像并捕获关键特征，通过编码器进行编码后的图像被采样回原始大小，并获取关键信息进行优化自定义损失函数，并输出一个与原始图像大小相同的二进制掩码；通过卷积网络执行二值分类，并输出U‑Net模型处理数据；根据U‑Net模型处理数据与工件原始图像数据进行比较，判断工件缺陷信息。用于窗玻璃、餐具、光电子、技术和装饰用途的表面缺陷检测系统。 也可用于玻璃瓶。该系统通过U‑Net模型对图像进行分割，并根据分割处理将数据与工件原始图像数据进行比较，从而实现了复杂的特征提取，并获得了较好的预测结果。 系统进行几何形状分析得到图像缺陷，以减少图像采集后的采集干扰，得到图像的误差，更好的进行图像缺陷分析，得到的图像缺陷信息准确。该系统具有图像获取模块和U-Net模型。 所述图像获取模块通过所述图像采集模块获取工件的图像，对所述图像进行预处理，提取所述工件的原始图像数据，对所述原始图片数据进行滤波，将滤波后的滤波后的图像数据输入所述U-Net模型，所述U-Net模型设有编码器，通过所述U-Net模型对所述图像进行压缩并捕获关键特征。 所述U网模型对编码器编码后的图像进行采样并返回至原始尺寸，并获取关键信息对自定义损失函数进行优化，并输出与原始照片尺寸相同的二值掩码，进行所述二值分类，输出所述U网模型加工数据并将所述工件加工数据与所述工件原始照片数据进行比对，确定所述缺陷信息。   6
本发明公开了一种基于改进的U‑net网络的OCT图像脉络膜分割方法，该U‑net网络主要改进点包括：(1)通过在网络中增加编码器和译码器的数量来提取更多特征信息；(2)在编码器后面加入精致残差块来增强每一层识别能力；(3)在译码器后面加入注意力模块让高层语义信息指导底层细节信息；(4)损失函数采用传统的L2损失和Dice损失结合来共同约束网络模型，采用本发明改进的U‑net网络可以自动分割无论是正常人眼还是病理性近视人眼脉络膜的上下边界，并且分割结果准确性高。基于U-net网络的OCT图像脉络膜分割方法。该方法改进了自动划分正常或病理性近视人眼或脉络膜上下边界的U-net网络，划分结果准确性高。该方法包括执行数据采集和预处理。 采集原始OCT图像。 专业标记通过脉络膜下边界进行。 进行归一化处理。 将得到的数据集作为训练集进行处理。 构建U-net网络结构。 进行卷积。 批处理被激活。 将卷积得到的特征图进行残差运算。 进行活化处理。 每一层中的路径由卷积层和通道注意力模块扩展。 将训练集输入构建好的U-net网络中进行训练。 将所述待分割图像传输至所述已训练模型中进行图像分割。   6
本发明涉及一种基于生成式人工智能的工单填报方法，包括以下步骤：通过工单填报终端输入语音信息，工单填报终端通过语音识别模型将输入的语音信息转换为文字信息；工单填报终端将文字信息输入自训练意图识别模型识别工单任务类型，识别工单任务类型后工单填报终端跳转至对应任务类型的工单填报页面；工单填报页面通过信息提取模型提取文字信息中的主要内容并自动将提取的内容填写至工单中；工单填写完成后通过纠错模型对填写完成的工单内容进行纠错，纠错完成后再经过用户确认信息是否正确，最后提交工单。文档分析抽取技术领域的基于生成人工智能的工作表填写方法。所述工单填写页面通过所述信息提取模型提取所述人物信息中的主要内容并将提取的内容自动填写工单。 该方法能够在完成工单填写后，通过纠错模型对填写的工单内容进行纠错，从而确认用户信息是否正确。该方法包括将输入的语音信息输入工单填写终端。 通过语音识别模型将输入的语音信息转换为字符信息。 将所述字符信息输入自训练的意图识别模型，以识别工作单任务类型。 所述工作表填写终端识别所述工作表的任务类型后跳转至对应的任务类型。 通过信息提取模型在字符信息中提取所述主要内容并将提取的内容自动填充到工单中。 填充完成后通过纠错模型对填充后的工单内容进行纠错。 由用户确认该信息，以在完成填充之后确认该信息是正确的。独立权利要求包括用于：(1)基于生成的人工智能的工作表填写系统； (2)一种电子设备，包括存储器和处理器，所述处理器被设计为执行基于所生成的人工智能的工作表填充方法； (3)一种计算机可读存储介质，包括一组程序，以执行基于生成的人工智能的工作表填充方法。 8
一种基于图神经网络预训练模型的风险商品异常检测方法，包括：获取电商数据，构建商品与用户之间复杂的异构图网络；通过异常节点传播方法获取新的异常节点和正常节点进行数据增强；搭建深度图神经网络模型，支持无监督预训练数据和下游有监督训练微调；将图神经网络模型进行无监督预训练；将预训练好的模型进行下游微调进行有监督的训练；将下游训练好的模型推理待测试的商品节点。该发明利用自监督学习策略，让模型充分学习到了大规模图数据的节点特征信息，规避了噪声干扰，提高了模型的扛干扰性，同时利用异常节点传播的方式做数据增强，丰富了数据的信息度，提高了模型检测风险商品的能力。基于神经网络预训练模型的风险商品异常检测方法，用于识别平台上的假冒商品，以及违禁商品。该方法利用自监督学习策略，使模型充分学习大规模图像数据的节点特征信息，避免了噪声干扰，提高了模型的干扰性，同时，利用异常节点传播的方式作为数据增强，丰富了数据的信息化程度，提高了模型检测风险商品的能力。该方法涉及获得电子商务数据(S110)。 构建商品与用户之间的复杂网络拓扑图。 获得当前异常节点和正常节点(S120)，以通过异常节点传输方法增强数据。 构建深度神经网络模型(S130)，用于支持无监督的预训练数据和下游的有监督的训练微调。 对神经网络模型进行无监督预训练(S140)。 对用于监督训练的预训练模型执行下游微调(S150)。 对所述待测商品节点进行下游训练模型推理(S160)。   4
本发明公开了一种基于生成式对抗神经网络的图像修复方法，该方法使用了四个部分，分别是生成网络、全局判别网络、局部判别网络和LSTM神经网络。两个判别器主要用于保证缺失区域修复后能够和周围保持一致性。LSTM神经网络主要用于分阶段修复破损图像。算法包括数据预处理模块、模型训练模块和图像修复模块，主要用于对大面积缺失的图像进行语义修复任务, 以重建出符合人眼感官的完整逼真图像。基于生成对抗神经网络的图像修复方法。该方法保证了缺失区域在修复后能够与周围保持一致性。该方法包括预处理数据以满足神经网络对输入数据的要求。 第一次将图像的像素值缩放到(0, 1)，然后将数据图像分辨率调整到128 128。 裁剪后的128 128图像制作四个掩模矩阵，以人工损伤图像，制作缺陷图像。 掩模矩阵对应于经修复的图像的四个阶段。 一次得到处理后的缺陷图像。 在生成网络的编码器中使用生成的卷积神经网络的卷积和池化操作来通过。 对缺陷程度最大的图像进行特征提取，得到深度特征图。   4
本发明涉及一种基于神经网络的在线车辆多目标跟踪方法，包括以下步骤：车载相机拍摄图像获取车辆跟踪数据集，并对车辆跟踪数据集作图像增强处理；获取预训练模型并进行微调；采用预训练模型对车辆跟踪数据集进行多次迭代训练，得到训练后的车辆目标检测模型；对车辆目标检测模型进行后帧处理，并为车辆目标检测模型中的目标分配ID并重新调整阈值参数；将重新调整阈值参数后的车辆目标检测模型用于车载摄像头拍摄的图像中，得到跟踪结果；本发明方法实现了在复杂道路场景中对多个目标的鲁棒跟踪，轻量化的模型结构在具备准确性的同时，还能实现实时在线的跟踪效果，可用于先进驾驶辅助系统和自动驾驶等领域。在高级驾驶辅助系统和自动驾驶领域有用的基于神经网络的在线车辆多目标跟踪方法。该方法：实现了复杂道路场景下多目标的鲁棒跟踪； 能够为轻量化模型结构提供精度； 并且能够实现实时在线跟踪效果。该方法包括通过车载摄像头拍摄图像获得车辆跟踪数据集(S1)。 通过所述车辆跟踪数据集进行图像增强处理操作。 得到所述预训练模型。 执行所述微调(S2)。 所述预训练模型用于对所述车辆跟踪数据集进行所述多次迭代训练。 训练后得到车辆目标检测模型(S3)。 对所述车辆目标检测模型进行帧后处理。 将身份证件(ID)分配给车辆目标检测模型中的目标。 阈值参数被重新调整(S4)。 将重新调整阈值参数后的车辆目标检测模型用于车载摄像头拍摄的图像，得到跟踪结果(S5)。 13
本发明涉及信息技术领域，具体涉及一种基于大语言模型的电商平台商品内容解析方法及模型。包括以下步骤：步骤S1将非结构化的图像数据转换为结构化的文本数据；步骤S2根据步骤S1解析获得的文本数据，并利用大语言模型进行解析，识别文本信息之间的关联关系，并汇总成结构化的数据；步骤S3检测并纠正在步骤S1和步骤S2中出现的错误或遗漏，包括识别结果为冗余信息造成误解析和错误关联关系，识别完成后，将进行自动校正或执行错误提醒，输出准确和完整的商品属性信息。本发明的有益技术效果包括：自适应性、纠错功能、深度文本关联解析，满足多变的商品展示需求并确保信息的准确性与完整性的。基于大型语言模型的电子商务平台产品内容分析方法。该方法能够提高自适应性、纠错功能、深入文本相关性分析，以满足不断变化的产品展示需求，保证信息的准确性和完整性。该方法包括将非结构化图像数据转换为结构化文本数据(S1)。 对文本数据进行解析(S2)。 利用大型语言模型来分析和识别文本信息关系之间的关联。 检测和校正由识别结果是冗余信息引起的包括错误稀疏和错误关联的错误或遗漏(S3)。 进行自动修正或错误提醒，识别完成后输出准确完整的产品属性信息。包括用于基于大型语言模型的商业平台商品内容分析模型的独立权利要求。  11
本公开的实施例公开了对话文本标签识别模型训练方法与对话文本标签识别方法。该方法的一具体实施方式包括：获取目标领域的标注对话文本组，其中，标注对话文本组中的标注对话文本包括对话信息序列；对于标注对话文本组中的每个标注对话文本，根据标注对话文本包括的对话信息序列对应的各个对话角色，对标注对话文本包括的对话信息序列进行标识处理，以生成标识后的标注对话文本作为标注对话样本；基于所生成的各个标注对话样本，对预训练对话文本标签识别模型进行训练，得到训练后的预训练对话文本标签识别模型作为对话文本标签识别模型。该实施方式与人工智能有关，提升了标签预测结果的准确性。对话文本标签识别模型训练方法。该方法能够实现人工智能的对话文本标签识别模型训练，提高标签预测结果的准确性。该方法包括获取目标领域的标记对话文本组。 标注对话文本组中的标注对话文本设置有对话信息序列。 根据所述对话信息序列对应的对话角色，识别所述标注对话文本包括的对话信息序列，生成所述标注对话文本作为标注对话样本。 基于生成的已标注对话样本对预训练对话文本标签识别模型进行训练，以用于将训练后的预训练对话文本标签识别模型作为对话文本标签识别模型。 对所述对话信息序列进行聚类，生成对话信息组序列。包括独立权利要求：(1)一种用于识别对话文本标签的方法； (2)对话文本标签识别模型训练装置； (3)对话文本标签识别装置； (4)电子设备； 以及(5)一种计算机可读介质，包括用于存储由处理器执行以实现对话文本标签识别模型训练过程的计算机程序的指令集。 3
本发明涉及人工智能技术领域，具体为一种基于大规模语言模型的时间文本抽取系统和方法，时间文本抽取系统由数据收集模块、数据预处理模块、模型训练模块、策略调整模块以及应用模块构成；有益效果为：本发明提出的基于大规模语言模型的时间文本抽取系统和方法，通过充分利用大规模语言模型的学习能力以及通用性，提高时间文本抽取的准确性和合理性。同时，本发明基于正则匹配构建不同形式的时间模板构造有监督训练数据，达到增强大语言模型的泛化能力的目的。最后，将提取出的时间文本应用于组织沿革、通讯、医疗等领域。基于大规模语言模型的时间文本提取系统，应用于组织皮革、通信、医疗领域。通过充分利用大规模语言模型的学习能力和共性，提高时间文本提取的准确性和合理性。 基于正则匹配构建不同形式的时间模板来构建监督训练数据，从而达到增强大型语言模型泛化能力的目的。所述系统具有数据采集模块，用于采集所述训练模型的相关数据。 数据预处理模块，用于对训练时间进行不规则处理。 模型训练模块，用于模型的微调和结果的评估。 策略调整模块，用于提取文本中的时间。 应用模块，用于将提取的时间应用于各个字段。 对时间文本执行大量的基于工作人员的标签，以便使模型能够更好地适应下游的时间识别任务。 将采集到的文本和对应的标签进行打包，得到训练模型的所有相关数据。包括以下独立权利要求：一种基于大规模语言模型的时间文本抽取系统及方法； 以及一种基于大规模语言模型的时间文本抽取方法。  11
本发明公开了一种基于车载单目摄像头的驾驶环境感知方法，包括对上采样模块进行结构重参数化和自动驾驶多任务感知。相比普通的线性插值和转置卷积，本发明使用RepUpsample对网络模型的精度有一定的提升。在语义分割模型任务上，对比DeepLabv3、FPN和U‑Net三种模型在使用不同上采样模块时的精度表现，不同的网络模型、不同的上采样位置、以及不同的网络规模，RepUpsample作为上采样方法都可以提升语义分割网络的性能。相比双线性插值算法，mIOU平均能够提升1.77％，P.A.平均能够提升0.74％，相比转置卷积，mIOU能够提升1.16％、P.A.能够提升0.35％。基于车载单目摄像头的行驶环境感知方法。该方法能够结合结构权重参数化上采样模块，设计一种自动驾驶感知多任务算法，通过一次推理完成多个任务，提高整个系统的吞吐速度，降低功耗和内存的使用，提高语义分割网络的性能。该方法涉及在训练阶段和推理阶段扩展上采样模块的转置卷积层。 在训练阶段扩展多个支路，其中一个支路使用线性插值算法，其他支路使用不同的卷积核大小。 在推理阶段对多个分支的结构进行重新参数化。 所述无损转换为单支路结构。 实现了自动驾驶多任务感知。 基于单目摄像头实现传感实时推理由多个任务、深度学习模型对目标检测、道路行驶区域划分、车道线划分三个任务。 13
本发明公开了一种地物要素的处理方法、装置、存储介质和处理器。其中，该方法包括：在显示界面显示地物分类模型；响应用户选择地物分类模型的选择指令，将地物分类模型作为预训练模型；将多张样本影像输入地物分类模型, 在显示界面上显示地物分类模型识别出的包括目标地物类型的目标样本影像；在显示界面上对目标样本影像中的目标地物要素进行标注，得到标注后的目标样本影像；在显示界面上显示采用标注后的目标样本影像对地物分类模型进行训练生成的地物要素识别模型，其中，地物要素识别模型用于识别影像中的目标地物要素。本发明解决了相关技术中对地物要素的处理效率较低的技术问题。该方法可用于通过使用处理器(要求保护)来处理地面对象元素。该方法包括：使用地物元素识别模型识别图像中的目标地物元素，以提高地物的处理效率； 有效地解决了相关技术中加工效率低的技术问题； 并允许用户选择目标样本图像来训练模型，从而可以有效地训练模型，从而方便地提高模型的训练效率。该方法包括在显示界面上显示地面对象分类模型。 通过使用标记的目标样本图像在显示界面上显示通过训练地面对象分类器模型而生成的地面对象元素识别模型。 地物要素识别模型用于识别图像中的目标地物要素。 使用训练地物特征识别模型识别目标地物类型。 通过在显示界面上使用标记的目标样本图像显示通过训练地物分类模型而生成的地物元素识别模型。本发明还涉及一种用于处理地面物体元件的装置； 以及计算机可读存储介质，包括用于处理地面对象元素的指令集。 14
本发明涉及文本分类模型的训练方法、装置、设备和计算机存储介质，文本分类模型的训练方法包括：获取文本分类模型；获取文本训练数据；将Dropout层的概率值设置为0，得到第一预训练模型，并将文本训练数据输入第一预训练模型，得到第一概率分布；将Dropout层的概率值设置为p(0<p<1)，得到第二预训练模型，并将文本训练数据输入第二预训练模型，得到第二概率分布；利用第一概率分布和第二概率分布计算文本分类模型的损失函数，并利用损失函数对文本分类模型的参数进行优化，得到训练完成的文本分类模型。本发明的训练方法不仅可以避免文本分类模型出现过度拟合的问题，而且还可以减少文本分类模型在训练阶段和验证阶段的不一致问题。一种文本分类模型的训练方法。本发明避免了文本分类模型过拟合的问题，减少了训练阶段和推理阶段由于缺失层导致的分类模型不一致性问题。该方法包括获得文本训练数据。 将丢失层的概率值设置为0，以获得第一预训练模型。 文本训练数据被输入到第一预训练模型以获得第一概率分布。 将丢失层的概率值设置为P(0<p<1)，以获得第二预训练模型。 文本训练数据被输入到第二预训练模型以获得第二概率分布。 计算利用第一概率分布和第二概率分布的文本分类模型的损失函数。 提供损失函数以优化文本分类模型的参数，从而获得训练的文本分类模型。本发明还涉及一种文本分类模型的训练装置。 和(2)存储用于训练文本分类模型的程序的计算机可读存储介质。  11
本发明公开一种应用在网络安全领域的实体抽取方法，包括：将分词后的网络安全文本数据输入已训练好的word2vec模型，得到网络安全领域词向量；对文本数据进行人工语料标注，构建网络安全数据集；将网络安全数据集输入SecurityBERT模型，得到字符级向量；对网络安全领域词向量和字符级向量进行融合；将BiLSTM模型的输出输入自注意力层，使用自注意力机制对字符向量进行局部关键网络安全字词特征增强，获得语义信息。本发明使用BiLSTM模型和自注意力机制进一步建模，得到上下文语义和捕捉局部关键信息，提高了网络安全领域实体抽取性能，取得更好的精确率、召回率和F1值。提取网络安全领域中的实体的方法。该方法利用BiLSTM模型和自注意力机制获取上下文语义并捕获关键信息，提高了领域实体的网络安全抽取性能，获得了更好的查准率、召回率和F1值。该方法涉及收集网络安全领域中的非结构化文本数据。 根据所述文本数据构建网络安全。 对所述文本数据进行预处理。 Word分。 将切分后的网络安全文本数据输入手套模型，得到网络安全人工语言数据的词向量。 将自注意力层的输出和BiLSTM模型的输出融合后输入到softmax层和条件随机场(CRF)模型，得到最终的标签序列，作为实体提取结果。  12
本申请公开了一种基于无监督学习的实体清洗方法及系统，涉及实体清洗技术领域。具体实现方案为：构造正训练样本和负训练样本，根据正训练样本和负训练样本训练预训练语言模型，得到精准的语言模型；获取知识图谱中的同名实体，将同名实体输入语言模型，得到第一编码数据和第二编码数据；拼接第三编码数据和第四编码数据，得到同名实体的第五编码数据；计算任意两个第五编码数据的余弦相似度得到相似度数据，对比计算后的相似度数据和预设的相似度阈值，判断是否是同一实体，有益效果在于不需要每一次判断都将实体信息经过语言模型，大大降低了计算消耗量，提高了实体清洗的速度。一种基于无监督学习的实体清洗方法。该方法能够判断实体信息是否通过语言模型，从而减少计算开销， 从而提高了实体的清理速度，构造了正反训练样本的不同方式，降低了标注成本消耗，保证了训练数据的质量，避免了语言模型只学习数据的浅层规则。该方法包括构造正训练样本和负训练样本。 根据正向训练样本和反向训练样本训练预训练语言模型，得到精确的语言模型。 在知识地图中获得同名实体。 将同名实体输入语言模型以获得第一编码数据和第二编码数据。 对第一编码数据进行预处理以获得第三编码数据。 对第二编码数据进行预处理以获得第四编码数据。 将第三编码数据与第四编码数据拼接，得到同名实体的第五编码数据。 计算第五码数据中的任意两个的余弦相似度以获得相似度数据。 将计算出的相似度数据与预设的相似度阈值进行比较。独立的权利要求书包括： (1)一种基于无监督学习的实体清洁系统； (2)一种计算机可读存储介质，包括一组用于基于无监督学习来清洁实体的指令。  11
一种基于注意力机制的多分支特征融合遥感场景图像分类方法，本发明涉及基于注意力机制的多分支特征融合遥感场景图像分类方法。本发明的目的是为了解决现有方法对遥感图像场景分类准确率低的问题。过程为：一、采集遥感图像，对遥感图像进行预处理，得到预处理后的遥感图像；步骤二、建立基于注意力机制的多分支特征融合卷积神经网络AMB‑CNN；三、采用预处理后的遥感图像训练基于注意力机制的多分支特征融合卷积神经网络AMB‑CNN，得到预训练好的基于注意力机制的多分支特征融合卷积神经网络AMB‑CNN；四、采用训练好的AMB‑CNN对待识别遥感图像进行分类。本发明用于遥感场景图像分类领域。基于注意力机制的多分支特征融合遥感场景图像分类方法。该方法能够增加多分支特征融合遥感场景图像分类精度。该方法包括收集遥感图像。 对所述遥感影像进行预处理，得到预处理后的遥感影像。 基于注意力机制建立多分支特征融合卷积神经网络(AMB-CNN)。 基于注意力机制的多分支特征融合卷积神经网络对预处理后的遥感图像进行训练，得到训练后的多分支特征融合卷积神经网络。 基于注意力机制对遥感影像进行分类。   6
本发明公开了一种基于度量学习的无监督目标检测模型训练方法，其包括以下步骤：S1、通过开源预训练模型对训练数据集所包含的图片进行目标提取，获得伪标签；S2、待训练目标检测模型包括图像编码骨干模型、特征金字塔网络和检测头；将训练数据集的图片输入到待训练目标检测模型中，得到整体图片i和各目标的区域图片；确定待训练目标检测模型得到的所有目标的伪标签，然后提取待训练目标检测模型得到的目标的特征向量；S3、基于度量学习对待训练目标检测模型进行训练。本方案适用于大多数常见的目标检测模型的训练。基于度量学习的无监督目标检测模型训练方法。该方法使得能够以高效的方式基于测量学习来训练待训练的目标检测模型。 该方法允许训练模块通过开源预训练模型对训练数据集中包含的图片进行目标提取，从而得到伪标签。该方法包括通过开源预训练模型从训练数据集中包含的图片中提取(S1)目标，得到伪标签。 所述待训练目标检测模型包括图像编码主干模型、特征金字塔网络和检测头。 在随机初始化待训练的目标检测模型或加载预训练模型检测点后，将训练数据集的图片输入(S2)待训练的目标检测模型。 基于所述量测模型对待训练的目标检测模型进行训练(S3)。 14
本发明提供一种分层会议摘要生成模型训练方法、生成方法及装置，所述方法包括：获取中文会议数据集并进行预处理，所述预处理包括分词和建立词典，构建中文会议词汇列表，将所述中文会议词汇列表输入到BERT模型中，输出BERT词向量；基于获取的中文会议数据集，利用双向长短期记忆网络及注意力机制，生成原始的中文会议数据每句话的对话行为标签；采用所述BERT词向量和对话行为标签构成的训练样本集对预先建立的分层会议摘要模型进行训练，得到目标分层会议摘要生成模型。本发明能够生成具备高流畅度、准确度、可读性、异质性的分层会议摘要。一种面向对话行为优化的层次化会议摘要生成模型的训练方法。该方法能够生成具有高流畅性，准确性，可读性和异构性的分级会议摘要。该方法包括获取中文会议数据集(S110)。 对中文会议数据集执行预处理，其中预处理包括分词。 建立字典。 构建中文会议词汇表。 将中文会议词汇表输入到来自变压器(BERT)模型的双向编码器表示中。 输出BERT字向量。 基于所获取的中文会议数据集，利用双向长期和短期存储网络和关注机制(S120)为每个句子生成原始中文会议数据。 获得由BERT词向量和对话动作标签组成的训练样本集。 训练(S130)分级会议摘要生成模型以获得目标分级会议摘要生成模型。独立的权利要求书包括： (1)一种生成用于对话行为优化的分级会议概要的方法； (2)用于生成用于对话行为优化的分级会议概要的设备； 以及 (3)计算机可读存储介质包括一组用于训练面向对话行为优化的分级会议摘要生成模型的指令。  12
本发明公开了一种基于任务分层的人格预测方法、系统及装置，该方法包括：基于预设的BERT预训练语言模型对用户帖子进行并行编码，得到特征向量；将用户帖子经过图卷积网络融合，得到图卷积输出向量；预测用户的外部特征信息；分层完成预测任务，得到人格信息；将外部特征向量和人格信息回传至图卷积网络并重新预测，直至达到预设的回传次数，得到人格预测结果。该系统包括：并行编码模块、图卷积网络融合模块、外部数据迁移预训练模块、分层自注意力人格预测模块和消息回传模块。该装置包括存储器以及用于执行上述基于任务分层的人格预测方法的处理器。通过使用本发明，得到更为准确的人格预测结果。本发明可广泛应用于文本处理领域。该基于任务分层的人类网格预测方法可用于文本处理领域。该方法能够获得准确的性格预测结果。方法涉及基于预置双向编码器表示从变换器(BERT)获得用户帖预训练语言模型以获得特征向量。 通过图卷积网络对所述用户帖进行融合。 基于所述特征向量构建拓扑图。 得到图卷积输出向量。 根据所述拓扑图预测用户的外部特征信息。 将所述外特征向量和所述图卷积输出向量进行分层，完成一个个性化预测任务的四维度。 达到预设返回次数，得到个性化预测结果。 将外部特征向量和个性信息返回到图卷积网络。独立权利要求还包括：一种基于任务分层预测人类网格的系统； 以及一种基于任务分层的人类网格预测装置。  12
本发明公开了一种测试用例模型训练方法、装置和电子设备，其中方法，包括以下步骤：对已有的测试用例，抽象出用例属性进行用例模版标记，并标记用例属性；将标记过的测试用例实时存储到用例库中；通过实时或者定时任务从用例库中扫描训练样本自动触发，进行用例微调；用例微调操作同步路由本地模版库及AI大语言模型库的微调操作，或者通过用例标记为本地或AI进行指向性路由，本地模版库通过标记特征对特征用例进行变更，AI大语言模型调用微调API进行特征用例的微调训练。测试用例模型训练方法。通过标记特征由本地模板库更改特征用例，由AI大语言模型调用微调应用程序编程接口进行特征用例的微调训练，从而提高了测试用例编写的效率，同时也保证了测试用例的覆盖率。该方法涉及对用例属性进行抽象，对用例模板进行标记，对已有的测试用例进行用例属性标记。 将标记后的测试用例实时存储到用例库中。 自动触发通过实时或预定任务从用例库中扫描训练样本以微调用例，其中用例的微调操作同时路由本地模板库和人工智能(AI)大语言模型库的微调操作。 特征用例由局部模板库通过标记特征的方式进行更改。 微调应用程序编程接口由AI大语言模型调用，进行特征用例的微调训练。独立权利要求书包括用于：(1)测试用例模型训练装置； (2)一种电子设备，包括处理器和存储器，所述存储器用于存储训练测试用例模型的计算机可执行指令； (3)一种计算机可读存储介质，用于存储训练测试用例模型的程序。  11
本发明公开了一种对话生成模型的方法，所述方法包括：获取对话历史记录，通过所构建的对话生成模型中的编码器分别对所述对话历史记录、所述对话历史记录中的最后一句话以及与所述对话历史记录的相关文档进行编码处理，得到编码器的输出结果；通过在所述编码器中附加一个二分类的任务器将所述输出结果分别与错误回复和最佳回复连接起来，并加上CLS令牌进行分类，以训练所述编码器进行背景知识的学习；当所述编码器进行训练后的参数处于收敛时，通过所述对话生成模型中的GPT‑2解码器基于所述编码器进行训练，直到生成具有知识感知的回复。能够通过基于对话上下文的语义拓展生成恰当的回复，有效解决无意义对话。该方法对于通过对话生成模型是有用的。通过构建的对话生成模型添加的下两个分类服务器的编码器对特殊场景的低频模式进行学习，从而选择正确的下一句回复，以准确地捕捉背景知识，并通过GPT-2解码器基于编码进行训练，直至生成具有知识感知的回复，当编码的训练后的参数收敛时。 从而有效地解决了无意义的对话。该方法涉及获得对话历史记录。 构建的对话生成模型记录对话历史。 对所述对话历史记录中的最后一句话和所述对话历史记录的相关文档进行编码，得到编码器的输出结果。 在编码器中增加一个二分类任务器，将输出结果分别连接错误回复和最佳回复。 添加CLS令牌进行分类，以训练编码器学习背景知识。 基于编解码过程训练GPT-2解码器，直到生成具有知识感知的回复。本发明还公开了一种通过对话生成模型的装置。 8
